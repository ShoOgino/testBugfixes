{"path":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","commits":[{"id":"01b5702c02a50fec5cd548d8a459434379a5908f","date":1291922553,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  delCount.addAndGet(toDeleteIDs.size());\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      final IndexSearcher s = new IndexSearcher(r);\n\n      // run search threads\n      final long searchStopTime = System.currentTimeMillis() + 500;\n      final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n      final AtomicInteger totHits = new AtomicInteger();\n      for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n        searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n              int seenTermCount = 0;\n              int shift;\n              int trigger;\n              if (totTermCount.get() == 0) {\n                shift = 0;\n                trigger = 1;\n              } else {\n                shift = random.nextInt(totTermCount.get()/10);\n                trigger = totTermCount.get()/10;\n              }\n              while(System.currentTimeMillis() < searchStopTime) {\n                BytesRef term = termsEnum.next();\n                if (term == null) {\n                  totTermCount.set(seenTermCount);\n                  seenTermCount = 0;\n                  trigger = totTermCount.get()/10;\n                  //System.out.println(\"trigger \" + trigger);\n                  shift = random.nextInt(totTermCount.get()/10);\n                  termsEnum.seek(new BytesRef(\"\"));\n                  continue;\n                }\n                seenTermCount++;\n                // search 10 terms\n                if (trigger == 0) {\n                  trigger = 1;\n                }\n                if ((seenTermCount + shift) % trigger == 0) {\n                  //if (VERBOSE) {\n                  //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                  //}\n                  totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                }\n              }\n              if (VERBOSE) {\n                System.out.println(Thread.currentThread().getName() + \": search done\");\n              }\n            } catch (Throwable t) {\n              failed.set(true);\n              t.printStackTrace(System.out);\n              throw new RuntimeException(t);\n            }\n          }\n          };\n        searchThreads[thread].setDaemon(true);\n        searchThreads[thread].start();\n      }\n\n      for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n        searchThreads[thread].join();\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    writer.commit();\n    assertEquals(addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d980012955f78d79fc86f5d2cba2689909338e1d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"981b7c4b63e61b7f963f13fb58194910b16cfcbb","date":1291974750,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  delCount.addAndGet(toDeleteIDs.size());\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    writer.commit();\n    assertEquals(addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  delCount.addAndGet(toDeleteIDs.size());\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      final IndexSearcher s = new IndexSearcher(r);\n\n      // run search threads\n      final long searchStopTime = System.currentTimeMillis() + 500;\n      final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n      final AtomicInteger totHits = new AtomicInteger();\n      for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n        searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n              int seenTermCount = 0;\n              int shift;\n              int trigger;\n              if (totTermCount.get() == 0) {\n                shift = 0;\n                trigger = 1;\n              } else {\n                shift = random.nextInt(totTermCount.get()/10);\n                trigger = totTermCount.get()/10;\n              }\n              while(System.currentTimeMillis() < searchStopTime) {\n                BytesRef term = termsEnum.next();\n                if (term == null) {\n                  totTermCount.set(seenTermCount);\n                  seenTermCount = 0;\n                  trigger = totTermCount.get()/10;\n                  //System.out.println(\"trigger \" + trigger);\n                  shift = random.nextInt(totTermCount.get()/10);\n                  termsEnum.seek(new BytesRef(\"\"));\n                  continue;\n                }\n                seenTermCount++;\n                // search 10 terms\n                if (trigger == 0) {\n                  trigger = 1;\n                }\n                if ((seenTermCount + shift) % trigger == 0) {\n                  //if (VERBOSE) {\n                  //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                  //}\n                  totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                }\n              }\n              if (VERBOSE) {\n                System.out.println(Thread.currentThread().getName() + \": search done\");\n              }\n            } catch (Throwable t) {\n              failed.set(true);\n              t.printStackTrace(System.out);\n              throw new RuntimeException(t);\n            }\n          }\n          };\n        searchThreads[thread].setDaemon(true);\n        searchThreads[thread].start();\n      }\n\n      for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n        searchThreads[thread].join();\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    writer.commit();\n    assertEquals(addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d980012955f78d79fc86f5d2cba2689909338e1d","date":1292014519,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  delCount.addAndGet(toDeleteIDs.size());\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString(), addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  delCount.addAndGet(toDeleteIDs.size());\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    writer.commit();\n    assertEquals(addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":["01b5702c02a50fec5cd548d8a459434379a5908f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca6229a2b7c875cd3185654e0561e5e6d289a91a","date":1292523089,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  delCount.addAndGet(toDeleteIDs.size());\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString(), addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b241ea5e635d896cc0af83cd96ffd0322e0aba7","date":1294226200,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3b2c50e54fbd02d573055c75580702f3d68cda5","date":1294494344,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d53c3f769ca0f9e7434937b792877770271aecf","date":1294785129,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87d122575733b906e11f496c1d6b4d1327f5308d","date":1295812808,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb378f8bdee16a26810e086303a4a86b4930ea12","date":1296410797,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(true);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n      \n    writer.close(false);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        sum += new IndexSearcher(reader).search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final List<String> delIDs = Collections.synchronizedList(new ArrayList<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = new IndexSearcher(r2);\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        fail(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n      }\n    }\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01e5948db9a07144112d2f08f28ca2e3cd880348","date":1301759232,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c986853309f96720b4528634c9131648cb0f7376","date":1305987691,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    MergeScheduler ms = writer.getConfig().getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      // try to keep max file open count down\n      ((ConcurrentMergeScheduler) ms).setMaxThreadCount(1);\n      ((ConcurrentMergeScheduler) ms).setMaxMergeCount(1);\n    }\n    /*\n    LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      lmp.setMergeFactor(5);\n    }\n    */\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"id\"));\n                  }\n                  writer.updateDocument(new Term(\"id\", doc.get(\"id\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"id\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"id\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"id\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"id\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"id\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","date":1306150983,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27","date":1306166545,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.addDocument(doc);\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                }\n                if (random.nextInt(5) == 3) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                  }\n                  toDeleteIDs.add(doc.get(\"docid\"));\n                }\n                if (random.nextInt(50) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n                }\n                addCount.getAndIncrement();\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n    \n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    s.close();\n    dir.close();\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    s.close();\n    dir.close();\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90d21e509984b28f469f192a9115d053a9031812","date":1307529165,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    s.close();\n    dir.close();\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    s.close();\n    dir.close();\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fce0295284f259a0cf53aeac61ce81163f94725d","date":1307538480,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    s.close();\n    dir.close();\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0762b640e0d0d12b6edb96db68986e13145c3484","date":1307575932,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Exception exc) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                exc.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(exc);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    s.close();\n    dir.close();\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d5626fd077eba69371a29616badd26143fea2fa","date":1308219320,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a2903ea38ae3e636b93a08c52a5e37ae939cf6b","date":1308291005,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n                public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() == 0) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    shift = random.nextInt(totTermCount.get()/10);\n                    trigger = totTermCount.get()/10;\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount == 0) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(totTermCount.get()/10);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc","date":1308411958,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","date":1308439813,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"97e30c53fd81463c6ccd52402c91a6548cf42acb","date":1309296018,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seek(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new TextField(addedField, \"a random field\"));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, StringField.TYPE_STORED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"edcc2c2cbab6bf89ea584169ffb3ca83a31827f9","date":1316963893,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  public void testNRTThreads() throws Exception {\n    runTest(\"TestNRTThreads\");\n  }\n\n","sourceOld":"  @Test\n  public void testNRTThreads() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    final String defaultCodec = CodecProvider.getDefault().getDefaultFieldCodec();\n    if (defaultCodec.equals(\"SimpleText\") || defaultCodec.equals(\"Memory\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper dir = newFSDirectory(tempDir);\n    dir.setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n\n    final int NUM_INDEX_THREADS = 2;\n    final int NUM_SEARCH_THREADS = 3;\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              try {\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new TextField(addedField, \"a random field\"));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": add doc id:\" + doc.get(\"docid\"));\n                  }\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, StringField.TYPE_STORED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(_TestUtil.cloneDocument(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(_TestUtil.cloneDocument(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      writer.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      writer.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        writer.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                  } else {\n                    writer.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  writer.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    writer.deleteDocuments(new Term(\"docid\", id));\n                  }\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    //System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assert !subDocs.deleted;\n                    writer.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    IndexReader r = IndexReader.open(writer, true);\n    boolean any = false;\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    final ExecutorService es = Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    while(System.currentTimeMillis() < stopTime && !failed.get()) {\n      if (random.nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now reopen r=\" + r);\n        }\n        final IndexReader r2 = r.reopen();\n        if (r != r2) {\n          r.close();\n          r = r2;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now close reader=\" + r);\n        }\n        r.close();\n        writer.commit();\n        final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n        if (openDeletedFiles.size() > 0) {\n          System.out.println(\"OBD files: \" + openDeletedFiles);\n        }\n        any |= openDeletedFiles.size() > 0;\n        //assertEquals(\"open but deleted: \" + openDeletedFiles, 0, openDeletedFiles.size());\n        if (VERBOSE) {\n          System.out.println(\"TEST: now open\");\n        }\n        r = IndexReader.open(writer, true);\n      }\n      if (VERBOSE) {\n        System.out.println(\"TEST: got new reader=\" + r);\n      }\n      //System.out.println(\"numDocs=\" + r.numDocs() + \"\n      //openDelFileCount=\" + dir.openDeleteFileCount());\n\n      smokeTestReader(r);\n\n      if (r.numDocs() > 0) {\n\n        final IndexSearcher s = new IndexSearcher(r, es);\n\n        // run search threads\n        final long searchStopTime = System.currentTimeMillis() + 500;\n        final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n        final AtomicInteger totHits = new AtomicInteger();\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread] = new Thread() {\n              @Override\n              public void run() {\n                try {\n                  TermsEnum termsEnum = MultiFields.getTerms(s.getIndexReader(), \"body\").iterator();\n                  int seenTermCount = 0;\n                  int shift;\n                  int trigger;\n                  if (totTermCount.get() < 10) {\n                    shift = 0;\n                    trigger = 1;\n                  } else {\n                    trigger = totTermCount.get()/10;\n                    shift = random.nextInt(trigger);\n                  }\n                  while(System.currentTimeMillis() < searchStopTime) {\n                    BytesRef term = termsEnum.next();\n                    if (term == null) {\n                      if (seenTermCount < 10) {\n                        break;\n                      }\n                      totTermCount.set(seenTermCount);\n                      seenTermCount = 0;\n                      trigger = totTermCount.get()/10;\n                      //System.out.println(\"trigger \" + trigger);\n                      shift = random.nextInt(trigger);\n                      termsEnum.seekCeil(new BytesRef(\"\"));\n                      continue;\n                    }\n                    seenTermCount++;\n                    // search 10 terms\n                    if (trigger == 0) {\n                      trigger = 1;\n                    }\n                    if ((seenTermCount + shift) % trigger == 0) {\n                      //if (VERBOSE) {\n                      //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                      //}\n                      totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                    }\n                  }\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": search done\");\n                  }\n                } catch (Throwable t) {\n                  System.out.println(Thread.currentThread().getName() + \": hit exc\");\n                  failed.set(true);\n                  t.printStackTrace(System.out);\n                  throw new RuntimeException(t);\n                }\n              }\n            };\n          searchThreads[thread].setDaemon(true);\n          searchThreads[thread].start();\n        }\n\n        for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n          searchThreads[thread].join();\n        }\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: DONE search: totHits=\" + totHits);\n        }\n      } else {\n        Thread.sleep(100);\n      }\n    }\n\n    es.shutdown();\n    es.awaitTermination(1, TimeUnit.SECONDS);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: all searching done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    //System.out.println(\"numDocs=\" + r.numDocs() + \" openDelFileCount=\" + dir.openDeleteFileCount());\n    r.close();\n    final Set<String> openDeletedFiles = dir.getOpenDeletedFiles();\n    if (openDeletedFiles.size() > 0) {\n      System.out.println(\"OBD files: \" + openDeletedFiles);\n    }\n    any |= openDeletedFiles.size() > 0;\n\n    assertFalse(\"saw non-zero open-but-deleted count\", any);\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n    }\n\n    final IndexReader r2 = writer.getReader();\n    final IndexSearcher s = newSearcher(r2);\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n    \n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), r2.numDocs());\n    r2.close();\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNRTThreads#testNRTThreads().mjava","sourceNew":"  public void testNRTThreads() throws Exception {\n    runTest(\"TestNRTThreads\");\n  }\n\n","sourceOld":"  public void testNRTThreads() throws Exception {\n    runTest(\"TestNRTThreads\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["edcc2c2cbab6bf89ea584169ffb3ca83a31827f9"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["97e30c53fd81463c6ccd52402c91a6548cf42acb"],"ca6229a2b7c875cd3185654e0561e5e6d289a91a":["d980012955f78d79fc86f5d2cba2689909338e1d"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ca6229a2b7c875cd3185654e0561e5e6d289a91a"],"d980012955f78d79fc86f5d2cba2689909338e1d":["981b7c4b63e61b7f963f13fb58194910b16cfcbb"],"c19f985e36a65cc969e8e564fe337a0d41512075":["87d122575733b906e11f496c1d6b4d1327f5308d"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"0a2903ea38ae3e636b93a08c52a5e37ae939cf6b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","3d5626fd077eba69371a29616badd26143fea2fa"],"97e30c53fd81463c6ccd52402c91a6548cf42acb":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":["0a2903ea38ae3e636b93a08c52a5e37ae939cf6b","7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a3776dccca01c11e7046323cfad46a3b4a471233","2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27"],"79c2cb24929f2649a8875fb629086171f914d5ce":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","790e1fde4caa765b3faaad3fbcd25c6973450336"],"edcc2c2cbab6bf89ea584169ffb3ca83a31827f9":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"fce0295284f259a0cf53aeac61ce81163f94725d":["90d21e509984b28f469f192a9115d053a9031812"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","790e1fde4caa765b3faaad3fbcd25c6973450336"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["79c2cb24929f2649a8875fb629086171f914d5ce","0762b640e0d0d12b6edb96db68986e13145c3484"],"70ad682703b8585f5d0a637efec044d57ec05efb":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27"],"962d04139994fce5193143ef35615499a9a96d78":["45669a651c970812a680841b97a77cce06af559f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"2553b00f699380c64959ccb27991289aae87be2e":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","fd9cc9d77712aba3662f24632df7539ab75e3667"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["c19f985e36a65cc969e8e564fe337a0d41512075"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"981b7c4b63e61b7f963f13fb58194910b16cfcbb":["01b5702c02a50fec5cd548d8a459434379a5908f"],"2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27":["c986853309f96720b4528634c9131648cb0f7376"],"a3776dccca01c11e7046323cfad46a3b4a471233":["790e1fde4caa765b3faaad3fbcd25c6973450336","c986853309f96720b4528634c9131648cb0f7376"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["2e10cb22a8bdb44339e282925a29182bb2f3174d","0762b640e0d0d12b6edb96db68986e13145c3484"],"3d5626fd077eba69371a29616badd26143fea2fa":["0762b640e0d0d12b6edb96db68986e13145c3484"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["135621f3a0670a9394eb563224a3b76cc4dddc0f","c986853309f96720b4528634c9131648cb0f7376"],"0762b640e0d0d12b6edb96db68986e13145c3484":["fce0295284f259a0cf53aeac61ce81163f94725d"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["868da859b43505d9d2a023bfeae6dd0c795f5295","87d122575733b906e11f496c1d6b4d1327f5308d"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3d53c3f769ca0f9e7434937b792877770271aecf":["f3b2c50e54fbd02d573055c75580702f3d68cda5"],"7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc":["3d5626fd077eba69371a29616badd26143fea2fa"],"87d122575733b906e11f496c1d6b4d1327f5308d":["3d53c3f769ca0f9e7434937b792877770271aecf"],"01b5702c02a50fec5cd548d8a459434379a5908f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c986853309f96720b4528634c9131648cb0f7376":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ca6229a2b7c875cd3185654e0561e5e6d289a91a"],"90d21e509984b28f469f192a9115d053a9031812":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"f3b2c50e54fbd02d573055c75580702f3d68cda5":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["ca6229a2b7c875cd3185654e0561e5e6d289a91a"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3d53c3f769ca0f9e7434937b792877770271aecf"],"45669a651c970812a680841b97a77cce06af559f":["bde51b089eb7f86171eb3406e38a274743f9b7ac","01e5948db9a07144112d2f08f28ca2e3cd880348"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["1509f151d7692d84fae414b2b799ac06ba60fcb4","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"ca6229a2b7c875cd3185654e0561e5e6d289a91a":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"d980012955f78d79fc86f5d2cba2689909338e1d":["ca6229a2b7c875cd3185654e0561e5e6d289a91a"],"c19f985e36a65cc969e8e564fe337a0d41512075":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["f2c5f0cb44df114db4228c8f77861714b5cabaea","45669a651c970812a680841b97a77cce06af559f"],"0a2903ea38ae3e636b93a08c52a5e37ae939cf6b":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886"],"97e30c53fd81463c6ccd52402c91a6548cf42acb":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":["2553b00f699380c64959ccb27991289aae87be2e"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["79c2cb24929f2649a8875fb629086171f914d5ce"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"edcc2c2cbab6bf89ea584169ffb3ca83a31827f9":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["edcc2c2cbab6bf89ea584169ffb3ca83a31827f9"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["97e30c53fd81463c6ccd52402c91a6548cf42acb","2553b00f699380c64959ccb27991289aae87be2e"],"fce0295284f259a0cf53aeac61ce81163f94725d":["0762b640e0d0d12b6edb96db68986e13145c3484"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["45669a651c970812a680841b97a77cce06af559f"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["0a2903ea38ae3e636b93a08c52a5e37ae939cf6b"],"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","90d21e509984b28f469f192a9115d053a9031812"],"962d04139994fce5193143ef35615499a9a96d78":[],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"981b7c4b63e61b7f963f13fb58194910b16cfcbb":["d980012955f78d79fc86f5d2cba2689909338e1d"],"2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","2e10cb22a8bdb44339e282925a29182bb2f3174d","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3d5626fd077eba69371a29616badd26143fea2fa":["0a2903ea38ae3e636b93a08c52a5e37ae939cf6b","7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["2e10cb22a8bdb44339e282925a29182bb2f3174d"],"0762b640e0d0d12b6edb96db68986e13145c3484":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","3d5626fd077eba69371a29616badd26143fea2fa"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["962d04139994fce5193143ef35615499a9a96d78","c986853309f96720b4528634c9131648cb0f7376","135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","01b5702c02a50fec5cd548d8a459434379a5908f","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"3d53c3f769ca0f9e7434937b792877770271aecf":["87d122575733b906e11f496c1d6b4d1327f5308d","868da859b43505d9d2a023bfeae6dd0c795f5295"],"87d122575733b906e11f496c1d6b4d1327f5308d":["c19f985e36a65cc969e8e564fe337a0d41512075","bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","fd9cc9d77712aba3662f24632df7539ab75e3667","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"01b5702c02a50fec5cd548d8a459434379a5908f":["981b7c4b63e61b7f963f13fb58194910b16cfcbb"],"c986853309f96720b4528634c9131648cb0f7376":["2c6dc1a64ac36088ccb8d5e20b74c48c8d3bba27","a3776dccca01c11e7046323cfad46a3b4a471233","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["70ad682703b8585f5d0a637efec044d57ec05efb"],"90d21e509984b28f469f192a9115d053a9031812":["fce0295284f259a0cf53aeac61ce81163f94725d"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["01e5948db9a07144112d2f08f28ca2e3cd880348","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"f3b2c50e54fbd02d573055c75580702f3d68cda5":["3d53c3f769ca0f9e7434937b792877770271aecf"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["70ad682703b8585f5d0a637efec044d57ec05efb","f3b2c50e54fbd02d573055c75580702f3d68cda5"],"45669a651c970812a680841b97a77cce06af559f":["962d04139994fce5193143ef35615499a9a96d78"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["962d04139994fce5193143ef35615499a9a96d78","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}