{"path":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","commits":[{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0936055c0eed56be3e4ae5c9db5b0e355390736a","date":1410874015,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":null,"sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.name);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.name).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.name));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.name));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}