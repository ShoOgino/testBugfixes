{"path":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","pathOld":"modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"efdcc56ba7e11759bb3c6a26c651e693ff84ac73","date":1351025592,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2126b84bd093fa3d921582a109a0ee578c28126","date":1351522501,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"82557a475db3e0849171dc0be5b02e3ae0745ddb","date":1358195918,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4015cd39dff8d4dec562d909f9766debac53aa6","date":1358548736,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader(0);\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader(0);\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"13927d699a111b970c38bc3eec00837464c3ede6","date":1363322510,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * <p>\n   * Uses the default AttributeFactory.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, input, userDictionary, discardPunctuation, mode);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   * <p>\n   * Uses the default AttributeFactory.\n   * \n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, userDictionary, discardPunctuation, mode);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   * <p>\n   * Uses the default AttributeFactory.\n   * \n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, input, userDictionary, discardPunctuation, mode);\n  }\n\n","bugFix":null,"bugIntro":["46a90052bc922c1df92a7a0c1132571f367ea9e4"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"82557a475db3e0849171dc0be5b02e3ae0745ddb":["efdcc56ba7e11759bb3c6a26c651e693ff84ac73"],"efdcc56ba7e11759bb3c6a26c651e693ff84ac73":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"13927d699a111b970c38bc3eec00837464c3ede6":["82557a475db3e0849171dc0be5b02e3ae0745ddb"],"c4015cd39dff8d4dec562d909f9766debac53aa6":["efdcc56ba7e11759bb3c6a26c651e693ff84ac73","82557a475db3e0849171dc0be5b02e3ae0745ddb"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["13927d699a111b970c38bc3eec00837464c3ede6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f2126b84bd093fa3d921582a109a0ee578c28126":["b89678825b68eccaf09e6ab71675fc0b0af1e099","efdcc56ba7e11759bb3c6a26c651e693ff84ac73"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"]},"commit2Childs":{"82557a475db3e0849171dc0be5b02e3ae0745ddb":["13927d699a111b970c38bc3eec00837464c3ede6","c4015cd39dff8d4dec562d909f9766debac53aa6"],"efdcc56ba7e11759bb3c6a26c651e693ff84ac73":["82557a475db3e0849171dc0be5b02e3ae0745ddb","c4015cd39dff8d4dec562d909f9766debac53aa6","f2126b84bd093fa3d921582a109a0ee578c28126"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["efdcc56ba7e11759bb3c6a26c651e693ff84ac73","f2126b84bd093fa3d921582a109a0ee578c28126"],"13927d699a111b970c38bc3eec00837464c3ede6":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"c4015cd39dff8d4dec562d909f9766debac53aa6":[],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"f2126b84bd093fa3d921582a109a0ee578c28126":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c4015cd39dff8d4dec562d909f9766debac53aa6","f2126b84bd093fa3d921582a109a0ee578c28126","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}