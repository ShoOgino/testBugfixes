{"path":"lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextTermVectorsReader#get(int).mjava","commits":[{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextTermVectorsReader#get(int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    // TestTV tests for this in testBadParams... but is this\n    // really guaranteed by the API?\n    if (doc < 0 || doc >= offsets.size()) {\n      throw new IllegalArgumentException(\"doc id out of range\");\n    }\n\n    SortedMap<String,SimpleTVTerms> fields = new TreeMap<String,SimpleTVTerms>();\n    in.seek(offsets.get(doc));\n    readLine();\n    assert scratch.startsWith(NUMFIELDS);\n    int numFields = parseIntAt(NUMFIELDS.length);\n    if (numFields == 0) {\n      return null; // no vectors for this doc\n    }\n    for (int i = 0; i < numFields; i++) {\n      readLine();\n      assert scratch.startsWith(FIELD);\n      int fieldNumber = parseIntAt(FIELD.length);\n      \n      readLine();\n      assert scratch.startsWith(FIELDNAME);\n      String fieldName = readString(FIELDNAME.length, scratch);\n      \n      readLine();\n      assert scratch.startsWith(FIELDPOSITIONS);\n      boolean positions = Boolean.parseBoolean(readString(FIELDPOSITIONS.length, scratch));\n      \n      readLine();\n      assert scratch.startsWith(FIELDOFFSETS);\n      boolean offsets = Boolean.parseBoolean(readString(FIELDOFFSETS.length, scratch));\n      \n      readLine();\n      assert scratch.startsWith(FIELDTERMCOUNT);\n      int termCount = parseIntAt(FIELDTERMCOUNT.length);\n      \n      SimpleTVTerms terms = new SimpleTVTerms();\n      fields.put(fieldName, terms);\n      \n      for (int j = 0; j < termCount; j++) {\n        readLine();\n        assert scratch.startsWith(TERMTEXT);\n        BytesRef term = new BytesRef();\n        int termLength = scratch.length - TERMTEXT.length;\n        term.grow(termLength);\n        term.length = termLength;\n        System.arraycopy(scratch.bytes, scratch.offset+TERMTEXT.length, term.bytes, term.offset, termLength);\n        \n        SimpleTVPostings postings = new SimpleTVPostings();\n        terms.terms.put(term, postings);\n        \n        readLine();\n        assert scratch.startsWith(TERMFREQ);\n        postings.freq = parseIntAt(TERMFREQ.length);\n        \n        if (positions || offsets) {\n          if (positions) {\n            postings.positions = new int[postings.freq];\n          }\n        \n          if (offsets) {\n            postings.startOffsets = new int[postings.freq];\n            postings.endOffsets = new int[postings.freq];\n          }\n          \n          for (int k = 0; k < postings.freq; k++) {\n            if (positions) {\n              readLine();\n              assert scratch.startsWith(POSITION);\n              postings.positions[k] = parseIntAt(POSITION.length);\n            }\n            \n            if (offsets) {\n              readLine();\n              assert scratch.startsWith(STARTOFFSET);\n              postings.startOffsets[k] = parseIntAt(STARTOFFSET.length);\n              \n              readLine();\n              assert scratch.startsWith(ENDOFFSET);\n              postings.endOffsets[k] = parseIntAt(ENDOFFSET.length);\n            }\n          }\n        }\n      }\n    }\n    return new SimpleTVFields(fields);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc","4d0ee734a67ae20fd4c683458847aebde606bb02","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"61f30939a6ca0891c7b0c0f34aa43800bd4c9a15","date":1322511317,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextTermVectorsReader#get(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextTermVectorsReader#get(int).mjava","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    // TestTV tests for this in testBadParams... but is this\n    // really guaranteed by the API?\n    if (doc < 0 || doc >= offsets.size()) {\n      throw new IllegalArgumentException(\"doc id out of range\");\n    }\n\n    SortedMap<String,SimpleTVTerms> fields = new TreeMap<String,SimpleTVTerms>();\n    in.seek(offsets.get(doc));\n    readLine();\n    assert StringHelper.startsWith(scratch, NUMFIELDS);\n    int numFields = parseIntAt(NUMFIELDS.length);\n    if (numFields == 0) {\n      return null; // no vectors for this doc\n    }\n    for (int i = 0; i < numFields; i++) {\n      readLine();\n      assert StringHelper.startsWith(scratch, FIELD);\n      int fieldNumber = parseIntAt(FIELD.length);\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDNAME);\n      String fieldName = readString(FIELDNAME.length, scratch);\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDPOSITIONS);\n      boolean positions = Boolean.parseBoolean(readString(FIELDPOSITIONS.length, scratch));\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDOFFSETS);\n      boolean offsets = Boolean.parseBoolean(readString(FIELDOFFSETS.length, scratch));\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDTERMCOUNT);\n      int termCount = parseIntAt(FIELDTERMCOUNT.length);\n      \n      SimpleTVTerms terms = new SimpleTVTerms();\n      fields.put(fieldName, terms);\n      \n      for (int j = 0; j < termCount; j++) {\n        readLine();\n        assert StringHelper.startsWith(scratch, TERMTEXT);\n        BytesRef term = new BytesRef();\n        int termLength = scratch.length - TERMTEXT.length;\n        term.grow(termLength);\n        term.length = termLength;\n        System.arraycopy(scratch.bytes, scratch.offset+TERMTEXT.length, term.bytes, term.offset, termLength);\n        \n        SimpleTVPostings postings = new SimpleTVPostings();\n        terms.terms.put(term, postings);\n        \n        readLine();\n        assert StringHelper.startsWith(scratch, TERMFREQ);\n        postings.freq = parseIntAt(TERMFREQ.length);\n        \n        if (positions || offsets) {\n          if (positions) {\n            postings.positions = new int[postings.freq];\n          }\n        \n          if (offsets) {\n            postings.startOffsets = new int[postings.freq];\n            postings.endOffsets = new int[postings.freq];\n          }\n          \n          for (int k = 0; k < postings.freq; k++) {\n            if (positions) {\n              readLine();\n              assert StringHelper.startsWith(scratch, POSITION);\n              postings.positions[k] = parseIntAt(POSITION.length);\n            }\n            \n            if (offsets) {\n              readLine();\n              assert StringHelper.startsWith(scratch, STARTOFFSET);\n              postings.startOffsets[k] = parseIntAt(STARTOFFSET.length);\n              \n              readLine();\n              assert StringHelper.startsWith(scratch, ENDOFFSET);\n              postings.endOffsets[k] = parseIntAt(ENDOFFSET.length);\n            }\n          }\n        }\n      }\n    }\n    return new SimpleTVFields(fields);\n  }\n\n","sourceOld":"  @Override\n  public Fields get(int doc) throws IOException {\n    // TestTV tests for this in testBadParams... but is this\n    // really guaranteed by the API?\n    if (doc < 0 || doc >= offsets.size()) {\n      throw new IllegalArgumentException(\"doc id out of range\");\n    }\n\n    SortedMap<String,SimpleTVTerms> fields = new TreeMap<String,SimpleTVTerms>();\n    in.seek(offsets.get(doc));\n    readLine();\n    assert scratch.startsWith(NUMFIELDS);\n    int numFields = parseIntAt(NUMFIELDS.length);\n    if (numFields == 0) {\n      return null; // no vectors for this doc\n    }\n    for (int i = 0; i < numFields; i++) {\n      readLine();\n      assert scratch.startsWith(FIELD);\n      int fieldNumber = parseIntAt(FIELD.length);\n      \n      readLine();\n      assert scratch.startsWith(FIELDNAME);\n      String fieldName = readString(FIELDNAME.length, scratch);\n      \n      readLine();\n      assert scratch.startsWith(FIELDPOSITIONS);\n      boolean positions = Boolean.parseBoolean(readString(FIELDPOSITIONS.length, scratch));\n      \n      readLine();\n      assert scratch.startsWith(FIELDOFFSETS);\n      boolean offsets = Boolean.parseBoolean(readString(FIELDOFFSETS.length, scratch));\n      \n      readLine();\n      assert scratch.startsWith(FIELDTERMCOUNT);\n      int termCount = parseIntAt(FIELDTERMCOUNT.length);\n      \n      SimpleTVTerms terms = new SimpleTVTerms();\n      fields.put(fieldName, terms);\n      \n      for (int j = 0; j < termCount; j++) {\n        readLine();\n        assert scratch.startsWith(TERMTEXT);\n        BytesRef term = new BytesRef();\n        int termLength = scratch.length - TERMTEXT.length;\n        term.grow(termLength);\n        term.length = termLength;\n        System.arraycopy(scratch.bytes, scratch.offset+TERMTEXT.length, term.bytes, term.offset, termLength);\n        \n        SimpleTVPostings postings = new SimpleTVPostings();\n        terms.terms.put(term, postings);\n        \n        readLine();\n        assert scratch.startsWith(TERMFREQ);\n        postings.freq = parseIntAt(TERMFREQ.length);\n        \n        if (positions || offsets) {\n          if (positions) {\n            postings.positions = new int[postings.freq];\n          }\n        \n          if (offsets) {\n            postings.startOffsets = new int[postings.freq];\n            postings.endOffsets = new int[postings.freq];\n          }\n          \n          for (int k = 0; k < postings.freq; k++) {\n            if (positions) {\n              readLine();\n              assert scratch.startsWith(POSITION);\n              postings.positions[k] = parseIntAt(POSITION.length);\n            }\n            \n            if (offsets) {\n              readLine();\n              assert scratch.startsWith(STARTOFFSET);\n              postings.startOffsets[k] = parseIntAt(STARTOFFSET.length);\n              \n              readLine();\n              assert scratch.startsWith(ENDOFFSET);\n              postings.endOffsets[k] = parseIntAt(ENDOFFSET.length);\n            }\n          }\n        }\n      }\n    }\n    return new SimpleTVFields(fields);\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader#get(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextTermVectorsReader#get(int).mjava","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    // TestTV tests for this in testBadParams... but is this\n    // really guaranteed by the API?\n    if (doc < 0 || doc >= offsets.size()) {\n      throw new IllegalArgumentException(\"doc id out of range\");\n    }\n\n    SortedMap<String,SimpleTVTerms> fields = new TreeMap<String,SimpleTVTerms>();\n    in.seek(offsets.get(doc));\n    readLine();\n    assert StringHelper.startsWith(scratch, NUMFIELDS);\n    int numFields = parseIntAt(NUMFIELDS.length);\n    if (numFields == 0) {\n      return null; // no vectors for this doc\n    }\n    for (int i = 0; i < numFields; i++) {\n      readLine();\n      assert StringHelper.startsWith(scratch, FIELD);\n      int fieldNumber = parseIntAt(FIELD.length);\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDNAME);\n      String fieldName = readString(FIELDNAME.length, scratch);\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDPOSITIONS);\n      boolean positions = Boolean.parseBoolean(readString(FIELDPOSITIONS.length, scratch));\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDOFFSETS);\n      boolean offsets = Boolean.parseBoolean(readString(FIELDOFFSETS.length, scratch));\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDTERMCOUNT);\n      int termCount = parseIntAt(FIELDTERMCOUNT.length);\n      \n      SimpleTVTerms terms = new SimpleTVTerms();\n      fields.put(fieldName, terms);\n      \n      for (int j = 0; j < termCount; j++) {\n        readLine();\n        assert StringHelper.startsWith(scratch, TERMTEXT);\n        BytesRef term = new BytesRef();\n        int termLength = scratch.length - TERMTEXT.length;\n        term.grow(termLength);\n        term.length = termLength;\n        System.arraycopy(scratch.bytes, scratch.offset+TERMTEXT.length, term.bytes, term.offset, termLength);\n        \n        SimpleTVPostings postings = new SimpleTVPostings();\n        terms.terms.put(term, postings);\n        \n        readLine();\n        assert StringHelper.startsWith(scratch, TERMFREQ);\n        postings.freq = parseIntAt(TERMFREQ.length);\n        \n        if (positions || offsets) {\n          if (positions) {\n            postings.positions = new int[postings.freq];\n          }\n        \n          if (offsets) {\n            postings.startOffsets = new int[postings.freq];\n            postings.endOffsets = new int[postings.freq];\n          }\n          \n          for (int k = 0; k < postings.freq; k++) {\n            if (positions) {\n              readLine();\n              assert StringHelper.startsWith(scratch, POSITION);\n              postings.positions[k] = parseIntAt(POSITION.length);\n            }\n            \n            if (offsets) {\n              readLine();\n              assert StringHelper.startsWith(scratch, STARTOFFSET);\n              postings.startOffsets[k] = parseIntAt(STARTOFFSET.length);\n              \n              readLine();\n              assert StringHelper.startsWith(scratch, ENDOFFSET);\n              postings.endOffsets[k] = parseIntAt(ENDOFFSET.length);\n            }\n          }\n        }\n      }\n    }\n    return new SimpleTVFields(fields);\n  }\n\n","sourceOld":"  @Override\n  public Fields get(int doc) throws IOException {\n    // TestTV tests for this in testBadParams... but is this\n    // really guaranteed by the API?\n    if (doc < 0 || doc >= offsets.size()) {\n      throw new IllegalArgumentException(\"doc id out of range\");\n    }\n\n    SortedMap<String,SimpleTVTerms> fields = new TreeMap<String,SimpleTVTerms>();\n    in.seek(offsets.get(doc));\n    readLine();\n    assert StringHelper.startsWith(scratch, NUMFIELDS);\n    int numFields = parseIntAt(NUMFIELDS.length);\n    if (numFields == 0) {\n      return null; // no vectors for this doc\n    }\n    for (int i = 0; i < numFields; i++) {\n      readLine();\n      assert StringHelper.startsWith(scratch, FIELD);\n      int fieldNumber = parseIntAt(FIELD.length);\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDNAME);\n      String fieldName = readString(FIELDNAME.length, scratch);\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDPOSITIONS);\n      boolean positions = Boolean.parseBoolean(readString(FIELDPOSITIONS.length, scratch));\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDOFFSETS);\n      boolean offsets = Boolean.parseBoolean(readString(FIELDOFFSETS.length, scratch));\n      \n      readLine();\n      assert StringHelper.startsWith(scratch, FIELDTERMCOUNT);\n      int termCount = parseIntAt(FIELDTERMCOUNT.length);\n      \n      SimpleTVTerms terms = new SimpleTVTerms();\n      fields.put(fieldName, terms);\n      \n      for (int j = 0; j < termCount; j++) {\n        readLine();\n        assert StringHelper.startsWith(scratch, TERMTEXT);\n        BytesRef term = new BytesRef();\n        int termLength = scratch.length - TERMTEXT.length;\n        term.grow(termLength);\n        term.length = termLength;\n        System.arraycopy(scratch.bytes, scratch.offset+TERMTEXT.length, term.bytes, term.offset, termLength);\n        \n        SimpleTVPostings postings = new SimpleTVPostings();\n        terms.terms.put(term, postings);\n        \n        readLine();\n        assert StringHelper.startsWith(scratch, TERMFREQ);\n        postings.freq = parseIntAt(TERMFREQ.length);\n        \n        if (positions || offsets) {\n          if (positions) {\n            postings.positions = new int[postings.freq];\n          }\n        \n          if (offsets) {\n            postings.startOffsets = new int[postings.freq];\n            postings.endOffsets = new int[postings.freq];\n          }\n          \n          for (int k = 0; k < postings.freq; k++) {\n            if (positions) {\n              readLine();\n              assert StringHelper.startsWith(scratch, POSITION);\n              postings.positions[k] = parseIntAt(POSITION.length);\n            }\n            \n            if (offsets) {\n              readLine();\n              assert StringHelper.startsWith(scratch, STARTOFFSET);\n              postings.startOffsets[k] = parseIntAt(STARTOFFSET.length);\n              \n              readLine();\n              assert StringHelper.startsWith(scratch, ENDOFFSET);\n              postings.endOffsets[k] = parseIntAt(ENDOFFSET.length);\n            }\n          }\n        }\n      }\n    }\n    return new SimpleTVFields(fields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"61f30939a6ca0891c7b0c0f34aa43800bd4c9a15":["3cc749c053615f5871f3b95715fe292f34e70a53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["61f30939a6ca0891c7b0c0f34aa43800bd4c9a15"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"61f30939a6ca0891c7b0c0f34aa43800bd4c9a15":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3cc749c053615f5871f3b95715fe292f34e70a53"],"3cc749c053615f5871f3b95715fe292f34e70a53":["61f30939a6ca0891c7b0c0f34aa43800bd4c9a15"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}