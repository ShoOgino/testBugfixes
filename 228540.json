{"path":"lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser#consumeToken(State).mjava","commits":[{"id":"fdc91c6aee685b616507b9e44fcc69315b8a9e6c","date":1384275771,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser#consumeToken(State).mjava","pathOld":"/dev/null","sourceNew":"  private void consumeToken(State state) {\n    int copied = 0;\n    boolean escaped = false;\n    boolean prefix = false;\n\n    while (state.index < state.length) {\n      if (!escaped) {\n        if (state.data[state.index] == '\\\\' && (flags & ESCAPE_OPERATOR) != 0) {\n          // an escape character has been found so\n          // whatever character is next will become\n          // part of the term unless the escape\n          // character is the last one in the data\n          escaped = true;\n          prefix = false;\n          ++state.index;\n\n          continue;\n        } else if ((state.data[state.index] == '\"' && (flags & PHRASE_OPERATOR) != 0)\n            || (state.data[state.index] == '|' && (flags & OR_OPERATOR) != 0)\n            || (state.data[state.index] == '+' && (flags & AND_OPERATOR) != 0)\n            || (state.data[state.index] == '(' && (flags & PRECEDENCE_OPERATORS) != 0)\n            || (state.data[state.index] == ')' && (flags & PRECEDENCE_OPERATORS) != 0)\n            || ((state.data[state.index] == ' '\n            || state.data[state.index] == '\\t'\n            || state.data[state.index] == '\\n'\n            || state.data[state.index] == '\\r') && (flags & WHITESPACE_OPERATOR) != 0)) {\n          // this should be the end of the term\n          // all characters found will used for\n          // creating the term query\n          break;\n        }\n\n        // wildcard tracks whether or not the last character\n        // was a '*' operator that hasn't been escaped\n        // there must be at least one valid character before\n        // searching for a prefixed set of terms\n        prefix = copied > 0 && state.data[state.index] == '*' && (flags & PREFIX_OPERATOR) != 0;\n      }\n\n      escaped = false;\n      state.buffer[copied++] = state.data[state.index++];\n    }\n\n    if (copied > 0) {\n      final Query branch;\n\n      if (prefix) {\n        // if a term is found with a closing '*' it is considered to be a prefix query\n        // and will have prefix added as an option\n        String token = new String(state.buffer, 0, copied - 1);\n        branch = newPrefixQuery(token);\n      } else {\n        // a standard term has been found so it will be run through\n        // the entire analysis chain from the specified schema field\n        String token = new String(state.buffer, 0, copied);\n        branch = newDefaultQuery(token);\n      }\n\n      buildQueryTree(state, branch);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bae2070aa7aaff000145c4978276eb085e2ff279","date":1391309822,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser#consumeToken(State).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser#consumeToken(State).mjava","sourceNew":"  private void consumeToken(State state) {\n    int copied = 0;\n    boolean escaped = false;\n    boolean prefix = false;\n    boolean fuzzy = false;\n\n    while (state.index < state.length) {\n      if (!escaped) {\n        if (state.data[state.index] == '\\\\' && (flags & ESCAPE_OPERATOR) != 0) {\n          // an escape character has been found so\n          // whatever character is next will become\n          // part of the term unless the escape\n          // character is the last one in the data\n          escaped = true;\n          prefix = false;\n          ++state.index;\n\n          continue;\n        } else if (tokenFinished(state)) {\n          // this should be the end of the term\n          // all characters found will used for\n          // creating the term query\n          break;\n        } else if (copied > 0 && state.data[state.index] == '~' && (flags & FUZZY_OPERATOR) != 0) {\n          fuzzy = true;\n          break;\n        }\n\n        // wildcard tracks whether or not the last character\n        // was a '*' operator that hasn't been escaped\n        // there must be at least one valid character before\n        // searching for a prefixed set of terms\n        prefix = copied > 0 && state.data[state.index] == '*' && (flags & PREFIX_OPERATOR) != 0;\n      }\n\n      escaped = false;\n      state.buffer[copied++] = state.data[state.index++];\n    }\n\n    if (copied > 0) {\n      final Query branch;\n\n      if (fuzzy && (flags & FUZZY_OPERATOR) != 0) {\n        String token = new String(state.buffer, 0, copied);\n        int fuzziness = parseFuzziness(state);\n        // edit distance has a maximum, limit to the maximum supported\n        fuzziness = Math.min(fuzziness, LevenshteinAutomata.MAXIMUM_SUPPORTED_DISTANCE);\n        if (fuzziness == 0) {\n          branch = newDefaultQuery(token);\n        } else {\n          branch = newFuzzyQuery(token, fuzziness);\n        }\n      } else if (prefix) {\n        // if a term is found with a closing '*' it is considered to be a prefix query\n        // and will have prefix added as an option\n        String token = new String(state.buffer, 0, copied - 1);\n        branch = newPrefixQuery(token);\n      } else {\n        // a standard term has been found so it will be run through\n        // the entire analysis chain from the specified schema field\n        String token = new String(state.buffer, 0, copied);\n        branch = newDefaultQuery(token);\n      }\n\n      buildQueryTree(state, branch);\n    }\n  }\n\n","sourceOld":"  private void consumeToken(State state) {\n    int copied = 0;\n    boolean escaped = false;\n    boolean prefix = false;\n\n    while (state.index < state.length) {\n      if (!escaped) {\n        if (state.data[state.index] == '\\\\' && (flags & ESCAPE_OPERATOR) != 0) {\n          // an escape character has been found so\n          // whatever character is next will become\n          // part of the term unless the escape\n          // character is the last one in the data\n          escaped = true;\n          prefix = false;\n          ++state.index;\n\n          continue;\n        } else if ((state.data[state.index] == '\"' && (flags & PHRASE_OPERATOR) != 0)\n            || (state.data[state.index] == '|' && (flags & OR_OPERATOR) != 0)\n            || (state.data[state.index] == '+' && (flags & AND_OPERATOR) != 0)\n            || (state.data[state.index] == '(' && (flags & PRECEDENCE_OPERATORS) != 0)\n            || (state.data[state.index] == ')' && (flags & PRECEDENCE_OPERATORS) != 0)\n            || ((state.data[state.index] == ' '\n            || state.data[state.index] == '\\t'\n            || state.data[state.index] == '\\n'\n            || state.data[state.index] == '\\r') && (flags & WHITESPACE_OPERATOR) != 0)) {\n          // this should be the end of the term\n          // all characters found will used for\n          // creating the term query\n          break;\n        }\n\n        // wildcard tracks whether or not the last character\n        // was a '*' operator that hasn't been escaped\n        // there must be at least one valid character before\n        // searching for a prefixed set of terms\n        prefix = copied > 0 && state.data[state.index] == '*' && (flags & PREFIX_OPERATOR) != 0;\n      }\n\n      escaped = false;\n      state.buffer[copied++] = state.data[state.index++];\n    }\n\n    if (copied > 0) {\n      final Query branch;\n\n      if (prefix) {\n        // if a term is found with a closing '*' it is considered to be a prefix query\n        // and will have prefix added as an option\n        String token = new String(state.buffer, 0, copied - 1);\n        branch = newPrefixQuery(token);\n      } else {\n        // a standard term has been found so it will be run through\n        // the entire analysis chain from the specified schema field\n        String token = new String(state.buffer, 0, copied);\n        branch = newDefaultQuery(token);\n      }\n\n      buildQueryTree(state, branch);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bae2070aa7aaff000145c4978276eb085e2ff279":["fdc91c6aee685b616507b9e44fcc69315b8a9e6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fdc91c6aee685b616507b9e44fcc69315b8a9e6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bae2070aa7aaff000145c4978276eb085e2ff279"]},"commit2Childs":{"bae2070aa7aaff000145c4978276eb085e2ff279":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fdc91c6aee685b616507b9e44fcc69315b8a9e6c"],"fdc91c6aee685b616507b9e44fcc69315b8a9e6c":["bae2070aa7aaff000145c4978276eb085e2ff279"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}