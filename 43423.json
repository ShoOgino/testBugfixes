{"path":"solr/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","commits":[{"id":"45e349695223fccf7b1b9d08ba85a1c919b06f7c","date":1277292317,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","pathOld":"/dev/null","sourceNew":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","pathOld":"/dev/null","sourceNew":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","pathOld":"solr/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","sourceNew":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","sourceOld":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","pathOld":"solr/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","sourceNew":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","sourceOld":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","pathOld":"solr/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory#testCapitalization().mjava","sourceNew":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","sourceOld":"  public void testCapitalization() throws Exception \n  {\n    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);\n    args.put( CapitalizationFilterFactory.KEEP, \"and the it BIG\" );\n    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, \"true\" );  \n    \n    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"kiTTEN\"))),\n        new String[] { \"Kitten\" });\n    \n    factory.forceFirstLetter = true;\n\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"and\"))),\n        new String[] { \"And\" });\n\n    //first is forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = false;\n\n    //first is not forced, but it's not a keep word, either\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"AnD\"))),\n        new String[] { \"And\" });\n\n    factory.forceFirstLetter = true;\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"big\"))),\n        new String[] { \"Big\" });\n    \n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"BIG\"))),\n        new String[] { \"BIG\" });\n\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello there my name is ryan\" });\n        \n    // now each token\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"My\", \"Name\", \"Is\", \"Ryan\" });\n    \n    // now only the long words\n    factory.minWordLength = 3;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"Hello thEre my Name is Ryan\"))),\n        new String[] { \"Hello\", \"There\", \"my\", \"Name\", \"is\", \"Ryan\" });\n    \n    // without prefix\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"Mckinley\" });\n    \n    // Now try some prefixes\n    factory = new CapitalizationFilterFactory();\n    args.put( \"okPrefix\", \"McK\" );  // all words\n    factory.init( args );\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"McKinley\"))),\n        new String[] { \"McKinley\" });\n    \n    // now try some stuff with numbers\n    factory.forceFirstLetter = false;\n    factory.onlyFirstWord = false;\n    assertTokenStreamContents(factory.create(\n        new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(\"1st 2nd third\"))),\n        new String[] { \"1st\", \"2nd\", \"Third\" });\n    \n    factory.forceFirstLetter = true;\n    assertTokenStreamContents(factory.create(\n        new KeywordTokenizer(new StringReader(\"the The the\"))),\n        new String[] { \"The The the\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"45e349695223fccf7b1b9d08ba85a1c919b06f7c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["45e349695223fccf7b1b9d08ba85a1c919b06f7c"],"c26f00b574427b55127e869b935845554afde1fa":["45e349695223fccf7b1b9d08ba85a1c919b06f7c","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["45e349695223fccf7b1b9d08ba85a1c919b06f7c"],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","45e349695223fccf7b1b9d08ba85a1c919b06f7c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"45e349695223fccf7b1b9d08ba85a1c919b06f7c":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee","5f4e87790277826a2aea119328600dfb07761f32"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["45e349695223fccf7b1b9d08ba85a1c919b06f7c","5f4e87790277826a2aea119328600dfb07761f32"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"5f4e87790277826a2aea119328600dfb07761f32":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","5f4e87790277826a2aea119328600dfb07761f32","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}