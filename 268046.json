{"path":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","commits":[{"id":"56fb5e4e4b239474721e13b4cd9542ea2d215451","date":1529091182,"type":1,"author":"Erick","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,Long]).mjava","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, reclaimDeletesWeight);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, Long> sizeInBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = sizeInBytes.get(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(sizeInBytes.get(candidate.get(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, reclaimDeletesWeight);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9707a68fe260631e514201dbf24e9afc9a3a4ba1","date":1531207054,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      final int mergeFactor = (int) Math.min(maxMergeAtOnce, segsPerTier);\n      skew = 1.0/mergeFactor;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, reclaimDeletesWeight);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, reclaimDeletesWeight);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":0,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","pathOld":"/dev/null","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      final int mergeFactor = (int) Math.min(maxMergeAtOnce, segsPerTier);\n      skew = 1.0/mergeFactor;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, reclaimDeletesWeight);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a90cc8c90aa53ddf51fbd15019989ac269514a3","date":1531845066,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      final int mergeFactor = (int) Math.min(maxMergeAtOnce, segsPerTier);\n      skew = 1.0/mergeFactor;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, 2);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      final int mergeFactor = (int) Math.min(maxMergeAtOnce, segsPerTier);\n      skew = 1.0/mergeFactor;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, reclaimDeletesWeight);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":0,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentCommitInfo],boolean,Map[SegmentCommitInfo,SegmentSizeAndDocs]).mjava","pathOld":"/dev/null","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentCommitInfo> candidate, boolean hitTooLarge, Map<SegmentCommitInfo, SegmentSizeAndDocs> segmentsSizes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentCommitInfo info : candidate) {\n      final long segBytes = segmentsSizes.get(info).sizeInBytes;\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes();\n    }\n\n    // Roughly measure \"skew\" of the merge, i.e. how\n    // \"balanced\" the merge is (whether the segments are\n    // about the same size), which can range from\n    // 1.0/numSegsBeingMerged (good) to 1.0 (poor). Heavily\n    // lopsided merges (skew near 1.0) is no good; it means\n    // O(N^2) merge cost over time:\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      final int mergeFactor = (int) Math.min(maxMergeAtOnce, segsPerTier);\n      skew = 1.0/mergeFactor;\n    } else {\n      skew = ((double) floorSize(segmentsSizes.get(candidate.get(0)).sizeInBytes)) / totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= Math.pow(nonDelRatio, 2);\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(Locale.ROOT, \"%.3f\", skew) + \" nonDelRatio=\" + String.format(Locale.ROOT, \"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9707a68fe260631e514201dbf24e9afc9a3a4ba1":["56fb5e4e4b239474721e13b4cd9542ea2d215451"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4a90cc8c90aa53ddf51fbd15019989ac269514a3"],"56fb5e4e4b239474721e13b4cd9542ea2d215451":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4a90cc8c90aa53ddf51fbd15019989ac269514a3":["9707a68fe260631e514201dbf24e9afc9a3a4ba1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4a90cc8c90aa53ddf51fbd15019989ac269514a3"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9707a68fe260631e514201dbf24e9afc9a3a4ba1"]},"commit2Childs":{"9707a68fe260631e514201dbf24e9afc9a3a4ba1":["4a90cc8c90aa53ddf51fbd15019989ac269514a3","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"56fb5e4e4b239474721e13b4cd9542ea2d215451":["9707a68fe260631e514201dbf24e9afc9a3a4ba1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","56fb5e4e4b239474721e13b4cd9542ea2d215451","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"4a90cc8c90aa53ddf51fbd15019989ac269514a3":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}