{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        null,\n        new int[] { 1, 1, 1, 1 },\n        null,\n        null,\n        false);\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        null,\n        new int[] { 1, 1, 1, 1 },\n        null,\n        null,\n        false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eafa8c5eabc3dacd34680054e6a33bda024080ac","date":1367691488,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(Version.LUCENE_43, ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        null,\n        new int[] { 1, 1, 1, 1 },\n        null,\n        null,\n        false);\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        null,\n        new int[] { 1, 1, 1, 1 },\n        null,\n        null,\n        false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"192e49c0445803405b0bc0eebc8b758485480c21","date":1367699151,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(Version.LUCENE_43, ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        null,\n        new int[] { 1, 1, 1, 1 },\n        null,\n        null,\n        false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75","date":1399205975,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(TEST_VERSION_CURRENT, ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bd063790d36bd9fb41ccad27a1be3e198ff5a7e","date":1472141273,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new CannedTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","date":1472163016,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new CannedTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new CannedTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(new String(a, 0, a.length), 1, 5),\n                    new Token(new String(b, 0, b.length), 6, 10),\n                    new Token(new String(ccc, 0, ccc.length), 11, 15),\n                    new Token(new String(whitespace, 0, whitespace.length), 16, 20),\n                    new Token(new String(empty, 0, empty.length), 21, 21));\n    ts = new TrimFilter(ts);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"192e49c0445803405b0bc0eebc8b758485480c21":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"ff4227bb146f97aabae888091c19e48c88dbb0db":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["192e49c0445803405b0bc0eebc8b758485480c21"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"6bd063790d36bd9fb41ccad27a1be3e198ff5a7e":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["379db3ad24c4f0214f30a122265a6d6be003a99d","6bd063790d36bd9fb41ccad27a1be3e198ff5a7e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["379db3ad24c4f0214f30a122265a6d6be003a99d","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"]},"commit2Childs":{"192e49c0445803405b0bc0eebc8b758485480c21":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["6bd063790d36bd9fb41ccad27a1be3e198ff5a7e","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["192e49c0445803405b0bc0eebc8b758485480c21"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"6bd063790d36bd9fb41ccad27a1be3e198ff5a7e":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}