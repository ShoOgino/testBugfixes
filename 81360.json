{"path":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","commits":[{"id":"1ea2ca01fc0b1375f71a47571ffacc7924742b30","date":1185994483,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"/dev/null","sourceNew":"  public int doLogic() throws Exception {\n    List fields = doc.getFields();\n    final int numField = fields.size();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(int i=0;i<numField;i++) {\n      final Field field = (Field) fields.get(i);\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.tokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.next() != null)\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6864413dbc0c12104c978c05456f3da1d45adb03","date":1186770873,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","sourceNew":"  public int doLogic() throws Exception {\n    List fields = doc.getFields();\n    final int numField = fields.size();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(int i=0;i<numField;i++) {\n      final Field field = (Field) fields.get(i);\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.next(token) != null)\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":"  public int doLogic() throws Exception {\n    List fields = doc.getFields();\n    final int numField = fields.size();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(int i=0;i<numField;i++) {\n      final Field field = (Field) fields.get(i);\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.tokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.next() != null)\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"439b0fe2f799d1c722151e88e32bdefad8d34ebe","date":1255282509,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","sourceNew":"  public int doLogic() throws Exception {\n    List fields = doc.getFields();\n    final int numField = fields.size();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(int i=0;i<numField;i++) {\n      final Field field = (Field) fields.get(i);\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":"  public int doLogic() throws Exception {\n    List fields = doc.getFields();\n    final int numField = fields.size();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(int i=0;i<numField;i++) {\n      final Field field = (Field) fields.get(i);\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.next(token) != null)\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e1ce9be74263e9659aad8a6ee1f213193710b71","date":1256298843,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","sourceNew":"  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":"  public int doLogic() throws Exception {\n    List fields = doc.getFields();\n    final int numField = fields.size();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(int i=0;i<numField;i++) {\n      final Field field = (Field) fields.get(i);\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d57eb7c98c08c03af6e4cd83509df31c81ac16af","date":1257684312,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","sourceNew":"  @Override\n  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":"  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19902de501347481fdd1e781868986601e2a7c7b","date":1263326777,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","sourceNew":"  @Override\n  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      if (!field.isTokenized()) continue;\n      \n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":"  @Override\n  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask#doLogic().mjava","sourceNew":"  @Override\n  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      if (!field.isTokenized()) continue;\n      \n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","sourceOld":"  @Override\n  public int doLogic() throws Exception {\n    List<Fieldable> fields = doc.getFields();\n    Analyzer analyzer = getRunData().getAnalyzer();\n    int tokenCount = 0;\n    for(final Fieldable field : fields) {\n      if (!field.isTokenized()) continue;\n      \n      final TokenStream stream;\n      final TokenStream streamValue = field.tokenStreamValue();\n\n      if (streamValue != null) \n        stream = streamValue;\n      else {\n        // the field does not have a TokenStream,\n        // so we have to obtain one from the analyzer\n        final Reader reader;\t\t\t  // find or make Reader\n        final Reader readerValue = field.readerValue();\n\n        if (readerValue != null)\n          reader = readerValue;\n        else {\n          String stringValue = field.stringValue();\n          if (stringValue == null)\n            throw new IllegalArgumentException(\"field must have either TokenStream, String or Reader value\");\n          stringReader.init(stringValue);\n          reader = stringReader;\n        }\n        \n        // Tokenize field\n        stream = analyzer.reusableTokenStream(field.name(), reader);\n      }\n\n      // reset the TokenStream to the first token\n      stream.reset();\n\n      while(stream.incrementToken())\n        tokenCount++;\n    }\n    totalTokenCount += tokenCount;\n    return tokenCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6864413dbc0c12104c978c05456f3da1d45adb03":["1ea2ca01fc0b1375f71a47571ffacc7924742b30"],"1ea2ca01fc0b1375f71a47571ffacc7924742b30":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4e1ce9be74263e9659aad8a6ee1f213193710b71":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["4e1ce9be74263e9659aad8a6ee1f213193710b71"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["6864413dbc0c12104c978c05456f3da1d45adb03"],"19902de501347481fdd1e781868986601e2a7c7b":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["19902de501347481fdd1e781868986601e2a7c7b"]},"commit2Childs":{"6864413dbc0c12104c978c05456f3da1d45adb03":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"1ea2ca01fc0b1375f71a47571ffacc7924742b30":["6864413dbc0c12104c978c05456f3da1d45adb03"],"4e1ce9be74263e9659aad8a6ee1f213193710b71":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1ea2ca01fc0b1375f71a47571ffacc7924742b30"],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["19902de501347481fdd1e781868986601e2a7c7b"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["4e1ce9be74263e9659aad8a6ee1f213193710b71"],"19902de501347481fdd1e781868986601e2a7c7b":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}