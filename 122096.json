{"path":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","commits":[{"id":"6864413dbc0c12104c978c05456f3da1d45adb03","date":1186770873,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"/dev/null","sourceNew":"  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) {\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    }\n    return tokenizer;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["5805e06f5e282a5a77a5d52080974bb8636a579e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5805e06f5e282a5a77a5d52080974bb8636a579e","date":1197969604,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) throws IOException {\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    } else\n      \ttokenizer.reset(reader);\n    return tokenizer;\n  }\n\n","sourceOld":"  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) {\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    }\n    return tokenizer;\n  }\n\n","bugFix":["6864413dbc0c12104c978c05456f3da1d45adb03"],"bugIntro":["d66301bc45f6e3ffc51d21dc8bd48290d58aad7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d66301bc45f6e3ffc51d21dc8bd48290d58aad7b","date":1247589138,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) throws IOException {\n    if (overridesTokenStreamMethod) {\n      // LUCENE-1678: force fallback to tokenStream() if we\n      // have been subclassed and that subclass overrides\n      // tokenStream but not reusableTokenStream\n      return tokenStream(fieldName, reader);\n    }\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    } else\n      tokenizer.reset(reader);\n    return tokenizer;\n  }\n\n","sourceOld":"  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) throws IOException {\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    } else\n      \ttokenizer.reset(reader);\n    return tokenizer;\n  }\n\n","bugFix":["5805e06f5e282a5a77a5d52080974bb8636a579e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a9e385641d717e641408d8fbbc62be8fc766357","date":1256746606,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"  @Override\n  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) throws IOException {\n    if (overridesTokenStreamMethod) {\n      // LUCENE-1678: force fallback to tokenStream() if we\n      // have been subclassed and that subclass overrides\n      // tokenStream but not reusableTokenStream\n      return tokenStream(fieldName, reader);\n    }\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    } else\n      tokenizer.reset(reader);\n    return tokenizer;\n  }\n\n","sourceOld":"  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) throws IOException {\n    if (overridesTokenStreamMethod) {\n      // LUCENE-1678: force fallback to tokenStream() if we\n      // have been subclassed and that subclass overrides\n      // tokenStream but not reusableTokenStream\n      return tokenStream(fieldName, reader);\n    }\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    } else\n      tokenizer.reset(reader);\n    return tokenizer;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":4,"author":"Dawid Weiss","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/KeywordAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":null,"sourceOld":"  @Override\n  public TokenStream reusableTokenStream(String fieldName,\n                                         final Reader reader) throws IOException {\n    if (overridesTokenStreamMethod) {\n      // LUCENE-1678: force fallback to tokenStream() if we\n      // have been subclassed and that subclass overrides\n      // tokenStream but not reusableTokenStream\n      return tokenStream(fieldName, reader);\n    }\n    Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n    if (tokenizer == null) {\n      tokenizer = new KeywordTokenizer(reader);\n      setPreviousTokenStream(tokenizer);\n    } else\n      tokenizer.reset(reader);\n    return tokenizer;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d66301bc45f6e3ffc51d21dc8bd48290d58aad7b":["5805e06f5e282a5a77a5d52080974bb8636a579e"],"6864413dbc0c12104c978c05456f3da1d45adb03":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8a9e385641d717e641408d8fbbc62be8fc766357":["d66301bc45f6e3ffc51d21dc8bd48290d58aad7b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5805e06f5e282a5a77a5d52080974bb8636a579e":["6864413dbc0c12104c978c05456f3da1d45adb03"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["8a9e385641d717e641408d8fbbc62be8fc766357"]},"commit2Childs":{"d66301bc45f6e3ffc51d21dc8bd48290d58aad7b":["8a9e385641d717e641408d8fbbc62be8fc766357"],"6864413dbc0c12104c978c05456f3da1d45adb03":["5805e06f5e282a5a77a5d52080974bb8636a579e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6864413dbc0c12104c978c05456f3da1d45adb03"],"8a9e385641d717e641408d8fbbc62be8fc766357":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5805e06f5e282a5a77a5d52080974bb8636a579e":["d66301bc45f6e3ffc51d21dc8bd48290d58aad7b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}