{"path":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(newRandom(), TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(newRandom(), TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (int i = 0; i < reader.core.fieldInfos.size(); i++) {\n      FieldInfo fi = reader.core.fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, IOContext.READ);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, IOContext.READ);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    Fieldable [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].isTermVectorStored());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6eb141f80638abdb6ffaa5149877f36ea39b6ad5","date":1315714072,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f","date":1323210518,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ce667c6d3400b22523701c549c0d35e26da8b46","date":1324405053,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.fieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.core.fieldInfos) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3321cfbf7f8aba27e37e7a4d6901531a97ac2b06","date":1326148180,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.fieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868186558eb3a854ce7e720a52bb445795d54910","date":1327853682,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","1f653cfcf159baeaafe5d01682a911e95bba4012"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["1224a4027481acce15495b03bce9b48b93b42722"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["a3776dccca01c11e7046323cfad46a3b4a471233","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"3321cfbf7f8aba27e37e7a4d6901531a97ac2b06":["9ce667c6d3400b22523701c549c0d35e26da8b46"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["f2c5f0cb44df114db4228c8f77861714b5cabaea","b6f9be74ca7baaef11857ad002cad40419979516"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5"],"868186558eb3a854ce7e720a52bb445795d54910":["3321cfbf7f8aba27e37e7a4d6901531a97ac2b06"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"6eb141f80638abdb6ffaa5149877f36ea39b6ad5":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d572389229127c297dd1fa5ce4758e1cec41e799":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3321cfbf7f8aba27e37e7a4d6901531a97ac2b06","868186558eb3a854ce7e720a52bb445795d54910"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["1f653cfcf159baeaafe5d01682a911e95bba4012","1224a4027481acce15495b03bce9b48b93b42722"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1224a4027481acce15495b03bce9b48b93b42722","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5","cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","ddc4c914be86e34b54f70023f45a60fa7f04e929","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d619839baa8ce5503e496b94a9e42ad6f079293f","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b6f9be74ca7baaef11857ad002cad40419979516":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3321cfbf7f8aba27e37e7a4d6901531a97ac2b06":["868186558eb3a854ce7e720a52bb445795d54910","5cab9a86bd67202d20b6adc463008c8e982b070a"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["3321cfbf7f8aba27e37e7a4d6901531a97ac2b06"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"868186558eb3a854ce7e720a52bb445795d54910":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"1224a4027481acce15495b03bce9b48b93b42722":["f2c5f0cb44df114db4228c8f77861714b5cabaea","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d572389229127c297dd1fa5ce4758e1cec41e799"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"6eb141f80638abdb6ffaa5149877f36ea39b6ad5":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"962d04139994fce5193143ef35615499a9a96d78":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","9ce667c6d3400b22523701c549c0d35e26da8b46"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","5d004d0e0b3f65bb40da76d476d659d7888270e8","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}