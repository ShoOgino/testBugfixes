{"path":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#simpleTest().mjava","commits":[{"id":"4d07d6c279b65daaca32ee033fa06e4d7e85e0dd","date":1525384847,"type":0,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#simpleTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void simpleTest() throws Exception {\n    int maxFileSizeBound = 1000;\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.25);\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Adding these docs will place the tlog size just under the threshold\n    int numDocs = 27;\n    int batchSize = 3;\n    int numBatches = numDocs / batchSize;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n    int numTlogs = -1;\n    TreeMap<String, Long> tlogsInfo = null;\n\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch update request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish (or at least mostly finish) before querying/submitting more documents\n      waitForCommit(200);\n\n      // There should just be 1 tlog and its size should be within the (buffered) file size bound\n      tlogsInfo = getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n      numTlogs = parseTotalNumTlogs(tlogsInfo);\n      Assert.assertEquals(1, numTlogs);\n    }\n\n    // Now that the core's tlog size is just under the threshold, one more update should induce a commit\n    int docStartId = batchSize * numBatches;\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n    waitForCommit(200);\n\n    // Verify that a commit happened. There should now be 2 tlogs, both of which are < maxFileSizeBound.\n    TreeMap<String, Long> tlogsInfoPostCommit = getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n    Assert.assertEquals(2, parseTotalNumTlogs(tlogsInfoPostCommit));\n\n    // And the current tlog's size should be less than the previous tlog's size\n    Assert.assertTrue(tlogsInfoPostCommit.lastEntry().getValue() < tlogsInfo.lastEntry().getValue());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"27d6f83edecd216b844079cc682096091dfa9fbc","date":1534485921,"type":4,"author":"Anshum Gupta","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#simpleTest().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void simpleTest() throws Exception {\n    int maxFileSizeBound = 1000;\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.25);\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Adding these docs will place the tlog size just under the threshold\n    int numDocs = 27;\n    int batchSize = 3;\n    int numBatches = numDocs / batchSize;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n    int numTlogs = -1;\n    TreeMap<String, Long> tlogsInfo = null;\n\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch update request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish (or at least mostly finish) before querying/submitting more documents\n      waitForCommit(200);\n\n      // There should just be 1 tlog and its size should be within the (buffered) file size bound\n      tlogsInfo = getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n      numTlogs = parseTotalNumTlogs(tlogsInfo);\n      Assert.assertEquals(1, numTlogs);\n    }\n\n    // Now that the core's tlog size is just under the threshold, one more update should induce a commit\n    int docStartId = batchSize * numBatches;\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n    waitForCommit(200);\n\n    // Verify that a commit happened. There should now be 2 tlogs, both of which are < maxFileSizeBound.\n    TreeMap<String, Long> tlogsInfoPostCommit = getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n    Assert.assertEquals(2, parseTotalNumTlogs(tlogsInfoPostCommit));\n\n    // And the current tlog's size should be less than the previous tlog's size\n    Assert.assertTrue(tlogsInfoPostCommit.lastEntry().getValue() < tlogsInfo.lastEntry().getValue());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4d07d6c279b65daaca32ee033fa06e4d7e85e0dd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"27d6f83edecd216b844079cc682096091dfa9fbc":["4d07d6c279b65daaca32ee033fa06e4d7e85e0dd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["27d6f83edecd216b844079cc682096091dfa9fbc"]},"commit2Childs":{"4d07d6c279b65daaca32ee033fa06e4d7e85e0dd":["27d6f83edecd216b844079cc682096091dfa9fbc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d07d6c279b65daaca32ee033fa06e4d7e85e0dd"],"27d6f83edecd216b844079cc682096091dfa9fbc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}