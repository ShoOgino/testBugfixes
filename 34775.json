{"path":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","commits":[{"id":"0216a47ac375092b9e018cf0498f45f450e8f4ed","date":1404782591,"type":0,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","pathOld":"/dev/null","sourceNew":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is garunteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0158ced21948b6626f733c1c42c1e18d94449789","date":1462994341,"type":3,"author":"Bartosz KrasiÅ„ski","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","sourceNew":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is guaranteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","sourceOld":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is garunteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","sourceNew":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is guaranteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","sourceOld":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is garunteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestMissingGroups#testGroupsOnMissingValues().mjava","sourceNew":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is guaranteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","sourceOld":"  public void testGroupsOnMissingValues() throws Exception {\n\n\n    final int numDocs = atLeast(500);\n\n    // setup some key values for some random docs in our index\n    // every other doc will have no values for these fields\n    // NOTE: special values may be randomly assigned to the *same* docs\n    final List<SpecialField> specials = new ArrayList<SpecialField>(7);\n    specials.add(new SpecialField(numDocs, \"group_s1\", \"xxx\",\"yyy\"));\n    specials.add(new SpecialField(numDocs, \"group_ti\", \"42\",\"24\"));\n    specials.add(new SpecialField(numDocs, \"group_td\", \"34.56\",\"12.78\"));\n    specials.add(new SpecialField(numDocs, \"group_tl\", \"66666666\",\"999999999\"));\n    specials.add(new SpecialField(numDocs, \"group_tf\", \"56.78\",\"78.45\"));\n    specials.add(new SpecialField(numDocs, \"group_b\", \"true\", \"false\"));\n    specials.add(new SpecialField(numDocs, \"group_tdt\", \n                                  \"2009-05-10T03:30:00Z\",\"1976-03-06T15:06:00Z\"));\n                                 \n    // build up our index of docs\n    \n    for (int i = 1; i < numDocs; i++) { // NOTE: start at 1, doc#0 is below...\n      SolrInputDocument d = sdoc(\"id\", i);\n      if (SpecialField.special_docids.contains(i)) {\n        d.addField(\"special_s\",\"special\");\n        for (SpecialField f : specials) {\n          if (f.docX == i) {\n            d.addField(f.field, f.valueX);\n          } else if (f.docY == i) {\n            d.addField(f.field, f.valueY);\n          }\n        }\n      } else {\n        // doc isn't special, give it a random chances of being excluded from some queries\n        d.addField(\"filter_b\", random().nextBoolean());\n      }\n      assertU(adoc(d));\n      if (rarely()) {\n        assertU(commit()); // mess with the segment counts\n      }\n    }\n    // doc#0: at least one doc that is garunteed not special and has no chance of being filtered\n    assertU(adoc(sdoc(\"id\",\"0\")));\n    assertU(commit());\n\n    // sanity check\n    assertQ(req(\"q\", \"*:*\"), \"//result[@numFound=\"+numDocs+\"]\");\n           \n    for (SpecialField special : specials) {\n      // sanity checks\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueX),\n              \"//result[@numFound=1]\");\n      assertQ(req(\"q\", \"{!term f=\" + special.field + \"}\" + special.valueY),\n              \"//result[@numFound=1]\");\n\n      // group on special field, and confirm all docs w/o group field get put into a single group\n      final String xpre = \"//lst[@name='grouped']/lst[@name='\"+special.field+\"']\";\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='3']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=3]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct groups for the special values with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueX+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docX+\"]\"\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+special.valueY+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+special.docY+\"]\"\n              );\n\n      // now do the same check, but exclude one special doc to force only 2 groups\n      final int doc = random().nextBoolean() ? special.docX : special.docY;\n      final Object val = (doc == special.docX) ? special.valueX : special.valueY;\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + ((doc == special.docX) ? special.docY : special.docX),\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='2']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=2]\"\n              // sanity check one group is the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              // check we have the correct group for the special value with a single doc\n              , xpre + \"/arr[@name='groups']/lst/*[@name='groupValue'][.='\"+val+\"']/following-sibling::result[@name='doclist'][@numFound=1]/doc/str[@name='id'][.=\"+doc+\"]\"\n              );\n\n      // one last check, exclude both docs and verify the only group is the missing value group\n      assertQ(req(\"q\", (random().nextBoolean() ? \"*:*\" : \"special_s:special id:[0 TO 400]\"),\n                  \"fq\", (random().nextBoolean() ? \"*:*\" : \"-filter_b:\"+random().nextBoolean()),\n                  \"fq\", \"-id:\" + special.docX,\n                  \"fq\", \"-id:\" + special.docY,\n                  \"group\",\"true\",\n                  \"group.field\",special.field,\n                  \"group.ngroups\", \"true\")\n              // basic grouping checks\n              , xpre + \"/int[@name='ngroups'][.='1']\"\n              , xpre + \"/arr[@name='groups'][count(lst)=1]\"\n              // the only group should be the missing values\n              , xpre + \"/arr[@name='groups']/lst/null[@name='groupValue']\"\n              );\n      \n     }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0216a47ac375092b9e018cf0498f45f450e8f4ed":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0216a47ac375092b9e018cf0498f45f450e8f4ed","d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["0216a47ac375092b9e018cf0498f45f450e8f4ed","0158ced21948b6626f733c1c42c1e18d94449789"],"0158ced21948b6626f733c1c42c1e18d94449789":["0216a47ac375092b9e018cf0498f45f450e8f4ed"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0216a47ac375092b9e018cf0498f45f450e8f4ed"],"0216a47ac375092b9e018cf0498f45f450e8f4ed":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","0158ced21948b6626f733c1c42c1e18d94449789"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"0158ced21948b6626f733c1c42c1e18d94449789":["d470c8182e92b264680e34081b75e70a9f2b3c89"]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}