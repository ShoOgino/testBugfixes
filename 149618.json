{"path":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","commits":[{"id":"fcc7eba0b32cbc7cc5b8fd388032bb833fa07786","date":1474482359,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // start the freshNode \n      ChaosMonkey.start(freshNode.jetty);\n      nodesDown.remove(freshNode);\n\n      waitTillNodesActive();\n      waitForThingsToLevelOut(30);\n      \n      //TODO check how to see if fresh node went into recovery (may be check count for replication handler on new leader) \n      \n      long numRequestsBefore = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n      \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , 15);\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      \n      long numRequestsAfter = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n\n      assertEquals(\"Node went into replication\", numRequestsBefore, numRequestsAfter);\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // start the freshNode \n      ChaosMonkey.start(freshNode.jetty);\n      nodesDown.remove(freshNode);\n\n      waitTillNodesActive();\n      waitForThingsToLevelOut(30);\n      \n      //TODO check how to see if fresh node went into recovery (may be check count for replication handler on new leader) \n      \n      long numRequestsBefore = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n      \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , 15);\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      \n      long numRequestsAfter = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n\n      assertEquals(\"Node went into replication\", numRequestsBefore, numRequestsAfter);\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // start the freshNode \n      ChaosMonkey.start(freshNode.jetty);\n      nodesDown.remove(freshNode);\n\n      waitTillNodesActive();\n      waitForThingsToLevelOut(30);\n      \n      //TODO check how to see if fresh node went into recovery (may be check count for replication handler on new leader) \n      \n      long numRequestsBefore = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n      \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , 15);\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      \n      long numRequestsAfter = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n\n      assertEquals(\"Node went into replication\", numRequestsBefore, numRequestsAfter);\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7540b2d98e89684a4076a7e99ba2f8ec7983de7c","date":1483428128,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      \n      String replicationProperties = (String) freshNode.jetty.getSolrHome() + \"/cores/\" +  DEFAULT_TEST_COLLECTION_NAME + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // start the freshNode \n      ChaosMonkey.start(freshNode.jetty);\n      nodesDown.remove(freshNode);\n\n      waitTillNodesActive();\n      waitForThingsToLevelOut(30);\n      \n      //TODO check how to see if fresh node went into recovery (may be check count for replication handler on new leader) \n      \n      long numRequestsBefore = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n      \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , 15);\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      \n      long numRequestsAfter = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n\n      assertEquals(\"Node went into replication\", numRequestsBefore, numRequestsAfter);\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      \n      String replicationProperties = (String) freshNode.jetty.getSolrHome() + \"/cores/\" +  DEFAULT_TEST_COLLECTION_NAME + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // start the freshNode \n      ChaosMonkey.start(freshNode.jetty);\n      nodesDown.remove(freshNode);\n\n      waitTillNodesActive();\n      waitForThingsToLevelOut(30);\n      \n      //TODO check how to see if fresh node went into recovery (may be check count for replication handler on new leader) \n      \n      long numRequestsBefore = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n      \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , 15);\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      \n      long numRequestsAfter = (Long) secondNode.jetty\n          .getCoreContainer()\n          .getCores()\n          .iterator()\n          .next()\n          .getRequestHandler(ReplicationHandler.PATH)\n          .getStatistics().get(\"requests\");\n\n      assertEquals(\"Node went into replication\", numRequestsBefore, numRequestsAfter);\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9b4296bd51ca61b482138791478afdd0f7d3a3d","date":1498058739,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      \n      String replicationProperties = (String) freshNode.jetty.getSolrHome() + \"/cores/\" +  DEFAULT_TEST_COLLECTION_NAME + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      \n      String replicationProperties = (String) freshNode.jetty.getSolrHome() + \"/cores/\" +  DEFAULT_TEST_COLLECTION_NAME + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      \n      String replicationProperties = (String) freshNode.jetty.getSolrHome() + \"/cores/\" +  DEFAULT_TEST_COLLECTION_NAME + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS, TimeSource.NANO_TIME));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderFailureAfterFreshStartTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30, TimeUnit.SECONDS);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30, TimeUnit.SECONDS);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n\n    try {\n      CloudJettyRunner initialLeaderJetty = shardToLeaderJetty.get(\"shard1\");\n      List<CloudJettyRunner> otherJetties = getOtherAvailableJetties(initialLeaderJetty);\n      \n      log.info(\"Leader node_name: {},  url: {}\", initialLeaderJetty.coreNodeName, initialLeaderJetty.url);\n      for (CloudJettyRunner cloudJettyRunner : otherJetties) {\n        log.info(\"Nonleader node_name: {},  url: {}\", cloudJettyRunner.coreNodeName, cloudJettyRunner.url);\n      }\n      \n      CloudJettyRunner secondNode = otherJetties.get(0);\n      CloudJettyRunner freshNode = otherJetties.get(1);\n      \n      // shutdown a node to simulate fresh start\n      otherJetties.remove(freshNode);\n      forceNodeFailures(singletonList(freshNode));\n\n      del(\"*:*\");\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n\n      // index a few docs and commit\n      for (int i = 0; i < 100; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n      }\n      commit();\n      waitForThingsToLevelOut(30);\n\n      checkShardConsistency(false, true);\n      \n      // bring down the other node and index a few docs; so the leader and other node segments diverge\n      forceNodeFailures(singletonList(secondNode));\n      for (int i = 0; i < 10; i++) {\n        indexDoc(id, docId, i1, 50, tlong, 50, t1,\n            \"document number \" + docId++);\n        if(i % 2 == 0) {\n          commit();\n        }\n      }\n      commit();\n      restartNodes(singletonList(secondNode));\n\n      // start the freshNode \n      restartNodes(singletonList(freshNode));\n      String coreName = freshNode.jetty.getCoreContainer().getCores().iterator().next().getName();\n      String replicationProperties = freshNode.jetty.getSolrHome() + \"/cores/\" +  coreName + \"/data/replication.properties\";\n      String md5 = DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties)));\n        \n      // shutdown the original leader\n      log.info(\"Now shutting down initial leader\");\n      forceNodeFailures(singletonList(initialLeaderJetty));\n      waitForNewLeader(cloudClient, \"shard1\", (Replica)initialLeaderJetty.client.info  , new TimeOut(15, SECONDS, TimeSource.NANO_TIME));\n      waitTillNodesActive();\n      log.info(\"Updating mappings from zk\");\n      updateMappingsFromZk(jettys, clients, true);\n      assertEquals(\"Node went into replication\", md5, DigestUtils.md5Hex(Files.readAllBytes(Paths.get(replicationProperties))));\n      \n      success = true;\n    } finally {\n      System.clearProperty(\"solr.disableFingerprint\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a9b4296bd51ca61b482138791478afdd0f7d3a3d":["7540b2d98e89684a4076a7e99ba2f8ec7983de7c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fcc7eba0b32cbc7cc5b8fd388032bb833fa07786"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"fcc7eba0b32cbc7cc5b8fd388032bb833fa07786":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["28288370235ed02234a64753cdbf0c6ec096304a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["7540b2d98e89684a4076a7e99ba2f8ec7983de7c","a9b4296bd51ca61b482138791478afdd0f7d3a3d"],"28288370235ed02234a64753cdbf0c6ec096304a":["7540b2d98e89684a4076a7e99ba2f8ec7983de7c","a9b4296bd51ca61b482138791478afdd0f7d3a3d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"7540b2d98e89684a4076a7e99ba2f8ec7983de7c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7540b2d98e89684a4076a7e99ba2f8ec7983de7c"]},"commit2Childs":{"a9b4296bd51ca61b482138791478afdd0f7d3a3d":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","fcc7eba0b32cbc7cc5b8fd388032bb833fa07786","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7540b2d98e89684a4076a7e99ba2f8ec7983de7c"],"fcc7eba0b32cbc7cc5b8fd388032bb833fa07786":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"7540b2d98e89684a4076a7e99ba2f8ec7983de7c":["a9b4296bd51ca61b482138791478afdd0f7d3a3d","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","cd5edd1f2b162a5cfa08efd17851a07373a96817","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}