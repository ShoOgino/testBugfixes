{"path":"sandbox/contributions/WordNet/src/java/org/apache/lucene/wordnet/SynLookup#expand(String,Searcher,Analyzer,String,float).mjava","commits":[{"id":"c66ea4e08d5b7e32ff205b48896a4da9bf70ac7a","date":1105477091,"type":0,"author":"David Spencer","isMerge":false,"pathNew":"sandbox/contributions/WordNet/src/java/org/apache/lucene/wordnet/SynLookup#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"/dev/null","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query\n\t * @param syns\n\t * @param a\n\t * @param field\n\t * @param boost\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups\t\t\n\t\tList top = new LinkedList(); // needs to be separately listed..\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\torg.apache.lucene.analysis.Token t;\n\t\twhile ( (t = ts.next()) != null)\n\t\t{\n\t\t\tString word = t.termText();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn))\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":5,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/WordNet/src/java/org/apache/lucene/wordnet/SynLookup#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"sandbox/contributions/WordNet/src/java/org/apache/lucene/wordnet/SynLookup#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query\n\t * @param syns\n\t * @param a\n\t * @param field\n\t * @param boost\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups\t\t\n\t\tList top = new LinkedList(); // needs to be separately listed..\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\torg.apache.lucene.analysis.Token t;\n\t\twhile ( (t = ts.next()) != null)\n\t\t{\n\t\t\tString word = t.termText();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn))\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query\n\t * @param syns\n\t * @param a\n\t * @param field\n\t * @param boost\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups\t\t\n\t\tList top = new LinkedList(); // needs to be separately listed..\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\torg.apache.lucene.analysis.Token t;\n\t\twhile ( (t = ts.next()) != null)\n\t\t{\n\t\t\tString word = t.termText();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn))\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["c66ea4e08d5b7e32ff205b48896a4da9bf70ac7a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c66ea4e08d5b7e32ff205b48896a4da9bf70ac7a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["043c298cb215f13ba7b9b81d20760704e8f93d66"]},"commit2Childs":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c66ea4e08d5b7e32ff205b48896a4da9bf70ac7a"],"c66ea4e08d5b7e32ff205b48896a4da9bf70ac7a":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}