{"path":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","commits":[{"id":"6776c9bdacef00ce712b87d1c8e999ae61c1c6a1","date":1448389841,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   * </p>\n   *\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   *\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n      startingOperation = startingUpdates.getLatestOperation();\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cfa6bab72dc1ef7209657e6685f9204e2e49bac8","date":1448391014,"type":4,"author":"Erick Erickson","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":null,"sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   * </p>\n   *\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   *\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n      startingOperation = startingUpdates.getLatestOperation();\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cae179618908dcb534af567cdf3019505ada6c","date":1449365361,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n      startingOperation = startingUpdates.getLatestOperation();\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1455c941cc4ce652efc776fc23471b0e499246f6","date":1528086751,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n      startingOperation = startingUpdates.getLatestOperation();\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n      startingOperation = startingUpdates.getLatestOperation();\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n      startingOperation = startingUpdates.getLatestOperation();\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"740d649f013f07efbeb73ca854f106c60166e7c0","date":1587431295,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir={}, existing tlogs={}, next id={}\", tlogDir, Arrays.asList(tlogFiles), id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir=\" + tlogDir + \", existing tlogs=\" + Arrays.asList(tlogFiles) + \", next id=\" + id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"018a36ff4088cb91ab12cbe44f696d81d1fadd77","date":1591657414,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir={}, existing tlogs={}, next id={}\", tlogDir, Arrays.asList(tlogFiles), id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        @SuppressWarnings({\"unchecked\"})\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir={}, existing tlogs={}, next id={}\", tlogDir, Arrays.asList(tlogFiles), id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1","date":1598647393,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/update/CdcrUpdateLog#initForRecovery(File,long).mjava","sourceNew":null,"sourceOld":"  /**\n   * <p>\n   *   expert: Initialise the update log with a tlog file containing buffered updates. This is called by\n   *   {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} during a Recovery operation.\n   *   This is mainly a copy of the original {@link UpdateLog#init(UpdateHandler, SolrCore)} method, but modified\n   *   to:\n   *   <ul>\n   *     <li>preserve the same {@link VersionInfo} instance in order to not \"unblock\" updates, since the\n   *     {@link org.apache.solr.handler.IndexFetcher#moveTlogFiles(File)} acquired a write lock from this instance.</li>\n   *     <li>copy the buffered updates.</li>\n   *   </ul>\n   * @see #resetForRecovery()\n   */\n  public void initForRecovery(File bufferedTlog, long offset) {\n    tlogFiles = getLogList(tlogDir);\n    id = getLastLogId() + 1;   // add 1 since we will create a new log for the next update\n\n    if (debug) {\n      log.debug(\"UpdateHandler init: tlogDir={}, existing tlogs={}, next id={}\", tlogDir, Arrays.asList(tlogFiles), id);\n    }\n\n    TransactionLog oldLog = null;\n    for (String oldLogName : tlogFiles) {\n      File f = new File(tlogDir, oldLogName);\n      try {\n        oldLog = newTransactionLog(f, null, true);\n        addOldLog(oldLog, false);  // don't remove old logs on startup since more than one may be uncapped.\n      } catch (Exception e) {\n        SolrException.log(log, \"Failure to open existing log file (non fatal) \" + f, e);\n        deleteFile(f);\n      }\n    }\n\n    // Record first two logs (oldest first) at startup for potential tlog recovery.\n    // It's possible that at abnormal close both \"tlog\" and \"prevTlog\" were uncapped.\n    for (TransactionLog ll : logs) {\n      newestLogsOnStartup.addFirst(ll);\n      if (newestLogsOnStartup.size() >= 2) break;\n    }\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    UpdateLog.RecentUpdates startingUpdates = getRecentUpdates();\n    long latestVersion = startingUpdates.getMaxRecentVersion();\n    try {\n      startingVersions = startingUpdates.getVersions(numRecordsToKeep);\n\n      // populate recent deletes list (since we can't get that info from the index)\n      for (int i=startingUpdates.deleteList.size()-1; i>=0; i--) {\n        DeleteUpdate du = startingUpdates.deleteList.get(i);\n        oldDeletes.put(new BytesRef(du.id), new LogPtr(-1,du.version));\n      }\n\n      // populate recent deleteByQuery commands\n      for (int i=startingUpdates.deleteByQueryList.size()-1; i>=0; i--) {\n        Update update = startingUpdates.deleteByQueryList.get(i);\n        @SuppressWarnings({\"unchecked\"})\n        List<Object> dbq = (List<Object>) update.log.lookup(update.pointer);\n        long version = (Long) dbq.get(1);\n        String q = (String) dbq.get(2);\n        trackDeleteByQuery(q, version);\n      }\n\n    } finally {\n      startingUpdates.close();\n    }\n\n    // Copy buffered updates\n    if (bufferedTlog != null) {\n      this.copyBufferedUpdates(bufferedTlog, offset, latestVersion);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"77cae179618908dcb534af567cdf3019505ada6c":["cfa6bab72dc1ef7209657e6685f9204e2e49bac8"],"018a36ff4088cb91ab12cbe44f696d81d1fadd77":["740d649f013f07efbeb73ca854f106c60166e7c0"],"740d649f013f07efbeb73ca854f106c60166e7c0":["1455c941cc4ce652efc776fc23471b0e499246f6"],"cfa6bab72dc1ef7209657e6685f9204e2e49bac8":["6776c9bdacef00ce712b87d1c8e999ae61c1c6a1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["77cae179618908dcb534af567cdf3019505ada6c","1455c941cc4ce652efc776fc23471b0e499246f6"],"6776c9bdacef00ce712b87d1c8e999ae61c1c6a1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["018a36ff4088cb91ab12cbe44f696d81d1fadd77"],"f592209545c71895260367152601e9200399776d":["77cae179618908dcb534af567cdf3019505ada6c","1455c941cc4ce652efc776fc23471b0e499246f6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"1455c941cc4ce652efc776fc23471b0e499246f6":["77cae179618908dcb534af567cdf3019505ada6c"]},"commit2Childs":{"77cae179618908dcb534af567cdf3019505ada6c":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","1455c941cc4ce652efc776fc23471b0e499246f6"],"018a36ff4088cb91ab12cbe44f696d81d1fadd77":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"740d649f013f07efbeb73ca854f106c60166e7c0":["018a36ff4088cb91ab12cbe44f696d81d1fadd77"],"cfa6bab72dc1ef7209657e6685f9204e2e49bac8":["77cae179618908dcb534af567cdf3019505ada6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6776c9bdacef00ce712b87d1c8e999ae61c1c6a1"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"6776c9bdacef00ce712b87d1c8e999ae61c1c6a1":["cfa6bab72dc1ef7209657e6685f9204e2e49bac8"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"1455c941cc4ce652efc776fc23471b0e499246f6":["740d649f013f07efbeb73ca854f106c60166e7c0","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}