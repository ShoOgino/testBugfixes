{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","commits":[{"id":"1987c0002f396ce6d6dada94c6773d6ba0e03f50","date":1458660902,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int,int,int).mjava","sourceNew":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n\n    assert pointCount < Integer.MAX_VALUE;\n    //int[] swapCount = new int[1];\n    //int[] cmpCount = new int[1];\n\n    // System.out.println(\"SORT length=\" + length);\n\n    // All buffered points are still in heap; just do in-place sort:\n    new IntroSorter() {\n      private final byte[] pivotPackedValue = new byte[bytesPerDim];\n      private int pivotDocID;\n\n      @Override\n      protected void setPivot(int i) {\n        pivotDocID = writer.docIDs[i];\n        int block = i / writer.valuesPerBlock;\n        int index = i % writer.valuesPerBlock;\n        System.arraycopy(writer.blocks.get(block), index*packedBytesLength+dim*bytesPerDim, pivotPackedValue, 0, bytesPerDim);\n      }\n\n      @Override\n      protected int comparePivot(int j) {\n        //cmpCount[0]++;\n        int block = j / writer.valuesPerBlock;\n        int index = j % writer.valuesPerBlock;\n        assert index >= 0: \"index=\" + index + \" j=\" + j;\n        int cmp = StringHelper.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), bytesPerDim*(index*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break\n        return Integer.compare(pivotDocID, writer.docIDs[j]);\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n      @Override\n      protected int compare(int i, int j) {\n        //cmpCount[0]++;\n        int blockI = i / writer.valuesPerBlock;\n        int dimI = i % writer.valuesPerBlock;\n        int blockJ = j / writer.valuesPerBlock;\n        int dimJ = j % writer.valuesPerBlock;\n        int cmp = StringHelper.compare(bytesPerDim, writer.blocks.get(blockI), bytesPerDim*(dimI*numDims+dim), writer.blocks.get(blockJ), bytesPerDim*(dimJ*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break by docID:\n\n        // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n        // can't matter at search time since we don't write ords into the index:\n        return Integer.compare(writer.docIDs[i], writer.docIDs[j]);\n      }\n    }.sort(0, Math.toIntExact(pointCount));\n    //System.out.println(\"LEN=\" + length + \" SWAP=\" + swapCount[0] + \" CMP=\" + cmpCount[0]);\n  }\n\n","sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int start, int length, int dim) {\n\n    assert pointCount < Integer.MAX_VALUE;\n    //int[] swapCount = new int[1];\n    //int[] cmpCount = new int[1];\n\n    // System.out.println(\"SORT length=\" + length);\n\n    // All buffered points are still in heap; just do in-place sort:\n    new IntroSorter() {\n      private final byte[] pivotPackedValue = new byte[bytesPerDim];\n      private int pivotDocID;\n\n      @Override\n      protected void setPivot(int i) {\n        pivotDocID = writer.docIDs[i];\n        int block = i / writer.valuesPerBlock;\n        int index = i % writer.valuesPerBlock;\n        System.arraycopy(writer.blocks.get(block), index*packedBytesLength+dim*bytesPerDim, pivotPackedValue, 0, bytesPerDim);\n      }\n\n      @Override\n      protected int comparePivot(int j) {\n        //cmpCount[0]++;\n        int block = j / writer.valuesPerBlock;\n        int index = j % writer.valuesPerBlock;\n        assert index >= 0: \"index=\" + index + \" j=\" + j;\n        int cmp = StringHelper.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), bytesPerDim*(index*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break\n        return Integer.compare(pivotDocID, writer.docIDs[j]);\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n      @Override\n      protected int compare(int i, int j) {\n        //cmpCount[0]++;\n        int blockI = i / writer.valuesPerBlock;\n        int dimI = i % writer.valuesPerBlock;\n        int blockJ = j / writer.valuesPerBlock;\n        int dimJ = j % writer.valuesPerBlock;\n        int cmp = StringHelper.compare(bytesPerDim, writer.blocks.get(blockI), bytesPerDim*(dimI*numDims+dim), writer.blocks.get(blockJ), bytesPerDim*(dimJ*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break by docID:\n\n        // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n        // can't matter at search time since we don't write ords into the index:\n        return Integer.compare(writer.docIDs[i], writer.docIDs[j]);\n      }\n    }.sort(start, start+length);\n    //System.out.println(\"LEN=\" + length + \" SWAP=\" + swapCount[0] + \" CMP=\" + cmpCount[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e","date":1464596999,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","sourceNew":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    // Tie-break by docID:\n\n    // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n    // can't matter at search time since we don't write ords into the index:\n    new MSBRadixSorter(bytesPerDim + Integer.BYTES) {\n\n      @Override\n      protected int byteAt(int i, int k) {\n        assert k >= 0;\n        if (k < bytesPerDim) {\n          // dim bytes\n          int block = i / writer.valuesPerBlock;\n          int index = i % writer.valuesPerBlock;\n          return writer.blocks.get(block)[index * packedBytesLength + dim * bytesPerDim + k] & 0xff;\n        } else {\n          // doc id\n          int s = 3 - (k - bytesPerDim);\n          return (writer.docIDs[i] >>> (s * 8)) & 0xff;\n        }\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n    }.sort(0, pointCount);\n  }\n\n","sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n\n    assert pointCount < Integer.MAX_VALUE;\n    //int[] swapCount = new int[1];\n    //int[] cmpCount = new int[1];\n\n    // System.out.println(\"SORT length=\" + length);\n\n    // All buffered points are still in heap; just do in-place sort:\n    new IntroSorter() {\n      private final byte[] pivotPackedValue = new byte[bytesPerDim];\n      private int pivotDocID;\n\n      @Override\n      protected void setPivot(int i) {\n        pivotDocID = writer.docIDs[i];\n        int block = i / writer.valuesPerBlock;\n        int index = i % writer.valuesPerBlock;\n        System.arraycopy(writer.blocks.get(block), index*packedBytesLength+dim*bytesPerDim, pivotPackedValue, 0, bytesPerDim);\n      }\n\n      @Override\n      protected int comparePivot(int j) {\n        //cmpCount[0]++;\n        int block = j / writer.valuesPerBlock;\n        int index = j % writer.valuesPerBlock;\n        assert index >= 0: \"index=\" + index + \" j=\" + j;\n        int cmp = StringHelper.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), bytesPerDim*(index*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break\n        return Integer.compare(pivotDocID, writer.docIDs[j]);\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n      @Override\n      protected int compare(int i, int j) {\n        //cmpCount[0]++;\n        int blockI = i / writer.valuesPerBlock;\n        int dimI = i % writer.valuesPerBlock;\n        int blockJ = j / writer.valuesPerBlock;\n        int dimJ = j % writer.valuesPerBlock;\n        int cmp = StringHelper.compare(bytesPerDim, writer.blocks.get(blockI), bytesPerDim*(dimI*numDims+dim), writer.blocks.get(blockJ), bytesPerDim*(dimJ*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break by docID:\n\n        // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n        // can't matter at search time since we don't write ords into the index:\n        return Integer.compare(writer.docIDs[i], writer.docIDs[j]);\n      }\n    }.sort(0, Math.toIntExact(pointCount));\n    //System.out.println(\"LEN=\" + length + \" SWAP=\" + swapCount[0] + \" CMP=\" + cmpCount[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da8a02bef7458089240404614139b53c9f875ec7","date":1464597207,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","sourceNew":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    // Tie-break by docID:\n\n    // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n    // can't matter at search time since we don't write ords into the index:\n    new MSBRadixSorter(bytesPerDim + Integer.BYTES) {\n\n      @Override\n      protected int byteAt(int i, int k) {\n        assert k >= 0;\n        if (k < bytesPerDim) {\n          // dim bytes\n          int block = i / writer.valuesPerBlock;\n          int index = i % writer.valuesPerBlock;\n          return writer.blocks.get(block)[index * packedBytesLength + dim * bytesPerDim + k] & 0xff;\n        } else {\n          // doc id\n          int s = 3 - (k - bytesPerDim);\n          return (writer.docIDs[i] >>> (s * 8)) & 0xff;\n        }\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n    }.sort(0, pointCount);\n  }\n\n","sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n\n    assert pointCount < Integer.MAX_VALUE;\n    //int[] swapCount = new int[1];\n    //int[] cmpCount = new int[1];\n\n    // System.out.println(\"SORT length=\" + length);\n\n    // All buffered points are still in heap; just do in-place sort:\n    new IntroSorter() {\n      private final byte[] pivotPackedValue = new byte[bytesPerDim];\n      private int pivotDocID;\n\n      @Override\n      protected void setPivot(int i) {\n        pivotDocID = writer.docIDs[i];\n        int block = i / writer.valuesPerBlock;\n        int index = i % writer.valuesPerBlock;\n        System.arraycopy(writer.blocks.get(block), index*packedBytesLength+dim*bytesPerDim, pivotPackedValue, 0, bytesPerDim);\n      }\n\n      @Override\n      protected int comparePivot(int j) {\n        //cmpCount[0]++;\n        int block = j / writer.valuesPerBlock;\n        int index = j % writer.valuesPerBlock;\n        assert index >= 0: \"index=\" + index + \" j=\" + j;\n        int cmp = StringHelper.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), bytesPerDim*(index*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break\n        return Integer.compare(pivotDocID, writer.docIDs[j]);\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n      @Override\n      protected int compare(int i, int j) {\n        //cmpCount[0]++;\n        int blockI = i / writer.valuesPerBlock;\n        int dimI = i % writer.valuesPerBlock;\n        int blockJ = j / writer.valuesPerBlock;\n        int dimJ = j % writer.valuesPerBlock;\n        int cmp = StringHelper.compare(bytesPerDim, writer.blocks.get(blockI), bytesPerDim*(dimI*numDims+dim), writer.blocks.get(blockJ), bytesPerDim*(dimJ*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break by docID:\n\n        // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n        // can't matter at search time since we don't write ords into the index:\n        return Integer.compare(writer.docIDs[i], writer.docIDs[j]);\n      }\n    }.sort(0, Math.toIntExact(pointCount));\n    //System.out.println(\"LEN=\" + length + \" SWAP=\" + swapCount[0] + \" CMP=\" + cmpCount[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b8ee93140fd0efef7e101786e3ed5160a700b5f","date":1464820111,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","sourceNew":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    // Tie-break by docID:\n\n    // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n    // can't matter at search time since we don't write ords into the index:\n    new MSBRadixSorter(bytesPerDim + Integer.BYTES) {\n\n      @Override\n      protected int byteAt(int i, int k) {\n        assert k >= 0;\n        if (k < bytesPerDim) {\n          // dim bytes\n          int block = i / writer.valuesPerBlock;\n          int index = i % writer.valuesPerBlock;\n          return writer.blocks.get(block)[index * packedBytesLength + dim * bytesPerDim + k] & 0xff;\n        } else {\n          // doc id\n          int s = 3 - (k - bytesPerDim);\n          return (writer.docIDs[i] >>> (s * 8)) & 0xff;\n        }\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n    }.sort(0, pointCount);\n  }\n\n","sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n\n    assert pointCount < Integer.MAX_VALUE;\n    //int[] swapCount = new int[1];\n    //int[] cmpCount = new int[1];\n\n    // System.out.println(\"SORT length=\" + length);\n\n    // All buffered points are still in heap; just do in-place sort:\n    new IntroSorter() {\n      private final byte[] pivotPackedValue = new byte[bytesPerDim];\n      private int pivotDocID;\n\n      @Override\n      protected void setPivot(int i) {\n        pivotDocID = writer.docIDs[i];\n        int block = i / writer.valuesPerBlock;\n        int index = i % writer.valuesPerBlock;\n        System.arraycopy(writer.blocks.get(block), index*packedBytesLength+dim*bytesPerDim, pivotPackedValue, 0, bytesPerDim);\n      }\n\n      @Override\n      protected int comparePivot(int j) {\n        //cmpCount[0]++;\n        int block = j / writer.valuesPerBlock;\n        int index = j % writer.valuesPerBlock;\n        assert index >= 0: \"index=\" + index + \" j=\" + j;\n        int cmp = StringHelper.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), bytesPerDim*(index*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break\n        return Integer.compare(pivotDocID, writer.docIDs[j]);\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n      @Override\n      protected int compare(int i, int j) {\n        //cmpCount[0]++;\n        int blockI = i / writer.valuesPerBlock;\n        int dimI = i % writer.valuesPerBlock;\n        int blockJ = j / writer.valuesPerBlock;\n        int dimJ = j % writer.valuesPerBlock;\n        int cmp = StringHelper.compare(bytesPerDim, writer.blocks.get(blockI), bytesPerDim*(dimI*numDims+dim), writer.blocks.get(blockJ), bytesPerDim*(dimJ*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break by docID:\n\n        // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n        // can't matter at search time since we don't write ords into the index:\n        return Integer.compare(writer.docIDs[i], writer.docIDs[j]);\n      }\n    }.sort(0, Math.toIntExact(pointCount));\n    //System.out.println(\"LEN=\" + length + \" SWAP=\" + swapCount[0] + \" CMP=\" + cmpCount[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","sourceNew":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    // Tie-break by docID:\n\n    // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n    // can't matter at search time since we don't write ords into the index:\n    new MSBRadixSorter(bytesPerDim + Integer.BYTES) {\n\n      @Override\n      protected int byteAt(int i, int k) {\n        assert k >= 0;\n        if (k < bytesPerDim) {\n          // dim bytes\n          int block = i / writer.valuesPerBlock;\n          int index = i % writer.valuesPerBlock;\n          return writer.blocks.get(block)[index * packedBytesLength + dim * bytesPerDim + k] & 0xff;\n        } else {\n          // doc id\n          int s = 3 - (k - bytesPerDim);\n          return (writer.docIDs[i] >>> (s * 8)) & 0xff;\n        }\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n    }.sort(0, pointCount);\n  }\n\n","sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n\n    assert pointCount < Integer.MAX_VALUE;\n    //int[] swapCount = new int[1];\n    //int[] cmpCount = new int[1];\n\n    // System.out.println(\"SORT length=\" + length);\n\n    // All buffered points are still in heap; just do in-place sort:\n    new IntroSorter() {\n      private final byte[] pivotPackedValue = new byte[bytesPerDim];\n      private int pivotDocID;\n\n      @Override\n      protected void setPivot(int i) {\n        pivotDocID = writer.docIDs[i];\n        int block = i / writer.valuesPerBlock;\n        int index = i % writer.valuesPerBlock;\n        System.arraycopy(writer.blocks.get(block), index*packedBytesLength+dim*bytesPerDim, pivotPackedValue, 0, bytesPerDim);\n      }\n\n      @Override\n      protected int comparePivot(int j) {\n        //cmpCount[0]++;\n        int block = j / writer.valuesPerBlock;\n        int index = j % writer.valuesPerBlock;\n        assert index >= 0: \"index=\" + index + \" j=\" + j;\n        int cmp = StringHelper.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), bytesPerDim*(index*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break\n        return Integer.compare(pivotDocID, writer.docIDs[j]);\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n      @Override\n      protected int compare(int i, int j) {\n        //cmpCount[0]++;\n        int blockI = i / writer.valuesPerBlock;\n        int dimI = i % writer.valuesPerBlock;\n        int blockJ = j / writer.valuesPerBlock;\n        int dimJ = j % writer.valuesPerBlock;\n        int cmp = StringHelper.compare(bytesPerDim, writer.blocks.get(blockI), bytesPerDim*(dimI*numDims+dim), writer.blocks.get(blockJ), bytesPerDim*(dimJ*numDims+dim));\n        if (cmp != 0) {\n          return cmp;\n        }\n\n        // Tie-break by docID:\n\n        // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n        // can't matter at search time since we don't write ords into the index:\n        return Integer.compare(writer.docIDs[i], writer.docIDs[j]);\n      }\n    }.sort(0, Math.toIntExact(pointCount));\n    //System.out.println(\"LEN=\" + length + \" SWAP=\" + swapCount[0] + \" CMP=\" + cmpCount[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"452aca01058c8a4e6827ff9096664dde4a1d9790","date":1543310809,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","sourceNew":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    sortHeapPointWriter(writer, pointCount, dim);\n  }\n\n","sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    // Tie-break by docID:\n\n    // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n    // can't matter at search time since we don't write ords into the index:\n    new MSBRadixSorter(bytesPerDim + Integer.BYTES) {\n\n      @Override\n      protected int byteAt(int i, int k) {\n        assert k >= 0;\n        if (k < bytesPerDim) {\n          // dim bytes\n          int block = i / writer.valuesPerBlock;\n          int index = i % writer.valuesPerBlock;\n          return writer.blocks.get(block)[index * packedBytesLength + dim * bytesPerDim + k] & 0xff;\n        } else {\n          // doc id\n          int s = 3 - (k - bytesPerDim);\n          return (writer.docIDs[i] >>> (s * 8)) & 0xff;\n        }\n      }\n\n      @Override\n      protected void swap(int i, int j) {\n        int docID = writer.docIDs[i];\n        writer.docIDs[i] = writer.docIDs[j];\n        writer.docIDs[j] = docID;\n\n        if (singleValuePerDoc == false) {\n          if (longOrds) {\n            long ord = writer.ordsLong[i];\n            writer.ordsLong[i] = writer.ordsLong[j];\n            writer.ordsLong[j] = ord;\n          } else {\n            int ord = writer.ords[i];\n            writer.ords[i] = writer.ords[j];\n            writer.ords[j] = ord;\n          }\n        }\n\n        byte[] blockI = writer.blocks.get(i / writer.valuesPerBlock);\n        int indexI = (i % writer.valuesPerBlock) * packedBytesLength;\n        byte[] blockJ = writer.blocks.get(j / writer.valuesPerBlock);\n        int indexJ = (j % writer.valuesPerBlock) * packedBytesLength;\n\n        // scratch1 = values[i]\n        System.arraycopy(blockI, indexI, scratch1, 0, packedBytesLength);\n        // values[i] = values[j]\n        System.arraycopy(blockJ, indexJ, blockI, indexI, packedBytesLength);\n        // values[j] = scratch1\n        System.arraycopy(scratch1, 0, blockJ, indexJ, packedBytesLength);\n      }\n\n    }.sort(0, pointCount);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5db3224bb6ba28cb735531b45593da725fa751d1","date":1547448966,"type":4,"author":"iverase","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sortHeapPointWriter(HeapPointWriter,int).mjava","sourceNew":null,"sourceOld":"  /** Sort the heap writer by the specified dim */\n  private void sortHeapPointWriter(final HeapPointWriter writer, int dim) {\n    final int pointCount = Math.toIntExact(this.pointCount);\n    sortHeapPointWriter(writer, pointCount, dim);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"452aca01058c8a4e6827ff9096664dde4a1d9790":["1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"da8a02bef7458089240404614139b53c9f875ec7":["1987c0002f396ce6d6dada94c6773d6ba0e03f50","1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"5db3224bb6ba28cb735531b45593da725fa751d1":["452aca01058c8a4e6827ff9096664dde4a1d9790"],"1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e":["1987c0002f396ce6d6dada94c6773d6ba0e03f50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1987c0002f396ce6d6dada94c6773d6ba0e03f50":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":["1987c0002f396ce6d6dada94c6773d6ba0e03f50","1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["1987c0002f396ce6d6dada94c6773d6ba0e03f50","1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5db3224bb6ba28cb735531b45593da725fa751d1"]},"commit2Childs":{"452aca01058c8a4e6827ff9096664dde4a1d9790":["5db3224bb6ba28cb735531b45593da725fa751d1"],"da8a02bef7458089240404614139b53c9f875ec7":[],"5db3224bb6ba28cb735531b45593da725fa751d1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e":["452aca01058c8a4e6827ff9096664dde4a1d9790","da8a02bef7458089240404614139b53c9f875ec7","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1987c0002f396ce6d6dada94c6773d6ba0e03f50"],"1987c0002f396ce6d6dada94c6773d6ba0e03f50":["da8a02bef7458089240404614139b53c9f875ec7","1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["da8a02bef7458089240404614139b53c9f875ec7","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}