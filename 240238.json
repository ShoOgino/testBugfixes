{"path":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","commits":[{"id":"c084e47df29de3330311d69dabf515ceaa989512","date":1279030906,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"/dev/null","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"/dev/null","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(newField(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(newField(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"150488c1317972164a9a824be05b1ba2ba0fc68c","date":1284316090,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(newField(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(newField(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a186ae8733084223c22044e935e4ef848a143d1","date":1289694819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n\n    LogMergePolicy lmp = (LogMergePolicy) writer.w.getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      // reduce risk of too many open files\n      lmp.setMergeFactor(5);\n    }\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n\n    LogMergePolicy lmp = (LogMergePolicy) writer.w.getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      // reduce risk of too many open files\n      lmp.setMergeFactor(5);\n    }\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"35fccc6fabc57267490c7aef14b9e52c67feef82","date":1290263266,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    _TestUtil.reduceOpenFiles(writer.w);\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n\n    LogMergePolicy lmp = (LogMergePolicy) writer.w.getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      // reduce risk of too many open files\n      lmp.setMergeFactor(5);\n    }\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f59cacf51112a3af6d01ca16002ca03feec1c93","date":1291064479,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    _TestUtil.reduceOpenFiles(writer.w);\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    int minCount = 0;\n    int maxCount = 0;\n\n    while(true) {\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        break;\n      }\n\n      // try again\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    _TestUtil.reduceOpenFiles(writer.w);\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e66a3ed6cd2597790ee09a40e908389d32c38c99","date":1291108922,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      _TestUtil.reduceOpenFiles(writer.w);\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    _TestUtil.reduceOpenFiles(writer.w);\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    int minCount = 0;\n    int maxCount = 0;\n\n    while(true) {\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        break;\n      }\n\n      // try again\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      _TestUtil.reduceOpenFiles(writer.w);\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n\n    LogMergePolicy lmp = (LogMergePolicy) writer.w.getMergePolicy();\n    if (lmp.getMergeFactor() > 5) {\n      // reduce risk of too many open files\n      lmp.setMergeFactor(5);\n    }\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n    \n    for (int d = minId; d <= maxId; d++) {\n      idField.setValue(pad(d));\n      int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      randField.setValue(pad(r));\n      bodyField.setValue(\"body\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      _TestUtil.reduceOpenFiles(writer.w);\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n    .setOpenMode(OpenMode.CREATE));\n    \n    for (int d = minId; d <= maxId; d++) {\n      Document doc = new Document();\n      doc.add(new Field(\"id\", pad(d), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand\n          .nextInt(Integer.MAX_VALUE);\n      if (index.maxR < r) {\n        index.maxR = r;\n      }\n      if (r < index.minR) {\n        index.minR = r;\n      }\n      doc.add(new Field(\"rand\", pad(r), Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      doc.add(new Field(\"body\", \"body\", Field.Store.YES,\n          Field.Index.NOT_ANALYZED));\n      writer.addDocument(doc);\n    }\n    \n    IndexReader ir = writer.getReader();\n    writer.close();\n    return ir;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      _TestUtil.reduceOpenFiles(writer.w);\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      _TestUtil.reduceOpenFiles(writer.w);\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      _TestUtil.reduceOpenFiles(writer.w);\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", StringField.TYPE_STORED);\n    Field randField = newField(random, \"rand\", \"\", StringField.TYPE_STORED);\n    Field bodyField = newField(random, \"body\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field randField = newField(random, \"rand\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n    Field bodyField = newField(random, \"body\", \"\", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter#build(Random,TestIndex).mjava","sourceNew":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", StringField.TYPE_STORED);\n    Field randField = newField(random, \"rand\", \"\", StringField.TYPE_STORED);\n    Field bodyField = newField(random, \"body\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","sourceOld":"  private static IndexReader build(Random random, TestIndex index) throws IOException {\n    /* build an index */\n    \n    Document doc = new Document();\n    Field idField = newField(random, \"id\", \"\", StringField.TYPE_STORED);\n    Field randField = newField(random, \"rand\", \"\", StringField.TYPE_STORED);\n    Field bodyField = newField(random, \"body\", \"\", StringField.TYPE_UNSTORED);\n    doc.add(idField);\n    doc.add(randField);\n    doc.add(bodyField);\n\n    RandomIndexWriter writer = new RandomIndexWriter(random, index.index, \n                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));\n    _TestUtil.reduceOpenFiles(writer.w);\n\n    while(true) {\n\n      int minCount = 0;\n      int maxCount = 0;\n\n      for (int d = minId; d <= maxId; d++) {\n        idField.setValue(pad(d));\n        int r = index.allowNegativeRandomInts ? random.nextInt() : random\n          .nextInt(Integer.MAX_VALUE);\n        if (index.maxR < r) {\n          index.maxR = r;\n          maxCount = 1;\n        } else if (index.maxR == r) {\n          maxCount++;\n        }\n\n        if (r < index.minR) {\n          index.minR = r;\n          minCount = 1;\n        } else if (r == index.minR) {\n          minCount++;\n        }\n        randField.setValue(pad(r));\n        bodyField.setValue(\"body\");\n        writer.addDocument(doc);\n      }\n\n      if (minCount == 1 && maxCount == 1) {\n        // our subclasses rely on only 1 doc having the min or\n        // max, so, we loop until we satisfy that.  it should be\n        // exceedingly rare (Yonik calculates 1 in ~429,000)\n        // times) that this loop requires more than one try:\n        IndexReader ir = writer.getReader();\n        writer.close();\n        return ir;\n      }\n\n      // try again\n      writer.deleteAll();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["c084e47df29de3330311d69dabf515ceaa989512"],"e66a3ed6cd2597790ee09a40e908389d32c38c99":["3f59cacf51112a3af6d01ca16002ca03feec1c93"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","e66a3ed6cd2597790ee09a40e908389d32c38c99"],"c19f985e36a65cc969e8e564fe337a0d41512075":["e66a3ed6cd2597790ee09a40e908389d32c38c99"],"c084e47df29de3330311d69dabf515ceaa989512":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["c19f985e36a65cc969e8e564fe337a0d41512075"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c19f985e36a65cc969e8e564fe337a0d41512075"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","4b103252dee6afa1b6d7a622c773d178788eb85a"],"2a186ae8733084223c22044e935e4ef848a143d1":["150488c1317972164a9a824be05b1ba2ba0fc68c"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["c084e47df29de3330311d69dabf515ceaa989512","15bbd254c1506df5299c4df8c148262c7bd6301e"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["150488c1317972164a9a824be05b1ba2ba0fc68c","2a186ae8733084223c22044e935e4ef848a143d1"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c084e47df29de3330311d69dabf515ceaa989512"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3f59cacf51112a3af6d01ca16002ca03feec1c93":["35fccc6fabc57267490c7aef14b9e52c67feef82"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c19f985e36a65cc969e8e564fe337a0d41512075","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"35fccc6fabc57267490c7aef14b9e52c67feef82":["2a186ae8733084223c22044e935e4ef848a143d1"],"150488c1317972164a9a824be05b1ba2ba0fc68c":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"3bb13258feba31ab676502787ab2e1779f129b7a":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","e66a3ed6cd2597790ee09a40e908389d32c38c99"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"e66a3ed6cd2597790ee09a40e908389d32c38c99":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c19f985e36a65cc969e8e564fe337a0d41512075","3bb13258feba31ab676502787ab2e1779f129b7a"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["150488c1317972164a9a824be05b1ba2ba0fc68c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c19f985e36a65cc969e8e564fe337a0d41512075":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"c084e47df29de3330311d69dabf515ceaa989512":["15bbd254c1506df5299c4df8c148262c7bd6301e","4b103252dee6afa1b6d7a622c773d178788eb85a","5f4e87790277826a2aea119328600dfb07761f32"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"79c2cb24929f2649a8875fb629086171f914d5ce":[],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c084e47df29de3330311d69dabf515ceaa989512","5f4e87790277826a2aea119328600dfb07761f32"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","1509f151d7692d84fae414b2b799ac06ba60fcb4","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["1f653cfcf159baeaafe5d01682a911e95bba4012","3242a09f703274d3b9283f2064a1a33064b53a1b"],"2a186ae8733084223c22044e935e4ef848a143d1":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","35fccc6fabc57267490c7aef14b9e52c67feef82"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["3bb13258feba31ab676502787ab2e1779f129b7a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"962d04139994fce5193143ef35615499a9a96d78":[],"3f59cacf51112a3af6d01ca16002ca03feec1c93":["e66a3ed6cd2597790ee09a40e908389d32c38c99"],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"35fccc6fabc57267490c7aef14b9e52c67feef82":["3f59cacf51112a3af6d01ca16002ca03feec1c93"],"150488c1317972164a9a824be05b1ba2ba0fc68c":["2a186ae8733084223c22044e935e4ef848a143d1","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["79c2cb24929f2649a8875fb629086171f914d5ce","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}