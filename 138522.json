{"path":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        BitSet bs = new BitSet(reader.maxDoc());\n        bs.set(0, reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        BitSet bs = new BitSet(reader.maxDoc());\n        bs.set(0, reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dadf0f3286a34a0fee6e788ffce88624bf2984e","date":1294260428,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(ReaderContext context) throws IOException {\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        BitSet bs = new BitSet(reader.maxDoc());\n        bs.set(0, reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a10b98ef1ef4bf9e38d2e07a9e425a916afa8705","date":1294747166,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(ReaderContext context) throws IOException {\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        BitSet bs = new BitSet(reader.maxDoc());\n        bs.set(0, reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n        BitSet bs = new BitSet(reader.maxDoc());\n        bs.set(0, reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6620df8541b174097b1133a4fc370adb2e570524","date":1319544675,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6fff8f4b218bd0626afcdce82027bafeb84a50a4","date":1327229950,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader().maxDoc());\n        bs.set(0, context.reader().maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader().maxDoc());\n        bs.set(0, context.reader().maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader.maxDoc());\n        bs.set(0, context.reader.maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSort#testTopDocsScores().mjava","sourceNew":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader().maxDoc());\n        bs.set(0, context.reader().maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","sourceOld":"  public void testTopDocsScores() throws Exception {\n\n    // There was previously a bug in FieldSortedHitQueue.maxscore when only a single\n    // doc was added.  That is what the following tests for.\n    Sort sort = new Sort();\n    int nDocs=10;\n\n    // try to pick a query that will result in an unnormalized\n    // score greater than 1 to test for correct normalization\n    final TopDocs docs1 = full.search(queryE,null,nDocs,sort);\n\n    // a filter that only allows through the first hit\n    Filter filt = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet (AtomicReaderContext context, Bits acceptDocs) {\n        assertNull(\"acceptDocs should be null, as we have no deletions\", acceptDocs);\n        BitSet bs = new BitSet(context.reader().maxDoc());\n        bs.set(0, context.reader().maxDoc());\n        bs.set(docs1.scoreDocs[0].doc);\n        return new DocIdBitSet(bs);\n      }\n    };\n\n    TopDocs docs2 = full.search(queryE, filt, nDocs, sort);\n    \n    assertEquals(docs1.scoreDocs[0].score, docs2.scoreDocs[0].score, 1e-6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6620df8541b174097b1133a4fc370adb2e570524":["a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["9454a6510e2db155fb01faa5c049b06ece95fab9","a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6fff8f4b218bd0626afcdce82027bafeb84a50a4":["6620df8541b174097b1133a4fc370adb2e570524"],"a10b98ef1ef4bf9e38d2e07a9e425a916afa8705":["2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["9454a6510e2db155fb01faa5c049b06ece95fab9","a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["6620df8541b174097b1133a4fc370adb2e570524","6fff8f4b218bd0626afcdce82027bafeb84a50a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"6620df8541b174097b1133a4fc370adb2e570524":["6fff8f4b218bd0626afcdce82027bafeb84a50a4","5cab9a86bd67202d20b6adc463008c8e982b070a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"6fff8f4b218bd0626afcdce82027bafeb84a50a4":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a10b98ef1ef4bf9e38d2e07a9e425a916afa8705":["6620df8541b174097b1133a4fc370adb2e570524","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["29ef99d61cda9641b6250bf9567329a6e65f901d","2dadf0f3286a34a0fee6e788ffce88624bf2984e","868da859b43505d9d2a023bfeae6dd0c795f5295"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}