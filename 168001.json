{"path":"lucene/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","commits":[{"id":"505bff044e47a553f461b6f4484d1d08faf4ac85","date":1420728783,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException If there is a low-level I/O error\n   */\n  public void split(IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      // pass the subreaders directly, as our wrapper's numDocs/hasDeletetions are not up-to-date\n      final List<? extends FakeDeleteLeafIndexReader> sr = input.getSequentialSubReaders();\n      w.addIndexes(sr.toArray(new CodecReader[sr.size()])); // TODO: maybe take List<IR> here?\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException If there is a low-level I/O error\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      // pass the subreaders directly, as our wrapper's numDocs/hasDeletetions are not up-to-date\n      final List<? extends FakeDeleteLeafIndexReader> sr = input.getSequentialSubReaders();\n      w.addIndexes(sr.toArray(new LeafReader[sr.size()])); // TODO: maybe take List<IR> here?\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"505bff044e47a553f461b6f4484d1d08faf4ac85":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["505bff044e47a553f461b6f4484d1d08faf4ac85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["505bff044e47a553f461b6f4484d1d08faf4ac85"],"505bff044e47a553f461b6f4484d1d08faf4ac85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}