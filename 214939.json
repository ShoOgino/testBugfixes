{"path":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","commits":[{"id":"415bbbe7da8065dd3c477bdc3c703c6425622998","date":1485393793,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    del(\"*:*\");\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    long seed = random().nextLong(); // seed for randomization within the threads\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"598b5d23aa7c9732bf473c21a9cd309c44599394","date":1485530378,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    del(\"*:*\");\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    long seed = random().nextLong(); // seed for randomization within the threads\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5048c558f8802f1689d38203111379406b171418","date":1486467652,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","sourceNew":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    long seed = random().nextLong(); // seed for randomization within the threads\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","sourceOld":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    del(\"*:*\");\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    long seed = random().nextLong(); // seed for randomization within the threads\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2795aeb0b4c10d1588f672d3d5ac7a394fc8461","date":1487476295,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","sourceNew":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","sourceOld":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    long seed = random().nextLong(); // seed for randomization within the threads\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e11e54ce6015434b2aaadb49ca5071dbe7be50c","date":1489404389,"type":5,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#reorderedDBQsUsingUpdatedValueFromADroppedUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#testDBQUsingUpdatedFieldFromDroppedUpdate().mjava","sourceNew":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void reorderedDBQsUsingUpdatedValueFromADroppedUpdate() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"reorderedDBQsUsingUpdatedValueFromADroppedUpdate: This test passed fine...\");\n  }\n\n","sourceOld":"  /*\n   * Situation:\n   * add(id=1,inpfield=12,title=mytitle,version=1)\n   * inp(id=1,inpfield=13,prevVersion=1,version=2) // timeout indefinitely\n   * inp(id=1,inpfield=14,prevVersion=2,version=3) // will wait till timeout, and then fetch a \"not found\" from leader\n   * dbq(\"inp:14\",version=4)\n   */\n  private void testDBQUsingUpdatedFieldFromDroppedUpdate() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"id_i\", 1, \"inplace_updatable_float\", 12, \"title_s\", \"mytitle\"));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1))); // delay indefinitely\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularDeleteByQueryRequest(\"inplace_updatable_float:14\"));\n\n    // The second request will be delayed very very long, so that the next update actually gives up waiting for this\n    // and fetches a full update from the leader.\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 2, 8000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 12 secs\", threadpool.awaitTermination(12, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (testDBQUsingUpdatedFieldFromDroppedUpdate): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertNull(client.getById(\"1\", params(\"distrib\", \"false\")));\n    }\n\n    log.info(\"testDBQUsingUpdatedFieldFromDroppedUpdate: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"598b5d23aa7c9732bf473c21a9cd309c44599394":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","415bbbe7da8065dd3c477bdc3c703c6425622998"],"2e11e54ce6015434b2aaadb49ca5071dbe7be50c":["c2795aeb0b4c10d1588f672d3d5ac7a394fc8461"],"c2795aeb0b4c10d1588f672d3d5ac7a394fc8461":["5048c558f8802f1689d38203111379406b171418"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5048c558f8802f1689d38203111379406b171418":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2e11e54ce6015434b2aaadb49ca5071dbe7be50c"]},"commit2Childs":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["598b5d23aa7c9732bf473c21a9cd309c44599394","5048c558f8802f1689d38203111379406b171418"],"598b5d23aa7c9732bf473c21a9cd309c44599394":[],"2e11e54ce6015434b2aaadb49ca5071dbe7be50c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["415bbbe7da8065dd3c477bdc3c703c6425622998","598b5d23aa7c9732bf473c21a9cd309c44599394"],"c2795aeb0b4c10d1588f672d3d5ac7a394fc8461":["2e11e54ce6015434b2aaadb49ca5071dbe7be50c"],"5048c558f8802f1689d38203111379406b171418":["c2795aeb0b4c10d1588f672d3d5ac7a394fc8461"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["598b5d23aa7c9732bf473c21a9cd309c44599394","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}