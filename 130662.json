{"path":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","commits":[{"id":"232252bc7056b698c1e1c550f4b97a9a3c00e520","date":1372943634,"type":0,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  //\n  // Since longs blob is fixed length, when these two are 'comparable'\n  // i.e. when every value in long[] fits the same ordering, the smaller one \n  // will be the result.\n  //\n  // NOTE: only long[] is 'shared', i.e. after sharing common value,\n  // the output of smaller one will be a all-zero long[] with original byte[] blob.\n  //\n  // nocommit: Builder.add() doesn't immediatelly consumes the output data, \n  // which means, the longs after one add() should all be deeply copied \n  // instead of being reused? quite hairly to detect it here, so the caller \n  // must be careful about this.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs != null;\n    assert t2.longs != null;\n    assert t1.longs.length == t2.longs.length;\n\n    long accum = 0;\n    long[] longs1 = t1.longs, longs2 = t2.longs;\n    int pos = 0;\n    boolean order = true;\n    TempMetaData ret;\n\n    while (pos < longsSize && longs1[pos] == longs2[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {\n      // unequal\n      order = (longs1[pos] > longs2[pos]);\n      if (order) {\n        // check whether strictly longs1 >= longs2 \n        while (pos < longsSize && longs1[pos] >= longs2[pos]) {\n          accum += longs2[pos];\n          pos++;\n        }\n      } else {\n        // check whether strictly longs1 <= longs2 \n        while (pos < longsSize && longs1[pos] <= longs2[pos]) {\n          accum += longs1[pos];\n          pos++;\n        }\n      }\n      if (pos < longsSize || accum == 0) {\n        ret = NO_OUTPUT;\n      } else if (order) {\n        ret = new TempMetaData(longs2, null);\n      } else {\n        ret = new TempMetaData(longs1, null);\n      }\n    } else {\n      // equal\n      if (t1.bytes!= null && Arrays.equals(t1.bytes, t2.bytes)) {  // all fields are equal\n        ret = t1;\n      } else if (accum == 0) { // all zero case\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(longs1, null);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a509b6df968a74c38a0528f5bf6ea26f503b756","date":1373188457,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","sourceNew":"  @Override\n  //\n  // Since longs blob is fixed length, when these two are 'comparable'\n  // i.e. when every value in long[] fits the same ordering, the smaller one \n  // will be the result.\n  //\n  // NOTE: only long[] is 'shared', i.e. if there are two byte[] on the successive\n  // arcs, only the last byte[] is valid. (this somewhat saves nodes, but might affect\n  // compression, since we'll have to load metadata block for other terms as well, currently,\n  // we don't support this)\n  //\n  // nocommit: get the byte[] from smaller one as well, so that\n  // byte[] is actually inherited\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs != null;\n    assert t2.longs != null;\n    assert t1.longs.length == t2.longs.length;\n\n    long accum = 0;\n    long[] longs1 = t1.longs, longs2 = t2.longs;\n    int pos = 0;\n    boolean order = true;\n    TempMetaData ret;\n\n    while (pos < longsSize && longs1[pos] == longs2[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {\n      // unequal\n      order = (longs1[pos] > longs2[pos]);\n      if (order) {\n        // check whether strictly longs1 >= longs2 \n        while (pos < longsSize && longs1[pos] >= longs2[pos]) {\n          accum += longs2[pos];\n          pos++;\n        }\n      } else {\n        // check whether strictly longs1 <= longs2 \n        while (pos < longsSize && longs1[pos] <= longs2[pos]) {\n          accum += longs1[pos];\n          pos++;\n        }\n      }\n      if (pos < longsSize || accum == 0) {\n        ret = NO_OUTPUT;\n      } else if (order) {\n        ret = new TempMetaData(longs2, null, 0, -1);\n      } else {\n        ret = new TempMetaData(longs1, null, 0, -1);\n      }\n    } else {\n      // equal\n      if (t1.bytes!= null && bytesEqual(t1, t2) && statsEqual(t1, t2)) {  // all fields are equal\n        ret = t1;\n      } else if (accum == 0) { // all zero case\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(longs1, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","sourceOld":"  @Override\n  //\n  // Since longs blob is fixed length, when these two are 'comparable'\n  // i.e. when every value in long[] fits the same ordering, the smaller one \n  // will be the result.\n  //\n  // NOTE: only long[] is 'shared', i.e. after sharing common value,\n  // the output of smaller one will be a all-zero long[] with original byte[] blob.\n  //\n  // nocommit: Builder.add() doesn't immediatelly consumes the output data, \n  // which means, the longs after one add() should all be deeply copied \n  // instead of being reused? quite hairly to detect it here, so the caller \n  // must be careful about this.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs != null;\n    assert t2.longs != null;\n    assert t1.longs.length == t2.longs.length;\n\n    long accum = 0;\n    long[] longs1 = t1.longs, longs2 = t2.longs;\n    int pos = 0;\n    boolean order = true;\n    TempMetaData ret;\n\n    while (pos < longsSize && longs1[pos] == longs2[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {\n      // unequal\n      order = (longs1[pos] > longs2[pos]);\n      if (order) {\n        // check whether strictly longs1 >= longs2 \n        while (pos < longsSize && longs1[pos] >= longs2[pos]) {\n          accum += longs2[pos];\n          pos++;\n        }\n      } else {\n        // check whether strictly longs1 <= longs2 \n        while (pos < longsSize && longs1[pos] <= longs2[pos]) {\n          accum += longs1[pos];\n          pos++;\n        }\n      }\n      if (pos < longsSize || accum == 0) {\n        ret = NO_OUTPUT;\n      } else if (order) {\n        ret = new TempMetaData(longs2, null);\n      } else {\n        ret = new TempMetaData(longs1, null);\n      }\n    } else {\n      // equal\n      if (t1.bytes!= null && Arrays.equals(t1.bytes, t2.bytes)) {  // all fields are equal\n        ret = t1;\n      } else if (accum == 0) { // all zero case\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(longs1, null);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f962e7e670c8f2b5f205969d2ab166dd92d4a5ce","date":1373299712,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","sourceNew":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] is 'shared', byte[] and term stats simply act \n  // as 'attachment': when walking on the FST, if we see two byte[] on \n  // successive arcs, only the second byte[] is valid. \n  //\n  // Therefore, during building, we always make sure that, for most nodes, \n  // the first output is 'pushed' one step towards root and reduced to \n  // be NO_OUTPUT, so that we get rid of the 'all zero' long[], and netly\n  // get smaller amount of total outputs. \n  //\n  // However, when decoding, terms might have to load redundant byte[] blob.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] longs1 = t1.longs, longs2 = t2.longs;\n    int pos = 0;\n    boolean smaller = true;\n    TempMetaData ret;\n\n    while (pos < longsSize && longs1[pos] == longs2[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {\n      // unequal\n      smaller = (longs1[pos] < longs2[pos]);\n      if (smaller) {\n        // check whether strictly longs1 <= longs2 \n        while (pos < longsSize && longs1[pos] <= longs2[pos]) {\n          pos++;\n        }\n      } else {\n        // check whether strictly longs1 >= longs2 \n        while (pos < longsSize && longs1[pos] >= longs2[pos]) {\n          pos++;\n        }\n      }\n      if (pos < longsSize) {  // not fully 'comparable'\n        ret = NO_OUTPUT;\n      } else if (smaller) {\n        ret = t1;\n      } else {\n        ret = t2;\n      }\n    } else {\n      // equal, we won't check byte[] and docFreq\n      ret = t1;\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","sourceOld":"  @Override\n  //\n  // Since longs blob is fixed length, when these two are 'comparable'\n  // i.e. when every value in long[] fits the same ordering, the smaller one \n  // will be the result.\n  //\n  // NOTE: only long[] is 'shared', i.e. if there are two byte[] on the successive\n  // arcs, only the last byte[] is valid. (this somewhat saves nodes, but might affect\n  // compression, since we'll have to load metadata block for other terms as well, currently,\n  // we don't support this)\n  //\n  // nocommit: get the byte[] from smaller one as well, so that\n  // byte[] is actually inherited\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs != null;\n    assert t2.longs != null;\n    assert t1.longs.length == t2.longs.length;\n\n    long accum = 0;\n    long[] longs1 = t1.longs, longs2 = t2.longs;\n    int pos = 0;\n    boolean order = true;\n    TempMetaData ret;\n\n    while (pos < longsSize && longs1[pos] == longs2[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {\n      // unequal\n      order = (longs1[pos] > longs2[pos]);\n      if (order) {\n        // check whether strictly longs1 >= longs2 \n        while (pos < longsSize && longs1[pos] >= longs2[pos]) {\n          accum += longs2[pos];\n          pos++;\n        }\n      } else {\n        // check whether strictly longs1 <= longs2 \n        while (pos < longsSize && longs1[pos] <= longs2[pos]) {\n          accum += longs1[pos];\n          pos++;\n        }\n      }\n      if (pos < longsSize || accum == 0) {\n        ret = NO_OUTPUT;\n      } else if (order) {\n        ret = new TempMetaData(longs2, null, 0, -1);\n      } else {\n        ret = new TempMetaData(longs1, null, 0, -1);\n      }\n    } else {\n      // equal\n      if (t1.bytes!= null && bytesEqual(t1, t2) && statsEqual(t1, t2)) {  // all fields are equal\n        ret = t1;\n      } else if (accum == 0) { // all zero case\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(longs1, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0bb367a7107f7ab6bfbb3d504d5f17f9a452e26b","date":1373471768,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","sourceNew":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] part is 'shared' and pushed towards root.\n  // byte[] and term stats will be on deeper arcs.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] min = t1.longs, max = t2.longs;\n    int pos = 0;\n    TempMetaData ret;\n\n    while (pos < longsSize && min[pos] == max[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {  // unequal long[]\n      if (min[pos] > max[pos]) {\n        min = t2.longs;\n        max = t1.longs;\n      }\n      // check whether strictly smaller\n      while (pos < longsSize && min[pos] <= max[pos]) {\n        pos++;\n      }\n      if (pos < longsSize || allZero(min)) {  // not comparable or all-zero\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    } else {  // equal long[]\n      if (statsEqual(t1, t2) && (t1.bytes == null || bytesEqual(t1, t2))) {\n        ret = t1;\n      } else if (allZero(min)) {\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","sourceOld":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] is 'shared', byte[] and term stats simply act \n  // as 'attachment': when walking on the FST, if we see two byte[] on \n  // successive arcs, only the second byte[] is valid. \n  //\n  // Therefore, during building, we always make sure that, for most nodes, \n  // the first output is 'pushed' one step towards root and reduced to \n  // be NO_OUTPUT, so that we get rid of the 'all zero' long[], and netly\n  // get smaller amount of total outputs. \n  //\n  // However, when decoding, terms might have to load redundant byte[] blob.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] longs1 = t1.longs, longs2 = t2.longs;\n    int pos = 0;\n    boolean smaller = true;\n    TempMetaData ret;\n\n    while (pos < longsSize && longs1[pos] == longs2[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {\n      // unequal\n      smaller = (longs1[pos] < longs2[pos]);\n      if (smaller) {\n        // check whether strictly longs1 <= longs2 \n        while (pos < longsSize && longs1[pos] <= longs2[pos]) {\n          pos++;\n        }\n      } else {\n        // check whether strictly longs1 >= longs2 \n        while (pos < longsSize && longs1[pos] >= longs2[pos]) {\n          pos++;\n        }\n      }\n      if (pos < longsSize) {  // not fully 'comparable'\n        ret = NO_OUTPUT;\n      } else if (smaller) {\n        ret = t1;\n      } else {\n        ret = t2;\n      }\n    } else {\n      // equal, we won't check byte[] and docFreq\n      ret = t1;\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd9f4b62b5707a45b44bd7d63ef9448c5eb6efaa","date":1373991484,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","sourceNew":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] part is 'shared' and pushed towards root.\n  // byte[] and term stats will be on deeper arcs.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] min = t1.longs, max = t2.longs;\n    int pos = 0;\n    TempMetaData ret;\n\n    while (pos < longsSize && min[pos] == max[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {  // unequal long[]\n      if (min[pos] > max[pos]) {\n        min = t2.longs;\n        max = t1.longs;\n      }\n      // check whether strictly smaller\n      while (pos < longsSize && min[pos] <= max[pos]) {\n        pos++;\n      }\n      if (pos < longsSize || allZero(min)) {  // not comparable or all-zero\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    } else {  // equal long[]\n      if (statsEqual(t1, t2) && bytesEqual(t1, t2)) {\n        ret = t1;\n      } else if (allZero(min)) {\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","sourceOld":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] part is 'shared' and pushed towards root.\n  // byte[] and term stats will be on deeper arcs.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] min = t1.longs, max = t2.longs;\n    int pos = 0;\n    TempMetaData ret;\n\n    while (pos < longsSize && min[pos] == max[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {  // unequal long[]\n      if (min[pos] > max[pos]) {\n        min = t2.longs;\n        max = t1.longs;\n      }\n      // check whether strictly smaller\n      while (pos < longsSize && min[pos] <= max[pos]) {\n        pos++;\n      }\n      if (pos < longsSize || allZero(min)) {  // not comparable or all-zero\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    } else {  // equal long[]\n      if (statsEqual(t1, t2) && (t1.bytes == null || bytesEqual(t1, t2))) {\n        ret = t1;\n      } else if (allZero(min)) {\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e6904bcc97d8afa27bd72ee29ac01e525e327ad4","date":1377958787,"type":5,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempTermOutputs#common(TempMetaData,TempMetaData).mjava","sourceNew":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] part is 'shared' and pushed towards root.\n  // byte[] and term stats will be on deeper arcs.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] min = t1.longs, max = t2.longs;\n    int pos = 0;\n    TempMetaData ret;\n\n    while (pos < longsSize && min[pos] == max[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {  // unequal long[]\n      if (min[pos] > max[pos]) {\n        min = t2.longs;\n        max = t1.longs;\n      }\n      // check whether strictly smaller\n      while (pos < longsSize && min[pos] <= max[pos]) {\n        pos++;\n      }\n      if (pos < longsSize || allZero(min)) {  // not comparable or all-zero\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    } else {  // equal long[]\n      if (statsEqual(t1, t2) && bytesEqual(t1, t2)) {\n        ret = t1;\n      } else if (allZero(min)) {\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","sourceOld":"  @Override\n  //\n  // The return value will be the smaller one, when these two are \n  // 'comparable', i.e. every value in long[] fits the same ordering.\n  //\n  // NOTE: \n  // Only long[] part is 'shared' and pushed towards root.\n  // byte[] and term stats will be on deeper arcs.\n  //\n  public TempMetaData common(TempMetaData t1, TempMetaData t2) {\n    if (DEBUG) System.out.print(\"common(\"+t1+\", \"+t2+\") = \");\n    if (t1 == NO_OUTPUT || t2 == NO_OUTPUT) {\n      if (DEBUG) System.out.println(\"ret:\"+NO_OUTPUT);\n      return NO_OUTPUT;\n    }\n    assert t1.longs.length == t2.longs.length;\n\n    long[] min = t1.longs, max = t2.longs;\n    int pos = 0;\n    TempMetaData ret;\n\n    while (pos < longsSize && min[pos] == max[pos]) {\n      pos++;\n    }\n    if (pos < longsSize) {  // unequal long[]\n      if (min[pos] > max[pos]) {\n        min = t2.longs;\n        max = t1.longs;\n      }\n      // check whether strictly smaller\n      while (pos < longsSize && min[pos] <= max[pos]) {\n        pos++;\n      }\n      if (pos < longsSize || allZero(min)) {  // not comparable or all-zero\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    } else {  // equal long[]\n      if (statsEqual(t1, t2) && bytesEqual(t1, t2)) {\n        ret = t1;\n      } else if (allZero(min)) {\n        ret = NO_OUTPUT;\n      } else {\n        ret = new TempMetaData(min, null, 0, -1);\n      }\n    }\n    if (DEBUG) System.out.println(\"ret:\"+ret);\n    return ret;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0bb367a7107f7ab6bfbb3d504d5f17f9a452e26b":["f962e7e670c8f2b5f205969d2ab166dd92d4a5ce"],"bd9f4b62b5707a45b44bd7d63ef9448c5eb6efaa":["0bb367a7107f7ab6bfbb3d504d5f17f9a452e26b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f962e7e670c8f2b5f205969d2ab166dd92d4a5ce":["3a509b6df968a74c38a0528f5bf6ea26f503b756"],"232252bc7056b698c1e1c550f4b97a9a3c00e520":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e6904bcc97d8afa27bd72ee29ac01e525e327ad4":["bd9f4b62b5707a45b44bd7d63ef9448c5eb6efaa"],"3a509b6df968a74c38a0528f5bf6ea26f503b756":["232252bc7056b698c1e1c550f4b97a9a3c00e520"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"0bb367a7107f7ab6bfbb3d504d5f17f9a452e26b":["bd9f4b62b5707a45b44bd7d63ef9448c5eb6efaa"],"bd9f4b62b5707a45b44bd7d63ef9448c5eb6efaa":["e6904bcc97d8afa27bd72ee29ac01e525e327ad4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["232252bc7056b698c1e1c550f4b97a9a3c00e520","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f962e7e670c8f2b5f205969d2ab166dd92d4a5ce":["0bb367a7107f7ab6bfbb3d504d5f17f9a452e26b"],"232252bc7056b698c1e1c550f4b97a9a3c00e520":["3a509b6df968a74c38a0528f5bf6ea26f503b756"],"3a509b6df968a74c38a0528f5bf6ea26f503b756":["f962e7e670c8f2b5f205969d2ab166dd92d4a5ce"],"e6904bcc97d8afa27bd72ee29ac01e525e327ad4":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e6904bcc97d8afa27bd72ee29ac01e525e327ad4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}