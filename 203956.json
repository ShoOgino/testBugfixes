{"path":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set[#],int,int,int,boolean).mjava","commits":[{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set[#],int,int,int,boolean).mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set,int,int,int,boolean).mjava","sourceNew":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set<?> dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","sourceOld":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set[#],int,int,int,boolean).mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,Set[#],int,int,int,boolean).mjava","sourceNew":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set<?> dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","sourceOld":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, Set<?> dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,\n        onlyLongestMatch);\n\n    this.hyphenator = hyphenator;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}