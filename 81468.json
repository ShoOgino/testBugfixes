{"path":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermDocs td2 = mr2.termDocs();\n    TermEnum te3 = mr3.terms(new Term(\"body\",\"wow\"));\n    td2.seek(te3);\n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td2.next()) ret += td2.doc();\n    td2.close();\n    te3.close();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermDocs td2 = mr2.termDocs();\n    TermEnum te3 = mr3.terms(new Term(\"body\",\"wow\"));\n    td2.seek(te3);\n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td2.next()) ret += td2.doc();\n    td2.close();\n    te3.close();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28427ef110c4c5bf5b4057731b83110bd1e13724","date":1276701452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermDocs td2 = mr2.termDocs();\n    TermEnum te3 = mr3.terms(new Term(\"body\",\"wow\"));\n    td2.seek(te3);\n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td2.next()) ret += td2.doc();\n    td2.close();\n    te3.close();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermDocs td2 = mr2.termDocs();\n    TermEnum te3 = mr3.terms(new Term(\"body\",\"wow\"));\n    td2.seek(te3);\n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td2.next()) ret += td2.doc();\n    td2.close();\n    te3.close();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Random random = newRandom();\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Random random = newRandom();\n    MockRAMDirectory ramDir1=new MockRAMDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    MockRAMDirectory ramDir2=new MockRAMDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    MockRAMDirectory ramDir3=new MockRAMDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Random random = newRandom();\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    MockRAMDirectory ramDir1=newDirectory(random);\n    addDoc(random, ramDir1, \"test foo\", true);\n    MockRAMDirectory ramDir2=newDirectory(random);\n    addDoc(random, ramDir2, \"test blah\", true);\n    MockRAMDirectory ramDir3=newDirectory(random);\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Random random = newRandom();\n    MockRAMDirectory ramDir1=new MockRAMDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    MockRAMDirectory ramDir2=new MockRAMDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    MockRAMDirectory ramDir3=new MockRAMDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory(random);\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory(random);\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory(random);\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    MockRAMDirectory ramDir1=newDirectory(random);\n    addDoc(random, ramDir1, \"test foo\", true);\n    MockRAMDirectory ramDir2=newDirectory(random);\n    addDoc(random, ramDir2, \"test blah\", true);\n    MockRAMDirectory ramDir3=newDirectory(random);\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory(random);\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory(random);\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory(random);\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    RAMDirectory ramDir1=new RAMDirectory();\n    addDoc(ramDir1, \"test foo\", true);\n    RAMDirectory ramDir2=new RAMDirectory();\n    addDoc(ramDir2, \"test blah\", true);\n    RAMDirectory ramDir3=new RAMDirectory();\n    addDoc(ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seek(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getDeletedDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seek(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getDeletedDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is optimized out.\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = MultiFields.getTermDocsEnum(mr2,\n                                              MultiFields.getLiveDocs(mr2),\n                                              \"body\",\n                                              te2.term());\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = te3.docs(MultiFields.getLiveDocs(mr3),\n                  td);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false), IndexReader.open(ramDir3, false)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["872cff1d3a554e0cd64014cd97f88d3002b0f491","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"3cc749c053615f5871f3b95715fe292f34e70a53":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"5f4e87790277826a2aea119328600dfb07761f32":["9454a6510e2db155fb01faa5c049b06ece95fab9","28427ef110c4c5bf5b4057731b83110bd1e13724"],"2553b00f699380c64959ccb27991289aae87be2e":["1f653cfcf159baeaafe5d01682a911e95bba4012","fd9cc9d77712aba3662f24632df7539ab75e3667"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","1f653cfcf159baeaafe5d01682a911e95bba4012"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["1f653cfcf159baeaafe5d01682a911e95bba4012","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["872cff1d3a554e0cd64014cd97f88d3002b0f491","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","b65b350ca9588f9fc76ce7d6804160d06c45ff42","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["3cc749c053615f5871f3b95715fe292f34e70a53"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","fd9cc9d77712aba3662f24632df7539ab75e3667"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["5f4e87790277826a2aea119328600dfb07761f32","b21422ff1d1d56499dec481f193b402e5e8def5b"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["5f4e87790277826a2aea119328600dfb07761f32","28427ef110c4c5bf5b4057731b83110bd1e13724"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}