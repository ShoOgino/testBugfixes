{"path":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","commits":[{"id":"c4f600f812447b5512daeaf8e5c9df5dbcc4a254","date":1428874774,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          Collection<byte[]> payloads = spans.getPayload();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          Collection<byte[]> payloads = spans.getPayload();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2d530e71ed32ab23b34ca3fc72b080a554a40404","date":1432026158,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq, collector);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          Collection<byte[]> payloads = collector.getPayloads();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          Collection<byte[]> payloads = spans.getPayload();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29aea3139c4326c0501d75d51059855463220279","date":1433952060,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq, SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          Collection<byte[]> payloads = collector.getPayloads();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq, collector);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          Collection<byte[]> payloads = collector.getPayloads();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4","date":1442407411,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch3().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq, SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    VerifyingCollector collector = new VerifyingCollector();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch3() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"j k a l f k k p a t a k l k t a\")));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 0, true);\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    Spans spans =  MultiSpansWrapper.wrap(is.getIndexReader(), snq, SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          Collection<byte[]> payloads = collector.getPayloads();\n  \n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    if(VERBOSE) {\n      for (final String payload : payloadSet)\n        System.out.println(\"match:\" +  payload);\n      \n    }\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["29aea3139c4326c0501d75d51059855463220279"],"29aea3139c4326c0501d75d51059855463220279":["2d530e71ed32ab23b34ca3fc72b080a554a40404"],"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2d530e71ed32ab23b34ca3fc72b080a554a40404":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"]},"commit2Childs":{"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"29aea3139c4326c0501d75d51059855463220279":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"],"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["2d530e71ed32ab23b34ca3fc72b080a554a40404"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254"],"2d530e71ed32ab23b34ca3fc72b080a554a40404":["29aea3139c4326c0501d75d51059855463220279"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}