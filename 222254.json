{"path":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","sourceNew":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      @Override\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          @Override\n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      @Override\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          @Override\n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"689f35bd9818b47b8d9fe96cf06518228e949ab6","date":1272894884,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      @Override\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          @Override\n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"689f35bd9818b47b8d9fe96cf06518228e949ab6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"689f35bd9818b47b8d9fe96cf06518228e949ab6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}