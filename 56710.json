{"path":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(SegmentInfos,boolean,long).mjava","commits":[{"id":"01e5948db9a07144112d2f08f28ca2e3cd880348","date":1301759232,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(SegmentInfos,boolean,long).mjava","pathOld":"/dev/null","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(SegmentInfos candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.info(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(SegmentInfos,boolean,long).mjava","pathOld":"/dev/null","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(SegmentInfos candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.info(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(SegmentInfos,boolean,long).mjava","pathOld":"/dev/null","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(SegmentInfos candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.info(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5270fb4f55a1b77663dda53cb8090c083f0a23b3","date":1305050821,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentInfo],boolean,long).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(SegmentInfos,boolean,long).mjava","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentInfo> candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.get(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(SegmentInfos candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.info(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(List[SegmentInfo],boolean,long).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#score(SegmentInfos,boolean,long).mjava","sourceNew":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(List<SegmentInfo> candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.get(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","sourceOld":"  /** Expert: scores one merge; subclasses can override. */\n  protected MergeScore score(SegmentInfos candidate, boolean hitTooLarge, long mergingBytes) throws IOException {\n    long totBeforeMergeBytes = 0;\n    long totAfterMergeBytes = 0;\n    long totAfterMergeBytesFloored = 0;\n    for(SegmentInfo info : candidate) {\n      final long segBytes = size(info);\n      totAfterMergeBytes += segBytes;\n      totAfterMergeBytesFloored += floorSize(segBytes);\n      totBeforeMergeBytes += info.sizeInBytes(true);\n    }\n\n    // Measure \"skew\" of the merge, which can range\n    // from 1.0/numSegsBeingMerged (good) to 1.0\n    // (poor):\n    final double skew;\n    if (hitTooLarge) {\n      // Pretend the merge has perfect skew; skew doesn't\n      // matter in this case because this merge will not\n      // \"cascade\" and so it cannot lead to N^2 merge cost\n      // over time:\n      skew = 1.0/maxMergeAtOnce;\n    } else {\n      skew = ((double) floorSize(size(candidate.info(0))))/totAfterMergeBytesFloored;\n    }\n\n    // Strongly favor merges with less skew (smaller\n    // mergeScore is better):\n    double mergeScore = skew;\n\n    // Gently favor smaller merges over bigger ones.  We\n    // don't want to make this exponent too large else we\n    // can end up doing poor merges of small segments in\n    // order to avoid the large merges:\n    mergeScore *= Math.pow(totAfterMergeBytes, 0.05);\n\n    // Strongly favor merges that reclaim deletes:\n    final double nonDelRatio = ((double) totAfterMergeBytes)/totBeforeMergeBytes;\n    mergeScore *= nonDelRatio;\n\n    final double finalMergeScore = mergeScore;\n\n    return new MergeScore() {\n\n      @Override\n      public double getScore() {\n        return finalMergeScore;\n      }\n\n      @Override\n      public String getExplanation() {\n        return \"skew=\" + String.format(\"%.3f\", skew) + \" nonDelRatio=\" + String.format(\"%.3f\", nonDelRatio);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"01e5948db9a07144112d2f08f28ca2e3cd880348":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","01e5948db9a07144112d2f08f28ca2e3cd880348"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["135621f3a0670a9394eb563224a3b76cc4dddc0f","5270fb4f55a1b77663dda53cb8090c083f0a23b3"],"5270fb4f55a1b77663dda53cb8090c083f0a23b3":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"45669a651c970812a680841b97a77cce06af559f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","01e5948db9a07144112d2f08f28ca2e3cd880348"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5270fb4f55a1b77663dda53cb8090c083f0a23b3"]},"commit2Childs":{"01e5948db9a07144112d2f08f28ca2e3cd880348":["135621f3a0670a9394eb563224a3b76cc4dddc0f","5270fb4f55a1b77663dda53cb8090c083f0a23b3","45669a651c970812a680841b97a77cce06af559f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["01e5948db9a07144112d2f08f28ca2e3cd880348","135621f3a0670a9394eb563224a3b76cc4dddc0f","45669a651c970812a680841b97a77cce06af559f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"5270fb4f55a1b77663dda53cb8090c083f0a23b3":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"45669a651c970812a680841b97a77cce06af559f":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","45669a651c970812a680841b97a77cce06af559f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}