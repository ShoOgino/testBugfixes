{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","commits":[{"id":"cc41b743423981e7ec17a024ce7e107096e472fe","date":1349975327,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"/dev/null","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", new StringReader(surfaceForm.utf8ToString()));\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.end();\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","date":1351615637,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"/dev/null","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", new StringReader(surfaceForm.utf8ToString()));\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.end();\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"70728fc5d87dc51506cd3f763d68d2c16948e127","date":1363037076,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", new StringReader(surfaceForm.utf8ToString()));\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", new StringReader(surfaceForm.utf8ToString()));\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.end();\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", new StringReader(surfaceForm.utf8ToString()));\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":["cc41b743423981e7ec17a024ce7e107096e472fe"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", new StringReader(surfaceForm.utf8ToString()));\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","date":1374158194,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n // Analyze surface form:\n    TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString());\n\n    // Create corresponding automaton: labels are bytes\n    // from each analyzed token, with byte 0 used as\n    // separator between tokens:\n    Automaton automaton = ts2a.toAutomaton(ts);\n    ts.close();\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":["c83d6c4335f31cae14f625a222bc842f20073dcd","cc41b743423981e7ec17a024ce7e107096e472fe"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a1b4b3eeb982c8dc5baea5886cfb0e8af4b3553","date":1399644656,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75ac8571c2d82c574e446c3729251b994c69a55c","date":1402523781,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    LightAutomaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n\n    return Operations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    LightAutomaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n\n    return Operations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n    return SpecialOperations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"35fa550f45857d99d3d6d743420ee54b4d0c37f8","date":1436039255,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toAutomaton(BytesRef,TokenStreamToAutomaton).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toFiniteStrings(BytesRef,TokenStreamToAutomaton).mjava","sourceNew":"  final Automaton toAutomaton(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n    return automaton;\n  }\n\n","sourceOld":"  final Set<IntsRef> toFiniteStrings(final BytesRef surfaceForm, final TokenStreamToAutomaton ts2a) throws IOException {\n    // Analyze surface form:\n    Automaton automaton = null;\n    try (TokenStream ts = indexAnalyzer.tokenStream(\"\", surfaceForm.utf8ToString())) {\n\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      automaton = ts2a.toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n    automaton = convertAutomaton(automaton);\n\n    // TODO: LUCENE-5660 re-enable this once we disallow massive suggestion strings\n    // assert SpecialOperations.isFinite(automaton);\n\n    // Get all paths from the automaton (there can be\n    // more than one path, eg if the analyzer created a\n    // graph using SynFilter or WDF):\n\n    // TODO: we could walk & add simultaneously, so we\n    // don't have to alloc [possibly biggish]\n    // intermediate HashSet in RAM:\n\n    return Operations.getFiniteStrings(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"75ac8571c2d82c574e446c3729251b994c69a55c":["1a1b4b3eeb982c8dc5baea5886cfb0e8af4b3553"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["70728fc5d87dc51506cd3f763d68d2c16948e127","c83d6c4335f31cae14f625a222bc842f20073dcd"],"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6"],"35fa550f45857d99d3d6d743420ee54b4d0c37f8":["5c84485629d80d203608e8975a1139de9933cc38"],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cc41b743423981e7ec17a024ce7e107096e472fe"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"cc41b743423981e7ec17a024ce7e107096e472fe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["75ac8571c2d82c574e446c3729251b994c69a55c"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["37a0f60745e53927c4c876cfe5b5a58170f0646c"],"5c84485629d80d203608e8975a1139de9933cc38":["1a1b4b3eeb982c8dc5baea5886cfb0e8af4b3553","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"1a1b4b3eeb982c8dc5baea5886cfb0e8af4b3553":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["35fa550f45857d99d3d6d743420ee54b4d0c37f8"]},"commit2Childs":{"75ac8571c2d82c574e446c3729251b994c69a55c":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["1a1b4b3eeb982c8dc5baea5886cfb0e8af4b3553"],"35fa550f45857d99d3d6d743420ee54b4d0c37f8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6"],"cc41b743423981e7ec17a024ce7e107096e472fe":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","cc41b743423981e7ec17a024ce7e107096e472fe"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"5c84485629d80d203608e8975a1139de9933cc38":["35fa550f45857d99d3d6d743420ee54b4d0c37f8"],"1a1b4b3eeb982c8dc5baea5886cfb0e8af4b3553":["75ac8571c2d82c574e446c3729251b994c69a55c","5c84485629d80d203608e8975a1139de9933cc38"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}