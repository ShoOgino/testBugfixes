{"path":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","commits":[{"id":"33c290fa45cdfec3aaa108916ec4b6017d0616cc","date":1432654478,"type":0,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"/dev/null","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n    \n    File solrXml = new File(SolrTestCaseJ4.TEST_HOME(), \"solr-no-core.xml\");\n    MiniSolrCloudCluster miniCluster = new MiniSolrCloudCluster(NUM_SERVERS, null, createTempDir().toFile(), solrXml, null, null);\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.maxIndexingThreads\", \"-1\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c02b804ab16489b95429791a2d8fb0e0728354d4","date":1436551798,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n    \n    File solrXml = new File(SolrTestCaseJ4.TEST_HOME(), \"solr-no-core.xml\");\n    MiniSolrCloudCluster miniCluster = new MiniSolrCloudCluster(NUM_SERVERS, null, createTempDir().toFile(), solrXml, null, null);\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n    \n    File solrXml = new File(SolrTestCaseJ4.TEST_HOME(), \"solr-no-core.xml\");\n    MiniSolrCloudCluster miniCluster = new MiniSolrCloudCluster(NUM_SERVERS, null, createTempDir().toFile(), solrXml, null, null);\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.maxIndexingThreads\", \"-1\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0c130ec24cbb2eef3d8e7f0e971736f0bea8f54","date":1446047031,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n    \n    File solrXml = new File(SolrTestCaseJ4.TEST_HOME(), \"solr-no-core.xml\");\n    MiniSolrCloudCluster miniCluster = new MiniSolrCloudCluster(NUM_SERVERS, null, createTempDir().toFile(), solrXml, null, null);\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f929b717ab7f8b4a75621bbf4e3c3b08ba561381","date":1446062278,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9f1a5871b8ff5e2e0c0bf62340337c7f3801cffe","date":1452379366,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, 45000, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d7d215f266ffde522863d265557253945d48c672","date":1456154575,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"419a8f52c6635419beb951255cacbbb281044c57","date":1456189353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(\"solr.tests.mergePolicy\", \"org.apache.lucene.index.TieredMergePolicy\");\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","date":1457343183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"859081acf00749f5dd462772c571d611d4a4d2db","date":1459527719,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    HttpClientUtil.setConfigurer(new Krb5HttpClientConfigurer());\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e89a32cc825033ebae8bb9e1c6877c2d9d76749e","date":1476790453,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      File configDir = new File(SolrTestCaseJ4.TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n      miniCluster.uploadConfigDir(configDir, configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac97ea104d893f16aab430d9904473bc1f233f3c","date":1496249396,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3217321f3e1d7922898c6c633d17acfa840d6875","date":1496257480,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42dc7f2d60851668d9efa2d12baa1d4ebe54b12f","date":1496281877,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70d848516a5d0b23d183a2ceb4f4fb8634205956","date":1496408348,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = new CollectionAdminRequest.Create();\n      createRequest.setCollectionName(collectionName);\n      createRequest.setNumShards(NUM_SHARDS);\n      createRequest.setReplicationFactor(REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.Delete deleteRequest = new CollectionAdminRequest.Delete();\n        deleteRequest.setCollectionName(collectionName);\n        deleteRequest.process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"197bbedf08450ade98a11f4a0001448059666bec","date":1498534625,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName, configName, NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","date":1498540685,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName, configName, NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName, configName, NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName,NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      if (random().nextBoolean()) {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICY, TieredMergePolicy.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"false\");\n      } else {\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICYFACTORY, \"true\");\n        properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_USEMERGEPOLICY, \"false\");\n      }\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5719bfb2650ba43855e20564d39873bbbdc7f02c","date":1500676092,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish\n        (collectionName, client.getZkStateReader(), true, true, 330);\n\n    // modify/query collection\n\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName, configName, NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"936cdd5882761db3b844afd6f84ab81cbb011a75","date":1500973524,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish\n        (collectionName, client.getZkStateReader(), true, true, 330);\n\n    // modify/query collection\n\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName, configName, NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a52341299179de5479672f7cf518bf4b173f34b3","date":1501079746,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish\n        (collectionName, client.getZkStateReader(), true, true, 330);\n\n    // modify/query collection\n\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","sourceOld":"  protected void testCollectionCreateSearchDelete() throws Exception {\n    String collectionName = \"testkerberoscollection\";\n\n    MiniSolrCloudCluster miniCluster\n        = new MiniSolrCloudCluster(NUM_SERVERS, createTempDir(), JettyConfig.builder().setContext(\"/solr\").build());\n    CloudSolrClient cloudSolrClient = miniCluster.getSolrClient();\n    cloudSolrClient.setDefaultCollection(collectionName);\n    \n    try {\n      assertNotNull(miniCluster.getZkServer());\n      List<JettySolrRunner> jettys = miniCluster.getJettySolrRunners();\n      assertEquals(NUM_SERVERS, jettys.size());\n      for (JettySolrRunner jetty : jettys) {\n        assertTrue(jetty.isRunning());\n      }\n\n      // create collection\n      String configName = \"solrCloudCollectionConfig\";\n      miniCluster.uploadConfigSet(SolrTestCaseJ4.TEST_PATH().resolve(\"collection1/conf\"), configName);\n\n      CollectionAdminRequest.Create createRequest = CollectionAdminRequest.createCollection(collectionName, configName, NUM_SHARDS,REPLICATION_FACTOR);\n      Properties properties = new Properties();\n      properties.put(CoreDescriptor.CORE_CONFIG, \"solrconfig-tlog.xml\");\n      properties.put(\"solr.tests.maxBufferedDocs\", \"100000\");\n      properties.put(\"solr.tests.ramBufferSizeMB\", \"100\");\n      // use non-test classes so RandomizedRunner isn't necessary\n      properties.put(SolrTestCaseJ4.SYSTEM_PROPERTY_SOLR_TESTS_MERGEPOLICYFACTORY, TieredMergePolicyFactory.class.getName());\n      properties.put(\"solr.tests.mergeScheduler\", \"org.apache.lucene.index.ConcurrentMergeScheduler\");\n      properties.put(\"solr.directoryFactory\", \"solr.RAMDirectoryFactory\");\n      createRequest.setProperties(properties);\n      \n      createRequest.process(cloudSolrClient);\n      \n      try (SolrZkClient zkClient = new SolrZkClient\n          (miniCluster.getZkServer().getZkAddress(), AbstractZkTestCase.TIMEOUT, AbstractZkTestCase.TIMEOUT, null);\n           ZkStateReader zkStateReader = new ZkStateReader(zkClient)) {\n        zkStateReader.createClusterStateWatchersAndUpdate();\n        AbstractDistribZkTestBase.waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);\n\n        // modify/query collection\n        \n        SolrInputDocument doc = new SolrInputDocument();\n        doc.setField(\"id\", \"1\");\n        cloudSolrClient.add(doc);\n        cloudSolrClient.commit();\n        SolrQuery query = new SolrQuery();\n        query.setQuery(\"*:*\");\n        QueryResponse rsp = cloudSolrClient.query(query);\n        assertEquals(1, rsp.getResults().getNumFound());\n        \n        // delete the collection we created earlier\n        CollectionAdminRequest.deleteCollection(collectionName).process(cloudSolrClient);\n        \n        AbstractDistribZkTestBase.waitForCollectionToDisappear(collectionName, zkStateReader, true, true, 330);\n      }\n    }\n    finally {\n      cloudSolrClient.close();\n      miniCluster.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","sourceOld":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish\n        (collectionName, client.getZkStateReader(), true, true, 330);\n\n    // modify/query collection\n\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","bugFix":["5719bfb2650ba43855e20564d39873bbbdc7f02c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f736775ffbf9966dcd5e63b74ecdc15b5eb64f33","date":1549126980,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","sourceOld":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, 330);\n  }\n\n","sourceOld":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, true, 330);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt#testCollectionCreateSearchDelete().mjava","sourceNew":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, 330);\n  }\n\n","sourceOld":"  private void testCollectionCreateSearchDelete() throws Exception {\n    CloudSolrClient client = cluster.getSolrClient();\n    CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)\n        .setMaxShardsPerNode(maxShardsPerNode)\n        .process(client);\n\n    cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);\n\n    // modify/query collection\n    new UpdateRequest().add(\"id\", \"1\").commit(client, collectionName);\n    QueryResponse rsp = client.query(collectionName, new SolrQuery(\"*:*\"));\n    assertEquals(1, rsp.getResults().getNumFound());\n        \n    // delete the collection we created earlier\n    CollectionAdminRequest.deleteCollection(collectionName).process(client);\n        \n    AbstractDistribZkTestBase.waitForCollectionToDisappear\n        (collectionName, client.getZkStateReader(), true, 330);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e89a32cc825033ebae8bb9e1c6877c2d9d76749e":["859081acf00749f5dd462772c571d611d4a4d2db"],"197bbedf08450ade98a11f4a0001448059666bec":["70d848516a5d0b23d183a2ceb4f4fb8634205956"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a52341299179de5479672f7cf518bf4b173f34b3"],"9f1a5871b8ff5e2e0c0bf62340337c7f3801cffe":["f929b717ab7f8b4a75621bbf4e3c3b08ba561381"],"419a8f52c6635419beb951255cacbbb281044c57":["9f1a5871b8ff5e2e0c0bf62340337c7f3801cffe","d7d215f266ffde522863d265557253945d48c672"],"5719bfb2650ba43855e20564d39873bbbdc7f02c":["28288370235ed02234a64753cdbf0c6ec096304a"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["419a8f52c6635419beb951255cacbbb281044c57"],"70d848516a5d0b23d183a2ceb4f4fb8634205956":["42dc7f2d60851668d9efa2d12baa1d4ebe54b12f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e","70d848516a5d0b23d183a2ceb4f4fb8634205956"],"33c290fa45cdfec3aaa108916ec4b6017d0616cc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["f736775ffbf9966dcd5e63b74ecdc15b5eb64f33"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["e9017cf144952056066919f1ebc7897ff9bd71b1","197bbedf08450ade98a11f4a0001448059666bec"],"d7d215f266ffde522863d265557253945d48c672":["9f1a5871b8ff5e2e0c0bf62340337c7f3801cffe"],"ac97ea104d893f16aab430d9904473bc1f233f3c":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e"],"936cdd5882761db3b844afd6f84ab81cbb011a75":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","5719bfb2650ba43855e20564d39873bbbdc7f02c"],"f929b717ab7f8b4a75621bbf4e3c3b08ba561381":["f0c130ec24cbb2eef3d8e7f0e971736f0bea8f54"],"3217321f3e1d7922898c6c633d17acfa840d6875":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e","ac97ea104d893f16aab430d9904473bc1f233f3c"],"f0c130ec24cbb2eef3d8e7f0e971736f0bea8f54":["c02b804ab16489b95429791a2d8fb0e0728354d4"],"f736775ffbf9966dcd5e63b74ecdc15b5eb64f33":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"28288370235ed02234a64753cdbf0c6ec096304a":["3217321f3e1d7922898c6c633d17acfa840d6875","197bbedf08450ade98a11f4a0001448059666bec"],"42dc7f2d60851668d9efa2d12baa1d4ebe54b12f":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e","3217321f3e1d7922898c6c633d17acfa840d6875"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["859081acf00749f5dd462772c571d611d4a4d2db","e89a32cc825033ebae8bb9e1c6877c2d9d76749e"],"c02b804ab16489b95429791a2d8fb0e0728354d4":["33c290fa45cdfec3aaa108916ec4b6017d0616cc"],"859081acf00749f5dd462772c571d611d4a4d2db":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"a52341299179de5479672f7cf518bf4b173f34b3":["28288370235ed02234a64753cdbf0c6ec096304a","5719bfb2650ba43855e20564d39873bbbdc7f02c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"]},"commit2Childs":{"e89a32cc825033ebae8bb9e1c6877c2d9d76749e":["e9017cf144952056066919f1ebc7897ff9bd71b1","ac97ea104d893f16aab430d9904473bc1f233f3c","3217321f3e1d7922898c6c633d17acfa840d6875","42dc7f2d60851668d9efa2d12baa1d4ebe54b12f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"197bbedf08450ade98a11f4a0001448059666bec":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","28288370235ed02234a64753cdbf0c6ec096304a"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["f736775ffbf9966dcd5e63b74ecdc15b5eb64f33"],"9f1a5871b8ff5e2e0c0bf62340337c7f3801cffe":["419a8f52c6635419beb951255cacbbb281044c57","d7d215f266ffde522863d265557253945d48c672"],"419a8f52c6635419beb951255cacbbb281044c57":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"5719bfb2650ba43855e20564d39873bbbdc7f02c":["936cdd5882761db3b844afd6f84ab81cbb011a75","a52341299179de5479672f7cf518bf4b173f34b3"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["859081acf00749f5dd462772c571d611d4a4d2db"],"70d848516a5d0b23d183a2ceb4f4fb8634205956":["197bbedf08450ade98a11f4a0001448059666bec","e9017cf144952056066919f1ebc7897ff9bd71b1"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"33c290fa45cdfec3aaa108916ec4b6017d0616cc":["c02b804ab16489b95429791a2d8fb0e0728354d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["33c290fa45cdfec3aaa108916ec4b6017d0616cc"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["936cdd5882761db3b844afd6f84ab81cbb011a75"],"d7d215f266ffde522863d265557253945d48c672":["419a8f52c6635419beb951255cacbbb281044c57"],"ac97ea104d893f16aab430d9904473bc1f233f3c":["3217321f3e1d7922898c6c633d17acfa840d6875"],"936cdd5882761db3b844afd6f84ab81cbb011a75":[],"f929b717ab7f8b4a75621bbf4e3c3b08ba561381":["9f1a5871b8ff5e2e0c0bf62340337c7f3801cffe"],"3217321f3e1d7922898c6c633d17acfa840d6875":["28288370235ed02234a64753cdbf0c6ec096304a","42dc7f2d60851668d9efa2d12baa1d4ebe54b12f"],"f0c130ec24cbb2eef3d8e7f0e971736f0bea8f54":["f929b717ab7f8b4a75621bbf4e3c3b08ba561381"],"f736775ffbf9966dcd5e63b74ecdc15b5eb64f33":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"28288370235ed02234a64753cdbf0c6ec096304a":["5719bfb2650ba43855e20564d39873bbbdc7f02c","a52341299179de5479672f7cf518bf4b173f34b3"],"42dc7f2d60851668d9efa2d12baa1d4ebe54b12f":["70d848516a5d0b23d183a2ceb4f4fb8634205956"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"c02b804ab16489b95429791a2d8fb0e0728354d4":["f0c130ec24cbb2eef3d8e7f0e971736f0bea8f54"],"859081acf00749f5dd462772c571d611d4a4d2db":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a52341299179de5479672f7cf518bf4b173f34b3":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["936cdd5882761db3b844afd6f84ab81cbb011a75","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}