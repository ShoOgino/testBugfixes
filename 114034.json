{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestSegmentingTokenizerBase.SentenceAndWordTokenizer#incrementWord().mjava","commits":[{"id":"ca700981d999d4025d8f401b1fc3f9b6f4e25ccf","date":1395362033,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestSegmentingTokenizerBase.SentenceAndWordTokenizer#incrementWord().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    protected boolean incrementWord() {\n      wordStart = wordEnd;\n      while (wordStart < sentenceEnd) {\n        if (Character.isLetterOrDigit(buffer[wordStart]))\n          break;\n        wordStart++;\n      }\n      \n      if (wordStart == sentenceEnd) return false;\n      \n      wordEnd = wordStart+1;\n      while (wordEnd < sentenceEnd && Character.isLetterOrDigit(buffer[wordEnd]))\n        wordEnd++;\n      \n      clearAttributes();\n      termAtt.copyBuffer(buffer, wordStart, wordEnd-wordStart);\n      offsetAtt.setOffset(correctOffset(offset+wordStart), correctOffset(offset+wordEnd));\n      posIncAtt.setPositionIncrement(posIncAtt.getPositionIncrement() + posBoost);\n      posBoost = 0;\n      return true;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ca700981d999d4025d8f401b1fc3f9b6f4e25ccf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ca700981d999d4025d8f401b1fc3f9b6f4e25ccf"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ca700981d999d4025d8f401b1fc3f9b6f4e25ccf"],"ca700981d999d4025d8f401b1fc3f9b6f4e25ccf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}