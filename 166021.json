{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","commits":[{"id":"59d4661023aa9541b0a759e4d2e11dcf83b923a0","date":1420124226,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b88448324d3a96c5842455dabea63450b697b58f","date":1421779050,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","bugFix":["eda61b1e90b490cc5837200e04c02639a0d272c7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409da428f28953cf35fddd5c9ff5c7e4f5439863","date":1547556145,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70a4487b07c49a1861c05720e04624826ecbe9fa","date":1580924108,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION_PREFIX, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b78d8dfe50af510bace3600bfc4cfa0b031f776","date":1598430423,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      metaStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION), context);\n      CodecUtil.writeIndexHeader(metaStream, VECTORS_INDEX_CODEC_NAME + \"Meta\", VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(VECTORS_INDEX_CODEC_NAME + \"Meta\", segmentSuffix) == metaStream.getFilePointer();\n\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      metaStream.writeVInt(PackedInts.VERSION_CURRENT);\n      metaStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(metaStream, vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION_PREFIX, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a801a0efdddea4f823c56104babbbc8c52382cf","date":1600074666,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","sourceNew":"  /** Sole constructor. */\n  CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      metaStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION), context);\n      CodecUtil.writeIndexHeader(metaStream, VECTORS_INDEX_CODEC_NAME + \"Meta\", VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(VECTORS_INDEX_CODEC_NAME + \"Meta\", segmentSuffix) == metaStream.getFilePointer();\n\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      metaStream.writeVInt(PackedInts.VERSION_CURRENT);\n      metaStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(metaStream, vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      metaStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION), context);\n      CodecUtil.writeIndexHeader(metaStream, VECTORS_INDEX_CODEC_NAME + \"Meta\", VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(VECTORS_INDEX_CODEC_NAME + \"Meta\", segmentSuffix) == metaStream.getFilePointer();\n\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      metaStream.writeVInt(PackedInts.VERSION_CURRENT);\n      metaStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(metaStream, vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","sourceNew":"  /** Sole constructor. */\n  CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      metaStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION), context);\n      CodecUtil.writeIndexHeader(metaStream, VECTORS_INDEX_CODEC_NAME + \"Meta\", VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(VECTORS_INDEX_CODEC_NAME + \"Meta\", segmentSuffix) == metaStream.getFilePointer();\n\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      metaStream.writeVInt(PackedInts.VERSION_CURRENT);\n      metaStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(metaStream, vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockShift) throws IOException {\n    assert directory != null;\n    this.segment = si.name;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = ByteBuffersDataOutput.newResettableInstance();\n    payloadBytes = ByteBuffersDataOutput.newResettableInstance();\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    try {\n      metaStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION), context);\n      CodecUtil.writeIndexHeader(metaStream, VECTORS_INDEX_CODEC_NAME + \"Meta\", VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(VECTORS_INDEX_CODEC_NAME + \"Meta\", segmentSuffix) == metaStream.getFilePointer();\n\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n      CodecUtil.writeIndexHeader(vectorsStream, formatName, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      indexWriter = new FieldsIndexWriter(directory, segment, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), blockShift, context);\n\n      metaStream.writeVInt(PackedInts.VERSION_CURRENT);\n      metaStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(metaStream, vectorsStream, indexWriter, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["b88448324d3a96c5842455dabea63450b697b58f"],"680b6449f09827f58fe987aff279e014c311d966":["2b78d8dfe50af510bace3600bfc4cfa0b031f776","5a801a0efdddea4f823c56104babbbc8c52382cf"],"b88448324d3a96c5842455dabea63450b697b58f":["59d4661023aa9541b0a759e4d2e11dcf83b923a0"],"59d4661023aa9541b0a759e4d2e11dcf83b923a0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["680b6449f09827f58fe987aff279e014c311d966"],"5a801a0efdddea4f823c56104babbbc8c52382cf":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"]},"commit2Childs":{"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["680b6449f09827f58fe987aff279e014c311d966","5a801a0efdddea4f823c56104babbbc8c52382cf"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"680b6449f09827f58fe987aff279e014c311d966":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b88448324d3a96c5842455dabea63450b697b58f":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"59d4661023aa9541b0a759e4d2e11dcf83b923a0":["b88448324d3a96c5842455dabea63450b697b58f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["59d4661023aa9541b0a759e4d2e11dcf83b923a0"],"5a801a0efdddea4f823c56104babbbc8c52382cf":["680b6449f09827f58fe987aff279e014c311d966"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}