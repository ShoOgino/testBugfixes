{"path":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}