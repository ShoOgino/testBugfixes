{"path":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, new StringReader(text));\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream);\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, new StringReader(text));\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30fd30bfbfa6b9e036bcd99c8339712e965d4a63","date":1351859294,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, new StringReader(text));\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, new StringReader(text));\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream);\n  }\n\n","bugFix":null,"bugIntro":["2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, text);\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, new StringReader(text));\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName));\n  }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, text);\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, new StringReader(text));\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9","date":1392385887,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, text);\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, text);\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName));\n  }\n\n","bugFix":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e859719dc778fb66d3d21e7be08cd408fc2bde98","date":1446717611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream;\n    try {\n      stream = analyzer.tokenStream(fieldName, text);\n    } catch (IOException ex) {\n      throw new RuntimeException(ex);\n    }\n\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"253a79e1af11467dd01315b1919025d288aa0ccb","date":1458032260,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName), DocValuesType.NONE, null);\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","bugFix":null,"bugIntro":["74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275","date":1458043999,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName),\n        DocValuesType.NONE, null, 0, 0, null);\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName), DocValuesType.NONE, null);\n  }\n\n","bugFix":["253a79e1af11467dd01315b1919025d288aa0ccb"],"bugIntro":["89b68d01c34172936f1aa2a8b9abf0e1bc68415f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"89b68d01c34172936f1aa2a8b9abf0e1bc68415f","date":1486637198,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    storeTerms(getInfo(fieldName, defaultFieldType), stream, 1.0f,\n        analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName),\n        DocValuesType.NONE, null, 0, 0, null);\n  }\n\n","bugFix":["74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acd9883560fd89e6448b2b447302fe543040cd4f","date":1488478696,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#addField(String,String,Analyzer).mjava","sourceNew":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    storeTerms(getInfo(fieldName, defaultFieldType), stream,\n        analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","sourceOld":"  /**\n   * Convenience method; Tokenizes the given field text and adds the resulting\n   * terms to the index; Equivalent to adding an indexed non-keyword Lucene\n   * {@link org.apache.lucene.document.Field} that is tokenized, not stored,\n   * termVectorStored with positions (or termVectorStored with positions and offsets),\n   * \n   * @param fieldName\n   *            a name to be associated with the text\n   * @param text\n   *            the text to tokenize and index.\n   * @param analyzer\n   *            the analyzer to use for tokenization\n   */\n  public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException(\"fieldName must not be null\");\n    if (text == null)\n      throw new IllegalArgumentException(\"text must not be null\");\n    if (analyzer == null)\n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    storeTerms(getInfo(fieldName, defaultFieldType), stream, 1.0f,\n        analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275":["253a79e1af11467dd01315b1919025d288aa0ccb"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63"],"253a79e1af11467dd01315b1919025d288aa0ccb":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"89b68d01c34172936f1aa2a8b9abf0e1bc68415f":["74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275"],"30fd30bfbfa6b9e036bcd99c8339712e965d4a63":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"acd9883560fd89e6448b2b447302fe543040cd4f":["89b68d01c34172936f1aa2a8b9abf0e1bc68415f"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["acd9883560fd89e6448b2b447302fe543040cd4f"],"2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9":["c83d6c4335f31cae14f625a222bc842f20073dcd"]},"commit2Childs":{"74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275":["89b68d01c34172936f1aa2a8b9abf0e1bc68415f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9"],"253a79e1af11467dd01315b1919025d288aa0ccb":["74d5d70ec9df9b59ea6d0dbdb5f7af1991ba7275"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"30fd30bfbfa6b9e036bcd99c8339712e965d4a63":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"89b68d01c34172936f1aa2a8b9abf0e1bc68415f":["acd9883560fd89e6448b2b447302fe543040cd4f"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["253a79e1af11467dd01315b1919025d288aa0ccb"],"acd9883560fd89e6448b2b447302fe543040cd4f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2eceb3be6e29e3ad7ee08d5025a431c3812aa0d9":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}