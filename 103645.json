{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocsEnum.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocsEnum.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocsEnum.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocsEnum.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8","date":1328775259,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocsEnum.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocsEnum.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocsEnum.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocsEnum.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocsEnum.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocsEnum.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocsEnum.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocsEnum.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random.nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random.nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random, context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random.nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext context : leaves) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, true);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"211b1506e56f7860762fbd4698f6d1d1b57f672c","date":1344976996,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, PostingsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(postingsEnum);\n          continue;\n        }\n        assertNotNull(postingsEnum);\n        postingsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, postingsEnum.docID());\n            assertEquals(postingsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = postingsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              postingsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + postingsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, postingsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(docsEnum);\n          continue;\n        }\n        assertNotNull(docsEnum);\n        docsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, docsEnum.docID());\n            assertEquals(docsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = docsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              docsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + docsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, docsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, PostingsEnum.FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(postingsEnum);\n          continue;\n        }\n        assertNotNull(postingsEnum);\n        postingsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, postingsEnum.docID());\n            assertEquals(postingsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = postingsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              postingsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + postingsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, postingsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, PostingsEnum.FLAG_FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(postingsEnum);\n          continue;\n        }\n        assertNotNull(postingsEnum);\n        postingsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, postingsEnum.docID());\n            assertEquals(postingsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = postingsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              postingsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + postingsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, postingsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testRandomDocs().mjava","sourceNew":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, PostingsEnum.FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(postingsEnum);\n          continue;\n        }\n        assertNotNull(postingsEnum);\n        postingsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, postingsEnum.docID());\n            assertEquals(postingsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = postingsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              postingsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + postingsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, postingsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomDocs() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n                                                     newIndexWriterConfig(new MockAnalyzer(random()))\n                                                       .setMergePolicy(newLogMergePolicy()));\n    int numDocs = atLeast(49);\n    int max = 15678;\n    int term = random().nextInt(max);\n    int[] freqInDoc = new int[numDocs];\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < 199; j++) {\n        int nextInt = random().nextInt(max);\n        builder.append(nextInt).append(' ');\n        if (nextInt == term) {\n          freqInDoc[i]++;\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"\" + term);\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext context : topReaderContext.leaves()) {\n        int maxDoc = context.reader().maxDoc();\n        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, PostingsEnum.FREQS);\n        if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {\n          assertNull(postingsEnum);\n          continue;\n        }\n        assertNotNull(postingsEnum);\n        postingsEnum.nextDoc();\n        for (int j = 0; j < maxDoc; j++) {\n          if (freqInDoc[context.docBase + j] != 0) {\n            assertEquals(j, postingsEnum.docID());\n            assertEquals(postingsEnum.freq(), freqInDoc[context.docBase +j]);\n            if (i % 2 == 0 && random().nextInt(10) == 0) {\n              int next = findNext(freqInDoc, context.docBase+j+1, context.docBase + maxDoc) - context.docBase;\n              int advancedTo = postingsEnum.advance(next);\n              if (next >= maxDoc) {\n                assertEquals(DocIdSetIterator.NO_MORE_DOCS, advancedTo);\n              } else {\n                assertTrue(\"advanced to: \" +advancedTo + \" but should be <= \" + next, next >= advancedTo);  \n              }\n            } else {\n              postingsEnum.nextDoc();\n            }\n          } \n        }\n        assertEquals(\"docBase: \" + context.docBase + \" maxDoc: \" + maxDoc + \" \" + postingsEnum.getClass(), DocIdSetIterator.NO_MORE_DOCS, postingsEnum.docID());\n      }\n      \n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3c188105a9aae04f56c24996f98f8333fc825d2e":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","211b1506e56f7860762fbd4698f6d1d1b57f672c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d6f074e73200c07d54f242d3880a8da5a35ff97b","211b1506e56f7860762fbd4698f6d1d1b57f672c"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"6613659748fe4411a7dcf85266e55db1f95f7315":["211b1506e56f7860762fbd4698f6d1d1b57f672c"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"211b1506e56f7860762fbd4698f6d1d1b57f672c":["02331260bb246364779cb6f04919ca47900d01bb"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"51f5280f31484820499077f41fcdfe92d527d9dc":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"02331260bb246364779cb6f04919ca47900d01bb":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"]},"commit2Childs":{"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["51f5280f31484820499077f41fcdfe92d527d9dc"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"211b1506e56f7860762fbd4698f6d1d1b57f672c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","6613659748fe4411a7dcf85266e55db1f95f7315"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"02331260bb246364779cb6f04919ca47900d01bb":["211b1506e56f7860762fbd4698f6d1d1b57f672c","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}