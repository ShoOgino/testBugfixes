{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","commits":[{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":1,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","sourceNew":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","date":1465824262,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","sourceNew":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","date":1465913303,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","sourceNew":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","sourceNew":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["379db3ad24c4f0214f30a122265a6d6be003a99d","fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["379db3ad24c4f0214f30a122265a6d6be003a99d","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"]},"commit2Childs":{"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}