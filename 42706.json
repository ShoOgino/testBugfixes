{"path":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#addReplicaToReplicasMap(Block,ReplicaMap,RamDiskReplicaTracker,boolean).mjava","commits":[{"id":"44ca189138a5b6e1989d12ab992fab60e235ddc7","date":1549051496,"type":0,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#addReplicaToReplicasMap(Block,ReplicaMap,RamDiskReplicaTracker,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n                                       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica = null;\n    long blockId = block.getBlockId();\n    long genStamp = block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica = new ReplicaBuilder(ReplicaState.FINALIZED)\n          .setBlockId(blockId)\n          .setLength(block.getNumBytes())\n          .setGenerationStamp(genStamp)\n          .setFsVolume(volume)\n          .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n          .build();\n    } else {\n      File file = new File(rbwDir, block.getBlockName());\n      boolean loadRwr = true;\n      File restartMeta = new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc = null;\n      try {\n        sc = new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() && (sc.nextLong() > timer.now())) {\n          // It didn't expire. Load the replica as a RBW.\n          // We don't know the expected block length, so just use 0\n          // and don't reserve any more space for writes.\n          newReplica = new ReplicaBuilder(ReplicaState.RBW)\n              .setBlockId(blockId)\n              .setLength(validateIntegrityAndSetLength(file, genStamp))\n              .setGenerationStamp(genStamp)\n              .setFsVolume(volume)\n              .setDirectoryToUse(file.getParentFile())\n              .setWriterThread(null)\n              .setBytesToReserve(0)\n              .build();\n          loadRwr = false;\n        }\n        sc.close();\n        if (!fileIoProvider.delete(volume, restartMeta)) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir =\n      } finally {\n        if (sc != null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn't exist or expired.\n      if (loadRwr) {\n        ReplicaBuilder builder = new ReplicaBuilder(ReplicaState.RWR)\n            .setBlockId(blockId)\n            .setLength(validateIntegrityAndSetLength(file, genStamp))\n            .setGenerationStamp(genStamp)\n            .setFsVolume(volume)\n            .setDirectoryToUse(file.getParentFile());\n        newReplica = builder.build();\n      }\n    }\n\n    ReplicaInfo tmpReplicaInfo = volumeMap.addAndGet(bpid, newReplica);\n    ReplicaInfo oldReplica = (tmpReplicaInfo == newReplica) ? null\n        : tmpReplicaInfo;\n    if (oldReplica != null) {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica = resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n    if (oldReplica == null) {\n      incrNumBlocks();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"44ca189138a5b6e1989d12ab992fab60e235ddc7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["44ca189138a5b6e1989d12ab992fab60e235ddc7"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44ca189138a5b6e1989d12ab992fab60e235ddc7"],"44ca189138a5b6e1989d12ab992fab60e235ddc7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}