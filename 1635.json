{"path":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","commits":[{"id":"811cdb4a80352766eb0c762e48972707a924e5cd","date":1358767313,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n            reusable.residue = 0;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.residue += reusable.value;\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],MutableFacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n            reusable.residue = 0;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.residue += reusable.value;\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,\n      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new MutableFacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.increaseResidue(reusable.getValue());\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dae862628c7a5275e1ff00ff3bc9803dedf124a9","date":1358939646,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n            reusable.residue = 0;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.residue += reusable.value;\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2d5244a676b83c2d551c3746e8181588ba619e1","date":1359031414,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n            reusable.residue = 0;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n          if (reusable != null) {\n            // TODO (Facet): is other logic (not add) needed, per aggregator?\n            parentResultNode.residue += reusable.value;\n          }\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"571abba77e55fea386a38c0024f72ffa5b37a9ad","date":1360272747,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dae862628c7a5275e1ff00ff3bc9803dedf124a9":["811cdb4a80352766eb0c762e48972707a924e5cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"07155cdd910937cdf6877e48884d5782845c8b8b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","811cdb4a80352766eb0c762e48972707a924e5cd"],"571abba77e55fea386a38c0024f72ffa5b37a9ad":["dae862628c7a5275e1ff00ff3bc9803dedf124a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["571abba77e55fea386a38c0024f72ffa5b37a9ad"],"811cdb4a80352766eb0c762e48972707a924e5cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b2d5244a676b83c2d551c3746e8181588ba619e1":["07155cdd910937cdf6877e48884d5782845c8b8b","dae862628c7a5275e1ff00ff3bc9803dedf124a9"]},"commit2Childs":{"dae862628c7a5275e1ff00ff3bc9803dedf124a9":["571abba77e55fea386a38c0024f72ffa5b37a9ad","b2d5244a676b83c2d551c3746e8181588ba619e1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["07155cdd910937cdf6877e48884d5782845c8b8b","811cdb4a80352766eb0c762e48972707a924e5cd"],"07155cdd910937cdf6877e48884d5782845c8b8b":["b2d5244a676b83c2d551c3746e8181588ba619e1"],"571abba77e55fea386a38c0024f72ffa5b37a9ad":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"811cdb4a80352766eb0c762e48972707a924e5cd":["dae862628c7a5275e1ff00ff3bc9803dedf124a9","07155cdd910937cdf6877e48884d5782845c8b8b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b2d5244a676b83c2d551c3746e8181588ba619e1":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b2d5244a676b83c2d551c3746e8181588ba619e1"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}