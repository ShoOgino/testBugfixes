{"path":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"6620df8541b174097b1133a4fc370adb2e570524","date":1319544675,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      int termCount = 0;\n      DocsEnum docsEnum = null;\n      do {\n        termCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();\n        while (true) {\n          final int count = docsEnum.read();\n          if (count != 0) {\n            final int[] docs = result.docs.ints;\n            for (int i = 0; i < count; i++) {\n              bitSet.set(docs[i]);\n            }\n          } else {\n            break;\n          }\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      query.incTotalNumberOfTerms(termCount);\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      int termCount = 0;\n      final Bits liveDocs = reader.getLiveDocs();\n      DocsEnum docsEnum = null;\n      do {\n        termCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(liveDocs, docsEnum);\n        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();\n        while (true) {\n          final int count = docsEnum.read();\n          if (count != 0) {\n            final int[] docs = result.docs.ints;\n            for (int i = 0; i < count; i++) {\n              bitSet.set(docs[i]);\n            }\n          } else {\n            break;\n          }\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      query.incTotalNumberOfTerms(termCount);\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a4965b25e439626b575c2281b39ad875f89d891","date":1321132400,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      int termCount = 0;\n      DocsEnum docsEnum = null;\n      do {\n        termCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();\n        while (true) {\n          final int count = docsEnum.read();\n          if (count != 0) {\n            final int[] docs = result.docs.ints;\n            for (int i = 0; i < count; i++) {\n              bitSet.set(docs[i]);\n            }\n          } else {\n            break;\n          }\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      int termCount = 0;\n      DocsEnum docsEnum = null;\n      do {\n        termCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();\n        while (true) {\n          final int count = docsEnum.read();\n          if (count != 0) {\n            final int[] docs = result.docs.ints;\n            for (int i = 0; i < count; i++) {\n              bitSet.set(docs[i]);\n            }\n          } else {\n            break;\n          }\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      query.incTotalNumberOfTerms(termCount);\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0445bcd8433e331f296f5502fc089b336cbac3a6","date":1322630375,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      int termCount = 0;\n      DocsEnum docsEnum = null;\n      do {\n        termCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();\n        while (true) {\n          final int count = docsEnum.read();\n          if (count != 0) {\n            final int[] docs = result.docs.ints;\n            for (int i = 0; i < count; i++) {\n              bitSet.set(docs[i]);\n            }\n          } else {\n            break;\n          }\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2725b2d479964ea5aaea0ba4ae2634716f3ec26c","date":1327188170,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicIndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6fff8f4b218bd0626afcdce82027bafeb84a50a4","date":1327229950,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicIndexReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicIndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicIndexReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final IndexReader reader = context.reader;\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6620df8541b174097b1133a4fc370adb2e570524":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0445bcd8433e331f296f5502fc089b336cbac3a6":["2a4965b25e439626b575c2281b39ad875f89d891"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["6fff8f4b218bd0626afcdce82027bafeb84a50a4"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["0445bcd8433e331f296f5502fc089b336cbac3a6","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6fff8f4b218bd0626afcdce82027bafeb84a50a4":["2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"2a4965b25e439626b575c2281b39ad875f89d891":["6620df8541b174097b1133a4fc370adb2e570524"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["0445bcd8433e331f296f5502fc089b336cbac3a6"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["872cff1d3a554e0cd64014cd97f88d3002b0f491","da6d5ac19a80d65b1e864251f155d30960353b7e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["872cff1d3a554e0cd64014cd97f88d3002b0f491"]},"commit2Childs":{"6620df8541b174097b1133a4fc370adb2e570524":["2a4965b25e439626b575c2281b39ad875f89d891"],"0445bcd8433e331f296f5502fc089b336cbac3a6":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6620df8541b174097b1133a4fc370adb2e570524"],"6fff8f4b218bd0626afcdce82027bafeb84a50a4":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"2a4965b25e439626b575c2281b39ad875f89d891":["0445bcd8433e331f296f5502fc089b336cbac3a6"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","5cab9a86bd67202d20b6adc463008c8e982b070a","2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["6fff8f4b218bd0626afcdce82027bafeb84a50a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}