{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new MockRAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory(random);\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new MockRAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory(random);\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e1cbd7e289dc1243c7a59e1a83d078163a147fe","date":1292268032,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = new RAMDirectory();\n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      Document doc = new Document();\n      doc.add(new Field(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      _TestUtil.checkIndex(dir);\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.setInfoStream(VERBOSE ? System.out : null);\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir, true);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDocAfterFlushingRealDoc().mjava","sourceNew":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","sourceOld":"    // Make sure we can flush segment w/ norms, then add\n    // empty doc (no norms) and flush\n    public void testEmptyDocAfterFlushingRealDoc() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\", customType));\n      writer.addDocument(doc);\n      writer.commit();\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: now add empty doc\");\n      }\n      writer.addDocument(new Document());\n      writer.close();\n      IndexReader reader = IndexReader.open(dir);\n      assertEquals(2, reader.numDocs());\n      reader.close();\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["06584e6e98d592b34e1329b384182f368d2025e8","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["06584e6e98d592b34e1329b384182f368d2025e8"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"06584e6e98d592b34e1329b384182f368d2025e8":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d572389229127c297dd1fa5ce4758e1cec41e799":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["132903c28af3aa6f67284b78de91c0f0a99488c2","7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a3776dccca01c11e7046323cfad46a3b4a471233":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["06584e6e98d592b34e1329b384182f368d2025e8","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"79c2cb24929f2649a8875fb629086171f914d5ce":[],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["06584e6e98d592b34e1329b384182f368d2025e8"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","ab5cb6a74aefb78aa0569857970b9151dfe2e787","a3776dccca01c11e7046323cfad46a3b4a471233"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d572389229127c297dd1fa5ce4758e1cec41e799"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","1509f151d7692d84fae414b2b799ac06ba60fcb4","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"06584e6e98d592b34e1329b384182f368d2025e8":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"962d04139994fce5193143ef35615499a9a96d78":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","79c2cb24929f2649a8875fb629086171f914d5ce","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}