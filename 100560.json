{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","commits":[{"id":"66b61ab77ab36893d701d693f1b6df2a383bb7b5","date":1364405461,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n    MergePolicy.DocMap docMap = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  docMap = merge.getDocMap(mergeState);\n                  assert docMap.isConsistent(merge.info.info.getDocCount());\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              docMap = merge.getDocMap(mergeState);\n              assert docMap.isConsistent(merge.info.info.getDocCount());\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  // TODO (DVU_RENAME) to commitMergedDeletesAndUpdates\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null; // TODO (DVU_RENAME) to mergedDeletesAndUpdates\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<Integer,Map<String,Long>> mergedUpdates = new HashMap<Integer,Map<String,Long>>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<Integer,Map<String,Long>> mergingUpdates = rld.getMergingUpdates();\n      \n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              } else if (mergingUpdates != null) {\n                // document isn't deleted, check if it has updates\n                Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n                if (docUpdates != null) {\n                  if (mergedDeletes == null) {\n                    mergedDeletes = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingUpdates != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if it has updates\n              Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n              if (docUpdates != null) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          } else if (mergingUpdates != null) {\n            // document isn't deleted, check if it has updates\n            Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n            if (docUpdates != null) {\n              if (mergedDeletes == null) {\n                mergedDeletes = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingUpdates != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n          if (docUpdates != null) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              docMap = getDocMap(merge, mergeState);\n            }\n            mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    // set any updates that came while the segment was merging\n    if (!mergedUpdates.isEmpty()) {\n      assert mergedDeletes != null;\n      mergedDeletes.setMergingUpdates(mergedUpdates);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started and \"\n                + mergedDeletes.getPendingUpdatesCount() + \" new field updates since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n    MergePolicy.DocMap docMap = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  docMap = merge.getDocMap(mergeState);\n                  assert docMap.isConsistent(merge.info.info.getDocCount());\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              docMap = merge.getDocMap(mergeState);\n              assert docMap.isConsistent(merge.info.info.getDocCount());\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":["36d84416fc00253f9e834f8dba14fa89b298e64e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  // TODO (DVU_RENAME) to commitMergedDeletesAndUpdates\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null; // TODO (DVU_RENAME) to mergedDeletesAndUpdates\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<Integer,Map<String,Long>> mergedUpdates = new HashMap<Integer,Map<String,Long>>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<Integer,Map<String,Long>> mergingUpdates = rld.getMergingUpdates();\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: info=\" + info + \", mergingUpdates=\" + mergingUpdates);\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              } else if (mergingUpdates != null) {\n                // document isn't deleted, check if it has updates\n                Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n                if (docUpdates != null) {\n                  if (mergedDeletes == null) {\n                    mergedDeletes = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingUpdates != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if it has updates\n              Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n              if (docUpdates != null) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          } else if (mergingUpdates != null) {\n            // document isn't deleted, check if it has updates\n            Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n            if (docUpdates != null) {\n              if (mergedDeletes == null) {\n                mergedDeletes = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingUpdates != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n          if (docUpdates != null) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              docMap = getDocMap(merge, mergeState);\n            }\n            mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    // set any updates that came while the segment was merging\n    if (!mergedUpdates.isEmpty()) {\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: mergedDeletes.info=\" + mergedDeletes.info + \", mergedUpdates=\" + mergedUpdates);\n      assert mergedDeletes != null;\n      mergedDeletes.setMergingUpdates(mergedUpdates);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started and \"\n                + mergedDeletes.getPendingUpdatesCount() + \" new field updates since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  // TODO (DVU_RENAME) to commitMergedDeletesAndUpdates\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null; // TODO (DVU_RENAME) to mergedDeletesAndUpdates\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<Integer,Map<String,Long>> mergedUpdates = new HashMap<Integer,Map<String,Long>>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<Integer,Map<String,Long>> mergingUpdates = rld.getMergingUpdates();\n      \n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              } else if (mergingUpdates != null) {\n                // document isn't deleted, check if it has updates\n                Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n                if (docUpdates != null) {\n                  if (mergedDeletes == null) {\n                    mergedDeletes = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingUpdates != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if it has updates\n              Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n              if (docUpdates != null) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          } else if (mergingUpdates != null) {\n            // document isn't deleted, check if it has updates\n            Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n            if (docUpdates != null) {\n              if (mergedDeletes == null) {\n                mergedDeletes = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingUpdates != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n          if (docUpdates != null) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              docMap = getDocMap(merge, mergeState);\n            }\n            mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    // set any updates that came while the segment was merging\n    if (!mergedUpdates.isEmpty()) {\n      assert mergedDeletes != null;\n      mergedDeletes.setMergingUpdates(mergedUpdates);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started and \"\n                + mergedDeletes.getPendingUpdatesCount() + \" new field updates since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  // TODO (DVU_RENAME) to commitMergedDeletesAndUpdates\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null; // TODO (DVU_RENAME) to mergedDeletesAndUpdates\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<String,NumericFieldUpdates> mergedFieldUpdates = new HashMap<String,NumericFieldUpdates>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<String,NumericFieldUpdates> mergingFieldUpdates = rld.getMergingFieldUpdates();\n      final String[] mergingFields;\n      final UpdatesIterator[] updatesIters;\n      if (mergingFieldUpdates.isEmpty()) {\n        mergingFields = null;\n        updatesIters = null;\n      } else {\n        mergingFields = new String[mergingFieldUpdates.size()];\n        updatesIters = new UpdatesIterator[mergingFieldUpdates.size()];\n        int idx = 0;\n        for (Entry<String,NumericFieldUpdates> e : mergingFieldUpdates.entrySet()) {\n          mergingFields[idx] = e.getKey();\n          updatesIters[idx] = e.getValue().getUpdates();\n          updatesIters[idx].nextDoc(); // advance to first update doc\n          ++idx;\n        }\n      }\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: info=\" + info + \", mergingUpdates=\" + mergingUpdates);\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n                if (mergingFields != null) { // advance all iters beyond the deleted document\n                  skipDeletedDoc(updatesIters, j);\n                }\n              } else if (mergingFields != null) {\n                // document isn't deleted, check if any of the fields have an update to it\n                int newDoc = -1;\n                for (int idx = 0; idx < mergingFields.length; idx++) {\n                  UpdatesIterator updatesIter = updatesIters[idx];\n                  if (updatesIter.doc() == j) { // document has an update\n                    if (mergedDeletes == null) {\n                      mergedDeletes = readerPool.get(merge.info, true);\n                      docMap = getDocMap(merge, mergeState);\n                    }\n                    if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                      newDoc = docMap.map(docUpto);\n                    }\n                    String field = mergingFields[idx];\n                    NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                    if (fieldUpdates == null) {\n                      // an approximantion of maxDoc, used to compute best bitsPerValue\n                      fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                      mergedFieldUpdates.put(field, fieldUpdates);\n                    }\n                    fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                    updatesIter.nextDoc(); // advance to next document\n                  } else {\n                    assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n                  }\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingFields != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if any of the fields have an update to it\n              int newDoc = -1;\n              for (int idx = 0; idx < mergingFields.length; idx++) {\n                UpdatesIterator updatesIter = updatesIters[idx];\n                if (updatesIter.doc() == j) { // document has an update\n                  if (mergedDeletes == null) {\n                    mergedDeletes = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                    newDoc = docMap.map(docUpto);\n                  }\n                  String field = mergingFields[idx];\n                  NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                  if (fieldUpdates == null) {\n                    // an approximantion of maxDoc, used to compute best bitsPerValue\n                    fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                    mergedFieldUpdates.put(field, fieldUpdates);\n                  }\n                  fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                  updatesIter.nextDoc(); // advance to next document\n                } else {\n                  assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n                }\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            } else {\n              // advance all iters beyond the deleted document\n              skipDeletedDoc(updatesIters, j);\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n            if (mergingFields != null) { // advance all iters beyond the deleted document\n              skipDeletedDoc(updatesIters, j);\n            }\n          } else if (mergingFields != null) {\n            // document isn't deleted, check if any of the fields have an update to it\n            int newDoc = -1;\n            for (int idx = 0; idx < mergingFields.length; idx++) {\n              UpdatesIterator updatesIter = updatesIters[idx];\n              if (updatesIter.doc() == j) { // document has an update\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                  newDoc = docMap.map(docUpto);\n                }\n                String field = mergingFields[idx];\n                NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                if (fieldUpdates == null) {\n                  // an approximantion of maxDoc, used to compute best bitsPerValue\n                  fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                  mergedFieldUpdates.put(field, fieldUpdates);\n                }\n                fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                updatesIter.nextDoc(); // advance to next document\n              } else {\n                assert updatesIter.doc() > j : \"field=\" + mergingFields[idx] + \" updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n              }\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingFields != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          int newDoc = -1;\n          for (int idx = 0; idx < mergingFields.length; idx++) {\n            UpdatesIterator updatesIter = updatesIters[idx];\n            if (updatesIter.doc() == j) { // document has an update\n              if (mergedDeletes == null) {\n                mergedDeletes = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                newDoc = docMap.map(docUpto);\n              }\n              String field = mergingFields[idx];\n              NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n              if (fieldUpdates == null) {\n                // an approximantion of maxDoc, used to compute best bitsPerValue\n                fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                mergedFieldUpdates.put(field, fieldUpdates);\n              }\n              fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n              updatesIter.nextDoc(); // advance to next document\n            } else {\n              assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n            }\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes or updates before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (!mergedFieldUpdates.isEmpty()) {\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: mergedDeletes.info=\" + mergedDeletes.info + \", mergedFieldUpdates=\" + mergedFieldUpdates);\n      boolean success = false;\n      try {\n        // if any error occurs while writing the field updates we should release\n        // the info, otherwise it stays in the pool but is considered not \"live\"\n        // which later causes false exceptions in pool.dropAll().\n        // NOTE: currently this is the only place which throws a true\n        // IOException. If this ever changes, we need to extend that try/finally\n        // block to the rest of the method too.\n        mergedDeletes.writeFieldUpdates(directory, mergedFieldUpdates);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        String msg = mergedDeletes.getPendingDeleteCount() + \" new deletes\";\n        if (!mergedFieldUpdates.isEmpty()) {\n          msg += \" and \" + mergedFieldUpdates.size() + \" new field updates\";\n        }\n        msg += \" since merge started\";\n        infoStream.message(\"IW\", msg);\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  // TODO (DVU_RENAME) to commitMergedDeletesAndUpdates\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null; // TODO (DVU_RENAME) to mergedDeletesAndUpdates\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<Integer,Map<String,Long>> mergedUpdates = new HashMap<Integer,Map<String,Long>>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<Integer,Map<String,Long>> mergingUpdates = rld.getMergingUpdates();\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: info=\" + info + \", mergingUpdates=\" + mergingUpdates);\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              } else if (mergingUpdates != null) {\n                // document isn't deleted, check if it has updates\n                Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n                if (docUpdates != null) {\n                  if (mergedDeletes == null) {\n                    mergedDeletes = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingUpdates != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if it has updates\n              Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n              if (docUpdates != null) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          } else if (mergingUpdates != null) {\n            // document isn't deleted, check if it has updates\n            Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n            if (docUpdates != null) {\n              if (mergedDeletes == null) {\n                mergedDeletes = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingUpdates != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          Map<String,Long> docUpdates = mergingUpdates.get(Integer.valueOf(j));\n          if (docUpdates != null) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              docMap = getDocMap(merge, mergeState);\n            }\n            mergedUpdates.put(Integer.valueOf(docMap.map(docUpto)), docUpdates);\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    // set any updates that came while the segment was merging\n    if (!mergedUpdates.isEmpty()) {\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: mergedDeletes.info=\" + mergedDeletes.info + \", mergedUpdates=\" + mergedUpdates);\n      assert mergedDeletes != null;\n      mergedDeletes.setMergingUpdates(mergedUpdates);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started and \"\n                + mergedDeletes.getPendingUpdatesCount() + \" new field updates since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletesAndUpdates(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  synchronized private ReadersAndUpdates commitMergedDeletesAndUpdates(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentCommitInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndUpdates mergedDeletesAndUpdates = null;\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<String,NumericFieldUpdates> mergedFieldUpdates = new HashMap<String,NumericFieldUpdates>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentCommitInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndUpdates rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<String,NumericFieldUpdates> mergingFieldUpdates = rld.getMergingFieldUpdates();\n      final String[] mergingFields;\n      final UpdatesIterator[] updatesIters;\n      if (mergingFieldUpdates.isEmpty()) {\n        mergingFields = null;\n        updatesIters = null;\n      } else {\n        mergingFields = new String[mergingFieldUpdates.size()];\n        updatesIters = new UpdatesIterator[mergingFieldUpdates.size()];\n        int idx = 0;\n        for (Entry<String,NumericFieldUpdates> e : mergingFieldUpdates.entrySet()) {\n          mergingFields[idx] = e.getKey();\n          updatesIters[idx] = e.getValue().getUpdates();\n          updatesIters[idx].nextDoc(); // advance to first update doc\n          ++idx;\n        }\n      }\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: info=\" + info + \", mergingUpdates=\" + mergingUpdates);\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletesAndUpdates == null) {\n                  mergedDeletesAndUpdates = readerPool.get(merge.info, true);\n                  mergedDeletesAndUpdates.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletesAndUpdates.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletesAndUpdates.delete(docMap.map(docUpto));\n                if (mergingFields != null) { // advance all iters beyond the deleted document\n                  skipDeletedDoc(updatesIters, j);\n                }\n              } else if (mergingFields != null) {\n                // document isn't deleted, check if any of the fields have an update to it\n                int newDoc = -1;\n                for (int idx = 0; idx < mergingFields.length; idx++) {\n                  UpdatesIterator updatesIter = updatesIters[idx];\n                  if (updatesIter.doc() == j) { // document has an update\n                    if (mergedDeletesAndUpdates == null) {\n                      mergedDeletesAndUpdates = readerPool.get(merge.info, true);\n                      docMap = getDocMap(merge, mergeState);\n                    }\n                    if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                      newDoc = docMap.map(docUpto);\n                    }\n                    String field = mergingFields[idx];\n                    NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                    if (fieldUpdates == null) {\n                      // an approximantion of maxDoc, used to compute best bitsPerValue\n                      fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                      mergedFieldUpdates.put(field, fieldUpdates);\n                    }\n                    fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                    updatesIter.nextDoc(); // advance to next document\n                  } else {\n                    assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n                  }\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingFields != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if any of the fields have an update to it\n              int newDoc = -1;\n              for (int idx = 0; idx < mergingFields.length; idx++) {\n                UpdatesIterator updatesIter = updatesIters[idx];\n                if (updatesIter.doc() == j) { // document has an update\n                  if (mergedDeletesAndUpdates == null) {\n                    mergedDeletesAndUpdates = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                    newDoc = docMap.map(docUpto);\n                  }\n                  String field = mergingFields[idx];\n                  NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                  if (fieldUpdates == null) {\n                    // an approximantion of maxDoc, used to compute best bitsPerValue\n                    fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                    mergedFieldUpdates.put(field, fieldUpdates);\n                  }\n                  fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                  updatesIter.nextDoc(); // advance to next document\n                } else {\n                  assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n                }\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            } else {\n              // advance all iters beyond the deleted document\n              skipDeletedDoc(updatesIters, j);\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletesAndUpdates == null) {\n              mergedDeletesAndUpdates = readerPool.get(merge.info, true);\n              mergedDeletesAndUpdates.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletesAndUpdates.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletesAndUpdates.delete(docMap.map(docUpto));\n            if (mergingFields != null) { // advance all iters beyond the deleted document\n              skipDeletedDoc(updatesIters, j);\n            }\n          } else if (mergingFields != null) {\n            // document isn't deleted, check if any of the fields have an update to it\n            int newDoc = -1;\n            for (int idx = 0; idx < mergingFields.length; idx++) {\n              UpdatesIterator updatesIter = updatesIters[idx];\n              if (updatesIter.doc() == j) { // document has an update\n                if (mergedDeletesAndUpdates == null) {\n                  mergedDeletesAndUpdates = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                  newDoc = docMap.map(docUpto);\n                }\n                String field = mergingFields[idx];\n                NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                if (fieldUpdates == null) {\n                  // an approximantion of maxDoc, used to compute best bitsPerValue\n                  fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                  mergedFieldUpdates.put(field, fieldUpdates);\n                }\n                fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                updatesIter.nextDoc(); // advance to next document\n              } else {\n                assert updatesIter.doc() > j : \"field=\" + mergingFields[idx] + \" updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n              }\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingFields != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          int newDoc = -1;\n          for (int idx = 0; idx < mergingFields.length; idx++) {\n            UpdatesIterator updatesIter = updatesIters[idx];\n            if (updatesIter.doc() == j) { // document has an update\n              if (mergedDeletesAndUpdates == null) {\n                mergedDeletesAndUpdates = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                newDoc = docMap.map(docUpto);\n              }\n              String field = mergingFields[idx];\n              NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n              if (fieldUpdates == null) {\n                // an approximantion of maxDoc, used to compute best bitsPerValue\n                fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                mergedFieldUpdates.put(field, fieldUpdates);\n              }\n              fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n              updatesIter.nextDoc(); // advance to next document\n            } else {\n              assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n            }\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes or updates before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (!mergedFieldUpdates.isEmpty()) {\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: mergedDeletes.info=\" + mergedDeletes.info + \", mergedFieldUpdates=\" + mergedFieldUpdates);\n      boolean success = false;\n      try {\n        // if any error occurs while writing the field updates we should release\n        // the info, otherwise it stays in the pool but is considered not \"live\"\n        // which later causes false exceptions in pool.dropAll().\n        // NOTE: currently this is the only place which throws a true\n        // IOException. If this ever changes, we need to extend that try/finally\n        // block to the rest of the method too.\n        mergedDeletesAndUpdates.writeFieldUpdates(directory, mergedFieldUpdates);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletesAndUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletesAndUpdates == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        String msg = mergedDeletesAndUpdates.getPendingDeleteCount() + \" new deletes\";\n        if (!mergedFieldUpdates.isEmpty()) {\n          msg += \" and \" + mergedFieldUpdates.size() + \" new field updates\";\n        }\n        msg += \" since merge started\";\n        infoStream.message(\"IW\", msg);\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletesAndUpdates;\n  }\n\n","sourceOld":"  /**\n   * Carefully merges deletes and updates for the segments we just merged. This\n   * is tricky because, although merging will clear all deletes (compacts the\n   * documents) and compact all the updates, new deletes and updates may have\n   * been flushed to the segments since the merge was started. This method\n   * \"carries over\" such new deletes and updates onto the newly merged segment,\n   * and saves the resulting deletes and updates files (incrementing the delete\n   * and DV generations for merge.info). If no deletes were flushed, no new\n   * deletes file is saved.\n   */\n  // TODO (DVU_RENAME) to commitMergedDeletesAndUpdates\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null; // TODO (DVU_RENAME) to mergedDeletesAndUpdates\n    boolean initWritableLiveDocs = false;\n    MergePolicy.DocMap docMap = null;\n    final Map<String,NumericFieldUpdates> mergedFieldUpdates = new HashMap<String,NumericFieldUpdates>();\n    \n    for (int i = 0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      final Bits currentLiveDocs = rld.getLiveDocs();\n      final Map<String,NumericFieldUpdates> mergingFieldUpdates = rld.getMergingFieldUpdates();\n      final String[] mergingFields;\n      final UpdatesIterator[] updatesIters;\n      if (mergingFieldUpdates.isEmpty()) {\n        mergingFields = null;\n        updatesIters = null;\n      } else {\n        mergingFields = new String[mergingFieldUpdates.size()];\n        updatesIters = new UpdatesIterator[mergingFieldUpdates.size()];\n        int idx = 0;\n        for (Entry<String,NumericFieldUpdates> e : mergingFieldUpdates.entrySet()) {\n          mergingFields[idx] = e.getKey();\n          updatesIters[idx] = e.getValue().getUpdates();\n          updatesIters[idx].nextDoc(); // advance to first update doc\n          ++idx;\n        }\n      }\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: info=\" + info + \", mergingUpdates=\" + mergingUpdates);\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for (int j = 0; j < docCount; j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                  docMap = getDocMap(merge, mergeState);\n                } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n                  mergedDeletes.initWritableLiveDocs();\n                  initWritableLiveDocs = true;\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n                if (mergingFields != null) { // advance all iters beyond the deleted document\n                  skipDeletedDoc(updatesIters, j);\n                }\n              } else if (mergingFields != null) {\n                // document isn't deleted, check if any of the fields have an update to it\n                int newDoc = -1;\n                for (int idx = 0; idx < mergingFields.length; idx++) {\n                  UpdatesIterator updatesIter = updatesIters[idx];\n                  if (updatesIter.doc() == j) { // document has an update\n                    if (mergedDeletes == null) {\n                      mergedDeletes = readerPool.get(merge.info, true);\n                      docMap = getDocMap(merge, mergeState);\n                    }\n                    if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                      newDoc = docMap.map(docUpto);\n                    }\n                    String field = mergingFields[idx];\n                    NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                    if (fieldUpdates == null) {\n                      // an approximantion of maxDoc, used to compute best bitsPerValue\n                      fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                      mergedFieldUpdates.put(field, fieldUpdates);\n                    }\n                    fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                    updatesIter.nextDoc(); // advance to next document\n                  } else {\n                    assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n                  }\n                }\n              }\n              docUpto++;\n            }\n          }\n        } else if (mergingFields != null) {\n          // need to check each non-deleted document if it has any updates\n          for (int j = 0; j < docCount; j++) {\n            if (prevLiveDocs.get(j)) {\n              // document isn't deleted, check if any of the fields have an update to it\n              int newDoc = -1;\n              for (int idx = 0; idx < mergingFields.length; idx++) {\n                UpdatesIterator updatesIter = updatesIters[idx];\n                if (updatesIter.doc() == j) { // document has an update\n                  if (mergedDeletes == null) {\n                    mergedDeletes = readerPool.get(merge.info, true);\n                    docMap = getDocMap(merge, mergeState);\n                  }\n                  if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                    newDoc = docMap.map(docUpto);\n                  }\n                  String field = mergingFields[idx];\n                  NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                  if (fieldUpdates == null) {\n                    // an approximantion of maxDoc, used to compute best bitsPerValue\n                    fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                    mergedFieldUpdates.put(field, fieldUpdates);\n                  }\n                  fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                  updatesIter.nextDoc(); // advance to next document\n                } else {\n                  assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n                }\n              }\n              // advance docUpto for every non-deleted document\n              docUpto++;\n            } else {\n              // advance all iters beyond the deleted document\n              skipDeletedDoc(updatesIters, j);\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for (int j = 0; j < docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n              docMap = getDocMap(merge, mergeState);\n            } else if (!initWritableLiveDocs) { // mergedDeletes was initialized by field-updates changes\n              mergedDeletes.initWritableLiveDocs();\n              initWritableLiveDocs = true;\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n            if (mergingFields != null) { // advance all iters beyond the deleted document\n              skipDeletedDoc(updatesIters, j);\n            }\n          } else if (mergingFields != null) {\n            // document isn't deleted, check if any of the fields have an update to it\n            int newDoc = -1;\n            for (int idx = 0; idx < mergingFields.length; idx++) {\n              UpdatesIterator updatesIter = updatesIters[idx];\n              if (updatesIter.doc() == j) { // document has an update\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  docMap = getDocMap(merge, mergeState);\n                }\n                if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                  newDoc = docMap.map(docUpto);\n                }\n                String field = mergingFields[idx];\n                NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n                if (fieldUpdates == null) {\n                  // an approximantion of maxDoc, used to compute best bitsPerValue\n                  fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                  mergedFieldUpdates.put(field, fieldUpdates);\n                }\n                fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n                updatesIter.nextDoc(); // advance to next document\n              } else {\n                assert updatesIter.doc() > j : \"field=\" + mergingFields[idx] + \" updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n              }\n            }\n          }\n          docUpto++;\n        }\n      } else if (mergingFields != null) {\n        // no deletions before or after, but there were updates\n        for (int j = 0; j < docCount; j++) {\n          int newDoc = -1;\n          for (int idx = 0; idx < mergingFields.length; idx++) {\n            UpdatesIterator updatesIter = updatesIters[idx];\n            if (updatesIter.doc() == j) { // document has an update\n              if (mergedDeletes == null) {\n                mergedDeletes = readerPool.get(merge.info, true);\n                docMap = getDocMap(merge, mergeState);\n              }\n              if (newDoc == -1) { // map once per all field updates, but only if there are any updates\n                newDoc = docMap.map(docUpto);\n              }\n              String field = mergingFields[idx];\n              NumericFieldUpdates fieldUpdates = mergedFieldUpdates.get(field);\n              if (fieldUpdates == null) {\n                // an approximantion of maxDoc, used to compute best bitsPerValue\n                fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(mergeState.segmentInfo.getDocCount());\n                mergedFieldUpdates.put(field, fieldUpdates);\n              }\n              fieldUpdates.add(newDoc, updatesIter.value() == null ? NumericUpdate.MISSING : updatesIter.value());\n              updatesIter.nextDoc(); // advance to next document\n            } else {\n              assert updatesIter.doc() > j : \"updateDoc=\" + updatesIter.doc() + \" curDoc=\" + j;\n            }\n          }\n          // advance docUpto for every non-deleted document\n          docUpto++;\n        }\n      } else {\n        // No deletes or updates before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (!mergedFieldUpdates.isEmpty()) {\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMergedDeletes: mergedDeletes.info=\" + mergedDeletes.info + \", mergedFieldUpdates=\" + mergedFieldUpdates);\n      boolean success = false;\n      try {\n        // if any error occurs while writing the field updates we should release\n        // the info, otherwise it stays in the pool but is considered not \"live\"\n        // which later causes false exceptions in pool.dropAll().\n        // NOTE: currently this is the only place which throws a true\n        // IOException. If this ever changes, we need to extend that try/finally\n        // block to the rest of the method too.\n        mergedDeletes.writeFieldUpdates(directory, mergedFieldUpdates);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes or field updates since merge started\");\n      } else {\n        String msg = mergedDeletes.getPendingDeleteCount() + \" new deletes\";\n        if (!mergedFieldUpdates.isEmpty()) {\n          msg += \" and \" + mergedFieldUpdates.size() + \" new field updates\";\n        }\n        msg += \" since merge started\";\n        infoStream.message(\"IW\", msg);\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}