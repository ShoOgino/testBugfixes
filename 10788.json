{"path":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyze(String).mjava","commits":[{"id":"f554f2d9b5456248ab6467b9d4f6015686797a6c","date":1554891357,"type":0,"author":"Tomoko Uchida","isMerge":false,"pathNew":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyze(String).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public List<Token> analyze(String text) {\n    Objects.requireNonNull(text);\n\n    if (analyzer == null) {\n      throw new LukeException(\"Analyzer is not set.\");\n    }\n\n    try {\n      List<Token> result = new ArrayList<>();\n\n      TokenStream stream = analyzer.tokenStream(\"\", text);\n      stream.reset();\n\n      CharTermAttribute charAtt = stream.getAttribute(CharTermAttribute.class);\n\n      // iterate tokens\n      while (stream.incrementToken()) {\n        List<TokenAttribute> attributes = new ArrayList<>();\n        Iterator<AttributeImpl> itr = stream.getAttributeImplsIterator();\n\n        while (itr.hasNext()) {\n          AttributeImpl att = itr.next();\n          Map<String, String> attValues = new LinkedHashMap<>();\n          att.reflectWith((attClass, key, value) -> {\n            if (value != null)\n              attValues.put(key, value.toString());\n          });\n          attributes.add(new TokenAttribute(att.getClass().getSimpleName(), attValues));\n        }\n\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      stream.close();\n\n      return result;\n    } catch (IOException e) {\n      throw new LukeException(e.getMessage(), e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77","date":1561188146,"type":3,"author":"Tomoko Uchida","isMerge":false,"pathNew":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyze(String).mjava","pathOld":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyze(String).mjava","sourceNew":"  @Override\n  public List<Token> analyze(String text) {\n    Objects.requireNonNull(text);\n\n    if (analyzer == null) {\n      throw new LukeException(\"Analyzer is not set.\");\n    }\n\n    try {\n      List<Token> result = new ArrayList<>();\n      TokenStream stream = analyzer.tokenStream(\"\", text);\n      stream.reset();\n\n      CharTermAttribute charAtt = stream.getAttribute(CharTermAttribute.class);\n\n      // iterate tokens\n      while (stream.incrementToken()) {\n        List<TokenAttribute> attributes = copyAttributes(stream, charAtt);\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      stream.close();\n\n      return result;\n    } catch (IOException e) {\n      throw new LukeException(e.getMessage(), e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public List<Token> analyze(String text) {\n    Objects.requireNonNull(text);\n\n    if (analyzer == null) {\n      throw new LukeException(\"Analyzer is not set.\");\n    }\n\n    try {\n      List<Token> result = new ArrayList<>();\n\n      TokenStream stream = analyzer.tokenStream(\"\", text);\n      stream.reset();\n\n      CharTermAttribute charAtt = stream.getAttribute(CharTermAttribute.class);\n\n      // iterate tokens\n      while (stream.incrementToken()) {\n        List<TokenAttribute> attributes = new ArrayList<>();\n        Iterator<AttributeImpl> itr = stream.getAttributeImplsIterator();\n\n        while (itr.hasNext()) {\n          AttributeImpl att = itr.next();\n          Map<String, String> attValues = new LinkedHashMap<>();\n          att.reflectWith((attClass, key, value) -> {\n            if (value != null)\n              attValues.put(key, value.toString());\n          });\n          attributes.add(new TokenAttribute(att.getClass().getSimpleName(), attValues));\n        }\n\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      stream.close();\n\n      return result;\n    } catch (IOException e) {\n      throw new LukeException(e.getMessage(), e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dde00f8ce3ea6870a348e607a273123f0895ec87","date":1561189287,"type":3,"author":"Tomoko Uchida","isMerge":true,"pathNew":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyze(String).mjava","pathOld":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyze(String).mjava","sourceNew":"  @Override\n  public List<Token> analyze(String text) {\n    Objects.requireNonNull(text);\n\n    if (analyzer == null) {\n      throw new LukeException(\"Analyzer is not set.\");\n    }\n\n    try {\n      List<Token> result = new ArrayList<>();\n      TokenStream stream = analyzer.tokenStream(\"\", text);\n      stream.reset();\n\n      CharTermAttribute charAtt = stream.getAttribute(CharTermAttribute.class);\n\n      // iterate tokens\n      while (stream.incrementToken()) {\n        List<TokenAttribute> attributes = copyAttributes(stream, charAtt);\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      stream.close();\n\n      return result;\n    } catch (IOException e) {\n      throw new LukeException(e.getMessage(), e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public List<Token> analyze(String text) {\n    Objects.requireNonNull(text);\n\n    if (analyzer == null) {\n      throw new LukeException(\"Analyzer is not set.\");\n    }\n\n    try {\n      List<Token> result = new ArrayList<>();\n\n      TokenStream stream = analyzer.tokenStream(\"\", text);\n      stream.reset();\n\n      CharTermAttribute charAtt = stream.getAttribute(CharTermAttribute.class);\n\n      // iterate tokens\n      while (stream.incrementToken()) {\n        List<TokenAttribute> attributes = new ArrayList<>();\n        Iterator<AttributeImpl> itr = stream.getAttributeImplsIterator();\n\n        while (itr.hasNext()) {\n          AttributeImpl att = itr.next();\n          Map<String, String> attValues = new LinkedHashMap<>();\n          att.reflectWith((attClass, key, value) -> {\n            if (value != null)\n              attValues.put(key, value.toString());\n          });\n          attributes.add(new TokenAttribute(att.getClass().getSimpleName(), attValues));\n        }\n\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      stream.close();\n\n      return result;\n    } catch (IOException e) {\n      throw new LukeException(e.getMessage(), e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f554f2d9b5456248ab6467b9d4f6015686797a6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"dde00f8ce3ea6870a348e607a273123f0895ec87":["f554f2d9b5456248ab6467b9d4f6015686797a6c","7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77"],"7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77":["f554f2d9b5456248ab6467b9d4f6015686797a6c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dde00f8ce3ea6870a348e607a273123f0895ec87"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f554f2d9b5456248ab6467b9d4f6015686797a6c"],"f554f2d9b5456248ab6467b9d4f6015686797a6c":["dde00f8ce3ea6870a348e607a273123f0895ec87","7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77"],"dde00f8ce3ea6870a348e607a273123f0895ec87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77":["dde00f8ce3ea6870a348e607a273123f0895ec87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}