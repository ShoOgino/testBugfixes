{"path":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":null,"sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b5f7137bd9491c6596681b1f56e481e17964e581","date":1294458451,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec58fb7921964848d01bea54f8ec4a2ac813eaeb","date":1295476876,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<AttributeSource> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<AttributeSource> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<AttributeSource> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0487f900016b7da69f089f740e28192189ef3972","date":1307810819,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<AttributeSource> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":["77e6111c8c695bcab271a048bf5aae6b05cf415b","77e6111c8c695bcab271a048bf5aae6b05cf415b","77e6111c8c695bcab271a048bf5aae6b05cf415b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9ed208afa1e7aa98899ddb1dedfddedddf898253","date":1308079587,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<AttributeSource> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb2f9f463f8178028c6e786ca3334253a55de16f","date":1310039892,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1291e4568eb7d9463d751627596ef14baf4c1603","date":1310112572,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"cb2f9f463f8178028c6e786ca3334253a55de16f":["0487f900016b7da69f089f740e28192189ef3972"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b5f7137bd9491c6596681b1f56e481e17964e581":["1da8d55113b689b06716246649de6f62430f15c0"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["cb2f9f463f8178028c6e786ca3334253a55de16f","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"0487f900016b7da69f089f740e28192189ef3972":["ec58fb7921964848d01bea54f8ec4a2ac813eaeb"],"ec58fb7921964848d01bea54f8ec4a2ac813eaeb":["b5f7137bd9491c6596681b1f56e481e17964e581"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["ec58fb7921964848d01bea54f8ec4a2ac813eaeb","0487f900016b7da69f089f740e28192189ef3972"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["868da859b43505d9d2a023bfeae6dd0c795f5295","ec58fb7921964848d01bea54f8ec4a2ac813eaeb"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"1291e4568eb7d9463d751627596ef14baf4c1603":["0487f900016b7da69f089f740e28192189ef3972","cb2f9f463f8178028c6e786ca3334253a55de16f"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["9ed208afa1e7aa98899ddb1dedfddedddf898253"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["1da8d55113b689b06716246649de6f62430f15c0","ec58fb7921964848d01bea54f8ec4a2ac813eaeb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["cb2f9f463f8178028c6e786ca3334253a55de16f"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["1da8d55113b689b06716246649de6f62430f15c0","b5f7137bd9491c6596681b1f56e481e17964e581"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"cb2f9f463f8178028c6e786ca3334253a55de16f":["c26f00b574427b55127e869b935845554afde1fa","1291e4568eb7d9463d751627596ef14baf4c1603","a258fbb26824fd104ed795e5d9033d2d040049ee"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"b5f7137bd9491c6596681b1f56e481e17964e581":["ec58fb7921964848d01bea54f8ec4a2ac813eaeb","868da859b43505d9d2a023bfeae6dd0c795f5295"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"0487f900016b7da69f089f740e28192189ef3972":["cb2f9f463f8178028c6e786ca3334253a55de16f","9ed208afa1e7aa98899ddb1dedfddedddf898253","1291e4568eb7d9463d751627596ef14baf4c1603"],"ec58fb7921964848d01bea54f8ec4a2ac813eaeb":["0487f900016b7da69f089f740e28192189ef3972","9ed208afa1e7aa98899ddb1dedfddedddf898253","e79a6d080bdd5b2a8f56342cf571b5476de04180","29ef99d61cda9641b6250bf9567329a6e65f901d"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":[],"1da8d55113b689b06716246649de6f62430f15c0":["b5f7137bd9491c6596681b1f56e481e17964e581","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295"],"1291e4568eb7d9463d751627596ef14baf4c1603":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e79a6d080bdd5b2a8f56342cf571b5476de04180","1291e4568eb7d9463d751627596ef14baf4c1603","29ef99d61cda9641b6250bf9567329a6e65f901d","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}