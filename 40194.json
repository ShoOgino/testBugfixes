{"path":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc4283a38102a08c5832529ccbd1dbe8bcb81da9","date":1310585920,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = searcher.weightSort(cmd.getSort());\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ?  sort : searcher.weightSort(QueryParsing.parseSort(groupSortStr, req));\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":["9c7cdfe5a1ea9db97faa404b251fa644faa73597","b2b1c725218c10a43512759db57f636658a1695a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3738f7d06920ae25ab2884f4efd80c42e95d6271","date":1312707753,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        boolean truncateGroups = params.getBool(GroupParams.GROUP_TRUNCATE, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = searcher.weightSort(cmd.getSort());\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ?  sort : searcher.weightSort(QueryParsing.parseSort(groupSortStr, req));\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault)\n            .setGetGroupedDocSet(truncateGroups);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = searcher.weightSort(cmd.getSort());\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ?  sort : searcher.weightSort(QueryParsing.parseSort(groupSortStr, req));\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ccc08aa684aee4964baee0644a6ba047bfd70829","date":1316263707,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(\"group.distibuted.first\", false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(\"group.distibuted.second\", false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(\"group.topgroups.\" + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        boolean truncateGroups = params.getBool(GroupParams.GROUP_TRUNCATE, false);\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(truncateGroups);\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        boolean truncateGroups = params.getBool(GroupParams.GROUP_TRUNCATE, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = searcher.weightSort(cmd.getSort());\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ?  sort : searcher.weightSort(QueryParsing.parseSort(groupSortStr, req));\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault)\n            .setGetGroupedDocSet(truncateGroups);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":["27270b721a573cf4b774ce70b062078ef490388e","b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3","af20870f6eab3807c968eec0b24e0c4358d0c1e5","29cb9edc6c1e87b23f635321e1c3de19172d32fb","d423443db06bfcac81733aafcce04ee491880cc7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0414a20d73ebe5c96a6e7e70e337083ec37f01fd","date":1316542523,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(\"group.distibuted.first\", false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(\"group.distibuted.second\", false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(\"group.topgroups.\" + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(\"group.distibuted.first\", false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(\"group.distibuted.second\", false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(\"group.topgroups.\" + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        boolean truncateGroups = params.getBool(GroupParams.GROUP_TRUNCATE, false);\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(truncateGroups);\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"27270b721a573cf4b774ce70b062078ef490388e","date":1329092012,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(\"group.distributed.first\", false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(\"group.distributed.second\", false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(\"group.topgroups.\" + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(\"group.distibuted.first\", false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(\"group.distibuted.second\", false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(\"group.topgroups.\" + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":["ccc08aa684aee4964baee0644a6ba047bfd70829"],"bugIntro":["b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3","date":1332285979,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(\"group.distributed.first\", false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(\"group.distributed.second\", false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(\"group.topgroups.\" + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":["27270b721a573cf4b774ce70b062078ef490388e","ccc08aa684aee4964baee0644a6ba047bfd70829"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"612521de57bdf68711c68b6d8565e4a80ca0d7f6","date":1333716414,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              continue;\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"af20870f6eab3807c968eec0b24e0c4358d0c1e5","date":1337002937,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .setNeedGroupCount(groupingSpec.isIncludeGroupCount())\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":["ccc08aa684aee4964baee0644a6ba047bfd70829"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"197070b7f9191af8b5d8598b579393d4a67e32f0","date":1341843740,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cdb67100dc016748799a77218aa409478372d79","date":1353699950,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d5bc8e25f59990525f5beb14afe9c96240dcf4a2","date":1389042945,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<SearchGroup<BytesRef>>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<BytesRef>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c70567cc1ae757045c80cb458b0b2a2ffcf0141","date":1400098332,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ccc69a67d5c846a04c7f71e28cb1914e3af895f3","date":1400252660,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ba39ba201a572fd944ed71d888de0cd4f2957af","date":1404307334,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" + \n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT, \n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e","date":1411674127,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da951a24a6a87d5ba7e1820f8c28a1e2beea76c1","date":1411744836,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"27b6648517583abadd334777ec0230aea09e2ab1","date":1418396023,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundementally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a94e45463a0089149b0d148ae5369140e7f54b8c","date":1419231934,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":["df72a23fb74bebe914e3f3972063a884327c0436"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7e0383a0a3421b9f6f61002dd4f6fb39bf71285","date":1427227523,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":["bc51dee911981d59e003ffa7442c4f68d9947083"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e1f55a6bbd78f36075a6f59ae26b75b5ce94ffc","date":1436274634,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = searcher.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(searcher.getSchema().getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(searcher.getSchema().getField(field).getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(searcher.getSchema().getField(field))\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc","date":1440797084,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"de65fb6e86ba37c5409efafefe587d0c897c2764","date":1445143934,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"09cb2e0d073412dbf283b88292b70aaf62d55276","date":1445181245,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ecd75942508378ccc92c3a26f71db6cba9f25784","date":1450708761,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5541f19734f6966068596a4a5fd378ab93d8bc25","date":1452083308,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new QueryCommand.Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac9de183adbc9483681f275ac1e2d92ed19f52e1","date":1452414626,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1a9c2b42591c0db6f85041d5cfc9cba17fe45e0b","date":1455308162,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29cb9edc6c1e87b23f635321e1c3de19172d32fb","date":1458495029,"type":3,"author":"Dennis Gove","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug() || params.getBool(MoreLikeThisParams.MLT, false)) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":["ccc08aa684aee4964baee0644a6ba047bfd70829"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d423443db06bfcac81733aafcce04ee491880cc7","date":1477501011,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getGroupOffset(), groupingSpec.getGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":["ccc08aa684aee4964baee0644a6ba047bfd70829"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getGroupOffset(), groupingSpec.getGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(groupingSpec.getGroupOffset() + groupingSpec.getGroupLimit())\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(groupingSpec.getOffset() + groupingSpec.getLimit())\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f20d97ebbd280405cebcc21d53c781bf4456453","date":1480454130,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getGroupOffset(), groupingSpec.getGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b101c3c0e7f5871415e80d970cb3289309f3522e","date":1480511898,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getGroupOffset(), groupingSpec.getGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getGroupOffset(), groupingSpec.getGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46dc9ac8b3e748407baaef82453138ff3974480c","date":1484789241,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90a682dc1bfd188ef61cc28373c7f5d700b4ac75","date":1485186128,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = searcher.getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ce489ffe249d0942d3dd9d8f0b46d3a5385ca01","date":1489998096,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                BytesRefBuilder builder = new BytesRefBuilder();\n                schemaField.getType().readableToIndexed(topGroup, builder);\n                searchGroup.groupValue = builder.get();\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06f29c9961912220543423aa6fc6f64362874871","date":1490280012,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                BytesRefBuilder builder = new BytesRefBuilder();\n                schemaField.getType().readableToIndexed(topGroup, builder);\n                searchGroup.groupValue = builder.get();\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                searchGroup.groupValue = new BytesRef(schemaField.getType().readableToIndexed(topGroup));\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af8334dcf26521da965e339ff1096e0e7bcdd8c6","date":1504885366,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                BytesRefBuilder builder = new BytesRefBuilder();\n                schemaField.getType().readableToIndexed(topGroup, builder);\n                searchGroup.groupValue = builder.get();\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":["f4924281697ed8ed3790f0f327be1fbde8160afc","df72a23fb74bebe914e3f3972063a884327c0436"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dd68c90c39731aaa564d6995e5dd4a4c2388e13e","date":1504887539,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                BytesRefBuilder builder = new BytesRefBuilder();\n                schemaField.getType().readableToIndexed(topGroup, builder);\n                searchGroup.groupValue = builder.get();\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4924281697ed8ed3790f0f327be1fbde8160afc","date":1505151135,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, result);\n  }\n\n","bugFix":["af8334dcf26521da965e339ff1096e0e7bcdd8c6"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ffb85feece8645a035c02443a625f5af15e1106b","date":1505219692,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"685bd38810c206c93e9058f3c2cfa9827c086c27","date":1505751821,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    SolrQueryResponse rsp = rb.rsp;\n    IndexSchema schema = searcher.getSchema();\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = schema.getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      if (idField.getType().isPointField()) {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.search(\n              idField.getType().getFieldQuery(null, idField, idArr.get(i)), 1).scoreDocs[0].doc;\n          if (id >= 0) {\n            luceneIds[docs++] = id;\n          }\n        }\n      } else {\n        for (int i=0; i<idArr.size(); i++) {\n          int id = searcher.getFirstMatch(\n                  new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n          if (id >= 0)\n            luceneIds[docs++] = id;\n        }\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n\n      ResultContext ctx = new BasicResultContext(rb);\n      rsp.addResponse(ctx);\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        boolean needScores = (cmd.getFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          CommandHandler.Builder topsGroupsActionBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setNeedDocSet(false) // Order matters here\n              .setIncludeHitCount(true)\n              .setSearcher(searcher);\n\n          for (String field : groupingSpec.getFields()) {\n            topsGroupsActionBuilder.addCommandField(new SearchGroupsFieldCommand.Builder()\n                .setField(schema.getField(field))\n                .setGroupSort(groupingSpec.getGroupSort())\n                .setTopNGroups(cmd.getOffset() + cmd.getLen())\n                .setIncludeGroupCount(groupingSpec.isIncludeGroupCount())\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = topsGroupsActionBuilder.build();\n          commandHandler.execute();\n          SearchGroupsResultTransformer serializer = new SearchGroupsResultTransformer(searcher);\n          rsp.add(\"firstPhase\", commandHandler.processResult(result, serializer));\n          rsp.add(\"totalHitCount\", commandHandler.getTotalHitCount());\n          rb.setResult(result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          CommandHandler.Builder secondPhaseBuilder = new CommandHandler.Builder()\n              .setQueryCommand(cmd)\n              .setTruncateGroups(groupingSpec.isTruncateGroups() && groupingSpec.getFields().length > 0)\n              .setSearcher(searcher);\n\n          int docsToCollect = Grouping.getMax(groupingSpec.getWithinGroupOffset(), groupingSpec.getWithinGroupLimit(), searcher.maxDoc());\n          docsToCollect = Math.max(docsToCollect, 1);\n\n          for (String field : groupingSpec.getFields()) {\n            SchemaField schemaField = schema.getField(field);\n            String[] topGroupsParam = params.getParams(GroupParams.GROUP_DISTRIBUTED_TOPGROUPS_PREFIX + field);\n            if (topGroupsParam == null) {\n              topGroupsParam = new String[0];\n            }\n\n            List<SearchGroup<BytesRef>> topGroups = new ArrayList<>(topGroupsParam.length);\n            for (String topGroup : topGroupsParam) {\n              SearchGroup<BytesRef> searchGroup = new SearchGroup<>();\n              if (!topGroup.equals(TopGroupsShardRequestFactory.GROUP_NULL_VALUE)) {\n                BytesRefBuilder builder = new BytesRefBuilder();\n                schemaField.getType().readableToIndexed(topGroup, builder);\n                searchGroup.groupValue = builder.get();\n              }\n              topGroups.add(searchGroup);\n            }\n\n            secondPhaseBuilder.addCommandField(\n                new TopGroupsFieldCommand.Builder()\n                    .setField(schemaField)\n                    .setGroupSort(groupingSpec.getGroupSort())\n                    .setSortWithinGroup(groupingSpec.getSortWithinGroup())\n                    .setFirstPhaseGroups(topGroups)\n                    .setMaxDocPerGroup(docsToCollect)\n                    .setNeedScores(needScores)\n                    .setNeedMaxScore(needScores)\n                    .build()\n            );\n          }\n\n          for (String query : groupingSpec.getQueries()) {\n            secondPhaseBuilder.addCommandField(new Builder()\n                .setDocsToCollect(docsToCollect)\n                .setSort(groupingSpec.getGroupSort())\n                .setQuery(query, rb.req)\n                .setDocSet(searcher)\n                .build()\n            );\n          }\n\n          CommandHandler commandHandler = secondPhaseBuilder.build();\n          commandHandler.execute();\n          TopGroupsResultTransformer serializer = new TopGroupsResultTransformer(rb);\n          rsp.add(\"secondPhase\", commandHandler.processResult(result, serializer));\n          rb.setResult(result);\n          return;\n        }\n\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        Grouping.TotalCount defaultTotalCount = groupingSpec.isIncludeGroupCount() ?\n            Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        Grouping grouping =\n            new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, groupingSpec.isMain());\n        grouping.setGroupSort(groupingSpec.getGroupSort())\n            .setWithinGroupSort(groupingSpec.getSortWithinGroup())\n            .setDefaultFormat(groupingSpec.getResponseFormat())\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(groupingSpec.getWithinGroupLimit())\n            .setGroupOffsetDefault(groupingSpec.getWithinGroupOffset())\n            .setGetGroupedDocSet(groupingSpec.isTruncateGroups());\n\n        if (groupingSpec.getFields() != null) {\n          for (String field : groupingSpec.getFields()) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (groupingSpec.getFunctions() != null) {\n          for (String groupByStr : groupingSpec.getFunctions()) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (groupingSpec.getQueries() != null) {\n          for (String groupByStr : groupingSpec.getQueries()) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if( rb.isNeedDocList() || rb.isDebug() ){\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(Locale.ROOT, \"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new BasicResultContext(rb, grouping.mainResult);\n          rsp.addResponse(ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.add(\"grouped\", result.groupedResults);\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result, cmd);\n    rb.setResult(result);\n\n    ResultContext ctx = new BasicResultContext(rb);\n    rsp.addResponse(ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    if ( ! rb.req.getParams().getBool(ShardParams.IS_SHARD,false) ) {\n      if (null != rb.getNextCursorMark()) {\n        rb.rsp.add(CursorMarkParams.CURSOR_MARK_NEXT,\n                   rb.getNextCursorMark().getSerializedTotem());\n      }\n    }\n\n    if(rb.mergeFieldHandler != null) {\n      rb.mergeFieldHandler.handleMergeFields(rb, searcher);\n    } else {\n      doFieldSortValues(rb, searcher);\n    }\n\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e9fbf0f8ed8f52f3f2580cd0a5fcd8cab1db43f","date":1518195028,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","date":1534976797,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    log.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    LOG.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df72a23fb74bebe914e3f3972063a884327c0436","date":1570470832,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    log.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    log.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":["a94e45463a0089149b0d148ae5369140e7f54b8c","af8334dcf26521da965e339ff1096e0e7bcdd8c6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    log.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    log.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    StatsCache statsCache = req.getCore().getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      SolrIndexSearcher searcher = req.getSearcher();\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"575e66bd4b2349209027f6801184da7fc3cba13f","date":1587609169,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    log.debug(\"process: {}\", rb.req.getParams());\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"640ded7811e1b7d29236a5e2934ec3cd266a8199","date":1588973147,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    cmd.setMinExactHits(getMinExactHits(params));\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6b8ad6d99eb2424679c78255c369b8fac243e7dd","date":1590104557,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    cmd.setMinExactCount(getMinExactCount(params));\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    cmd.setMinExactHits(getMinExactHits(params));\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"72afa881b0b5c361ebd0b6d37927fe072151fbe0","date":1590107364,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    cmd.setMinExactCount(getMinExactCount(params));\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    if (log.isDebugEnabled()) {\n      log.debug(\"process: {}\", rb.req.getParams());\n    }\n  \n    SolrQueryRequest req = rb.req;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    SolrIndexSearcher searcher = req.getSearcher();\n    StatsCache statsCache = searcher.getStatsCache();\n    \n    int purpose = params.getInt(ShardParams.SHARDS_PURPOSE, ShardRequest.PURPOSE_GET_TOP_IDS);\n    if ((purpose & ShardRequest.PURPOSE_GET_TERM_STATS) != 0) {\n      statsCache.returnLocalStats(rb, searcher);\n      return;\n    }\n    // check if we need to update the local copy of global dfs\n    if ((purpose & ShardRequest.PURPOSE_SET_TERM_STATS) != 0) {\n      // retrieve from request and update local cache\n      statsCache.receiveGlobalStats(req);\n    }\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    if (doProcessSearchByIds(rb)) {\n      return;\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = params.getLong(CommonParams.TIME_ALLOWED, -1L);\n    if (null != rb.getCursorMark() && 0 < timeAllowed) {\n      // fundamentally incompatible\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Can not search using both \" +\n                              CursorMarkParams.CURSOR_MARK_PARAM + \" and \" + CommonParams.TIME_ALLOWED);\n    }\n\n    QueryCommand cmd = rb.createQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    cmd.setMinExactHits(getMinExactHits(params));\n\n    req.getContext().put(SolrIndexSearcher.STATS_SOURCE, statsCache.get(req));\n    \n    QueryResult result = new QueryResult();\n\n    cmd.setSegmentTerminateEarly(params.getBool(CommonParams.SEGMENT_TERMINATE_EARLY, CommonParams.SEGMENT_TERMINATE_EARLY_DEFAULT));\n    if (cmd.getSegmentTerminateEarly()) {\n      result.setSegmentTerminatedEarly(Boolean.FALSE);\n    }\n\n    //\n    // grouping / field collapsing\n    //\n    GroupingSpecification groupingSpec = rb.getGroupingSpec();\n    if (groupingSpec != null) {\n      cmd.setSegmentTerminateEarly(false); // not supported, silently ignore any segmentTerminateEarly flag\n      try {\n        if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) {\n          doProcessGroupedDistributedSearchFirstPhase(rb, cmd, result);\n          return;\n        } else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false)) {\n          doProcessGroupedDistributedSearchSecondPhase(rb, cmd, result);\n          return;\n        }\n\n        doProcessGroupedSearch(rb, cmd, result);\n        return;\n      } catch (SyntaxError e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    doProcessUngroupedSearch(rb, cmd, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"de65fb6e86ba37c5409efafefe587d0c897c2764":["7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc"],"1a9c2b42591c0db6f85041d5cfc9cba17fe45e0b":["ac9de183adbc9483681f275ac1e2d92ed19f52e1"],"af8334dcf26521da965e339ff1096e0e7bcdd8c6":["6ce489ffe249d0942d3dd9d8f0b46d3a5385ca01"],"640ded7811e1b7d29236a5e2934ec3cd266a8199":["575e66bd4b2349209027f6801184da7fc3cba13f"],"2acf500f78aa12b92e371fd89c719291986b6b90":["af20870f6eab3807c968eec0b24e0c4358d0c1e5","197070b7f9191af8b5d8598b579393d4a67e32f0"],"72afa881b0b5c361ebd0b6d37927fe072151fbe0":["640ded7811e1b7d29236a5e2934ec3cd266a8199","6b8ad6d99eb2424679c78255c369b8fac243e7dd"],"c7e0383a0a3421b9f6f61002dd4f6fb39bf71285":["a94e45463a0089149b0d148ae5369140e7f54b8c"],"6ce489ffe249d0942d3dd9d8f0b46d3a5385ca01":["46dc9ac8b3e748407baaef82453138ff3974480c"],"09cb2e0d073412dbf283b88292b70aaf62d55276":["de65fb6e86ba37c5409efafefe587d0c897c2764"],"b101c3c0e7f5871415e80d970cb3289309f3522e":["d423443db06bfcac81733aafcce04ee491880cc7","3f20d97ebbd280405cebcc21d53c781bf4456453"],"9856095f7afb5a607bf5e65077615ed91273508c":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","b101c3c0e7f5871415e80d970cb3289309f3522e"],"d423443db06bfcac81733aafcce04ee491880cc7":["29cb9edc6c1e87b23f635321e1c3de19172d32fb"],"197070b7f9191af8b5d8598b579393d4a67e32f0":["af20870f6eab3807c968eec0b24e0c4358d0c1e5"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["1e9fbf0f8ed8f52f3f2580cd0a5fcd8cab1db43f"],"1e9fbf0f8ed8f52f3f2580cd0a5fcd8cab1db43f":["ffb85feece8645a035c02443a625f5af15e1106b"],"27270b721a573cf4b774ce70b062078ef490388e":["0414a20d73ebe5c96a6e7e70e337083ec37f01fd"],"46dc9ac8b3e748407baaef82453138ff3974480c":["b101c3c0e7f5871415e80d970cb3289309f3522e"],"575e66bd4b2349209027f6801184da7fc3cba13f":["df72a23fb74bebe914e3f3972063a884327c0436"],"df72a23fb74bebe914e3f3972063a884327c0436":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"a94e45463a0089149b0d148ae5369140e7f54b8c":["27b6648517583abadd334777ec0230aea09e2ab1"],"3738f7d06920ae25ab2884f4efd80c42e95d6271":["bc4283a38102a08c5832529ccbd1dbe8bcb81da9"],"b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3":["27270b721a573cf4b774ce70b062078ef490388e"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["af20870f6eab3807c968eec0b24e0c4358d0c1e5","2acf500f78aa12b92e371fd89c719291986b6b90"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["29cb9edc6c1e87b23f635321e1c3de19172d32fb","d423443db06bfcac81733aafcce04ee491880cc7"],"dd68c90c39731aaa564d6995e5dd4a4c2388e13e":["6ce489ffe249d0942d3dd9d8f0b46d3a5385ca01","af8334dcf26521da965e339ff1096e0e7bcdd8c6"],"eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e":["5ba39ba201a572fd944ed71d888de0cd4f2957af"],"bc4283a38102a08c5832529ccbd1dbe8bcb81da9":["c26f00b574427b55127e869b935845554afde1fa"],"6c70567cc1ae757045c80cb458b0b2a2ffcf0141":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"ccc08aa684aee4964baee0644a6ba047bfd70829":["3738f7d06920ae25ab2884f4efd80c42e95d6271"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"d5bc8e25f59990525f5beb14afe9c96240dcf4a2":["08970e5b8411182a29412c177eff67ec1110095b"],"612521de57bdf68711c68b6d8565e4a80ca0d7f6":["b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3"],"7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc":["3e1f55a6bbd78f36075a6f59ae26b75b5ce94ffc"],"08970e5b8411182a29412c177eff67ec1110095b":["3cdb67100dc016748799a77218aa409478372d79"],"ccc69a67d5c846a04c7f71e28cb1914e3af895f3":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","6c70567cc1ae757045c80cb458b0b2a2ffcf0141"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a94e45463a0089149b0d148ae5369140e7f54b8c","c7e0383a0a3421b9f6f61002dd4f6fb39bf71285"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"af20870f6eab3807c968eec0b24e0c4358d0c1e5":["612521de57bdf68711c68b6d8565e4a80ca0d7f6"],"29cb9edc6c1e87b23f635321e1c3de19172d32fb":["1a9c2b42591c0db6f85041d5cfc9cba17fe45e0b"],"6b8ad6d99eb2424679c78255c369b8fac243e7dd":["640ded7811e1b7d29236a5e2934ec3cd266a8199"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["d5bc8e25f59990525f5beb14afe9c96240dcf4a2"],"ffb85feece8645a035c02443a625f5af15e1106b":["dd68c90c39731aaa564d6995e5dd4a4c2388e13e","f4924281697ed8ed3790f0f327be1fbde8160afc"],"f4924281697ed8ed3790f0f327be1fbde8160afc":["dd68c90c39731aaa564d6995e5dd4a4c2388e13e"],"3cdb67100dc016748799a77218aa409478372d79":["2acf500f78aa12b92e371fd89c719291986b6b90"],"27b6648517583abadd334777ec0230aea09e2ab1":["eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e"],"3f20d97ebbd280405cebcc21d53c781bf4456453":["d423443db06bfcac81733aafcce04ee491880cc7"],"407687e67faf6e1f02a211ca078d8e3eed631027":["2acf500f78aa12b92e371fd89c719291986b6b90","3cdb67100dc016748799a77218aa409478372d79"],"ac9de183adbc9483681f275ac1e2d92ed19f52e1":["5541f19734f6966068596a4a5fd378ab93d8bc25"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":["9856095f7afb5a607bf5e65077615ed91273508c","46dc9ac8b3e748407baaef82453138ff3974480c"],"46d8ada1fff8d18cb197c38c7983225162599948":["af20870f6eab3807c968eec0b24e0c4358d0c1e5","2acf500f78aa12b92e371fd89c719291986b6b90"],"3e1f55a6bbd78f36075a6f59ae26b75b5ce94ffc":["c7e0383a0a3421b9f6f61002dd4f6fb39bf71285"],"0414a20d73ebe5c96a6e7e70e337083ec37f01fd":["ccc08aa684aee4964baee0644a6ba047bfd70829"],"685bd38810c206c93e9058f3c2cfa9827c086c27":["06f29c9961912220543423aa6fc6f64362874871","ffb85feece8645a035c02443a625f5af15e1106b"],"da951a24a6a87d5ba7e1820f8c28a1e2beea76c1":["5ba39ba201a572fd944ed71d888de0cd4f2957af","eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5541f19734f6966068596a4a5fd378ab93d8bc25":["ecd75942508378ccc92c3a26f71db6cba9f25784"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ecd75942508378ccc92c3a26f71db6cba9f25784":["09cb2e0d073412dbf283b88292b70aaf62d55276"],"06f29c9961912220543423aa6fc6f64362874871":["46dc9ac8b3e748407baaef82453138ff3974480c"],"5ba39ba201a572fd944ed71d888de0cd4f2957af":["6c70567cc1ae757045c80cb458b0b2a2ffcf0141"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["72afa881b0b5c361ebd0b6d37927fe072151fbe0"],"b0b597c65628ca9e73913a07e81691f8229bae35":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","df72a23fb74bebe914e3f3972063a884327c0436"]},"commit2Childs":{"de65fb6e86ba37c5409efafefe587d0c897c2764":["09cb2e0d073412dbf283b88292b70aaf62d55276"],"1a9c2b42591c0db6f85041d5cfc9cba17fe45e0b":["29cb9edc6c1e87b23f635321e1c3de19172d32fb"],"af8334dcf26521da965e339ff1096e0e7bcdd8c6":["dd68c90c39731aaa564d6995e5dd4a4c2388e13e"],"640ded7811e1b7d29236a5e2934ec3cd266a8199":["72afa881b0b5c361ebd0b6d37927fe072151fbe0","6b8ad6d99eb2424679c78255c369b8fac243e7dd"],"2acf500f78aa12b92e371fd89c719291986b6b90":["fe33227f6805edab2036cbb80645cc4e2d1fa424","3cdb67100dc016748799a77218aa409478372d79","407687e67faf6e1f02a211ca078d8e3eed631027","46d8ada1fff8d18cb197c38c7983225162599948"],"72afa881b0b5c361ebd0b6d37927fe072151fbe0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c7e0383a0a3421b9f6f61002dd4f6fb39bf71285":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","3e1f55a6bbd78f36075a6f59ae26b75b5ce94ffc"],"6ce489ffe249d0942d3dd9d8f0b46d3a5385ca01":["af8334dcf26521da965e339ff1096e0e7bcdd8c6","dd68c90c39731aaa564d6995e5dd4a4c2388e13e"],"09cb2e0d073412dbf283b88292b70aaf62d55276":["ecd75942508378ccc92c3a26f71db6cba9f25784"],"b101c3c0e7f5871415e80d970cb3289309f3522e":["9856095f7afb5a607bf5e65077615ed91273508c","46dc9ac8b3e748407baaef82453138ff3974480c"],"9856095f7afb5a607bf5e65077615ed91273508c":["90a682dc1bfd188ef61cc28373c7f5d700b4ac75"],"197070b7f9191af8b5d8598b579393d4a67e32f0":["2acf500f78aa12b92e371fd89c719291986b6b90"],"d423443db06bfcac81733aafcce04ee491880cc7":["b101c3c0e7f5871415e80d970cb3289309f3522e","80d0e6d59ae23f4a6f30eaf40bfb40742300287f","3f20d97ebbd280405cebcc21d53c781bf4456453"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["df72a23fb74bebe914e3f3972063a884327c0436","b0b597c65628ca9e73913a07e81691f8229bae35"],"1e9fbf0f8ed8f52f3f2580cd0a5fcd8cab1db43f":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"27270b721a573cf4b774ce70b062078ef490388e":["b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3"],"46dc9ac8b3e748407baaef82453138ff3974480c":["6ce489ffe249d0942d3dd9d8f0b46d3a5385ca01","90a682dc1bfd188ef61cc28373c7f5d700b4ac75","06f29c9961912220543423aa6fc6f64362874871"],"575e66bd4b2349209027f6801184da7fc3cba13f":["640ded7811e1b7d29236a5e2934ec3cd266a8199"],"df72a23fb74bebe914e3f3972063a884327c0436":["575e66bd4b2349209027f6801184da7fc3cba13f","b0b597c65628ca9e73913a07e81691f8229bae35"],"a94e45463a0089149b0d148ae5369140e7f54b8c":["c7e0383a0a3421b9f6f61002dd4f6fb39bf71285","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"3738f7d06920ae25ab2884f4efd80c42e95d6271":["ccc08aa684aee4964baee0644a6ba047bfd70829"],"b83283b2e5ac002ef83f3f5972fa40fb0bc24ed3":["612521de57bdf68711c68b6d8565e4a80ca0d7f6"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["9856095f7afb5a607bf5e65077615ed91273508c"],"dd68c90c39731aaa564d6995e5dd4a4c2388e13e":["ffb85feece8645a035c02443a625f5af15e1106b","f4924281697ed8ed3790f0f327be1fbde8160afc"],"bc4283a38102a08c5832529ccbd1dbe8bcb81da9":["3738f7d06920ae25ab2884f4efd80c42e95d6271"],"eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e":["27b6648517583abadd334777ec0230aea09e2ab1","da951a24a6a87d5ba7e1820f8c28a1e2beea76c1"],"6c70567cc1ae757045c80cb458b0b2a2ffcf0141":["ccc69a67d5c846a04c7f71e28cb1914e3af895f3","5ba39ba201a572fd944ed71d888de0cd4f2957af"],"c26f00b574427b55127e869b935845554afde1fa":["bc4283a38102a08c5832529ccbd1dbe8bcb81da9"],"ccc08aa684aee4964baee0644a6ba047bfd70829":["0414a20d73ebe5c96a6e7e70e337083ec37f01fd"],"d5bc8e25f59990525f5beb14afe9c96240dcf4a2":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"612521de57bdf68711c68b6d8565e4a80ca0d7f6":["af20870f6eab3807c968eec0b24e0c4358d0c1e5"],"7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc":["de65fb6e86ba37c5409efafefe587d0c897c2764"],"08970e5b8411182a29412c177eff67ec1110095b":["d5bc8e25f59990525f5beb14afe9c96240dcf4a2"],"ccc69a67d5c846a04c7f71e28cb1914e3af895f3":[],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"af20870f6eab3807c968eec0b24e0c4358d0c1e5":["2acf500f78aa12b92e371fd89c719291986b6b90","197070b7f9191af8b5d8598b579393d4a67e32f0","fe33227f6805edab2036cbb80645cc4e2d1fa424","46d8ada1fff8d18cb197c38c7983225162599948"],"29cb9edc6c1e87b23f635321e1c3de19172d32fb":["d423443db06bfcac81733aafcce04ee491880cc7","80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"6b8ad6d99eb2424679c78255c369b8fac243e7dd":["72afa881b0b5c361ebd0b6d37927fe072151fbe0"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6c70567cc1ae757045c80cb458b0b2a2ffcf0141","ccc69a67d5c846a04c7f71e28cb1914e3af895f3"],"ffb85feece8645a035c02443a625f5af15e1106b":["1e9fbf0f8ed8f52f3f2580cd0a5fcd8cab1db43f","685bd38810c206c93e9058f3c2cfa9827c086c27"],"f4924281697ed8ed3790f0f327be1fbde8160afc":["ffb85feece8645a035c02443a625f5af15e1106b"],"3cdb67100dc016748799a77218aa409478372d79":["08970e5b8411182a29412c177eff67ec1110095b","407687e67faf6e1f02a211ca078d8e3eed631027"],"27b6648517583abadd334777ec0230aea09e2ab1":["a94e45463a0089149b0d148ae5369140e7f54b8c"],"3f20d97ebbd280405cebcc21d53c781bf4456453":["b101c3c0e7f5871415e80d970cb3289309f3522e"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"ac9de183adbc9483681f275ac1e2d92ed19f52e1":["1a9c2b42591c0db6f85041d5cfc9cba17fe45e0b"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":[],"46d8ada1fff8d18cb197c38c7983225162599948":[],"0414a20d73ebe5c96a6e7e70e337083ec37f01fd":["27270b721a573cf4b774ce70b062078ef490388e"],"3e1f55a6bbd78f36075a6f59ae26b75b5ce94ffc":["7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc"],"685bd38810c206c93e9058f3c2cfa9827c086c27":[],"da951a24a6a87d5ba7e1820f8c28a1e2beea76c1":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"5541f19734f6966068596a4a5fd378ab93d8bc25":["ac9de183adbc9483681f275ac1e2d92ed19f52e1"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ecd75942508378ccc92c3a26f71db6cba9f25784":["5541f19734f6966068596a4a5fd378ab93d8bc25"],"06f29c9961912220543423aa6fc6f64362874871":["685bd38810c206c93e9058f3c2cfa9827c086c27"],"5ba39ba201a572fd944ed71d888de0cd4f2957af":["eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e","da951a24a6a87d5ba7e1820f8c28a1e2beea76c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["fe33227f6805edab2036cbb80645cc4e2d1fa424","ccc69a67d5c846a04c7f71e28cb1914e3af895f3","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","407687e67faf6e1f02a211ca078d8e3eed631027","90a682dc1bfd188ef61cc28373c7f5d700b4ac75","46d8ada1fff8d18cb197c38c7983225162599948","685bd38810c206c93e9058f3c2cfa9827c086c27","da951a24a6a87d5ba7e1820f8c28a1e2beea76c1","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}