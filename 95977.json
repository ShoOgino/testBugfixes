{"path":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0791b41f65aecff2e75db0c1ebf95d745a5ab1b1","date":1338332414,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":["01e5948db9a07144112d2f08f28ca2e3cd880348","34ce7c842452c79b12c45a8feb64e4597c7110e8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<SegmentCommitInfo>();\n    final Collection<SegmentCommitInfo> merging = writer.get().getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfoPerCommit> eligible = new ArrayList<SegmentInfoPerCommit>();\n    final Collection<SegmentInfoPerCommit> merging = writer.get().getMergingSegments();\n    for(SegmentInfoPerCommit info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Collection<SegmentCommitInfo> merging = writer.get().getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<SegmentCommitInfo>();\n    final Collection<SegmentCommitInfo> merging = writer.get().getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"027bee21e09164c9ee230395405076d1e0034b30","date":1401521821,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, IndexWriter writer) throws IOException {\n    if (verbose(writer)) {\n      message(\"findForcedDeletesMerges infos=\" + writer.segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, writer);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Collection<SegmentCommitInfo> merging = writer.getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending(writer));\n\n    if (verbose(writer)) {\n      message(\"eligible=\" + eligible, writer);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose(writer)) {\n        message(\"add merge=\" + writer.segString(merge.segments), writer);\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos) throws IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Collection<SegmentCommitInfo> merging = writer.get().getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.info.getDocCount();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, new SegmentByteSizeDescending());\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","203d7d3cb7712e10ef33009a63247ae40c302d7a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["0791b41f65aecff2e75db0c1ebf95d745a5ab1b1","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"0791b41f65aecff2e75db0c1ebf95d745a5ab1b1":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["0791b41f65aecff2e75db0c1ebf95d745a5ab1b1"],"027bee21e09164c9ee230395405076d1e0034b30":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["027bee21e09164c9ee230395405076d1e0034b30"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["027bee21e09164c9ee230395405076d1e0034b30"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["0791b41f65aecff2e75db0c1ebf95d745a5ab1b1"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","9d153abcf92dc5329d98571a8c3035df9bd80648"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"0791b41f65aecff2e75db0c1ebf95d745a5ab1b1":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"027bee21e09164c9ee230395405076d1e0034b30":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}