{"path":"src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(FreqProxTermsWriterPerField[],FormatPostingsFieldsConsumer).mjava","commits":[{"id":"4d17492f26096e19670d947d1be5e9adc52b1d3d","date":1224931200,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(FreqProxTermsWriterPerField[],FormatPostingsFieldsConsumer).mjava","pathOld":"src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(DocumentsWriter.FlushState,FreqProxTermsWriterPerField[],TermInfosWriter,IndexOutput,IndexOutput,DefaultSkipListWriter).mjava","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(FreqProxTermsWriterPerField[] fields,\n                      FormatPostingsFieldsConsumer consumer)\n    throws CorruptIndexException, IOException {\n\n    int numFields = fields.length;\n\n    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i]);\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final FormatPostingsTermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);\n\n    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];\n\n    final boolean currentFieldOmitTf = fields[0].fieldInfo.omitTf;\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(termStates[0].text, termStates[0].textOffset);\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        FreqProxFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int termDocFreq = minState.termFreq;\n\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(minState.docID, termDocFreq);\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        if (!currentFieldOmitTf) {\n          // omitTf == false so we do write positions &\n          // payload          \n          int position = 0;\n          for(int j=0;j<termDocFreq;j++) {\n            final int code = prox.readVInt();\n            position += code >> 1;\n\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n\n              prox.readBytes(payloadBuffer, 0, payloadLength);\n\n            } else\n              payloadLength = 0;\n\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          } //End for\n\n          posConsumer.finish();\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      docConsumer.finish();\n    }\n\n    termsConsumer.finish();\n  }\n\n","sourceOld":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(final DocumentsWriter.FlushState flushState,\n                      FreqProxTermsWriterPerField[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut,\n                      DefaultSkipListWriter skipListWriter)\n    throws CorruptIndexException, IOException {\n\n    final int fieldNumber = fields[0].fieldInfo.number;\n    int numFields = fields.length;\n\n    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i]);\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final int skipInterval = termsOut.skipInterval;\n    final boolean currentFieldOmitTf = fields[0].fieldInfo.omitTf;\n\n    // If current field omits tf then it cannot store\n    // payloads.  We silently drop the payloads in this case:\n    final boolean currentFieldStorePayloads = currentFieldOmitTf ? false : fields[0].fieldInfo.storePayloads;\n  \n    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n\n      final long freqPointer = freqOut.getFilePointer();\n      final long proxPointer;\n      if (proxOut != null)\n        proxPointer = proxOut.getFilePointer();\n      else\n        proxPointer = 0;\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FreqProxFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < flushState.numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        if (!currentFieldOmitTf) {\n          // omitTf == false so we do write positions & payload          \n          assert proxOut != null;\n          for(int j=0;j<termDocFreq;j++) {\n            final int code = prox.readVInt();\n            if (currentFieldStorePayloads) {\n              final int payloadLength;\n              if ((code & 1) != 0) {\n                // This position has a payload\n                payloadLength = prox.readVInt();\n              } else\n                payloadLength = 0;\n              if (payloadLength != lastPayloadLength) {\n                proxOut.writeVInt(code|1);\n                proxOut.writeVInt(payloadLength);\n                lastPayloadLength = payloadLength;\n              } else\n                proxOut.writeVInt(code & (~1));\n              if (payloadLength > 0)\n                copyBytes(prox, proxOut, payloadLength);\n            } else {\n              assert 0 == (code & 1);\n              proxOut.writeVInt(code>>1);\n            }\n          } //End for\n          \n          final int newDocCode = (doc-lastDoc)<<1;\n\n          if (1 == termDocFreq) {\n            freqOut.writeVInt(newDocCode|1);\n           } else {\n            freqOut.writeVInt(newDocCode);\n            freqOut.writeVInt(termDocFreq);\n          }\n        } else {\n          // omitTf==true: we store only the docs, without\n          // term freq, positions, payloads\n          freqOut.writeVInt(doc-lastDoc);\n        }\n\n        lastDoc = doc;\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n\n      // TODO: we could do this incrementally\n      UnicodeUtil.UTF16toUTF8(text, start, termsUTF8);\n\n      // TODO: we could save O(n) re-scan of the term by\n      // computing the shared prefix with the last term\n      // while during the UTF8 encoding\n      termsOut.add(fieldNumber,\n                   termsUTF8.result,\n                   termsUTF8.length,\n                   termInfo);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"066b6ff5a08e35c3b6880e7c3ddda79526acdab1","date":1237569961,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(FreqProxTermsWriterPerField[],FormatPostingsFieldsConsumer).mjava","pathOld":"src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(FreqProxTermsWriterPerField[],FormatPostingsFieldsConsumer).mjava","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(FreqProxTermsWriterPerField[] fields,\n                      FormatPostingsFieldsConsumer consumer)\n    throws CorruptIndexException, IOException {\n\n    int numFields = fields.length;\n\n    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i]);\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final FormatPostingsTermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);\n\n    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];\n\n    final boolean currentFieldOmitTermFreqAndPositions = fields[0].fieldInfo.omitTermFreqAndPositions;\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(termStates[0].text, termStates[0].textOffset);\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        FreqProxFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int termDocFreq = minState.termFreq;\n\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(minState.docID, termDocFreq);\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        if (!currentFieldOmitTermFreqAndPositions) {\n          // omitTermFreqAndPositions == false so we do write positions &\n          // payload          \n          int position = 0;\n          for(int j=0;j<termDocFreq;j++) {\n            final int code = prox.readVInt();\n            position += code >> 1;\n\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n\n              prox.readBytes(payloadBuffer, 0, payloadLength);\n\n            } else\n              payloadLength = 0;\n\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          } //End for\n\n          posConsumer.finish();\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      docConsumer.finish();\n    }\n\n    termsConsumer.finish();\n  }\n\n","sourceOld":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(FreqProxTermsWriterPerField[] fields,\n                      FormatPostingsFieldsConsumer consumer)\n    throws CorruptIndexException, IOException {\n\n    int numFields = fields.length;\n\n    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i]);\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final FormatPostingsTermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);\n\n    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];\n\n    final boolean currentFieldOmitTf = fields[0].fieldInfo.omitTf;\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(termStates[0].text, termStates[0].textOffset);\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        FreqProxFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int termDocFreq = minState.termFreq;\n\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(minState.docID, termDocFreq);\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        if (!currentFieldOmitTf) {\n          // omitTf == false so we do write positions &\n          // payload          \n          int position = 0;\n          for(int j=0;j<termDocFreq;j++) {\n            final int code = prox.readVInt();\n            position += code >> 1;\n\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n\n              prox.readBytes(payloadBuffer, 0, payloadLength);\n\n            } else\n              payloadLength = 0;\n\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          } //End for\n\n          posConsumer.finish();\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      docConsumer.finish();\n    }\n\n    termsConsumer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(FreqProxTermsWriterPerField[],FormatPostingsFieldsConsumer).mjava","pathOld":"src/java/org/apache/lucene/index/FreqProxTermsWriter#appendPostings(FreqProxTermsWriterPerField[],FormatPostingsFieldsConsumer).mjava","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(FreqProxTermsWriterPerField[] fields,\n                      FormatPostingsFieldsConsumer consumer)\n    throws CorruptIndexException, IOException {\n\n    int numFields = fields.length;\n\n    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i]);\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final FormatPostingsTermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);\n\n    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];\n\n    final boolean currentFieldOmitTermFreqAndPositions = fields[0].fieldInfo.omitTermFreqAndPositions;\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(termStates[0].text, termStates[0].textOffset);\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        FreqProxFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int termDocFreq = minState.termFreq;\n\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(minState.docID, termDocFreq);\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        if (!currentFieldOmitTermFreqAndPositions) {\n          // omitTermFreqAndPositions == false so we do write positions &\n          // payload          \n          int position = 0;\n          for(int j=0;j<termDocFreq;j++) {\n            final int code = prox.readVInt();\n            position += code >> 1;\n\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n\n              prox.readBytes(payloadBuffer, 0, payloadLength);\n\n            } else\n              payloadLength = 0;\n\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          } //End for\n\n          posConsumer.finish();\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      docConsumer.finish();\n    }\n\n    termsConsumer.finish();\n  }\n\n","sourceOld":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(FreqProxTermsWriterPerField[] fields,\n                      FormatPostingsFieldsConsumer consumer)\n    throws CorruptIndexException, IOException {\n\n    int numFields = fields.length;\n\n    final FreqProxFieldMergeState[] mergeStates = new FreqProxFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FreqProxFieldMergeState fms = mergeStates[i] = new FreqProxFieldMergeState(fields[i]);\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final FormatPostingsTermsConsumer termsConsumer = consumer.addField(fields[0].fieldInfo);\n\n    FreqProxFieldMergeState[] termStates = new FreqProxFieldMergeState[numFields];\n\n    final boolean currentFieldOmitTermFreqAndPositions = fields[0].fieldInfo.omitTermFreqAndPositions;\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(termStates[0].text, termStates[0].textOffset);\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        FreqProxFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int termDocFreq = minState.termFreq;\n\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(minState.docID, termDocFreq);\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        if (!currentFieldOmitTermFreqAndPositions) {\n          // omitTermFreqAndPositions == false so we do write positions &\n          // payload          \n          int position = 0;\n          for(int j=0;j<termDocFreq;j++) {\n            final int code = prox.readVInt();\n            position += code >> 1;\n\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n\n              prox.readBytes(payloadBuffer, 0, payloadLength);\n\n            } else\n              payloadLength = 0;\n\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          } //End for\n\n          posConsumer.finish();\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      docConsumer.finish();\n    }\n\n    termsConsumer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"066b6ff5a08e35c3b6880e7c3ddda79526acdab1":["4d17492f26096e19670d947d1be5e9adc52b1d3d"],"4d17492f26096e19670d947d1be5e9adc52b1d3d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["066b6ff5a08e35c3b6880e7c3ddda79526acdab1"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d17492f26096e19670d947d1be5e9adc52b1d3d"],"066b6ff5a08e35c3b6880e7c3ddda79526acdab1":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"4d17492f26096e19670d947d1be5e9adc52b1d3d":["066b6ff5a08e35c3b6880e7c3ddda79526acdab1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}