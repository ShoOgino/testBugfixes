{"path":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","commits":[{"id":"1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30","date":1327936772,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"/dev/null","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09cced0ffd4d11eee37ef7655cc4096103909122","date":1327939357,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3","date":1327944832,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296df632fd63421ea20756fa11ad36fbc6f4c8a9","date":1327957998,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"/dev/null","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"410e066f093e407222d9681429d209084e783149","date":1327958394,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"/dev/null","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"410e066f093e407222d9681429d209084e783149":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09cced0ffd4d11eee37ef7655cc4096103909122":["1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3"],"1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3":["09cced0ffd4d11eee37ef7655cc4096103909122"]},"commit2Childs":{"410e066f093e407222d9681429d209084e783149":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["410e066f093e407222d9681429d209084e783149","296df632fd63421ea20756fa11ad36fbc6f4c8a9","1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30"],"09cced0ffd4d11eee37ef7655cc4096103909122":["be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["410e066f093e407222d9681429d209084e783149","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30":["09cced0ffd4d11eee37ef7655cc4096103909122"],"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["410e066f093e407222d9681429d209084e783149","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}