{"path":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"/dev/null","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      for( Token token = ts.next(); token != null; token = ts.next() ){\n        String text = new String(token.termBuffer(), 0, token.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":null,"sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      for( Token token = ts.next(); token != null; token = ts.next() ){\n        String text = new String(token.termBuffer(), 0, token.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"/dev/null","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c8b12bda3f5864b27e3e04df1be4f6736ec067a","date":1270088127,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d085fb336a7208eea2214e5ffcc803960819b60b","date":1270981894,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      while (ts.incrementToken()){\n        if( termAtt.length() > 0 )\n          tokList.add( termAtt.toString() );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9c8b12bda3f5864b27e3e04df1be4f6736ec067a":["1da8d55113b689b06716246649de6f62430f15c0"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["d085fb336a7208eea2214e5ffcc803960819b60b"],"c26f00b574427b55127e869b935845554afde1fa":["d085fb336a7208eea2214e5ffcc803960819b60b","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["d085fb336a7208eea2214e5ffcc803960819b60b"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"d085fb336a7208eea2214e5ffcc803960819b60b":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"9c8b12bda3f5864b27e3e04df1be4f6736ec067a":["d085fb336a7208eea2214e5ffcc803960819b60b"],"1da8d55113b689b06716246649de6f62430f15c0":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"d085fb336a7208eea2214e5ffcc803960819b60b":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}