{"path":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","commits":[{"id":"32c97797222c63ae0cce3322818565bdb8d2b8c9","date":1177418982,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"/dev/null","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(\"multiField\", \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0)\n      {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      }\n      else\n      {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next())\n    {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d6b0d3878b50401a76f5239a2c4a8391fced796f","0e60b4907a1867e066f425a450d96e4297dfa973"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e60b4907a1867e066f425a450d96e4297dfa973","date":1180989666,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(\"multiField\", \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0)\n      {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      }\n      else\n      {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next())\n    {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(\"multiField\", \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0)\n      {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      }\n      else\n      {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next())\n    {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":["32c97797222c63ae0cce3322818565bdb8d2b8c9"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6b0d3878b50401a76f5239a2c4a8391fced796f","date":1189270648,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(\"multiField\", \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(\"multiField\", \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0)\n      {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      }\n      else\n      {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next())\n    {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":["32c97797222c63ae0cce3322818565bdb8d2b8c9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd5947db4de866f035b932f219674c03562d904e","date":1219248396,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(\"multiField\", \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8d1458a2543cbd30cbfe7929be4dcb5c5251659","date":1254582241,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":null,"sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a046c0c310bc77931fc8441bd920053b607dd14","date":1254584734,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":null,"sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    BoostingTermQuery query = new BoostingTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"));\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 3, hits.getMaxScore() == 3);\n    //there should be exactly 10 items that score a 3, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 3, doc.score == 3);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d6b0d3878b50401a76f5239a2c4a8391fced796f":["0e60b4907a1867e066f425a450d96e4297dfa973"],"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["fd5947db4de866f035b932f219674c03562d904e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0a046c0c310bc77931fc8441bd920053b607dd14":["fd5947db4de866f035b932f219674c03562d904e","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"fd5947db4de866f035b932f219674c03562d904e":["d6b0d3878b50401a76f5239a2c4a8391fced796f"],"0e60b4907a1867e066f425a450d96e4297dfa973":["32c97797222c63ae0cce3322818565bdb8d2b8c9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0a046c0c310bc77931fc8441bd920053b607dd14"],"32c97797222c63ae0cce3322818565bdb8d2b8c9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"d6b0d3878b50401a76f5239a2c4a8391fced796f":["fd5947db4de866f035b932f219674c03562d904e"],"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["0a046c0c310bc77931fc8441bd920053b607dd14"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["32c97797222c63ae0cce3322818565bdb8d2b8c9"],"0a046c0c310bc77931fc8441bd920053b607dd14":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fd5947db4de866f035b932f219674c03562d904e":["e8d1458a2543cbd30cbfe7929be4dcb5c5251659","0a046c0c310bc77931fc8441bd920053b607dd14"],"0e60b4907a1867e066f425a450d96e4297dfa973":["d6b0d3878b50401a76f5239a2c4a8391fced796f"],"32c97797222c63ae0cce3322818565bdb8d2b8c9":["0e60b4907a1867e066f425a450d96e4297dfa973"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}