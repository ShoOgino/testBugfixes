{"path":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","commits":[{"id":"4d07d6c279b65daaca32ee033fa06e4d7e85e0dd","date":1525384847,"type":0,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  @Repeat(iterations = 5)\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1c374690db69470f6aa4bffc43dcacf1f4e3e49","date":1529007399,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","sourceNew":"  @Test\n  @Repeat(iterations = 5)\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","sourceOld":"  @Test\n  @Repeat(iterations = 5)\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","sourceNew":"  @Test\n  @Repeat(iterations = 5)\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","sourceOld":"  @Test\n  @Repeat(iterations = 5)\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","sourceNew":"  @Test\n  @Repeat(iterations = 5)\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","sourceOld":"  @Test\n  @Repeat(iterations = 5)\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","date":1533256859,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","sourceNew":"  @Test\n  @Repeat(iterations = 5)\n  //commented 2-Aug-2018 @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","sourceOld":"  @Test\n  @Repeat(iterations = 5)\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"27d6f83edecd216b844079cc682096091dfa9fbc","date":1534485921,"type":4,"author":"Anshum Gupta","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest#endToEndTest().mjava","sourceNew":null,"sourceOld":"  @Test\n  @Repeat(iterations = 5)\n  //commented 2-Aug-2018 @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 12-Jun-2018\n  public void endToEndTest() throws Exception {\n    int maxFileSizeBound = 5000;\n    // Set max size bound\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    // Giving a 10% buffer for the max size bound\n    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.1);\n\n    SolrQueryRequest selectQuery = req(\"*:*\");\n    List<Integer> docCounts = new ArrayList<>();\n\n    int numDocs = 1000;\n    int batchSize = 20;\n    int numBatches = numDocs / batchSize;\n    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {\n      SolrQueryResponse updateResp = new SolrQueryResponse();\n      int docStartId = batchSize * batchCounter;\n\n      // Send batch add doc request\n      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);\n\n      // The sleep is to allow existing commits to finish before querying/submitting more documents\n      waitForCommit(200);\n\n      // Check tlog file sizes\n      getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);\n\n      // See how many documents are currently visible. This should increase as more commits occur.\n      docCounts.add(queryCore(selectQuery));\n    }\n\n    // One final commit, after which all documents should be visible\n    CommitUpdateCommand commitUpdateCommand = new CommitUpdateCommand(req(), false);\n    updateHandler.commit(commitUpdateCommand);\n    waitForCommit(200);\n    docCounts.add(queryCore(selectQuery));\n\n    // Evaluate the document counts\n    checkNumFoundDocuments(docCounts, numDocs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["4d07d6c279b65daaca32ee033fa06e4d7e85e0dd","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"4d07d6c279b65daaca32ee033fa06e4d7e85e0dd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"27d6f83edecd216b844079cc682096091dfa9fbc":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["27d6f83edecd216b844079cc682096091dfa9fbc"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["4d07d6c279b65daaca32ee033fa06e4d7e85e0dd"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["4d07d6c279b65daaca32ee033fa06e4d7e85e0dd","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"]},"commit2Childs":{"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["27d6f83edecd216b844079cc682096091dfa9fbc"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"4d07d6c279b65daaca32ee033fa06e4d7e85e0dd":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","a1c374690db69470f6aa4bffc43dcacf1f4e3e49","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d07d6c279b65daaca32ee033fa06e4d7e85e0dd"],"27d6f83edecd216b844079cc682096091dfa9fbc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}