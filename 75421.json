{"path":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","commits":[{"id":"64714133cf5ec732e3bbceee63351bb9af0117dc","date":1239647636,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"/dev/null","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * @todo parallelize this one too\n  */\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"052fac7830290bd38a04cddee1a121ee07656b56","date":1245780702,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(QueryWeight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * @todo parallelize this one too\n  */\n  public void search(QueryWeight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * @todo parallelize this one too\n  */\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe941135bdfc28c81e20b4d21422f8726af34925","date":1250040150,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(QueryWeight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * @todo parallelize this one too\n  */\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * @todo parallelize this one too\n  */\n  public void search(QueryWeight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f573a38b5b129663e19cdf55adc5d12330c0504","date":1251326380,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * TODO: parallelize this one too\n  */\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * @todo parallelize this one too\n  */\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a9e385641d717e641408d8fbbc62be8fc766357","date":1256746606,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * TODO: parallelize this one too\n  */\n  @Override\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * TODO: parallelize this one too\n  */\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7325af1b9f607a9e8e30785e8de8ffd1d4c08ddf","date":1257873376,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  * \n  * <p>This method cannot be parallelized, because {@link Collector}\n  * supports no concurrent access.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  */\n  @Override\n  public void search(final Weight weight, final Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(final Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(final int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(final IndexReader reader, final int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  * \n  * TODO: parallelize this one too\n  */\n  @Override\n  public void search(Weight weight, Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(IndexReader reader, int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ae3763b337aadea2838f75b69d6b00c4e6949c7","date":1257894961,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query,int)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  * \n  * <p>This method cannot be parallelized, because {@link Collector}\n  * supports no concurrent access.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  */\n  @Override\n  public void search(final Weight weight, final Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(final Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(final int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(final IndexReader reader, final int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  * \n  * <p>This method cannot be parallelized, because {@link Collector}\n  * supports no concurrent access.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  */\n  @Override\n  public void search(final Weight weight, final Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(final Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(final int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(final IndexReader reader, final int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,Collector).mjava","sourceNew":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query,int)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  * \n  * <p>This method cannot be parallelized, because {@link Collector}\n  * supports no concurrent access.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  */\n  @Override\n  public void search(final Weight weight, final Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(final Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(final int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(final IndexReader reader, final int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","sourceOld":"  /** Lower-level search API.\n  *\n  * <p>{@link Collector#collect(int)} is called for every matching document.\n  *\n  * <p>Applications should only use this if they need <i>all</i> of the\n  * matching documents.  The high-level search API ({@link\n  * Searcher#search(Query,int)}) is usually more efficient, as it skips\n  * non-high-scoring hits.\n  * \n  * <p>This method cannot be parallelized, because {@link Collector}\n  * supports no concurrent access.\n  *\n  * @param weight to match documents\n  * @param filter if non-null, a bitset used to eliminate some documents\n  * @param collector to receive hits\n  */\n  @Override\n  public void search(final Weight weight, final Filter filter, final Collector collector)\n   throws IOException {\n   for (int i = 0; i < searchables.length; i++) {\n\n     final int start = starts[i];\n\n     final Collector hc = new Collector() {\n       @Override\n       public void setScorer(final Scorer scorer) throws IOException {\n         collector.setScorer(scorer);\n       }\n       \n       @Override\n       public void collect(final int doc) throws IOException {\n         collector.collect(doc);\n       }\n       \n       @Override\n       public void setNextReader(final IndexReader reader, final int docBase) throws IOException {\n         collector.setNextReader(reader, start + docBase);\n       }\n       \n       @Override\n       public boolean acceptsDocsOutOfOrder() {\n         return collector.acceptsDocsOutOfOrder();\n       }\n     };\n     \n     searchables[i].search(weight, filter, hc);\n   }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6ae3763b337aadea2838f75b69d6b00c4e6949c7":["7325af1b9f607a9e8e30785e8de8ffd1d4c08ddf"],"64714133cf5ec732e3bbceee63351bb9af0117dc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7325af1b9f607a9e8e30785e8de8ffd1d4c08ddf":["8a9e385641d717e641408d8fbbc62be8fc766357"],"8a9e385641d717e641408d8fbbc62be8fc766357":["2f573a38b5b129663e19cdf55adc5d12330c0504"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2f573a38b5b129663e19cdf55adc5d12330c0504":["fe941135bdfc28c81e20b4d21422f8726af34925"],"fe941135bdfc28c81e20b4d21422f8726af34925":["052fac7830290bd38a04cddee1a121ee07656b56"],"052fac7830290bd38a04cddee1a121ee07656b56":["64714133cf5ec732e3bbceee63351bb9af0117dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["6ae3763b337aadea2838f75b69d6b00c4e6949c7"]},"commit2Childs":{"6ae3763b337aadea2838f75b69d6b00c4e6949c7":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"64714133cf5ec732e3bbceee63351bb9af0117dc":["052fac7830290bd38a04cddee1a121ee07656b56"],"7325af1b9f607a9e8e30785e8de8ffd1d4c08ddf":["6ae3763b337aadea2838f75b69d6b00c4e6949c7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["64714133cf5ec732e3bbceee63351bb9af0117dc"],"8a9e385641d717e641408d8fbbc62be8fc766357":["7325af1b9f607a9e8e30785e8de8ffd1d4c08ddf"],"2f573a38b5b129663e19cdf55adc5d12330c0504":["8a9e385641d717e641408d8fbbc62be8fc766357"],"fe941135bdfc28c81e20b4d21422f8726af34925":["2f573a38b5b129663e19cdf55adc5d12330c0504"],"052fac7830290bd38a04cddee1a121ee07656b56":["fe941135bdfc28c81e20b4d21422f8726af34925"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}