{"path":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/SolrCloudPartitioner#getPartition(Text,SolrInputDocumentWritable,int).mjava","commits":[{"id":"d6e604e9030fb0cabf0c5a85ae6039921a81419c","date":1386009743,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/SolrCloudPartitioner#getPartition(Text,SolrInputDocumentWritable,int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public int getPartition(Text key, SolrInputDocumentWritable value, int numPartitions) {\n    DocRouter docRouter = docCollection.getRouter();\n    SolrInputDocument doc = value.getSolrInputDocument();\n    String keyStr = key.toString();\n    \n    // TODO: scalability: replace linear search in HashBasedRouter.hashToSlice() with binary search on sorted hash ranges\n    Slice slice = docRouter.getTargetSlice(keyStr, doc, emptySolrParams, docCollection); \n    \n//    LOG.info(\"slice: {}\", slice);\n    if (slice == null) {\n      throw new IllegalStateException(\"No matching slice found! The slice seems unavailable. docRouterClass: \"\n          + docRouter.getClass().getName());\n    }\n    int rootShard = shardNumbers.get(slice.getName());\n    if (rootShard < 0 || rootShard >= shards) {\n      throw new IllegalStateException(\"Illegal shard number \" + rootShard + \" for slice: \" + slice + \", docCollection: \"\n          + docCollection);\n    }      \n\n    // map doc to micro shard aka leaf shard, akin to HashBasedRouter.sliceHash()\n    // taking into account mtree merge algorithm\n    assert numPartitions % shards == 0; // Also note that numPartitions is equal to the number of reducers\n    int hashCode = Hash.murmurhash3_x86_32(keyStr, 0, keyStr.length(), 0); \n    int offset = (hashCode & Integer.MAX_VALUE) % (numPartitions / shards);\n    int microShard = (rootShard * (numPartitions / shards)) + offset;\n//    LOG.info(\"Subpartitions rootShard: {}, offset: {}\", rootShard, offset);\n//    LOG.info(\"Partitioned to p: {} for numPartitions: {}, shards: {}, key: {}, value: {}\", microShard, numPartitions, shards, key, value);\n    \n    assert microShard >= 0 && microShard < numPartitions;\n    return microShard;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["747dd71fefcbc7142661c25334b74c518fef4d81"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrCloudPartitioner#getPartition(Text,SolrInputDocumentWritable,int).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/SolrCloudPartitioner#getPartition(Text,SolrInputDocumentWritable,int).mjava","sourceNew":"  @Override\n  public int getPartition(Text key, SolrInputDocumentWritable value, int numPartitions) {\n    DocRouter docRouter = docCollection.getRouter();\n    SolrInputDocument doc = value.getSolrInputDocument();\n    String keyStr = key.toString();\n    \n    // TODO: scalability: replace linear search in HashBasedRouter.hashToSlice() with binary search on sorted hash ranges\n    Slice slice = docRouter.getTargetSlice(keyStr, doc, emptySolrParams, docCollection); \n    \n//    LOG.info(\"slice: {}\", slice);\n    if (slice == null) {\n      throw new IllegalStateException(\"No matching slice found! The slice seems unavailable. docRouterClass: \"\n          + docRouter.getClass().getName());\n    }\n    int rootShard = shardNumbers.get(slice.getName());\n    if (rootShard < 0 || rootShard >= shards) {\n      throw new IllegalStateException(\"Illegal shard number \" + rootShard + \" for slice: \" + slice + \", docCollection: \"\n          + docCollection);\n    }      \n\n    // map doc to micro shard aka leaf shard, akin to HashBasedRouter.sliceHash()\n    // taking into account mtree merge algorithm\n    assert numPartitions % shards == 0; // Also note that numPartitions is equal to the number of reducers\n    int hashCode = Hash.murmurhash3_x86_32(keyStr, 0, keyStr.length(), 0); \n    int offset = (hashCode & Integer.MAX_VALUE) % (numPartitions / shards);\n    int microShard = (rootShard * (numPartitions / shards)) + offset;\n//    LOG.info(\"Subpartitions rootShard: {}, offset: {}\", rootShard, offset);\n//    LOG.info(\"Partitioned to p: {} for numPartitions: {}, shards: {}, key: {}, value: {}\", microShard, numPartitions, shards, key, value);\n    \n    assert microShard >= 0 && microShard < numPartitions;\n    return microShard;\n  }\n\n","sourceOld":"  @Override\n  public int getPartition(Text key, SolrInputDocumentWritable value, int numPartitions) {\n    DocRouter docRouter = docCollection.getRouter();\n    SolrInputDocument doc = value.getSolrInputDocument();\n    String keyStr = key.toString();\n    \n    // TODO: scalability: replace linear search in HashBasedRouter.hashToSlice() with binary search on sorted hash ranges\n    Slice slice = docRouter.getTargetSlice(keyStr, doc, emptySolrParams, docCollection); \n    \n//    LOG.info(\"slice: {}\", slice);\n    if (slice == null) {\n      throw new IllegalStateException(\"No matching slice found! The slice seems unavailable. docRouterClass: \"\n          + docRouter.getClass().getName());\n    }\n    int rootShard = shardNumbers.get(slice.getName());\n    if (rootShard < 0 || rootShard >= shards) {\n      throw new IllegalStateException(\"Illegal shard number \" + rootShard + \" for slice: \" + slice + \", docCollection: \"\n          + docCollection);\n    }      \n\n    // map doc to micro shard aka leaf shard, akin to HashBasedRouter.sliceHash()\n    // taking into account mtree merge algorithm\n    assert numPartitions % shards == 0; // Also note that numPartitions is equal to the number of reducers\n    int hashCode = Hash.murmurhash3_x86_32(keyStr, 0, keyStr.length(), 0); \n    int offset = (hashCode & Integer.MAX_VALUE) % (numPartitions / shards);\n    int microShard = (rootShard * (numPartitions / shards)) + offset;\n//    LOG.info(\"Subpartitions rootShard: {}, offset: {}\", rootShard, offset);\n//    LOG.info(\"Partitioned to p: {} for numPartitions: {}, shards: {}, key: {}, value: {}\", microShard, numPartitions, shards, key, value);\n    \n    assert microShard >= 0 && microShard < numPartitions;\n    return microShard;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"]},"commit2Childs":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}