{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","commits":[{"id":"6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09","date":1492411712,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger\");\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        log.info(\"Tracking new node: {}\", n);\n        nodeNameVsTimeAdded.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger firing registered listener\");\n            listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"326b5c746af092eb827c5c1accdab1b47fe0cf3c","date":1492433195,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger\");\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        log.info(\"Tracking new node: {}\", n);\n        nodeNameVsTimeAdded.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger firing registered listener\");\n            listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7699e9ae4550ba2a55335a64ae7de9d5d9de39e","date":1493894873,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger\");\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        log.info(\"Tracking new node: {}\", n);\n        nodeNameVsTimeAdded.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger firing registered listener\");\n            listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"009caa80830ac6369c42e5f6515405d686eabfee","date":1494487120,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d","date":1494838933,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"464244264804e3f981bf1fb4b732516d8d62dbc2","date":1495736161,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        nodeNameVsTimeAdded.put(n, eventTime);\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5531f16a602ef350b6c9adfb08ebaa13a60fe3db","date":1495756318,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        nodeNameVsTimeAdded.put(n, eventTime);\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n      if (lastLiveNodes == null) {\n        lastLiveNodes = newLiveNodes;\n        return;\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long nanoTime = System.nanoTime();\n        nodeNameVsTimeAdded.put(n, nanoTime);\n        log.info(\"Tracking new node: {} at {} nanotime\", n, nanoTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = System.nanoTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeAddedEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeAddedTrigger {} firing registered listener for node: {} added at {} nanotime, now: {} nanotime\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(this, timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c32a8448145a74a8902798f2e63e322827757ff2","date":1496834422,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        nodeNameVsTimeAdded.put(n, eventTime);\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"664ff2b928393480d9655010aa700656b0fcade0","date":1496842764,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        nodeNameVsTimeAdded.put(n, eventTime);\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeAdded.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c5fd294da67452cd8d116692194908de00eb5209","date":1499704155,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.EventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered processor for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (processor.process(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered listener for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (listener.triggerFired(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25","date":1499961129,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerEventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered processor for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (processor.process(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.EventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered processor for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (processor.process(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc5ed4ca39a59c23d13866a1e110e608d93cbcc1","date":1503489512,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerEventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeAddedTrigger {} firing registered processor for node: {} added at time {} , now: {}\", name, nodeName, timeAdded, now);\n            if (processor.process(new NodeAddedEvent(getEventType(), getName(), timeAdded, nodeName))) {\n              // remove from tracking set only if the fire was accepted\n              it.remove();\n              removeNodeAddedMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeAddedMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac","date":1503580177,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(clusterDataProvider.getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b869898f50ca80263bac2e3ae0949f7700e5c977","date":1503580229,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(clusterDataProvider.getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b8cffee0b9c10b78bd087c71485b482217fe84f","date":1505950827,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":0,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85212dad4ed576c7f7e6c165ee19e597b7b4efc8","date":1507997740,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(dataProvider.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3f354f2175f861ee625bb3c9572d53b77cd8545","date":1508405819,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(dataProvider.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"67e503ef0f418bc92404ff5d55694087c23d48eb","date":1509025368,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name, nodeNames, times, timeSource.getTime());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}\", name, nodeNames, times);\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTime());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = timeSource.getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name, nodeNames, times, timeSource.getTime());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4412883c12067d8a4e2a354aa8adc58c32be1d6","date":1521129281,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTime();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTime();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTime());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f7f315cd0d0955ce9ca691cc8e2796af69c4b9b6","date":1536060944,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["8b6783b03ea9c6398156b4e964266166193d4364"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f7fb1186f5b61e0b74289e6786df8cbecfa471bc","date":1545308188,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              log.debug(\"Removing new node from tracking: {}\", n);\n              nodeNameVsTimeAdded.remove(n);\n            });\n          } else {\n            log.debug(\"Processor returned false for {}!\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeAdded.remove(n);\n              removeMarker(n);\n            });\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b6783b03ea9c6398156b4e964266166193d4364","date":1565257495,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp, replicaType))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              log.debug(\"Removing new node from tracking: {}\", n);\n              nodeNameVsTimeAdded.remove(n);\n            });\n          } else {\n            log.debug(\"Processor returned false for {}!\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              log.debug(\"Removing new node from tracking: {}\", n);\n              nodeNameVsTimeAdded.remove(n);\n            });\n          } else {\n            log.debug(\"Processor returned false for {}!\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":["f7f315cd0d0955ce9ca691cc8e2796af69c4b9b6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e35f2dde06b35aa9904949a3a93fabd090371077","date":1587906921,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      if (log.isDebugEnabled()) {\n        log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          if (log.isDebugEnabled()) {\n            log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n                nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          }\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp, replicaType))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              log.debug(\"Removing new node from tracking: {}\", n);\n              nodeNameVsTimeAdded.remove(n);\n            });\n          } else {\n            log.debug(\"Processor returned false for {}!\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n              nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp, replicaType))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              log.debug(\"Removing new node from tracking: {}\", n);\n              nodeNameVsTimeAdded.remove(n);\n            });\n          } else {\n            log.debug(\"Processor returned false for {}!\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeAddedTrigger#run().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeAddedTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeAddedTrigger {}\", name);\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      if (log.isDebugEnabled()) {\n        log.debug(\"Found livenodes: {}\", newLiveNodes.size());\n      }\n\n      // have any nodes that we were tracking been removed from the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeAdded.keySet();\n      trackingKeySet.retainAll(newLiveNodes);\n\n      // have any new nodes been added?\n      Set<String> copyOfNew = new HashSet<>(newLiveNodes);\n      copyOfNew.removeAll(lastLiveNodes);\n      copyOfNew.forEach(n -> {\n        long eventTime = cloudManager.getTimeSource().getTimeNs();\n        log.debug(\"Tracking new node: {} at time {}\", n, eventTime);\n        nodeNameVsTimeAdded.put(n, eventTime);\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeAdded.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeAdded = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeAdded, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeAdded);\n        }\n      }\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          if (log.isDebugEnabled()) {\n            log.debug(\"NodeAddedTrigger {} firing registered processor for nodes: {} added at times {}, now={}\", name,\n                nodeNames, times, cloudManager.getTimeSource().getTimeNs());\n          }\n          if (processor.process(new NodeAddedEvent(getEventType(), getName(), times, nodeNames, preferredOp, replicaType))) {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              log.debug(\"Removing new node from tracking: {}\", n);\n              nodeNameVsTimeAdded.remove(n);\n            });\n          } else {\n            log.debug(\"Processor returned false for {}!\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeAdded.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeAddedTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5b8cffee0b9c10b78bd087c71485b482217fe84f"],"a7699e9ae4550ba2a55335a64ae7de9d5d9de39e":["326b5c746af092eb827c5c1accdab1b47fe0cf3c"],"cc5ed4ca39a59c23d13866a1e110e608d93cbcc1":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["c5fd294da67452cd8d116692194908de00eb5209"],"f7fb1186f5b61e0b74289e6786df8cbecfa471bc":["f7f315cd0d0955ce9ca691cc8e2796af69c4b9b6"],"009caa80830ac6369c42e5f6515405d686eabfee":["a7699e9ae4550ba2a55335a64ae7de9d5d9de39e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["67e503ef0f418bc92404ff5d55694087c23d48eb"],"560c18d71dad43d675158783c3840f8c80d6d39c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"664ff2b928393480d9655010aa700656b0fcade0":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db","c32a8448145a74a8902798f2e63e322827757ff2"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["cc5ed4ca39a59c23d13866a1e110e608d93cbcc1"],"6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3f504512a03d978990cbff30db0522b354e846db":["e35f2dde06b35aa9904949a3a93fabd090371077"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["560c18d71dad43d675158783c3840f8c80d6d39c"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"326b5c746af092eb827c5c1accdab1b47fe0cf3c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09"],"8b6783b03ea9c6398156b4e964266166193d4364":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"c3f354f2175f861ee625bb3c9572d53b77cd8545":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d":["009caa80830ac6369c42e5f6515405d686eabfee"],"5531f16a602ef350b6c9adfb08ebaa13a60fe3db":["21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d","464244264804e3f981bf1fb4b732516d8d62dbc2"],"f7f315cd0d0955ce9ca691cc8e2796af69c4b9b6":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"67e503ef0f418bc92404ff5d55694087c23d48eb":["c3f354f2175f861ee625bb3c9572d53b77cd8545"],"c5fd294da67452cd8d116692194908de00eb5209":["664ff2b928393480d9655010aa700656b0fcade0"],"5b8cffee0b9c10b78bd087c71485b482217fe84f":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"464244264804e3f981bf1fb4b732516d8d62dbc2":["21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d"],"e35f2dde06b35aa9904949a3a93fabd090371077":["8b6783b03ea9c6398156b4e964266166193d4364"],"c32a8448145a74a8902798f2e63e322827757ff2":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"]},"commit2Childs":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"a7699e9ae4550ba2a55335a64ae7de9d5d9de39e":["009caa80830ac6369c42e5f6515405d686eabfee"],"cc5ed4ca39a59c23d13866a1e110e608d93cbcc1":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["cc5ed4ca39a59c23d13866a1e110e608d93cbcc1"],"f7fb1186f5b61e0b74289e6786df8cbecfa471bc":["8b6783b03ea9c6398156b4e964266166193d4364"],"009caa80830ac6369c42e5f6515405d686eabfee":["21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c304e97e7c1d472bc70e801b35ee78583916c6cd","560c18d71dad43d675158783c3840f8c80d6d39c","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09","326b5c746af092eb827c5c1accdab1b47fe0cf3c"],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["f7f315cd0d0955ce9ca691cc8e2796af69c4b9b6"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"560c18d71dad43d675158783c3840f8c80d6d39c":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"664ff2b928393480d9655010aa700656b0fcade0":["c5fd294da67452cd8d116692194908de00eb5209"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09":["326b5c746af092eb827c5c1accdab1b47fe0cf3c"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["c3f354f2175f861ee625bb3c9572d53b77cd8545"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["5b8cffee0b9c10b78bd087c71485b482217fe84f"],"326b5c746af092eb827c5c1accdab1b47fe0cf3c":["a7699e9ae4550ba2a55335a64ae7de9d5d9de39e"],"8b6783b03ea9c6398156b4e964266166193d4364":["e35f2dde06b35aa9904949a3a93fabd090371077"],"c3f354f2175f861ee625bb3c9572d53b77cd8545":["67e503ef0f418bc92404ff5d55694087c23d48eb"],"21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db","464244264804e3f981bf1fb4b732516d8d62dbc2"],"5531f16a602ef350b6c9adfb08ebaa13a60fe3db":["664ff2b928393480d9655010aa700656b0fcade0","c32a8448145a74a8902798f2e63e322827757ff2"],"f7f315cd0d0955ce9ca691cc8e2796af69c4b9b6":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"c5fd294da67452cd8d116692194908de00eb5209":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"67e503ef0f418bc92404ff5d55694087c23d48eb":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"5b8cffee0b9c10b78bd087c71485b482217fe84f":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"464244264804e3f981bf1fb4b732516d8d62dbc2":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db"],"c32a8448145a74a8902798f2e63e322827757ff2":["664ff2b928393480d9655010aa700656b0fcade0"],"e35f2dde06b35aa9904949a3a93fabd090371077":["3f504512a03d978990cbff30db0522b354e846db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}