{"path":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","commits":[{"id":"a851824c09818632c94eba41e60ef5e72e323c8e","date":1337355760,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadOnlyFieldInfos#ReadOnlyFieldInfos(FieldInfo[]).mjava","sourceNew":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  public ReadOnlyFieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"/dev/null","sourceNew":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e885d2b1e112b1d9db6a2dae82b3b493dfba1df1","date":1342716838,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8615860cb50aefb8eebca1d1b3893dbe21cf126","date":1345550448,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3b4a63b6b0155323dde6b827e0dc22a43580753","date":1346168671,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e5adcbe5a27941451fdb6194bcbff96c8630e14","date":1346419102,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0d1f90e969803cc84174589b5e4a39b7935fecd","date":1346584861,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      assert !byNumber.containsKey(info.number);\n      byNumber.put(info.number, info);\n      assert !byName.containsKey(info.name);\n      byName.put(info.name, info);\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb13dd414f655a70c821300dea007cb565533e03","date":1397838390,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS_ONLY;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"556a4aab886d75371b2af129d87be3c2795cea76","date":1414954991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.isIndexed() && info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.isIndexed() && info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.hasDocValues();\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2fc361419eab9d1ac199a5f3dd0a7231f53a9e20","date":1435334043,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n  }\n\n","bugFix":null,"bugIntro":["5cd4b7e3cc2e7eca187645175c9048a8f7e75002"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ca792c26af46bd6c4a08d81117c60440cf6a7e3d","date":1445938295,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasDimensionalValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasDimensionalValues |= info.getDimensionCount() != 0;\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasDimensionalValues = hasDimensionalValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1eee4175312c41f89aa23427f9e4edfc00deeaac","date":1446373190,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasDimensionalValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasDimensionalValues |= (info.getDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasDimensionalValues = hasDimensionalValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasDimensionalValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasDimensionalValues |= info.getDimensionCount() != 0;\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasDimensionalValues = hasDimensionalValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasDimensionalValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasDimensionalValues |= (info.getDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasDimensionalValues = hasDimensionalValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cd4b7e3cc2e7eca187645175c9048a8f7e75002","date":1509086187,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    Integer max = byNumber.isEmpty() ? null : byNumber.lastKey();\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      // Pull infos into an arraylist to avoid holding a reference to the TreeMap\n      values = Collections.unmodifiableCollection(new ArrayList<>(byNumber.values()));\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      values = Collections.unmodifiableCollection(byNumber.values());\n      byNumberTable = null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.values = Collections.unmodifiableCollection(byNumber.values());\n    Integer max = byNumber.isEmpty() ? null : Collections.max(byNumber.keySet());\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      byNumberTable = null;\n    }\n  }\n\n","bugFix":["2fc361419eab9d1ac199a5f3dd0a7231f53a9e20","76923f6a33f2c4bec7f584e3f251261afe7ea276"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c1c835c1d1d2594b34b55026a015b3f13afb477","date":1518518197,"type":3,"author":"Mayya Sharipova","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    Integer max = byNumber.isEmpty() ? null : byNumber.lastKey();\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      // Pull infos into an arraylist to avoid holding a reference to the TreeMap\n      values = Collections.unmodifiableCollection(new ArrayList<>(byNumber.values()));\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      values = Collections.unmodifiableCollection(byNumber.values());\n      byNumberTable = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bfcdec9fcf0409223f35c5ec3bc14094314941b4","date":1518533599,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    \n    TreeMap<Integer, FieldInfo> byNumber = new TreeMap<>();\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      FieldInfo previous = byNumber.put(info.number, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n      \n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    Integer max = byNumber.isEmpty() ? null : byNumber.lastKey();\n    \n    // Only usee TreeMap in the very sparse case (< 1/16th of the numbers are used),\n    // because TreeMap uses ~ 64 (32 bit JVM) or 120 (64 bit JVM w/o compressed oops)\n    // overall bytes per entry, but array uses 4 (32 bit JMV) or 8\n    // (64 bit JVM w/o compressed oops):\n    if (max != null && max < ArrayUtil.MAX_ARRAY_LENGTH && max < 16L*byNumber.size()) {\n      // Pull infos into an arraylist to avoid holding a reference to the TreeMap\n      values = Collections.unmodifiableCollection(new ArrayList<>(byNumber.values()));\n      byNumberMap = null;\n      byNumberTable = new FieldInfo[max+1];\n      for (Map.Entry<Integer,FieldInfo> entry : byNumber.entrySet()) {\n        byNumberTable[entry.getKey()] = entry.getValue();\n      }\n    } else {\n      byNumberMap = byNumber;\n      values = Collections.unmodifiableCollection(byNumber.values());\n      byNumberTable = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7e4ca6dc9612ff741d8713743e2bccfae5eadac","date":1528093718,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDataDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59ed8c026ba85e3c42fb89605b2032dc6f9cc241","date":1581113294,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FieldInfos#FieldInfos(FieldInfo[]).mjava","sourceNew":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","sourceOld":"  /**\n   * Constructs a new FieldInfos from an array of FieldInfo objects\n   */\n  public FieldInfos(FieldInfo[] infos) {\n    boolean hasVectors = false;\n    boolean hasProx = false;\n    boolean hasPayloads = false;\n    boolean hasOffsets = false;\n    boolean hasFreq = false;\n    boolean hasNorms = false;\n    boolean hasDocValues = false;\n    boolean hasPointValues = false;\n    String softDeletesField = null;\n\n    int size = 0; // number of elements in byNumberTemp, number of used array slots\n    FieldInfo[] byNumberTemp = new FieldInfo[10]; // initial array capacity of 10\n    for (FieldInfo info : infos) {\n      if (info.number < 0) {\n        throw new IllegalArgumentException(\"illegal field number: \" + info.number + \" for field \" + info.name);\n      }\n      size = info.number >= size ? info.number+1 : size;\n      if (info.number >= byNumberTemp.length){ //grow array\n        byNumberTemp = ArrayUtil.grow(byNumberTemp, info.number + 1);\n      }\n      FieldInfo previous = byNumberTemp[info.number];\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field numbers: \" + previous.name + \" and \" + info.name + \" have: \" + info.number);\n      }\n      byNumberTemp[info.number] = info;\n\n      previous = byName.put(info.name, info);\n      if (previous != null) {\n        throw new IllegalArgumentException(\"duplicate field names: \" + previous.number + \" and \" + info.number + \" have: \" + info.name);\n      }\n\n      hasVectors |= info.hasVectors();\n      hasProx |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n      hasFreq |= info.getIndexOptions() != IndexOptions.DOCS;\n      hasOffsets |= info.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n      hasNorms |= info.hasNorms();\n      hasDocValues |= info.getDocValuesType() != DocValuesType.NONE;\n      hasPayloads |= info.hasPayloads();\n      hasPointValues |= (info.getPointDataDimensionCount() != 0);\n      if (info.isSoftDeletesField()) {\n        if (softDeletesField != null && softDeletesField.equals(info.name) == false) {\n          throw new IllegalArgumentException(\"multiple soft-deletes fields [\" + info.name + \", \" + softDeletesField + \"]\");\n        }\n        softDeletesField = info.name;\n      }\n    }\n    \n    this.hasVectors = hasVectors;\n    this.hasProx = hasProx;\n    this.hasPayloads = hasPayloads;\n    this.hasOffsets = hasOffsets;\n    this.hasFreq = hasFreq;\n    this.hasNorms = hasNorms;\n    this.hasDocValues = hasDocValues;\n    this.hasPointValues = hasPointValues;\n    this.softDeletesField = softDeletesField;\n\n    List<FieldInfo> valuesTemp = new ArrayList<>();\n    byNumber = new FieldInfo[size];\n    for(int i=0; i<size; i++){\n      byNumber[i] = byNumberTemp[i];\n      if (byNumberTemp[i] != null) {\n        valuesTemp.add(byNumberTemp[i]);\n      }\n    }\n    values = Collections.unmodifiableCollection(Arrays.asList(valuesTemp.toArray(new FieldInfo[0])));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fb13dd414f655a70c821300dea007cb565533e03":["6e5adcbe5a27941451fdb6194bcbff96c8630e14"],"001b25b42373b22a52f399dbf072f1224632e8e6":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["f6652c943595e92c187ee904c382863013eae28f"],"f6652c943595e92c187ee904c382863013eae28f":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"a3b4a63b6b0155323dde6b827e0dc22a43580753":["f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["fb13dd414f655a70c821300dea007cb565533e03"],"a851824c09818632c94eba41e60ef5e72e323c8e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f8615860cb50aefb8eebca1d1b3893dbe21cf126":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","e885d2b1e112b1d9db6a2dae82b3b493dfba1df1"],"4c1c835c1d1d2594b34b55026a015b3f13afb477":["5cd4b7e3cc2e7eca187645175c9048a8f7e75002"],"bfcdec9fcf0409223f35c5ec3bc14094314941b4":["5cd4b7e3cc2e7eca187645175c9048a8f7e75002","4c1c835c1d1d2594b34b55026a015b3f13afb477"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["bfcdec9fcf0409223f35c5ec3bc14094314941b4","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["bfcdec9fcf0409223f35c5ec3bc14094314941b4"],"1eee4175312c41f89aa23427f9e4edfc00deeaac":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"e885d2b1e112b1d9db6a2dae82b3b493dfba1df1":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["1eee4175312c41f89aa23427f9e4edfc00deeaac"],"5cd4b7e3cc2e7eca187645175c9048a8f7e75002":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"556a4aab886d75371b2af129d87be3c2795cea76":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["001b25b42373b22a52f399dbf072f1224632e8e6","a3b4a63b6b0155323dde6b827e0dc22a43580753"],"d0d1f90e969803cc84174589b5e4a39b7935fecd":["05a14b2611ead08655a2b2bdc61632eb31316e57","6e5adcbe5a27941451fdb6194bcbff96c8630e14"],"2fc361419eab9d1ac199a5f3dd0a7231f53a9e20":["556a4aab886d75371b2af129d87be3c2795cea76"],"6e5adcbe5a27941451fdb6194bcbff96c8630e14":["a3b4a63b6b0155323dde6b827e0dc22a43580753"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a851824c09818632c94eba41e60ef5e72e323c8e"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["2fc361419eab9d1ac199a5f3dd0a7231f53a9e20"],"f592209545c71895260367152601e9200399776d":["bfcdec9fcf0409223f35c5ec3bc14094314941b4","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"]},"commit2Childs":{"fb13dd414f655a70c821300dea007cb565533e03":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"001b25b42373b22a52f399dbf072f1224632e8e6":["05a14b2611ead08655a2b2bdc61632eb31316e57"],"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f6652c943595e92c187ee904c382863013eae28f":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"],"a3b4a63b6b0155323dde6b827e0dc22a43580753":["05a14b2611ead08655a2b2bdc61632eb31316e57","6e5adcbe5a27941451fdb6194bcbff96c8630e14"],"f8615860cb50aefb8eebca1d1b3893dbe21cf126":["001b25b42373b22a52f399dbf072f1224632e8e6","a3b4a63b6b0155323dde6b827e0dc22a43580753"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["556a4aab886d75371b2af129d87be3c2795cea76"],"a851824c09818632c94eba41e60ef5e72e323c8e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"4c1c835c1d1d2594b34b55026a015b3f13afb477":["bfcdec9fcf0409223f35c5ec3bc14094314941b4"],"bfcdec9fcf0409223f35c5ec3bc14094314941b4":["b70042a8a492f7054d480ccdd2be9796510d4327","b7e4ca6dc9612ff741d8713743e2bccfae5eadac","f592209545c71895260367152601e9200399776d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a851824c09818632c94eba41e60ef5e72e323c8e","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["f6652c943595e92c187ee904c382863013eae28f","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"1eee4175312c41f89aa23427f9e4edfc00deeaac":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"e885d2b1e112b1d9db6a2dae82b3b493dfba1df1":["f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["5cd4b7e3cc2e7eca187645175c9048a8f7e75002"],"5cd4b7e3cc2e7eca187645175c9048a8f7e75002":["4c1c835c1d1d2594b34b55026a015b3f13afb477","bfcdec9fcf0409223f35c5ec3bc14094314941b4"],"556a4aab886d75371b2af129d87be3c2795cea76":["2fc361419eab9d1ac199a5f3dd0a7231f53a9e20"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["d0d1f90e969803cc84174589b5e4a39b7935fecd"],"d0d1f90e969803cc84174589b5e4a39b7935fecd":[],"2fc361419eab9d1ac199a5f3dd0a7231f53a9e20":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"6e5adcbe5a27941451fdb6194bcbff96c8630e14":["fb13dd414f655a70c821300dea007cb565533e03","d0d1f90e969803cc84174589b5e4a39b7935fecd"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["001b25b42373b22a52f399dbf072f1224632e8e6","f8615860cb50aefb8eebca1d1b3893dbe21cf126","e885d2b1e112b1d9db6a2dae82b3b493dfba1df1"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["1eee4175312c41f89aa23427f9e4edfc00deeaac"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","d0d1f90e969803cc84174589b5e4a39b7935fecd","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}