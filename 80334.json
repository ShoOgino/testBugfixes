{"path":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n    SegmentTermDocs segTermDocs = new SegmentTermDocs(reader);\n    segTermDocs.seek(new Term(DocHelper.TEXT_FIELD_2_KEY, \"field\"));\n    if (segTermDocs.next() == true)\n    {\n      int docId = segTermDocs.doc();\n      assertTrue(docId == 0);\n      int freq = segTermDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n    SegmentTermDocs segTermDocs = new SegmentTermDocs(reader);\n    segTermDocs.seek(new Term(DocHelper.TEXT_FIELD_2_KEY, \"field\"));\n    if (segTermDocs.next() == true)\n    {\n      int docId = segTermDocs.doc();\n      assertTrue(docId == 0);\n      int freq = segTermDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n    TermDocs termDocs = reader.termDocs();\n    assertTrue(termDocs != null);\n    termDocs.seek(new Term(DocHelper.TEXT_FIELD_2_KEY, \"field\"));\n    if (termDocs.next() == true)    {\n      int docId = termDocs.doc();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n    SegmentTermDocs segTermDocs = new SegmentTermDocs(reader);\n    segTermDocs.seek(new Term(DocHelper.TEXT_FIELD_2_KEY, \"field\"));\n    if (segTermDocs.next() == true)\n    {\n      int docId = segTermDocs.doc();\n      assertTrue(docId == 0);\n      int freq = segTermDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28427ef110c4c5bf5b4057731b83110bd1e13724","date":1276701452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n    TermDocs termDocs = reader.termDocs();\n    assertTrue(termDocs != null);\n    termDocs.seek(new Term(DocHelper.TEXT_FIELD_2_KEY, \"field\"));\n    if (termDocs.next() == true)    {\n      int docId = termDocs.doc();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n    TermDocs termDocs = reader.termDocs();\n    assertTrue(termDocs != null);\n    termDocs.seek(new Term(DocHelper.TEXT_FIELD_2_KEY, \"field\"));\n    if (termDocs.next() == true)    {\n      int docId = termDocs.doc();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, IOContext.DEFAULT);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, IOContext.DEFAULT);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seek(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getDeletedDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor);\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = terms.docs(reader.getLiveDocs(), null);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f","date":1323210518,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(true, info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ce667c6d3400b22523701c549c0d35e26da8b46","date":1324405053,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = SegmentReader.get(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs(int).mjava","sourceNew":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs(int indexDivisor) throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, indexDivisor, newIOContext(random));\n    assertTrue(reader != null);\n    assertEquals(indexDivisor, reader.getTermInfosIndexDivisor());\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random, terms, reader.getLiveDocs(), null, true);\n    if (termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["872cff1d3a554e0cd64014cd97f88d3002b0f491","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9ce667c6d3400b22523701c549c0d35e26da8b46"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"3cc749c053615f5871f3b95715fe292f34e70a53":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"5f4e87790277826a2aea119328600dfb07761f32":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","28427ef110c4c5bf5b4057731b83110bd1e13724"],"2553b00f699380c64959ccb27991289aae87be2e":["28427ef110c4c5bf5b4057731b83110bd1e13724","fd9cc9d77712aba3662f24632df7539ab75e3667"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["b6f9be74ca7baaef11857ad002cad40419979516","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["872cff1d3a554e0cd64014cd97f88d3002b0f491","cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["817d8435e9135b756f08ce6710ab0baac51bdf88","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f":["b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["5f4e87790277826a2aea119328600dfb07761f32","28427ef110c4c5bf5b4057731b83110bd1e13724"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","b65b350ca9588f9fc76ce7d6804160d06c45ff42","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"5f4e87790277826a2aea119328600dfb07761f32":[],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f"],"b6f9be74ca7baaef11857ad002cad40419979516":["d083e83f225b11e5fdd900e83d26ddb385b6955c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","5f4e87790277826a2aea119328600dfb07761f32","2553b00f699380c64959ccb27991289aae87be2e","fd9cc9d77712aba3662f24632df7539ab75e3667"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","9ce667c6d3400b22523701c549c0d35e26da8b46"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["3cc749c053615f5871f3b95715fe292f34e70a53","5d004d0e0b3f65bb40da76d476d659d7888270e8"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"cb4972c6aaf6c714c8f5957b5aeb14dcce34b75f":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","5f4e87790277826a2aea119328600dfb07761f32","5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}