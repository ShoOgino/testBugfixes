{"path":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","commits":[{"id":"18359c8e12d55f66c27cfe7babe86283f06a6aa5","date":1250426225,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","pathOld":"/dev/null","sourceNew":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer();\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba1116b3450a9c1642c89445d131b37344055245","date":1256329517,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","sourceNew":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer(Version.LUCENE_CURRENT);\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","sourceOld":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer();\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","sourceNew":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer(TEST_VERSION_CURRENT);\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","sourceOld":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer(Version.LUCENE_CURRENT);\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testReusableTokenStream().mjava","sourceNew":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer(TEST_VERSION_CURRENT);\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","sourceOld":"  public void testReusableTokenStream() throws Exception {\n    Analyzer analyzer = new CJKAnalyzer(TEST_VERSION_CURRENT);\n    String str = \"\\u3042\\u3044\\u3046\\u3048\\u304aabc\\u304b\\u304d\\u304f\\u3051\\u3053\";\n    \n    TestToken[] out_tokens = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"abc\", 5, 8, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 10,12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3051\\u3053\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens);\n    \n    str = \"\\u3042\\u3044\\u3046\\u3048\\u304aab\\u3093c\\u304b\\u304d\\u304f\\u3051 \\u3053\";\n    TestToken[] out_tokens2 = { \n      newToken(\"\\u3042\\u3044\", 0, 2, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"\\u3044\\u3046\", 1, 3, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3046\\u3048\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3048\\u304a\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"ab\", 5, 7, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u3093\", 7, 8, CJKTokenizer.DOUBLE_TOKEN_TYPE), \n      newToken(\"c\", 8, 9, CJKTokenizer.SINGLE_TOKEN_TYPE), \n      newToken(\"\\u304b\\u304d\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304d\\u304f\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u304f\\u3051\", 11,13, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n      newToken(\"\\u3053\", 14,15, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKTokenReusable(analyzer, str, out_tokens2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"18359c8e12d55f66c27cfe7babe86283f06a6aa5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["ba1116b3450a9c1642c89445d131b37344055245"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"ba1116b3450a9c1642c89445d131b37344055245":["18359c8e12d55f66c27cfe7babe86283f06a6aa5"]},"commit2Childs":{"18359c8e12d55f66c27cfe7babe86283f06a6aa5":["ba1116b3450a9c1642c89445d131b37344055245"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["18359c8e12d55f66c27cfe7babe86283f06a6aa5"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ba1116b3450a9c1642c89445d131b37344055245":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}