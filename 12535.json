{"path":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","pathOld":"/dev/null","sourceNew":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int startNumPostings = numPostings;\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this field:\n        for(int j=0;j<limit;j++) {\n          Fieldable field = docFieldsFinal[j];\n\n          if (field.isIndexed())\n            invertField(field, analyzer, maxFieldLength);\n\n          if (field.isStored())\n            localFieldsWriter.writeField(fieldInfo, field);\n\n          docFieldsFinal[j] = null;\n        }\n\n        if (postingsVectorsUpto > 0) {\n          // Add term vectors for this field\n          writeVectors(fieldInfo);\n          if (postingsVectorsUpto > maxPostingsVectors)\n            maxPostingsVectors = postingsVectorsUpto;\n          postingsVectorsUpto = 0;\n          vectorsPool.reset();\n        }\n      }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["83bbb041887bbef07b8a98d08a0e1713ce137039","8560794cda5bcd510c60e38ed553e9c5a6204983"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6a1f29c9b1051488fd5fa7d56c98db5f4388408","date":1196281221,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","sourceNew":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this field:\n        for(int j=0;j<limit;j++) {\n          Fieldable field = docFieldsFinal[j];\n\n          if (field.isIndexed())\n            invertField(field, analyzer, maxFieldLength);\n\n          if (field.isStored())\n            localFieldsWriter.writeField(fieldInfo, field);\n\n          docFieldsFinal[j] = null;\n        }\n\n        if (postingsVectorsUpto > 0) {\n          // Add term vectors for this field\n          writeVectors(fieldInfo);\n          if (postingsVectorsUpto > maxPostingsVectors)\n            maxPostingsVectors = postingsVectorsUpto;\n          postingsVectorsUpto = 0;\n          vectorsPool.reset();\n        }\n      }\n\n","sourceOld":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int startNumPostings = numPostings;\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this field:\n        for(int j=0;j<limit;j++) {\n          Fieldable field = docFieldsFinal[j];\n\n          if (field.isIndexed())\n            invertField(field, analyzer, maxFieldLength);\n\n          if (field.isStored())\n            localFieldsWriter.writeField(fieldInfo, field);\n\n          docFieldsFinal[j] = null;\n        }\n\n        if (postingsVectorsUpto > 0) {\n          // Add term vectors for this field\n          writeVectors(fieldInfo);\n          if (postingsVectorsUpto > maxPostingsVectors)\n            maxPostingsVectors = postingsVectorsUpto;\n          postingsVectorsUpto = 0;\n          vectorsPool.reset();\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8560794cda5bcd510c60e38ed553e9c5a6204983","date":1196807382,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","sourceNew":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored())\n              localFieldsWriter.writeField(fieldInfo, field);\n\n            docFieldsFinal[j] = null;\n          }\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            // Add term vectors for this field\n            writeVectors(fieldInfo);\n            if (postingsVectorsUpto > maxPostingsVectors)\n              maxPostingsVectors = postingsVectorsUpto;\n            postingsVectorsUpto = 0;\n            vectorsPool.reset();\n          }\n        }\n      }\n\n","sourceOld":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this field:\n        for(int j=0;j<limit;j++) {\n          Fieldable field = docFieldsFinal[j];\n\n          if (field.isIndexed())\n            invertField(field, analyzer, maxFieldLength);\n\n          if (field.isStored())\n            localFieldsWriter.writeField(fieldInfo, field);\n\n          docFieldsFinal[j] = null;\n        }\n\n        if (postingsVectorsUpto > 0) {\n          // Add term vectors for this field\n          writeVectors(fieldInfo);\n          if (postingsVectorsUpto > maxPostingsVectors)\n            maxPostingsVectors = postingsVectorsUpto;\n          postingsVectorsUpto = 0;\n          vectorsPool.reset();\n        }\n      }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"bugIntro":["c9a0deca56efc5191d6b3c41047fd538f3fae1d8","176324efd1eab6bd44a6d81c27c9b3a1a175ba3d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9a0deca56efc5191d6b3c41047fd538f3fae1d8","date":1198156049,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","sourceNew":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored()) {\n              numStoredFields++;\n              boolean success = false;\n              try {\n                localFieldsWriter.writeField(fieldInfo, field);\n                success = true;\n              } finally {\n                // If we hit an exception inside\n                // localFieldsWriter.writeField, the\n                // contents of fdtLocal can be corrupt, so\n                // we must discard all stored fields for\n                // this document:\n                if (!success) {\n                  numStoredFields = 0;\n                  fdtLocal.reset();\n                }\n              }\n            }\n\n            docFieldsFinal[j] = null;\n          }\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            // Add term vectors for this field\n            boolean success = false;\n            try {\n              writeVectors(fieldInfo);\n              success = true;\n            } finally {\n              if (!success) {\n                // If we hit an exception inside\n                // writeVectors, the contents of tvfLocal\n                // can be corrupt, so we must discard all\n                // term vectors for this document:\n                numVectorFields = 0;\n                tvfLocal.reset();\n              }\n              if (postingsVectorsUpto > maxPostingsVectors)\n                maxPostingsVectors = postingsVectorsUpto;\n              postingsVectorsUpto = 0;\n              vectorsPool.reset();\n            }\n          }\n        }\n      }\n\n","sourceOld":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored())\n              localFieldsWriter.writeField(fieldInfo, field);\n\n            docFieldsFinal[j] = null;\n          }\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            // Add term vectors for this field\n            writeVectors(fieldInfo);\n            if (postingsVectorsUpto > maxPostingsVectors)\n              maxPostingsVectors = postingsVectorsUpto;\n            postingsVectorsUpto = 0;\n            vectorsPool.reset();\n          }\n        }\n      }\n\n","bugFix":["8560794cda5bcd510c60e38ed553e9c5a6204983"],"bugIntro":["83bbb041887bbef07b8a98d08a0e1713ce137039","176324efd1eab6bd44a6d81c27c9b3a1a175ba3d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"83bbb041887bbef07b8a98d08a0e1713ce137039","date":1200330381,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","sourceNew":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException, AbortException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored()) {\n              numStoredFields++;\n              boolean success = false;\n              try {\n                localFieldsWriter.writeField(fieldInfo, field);\n                success = true;\n              } finally {\n                // If we hit an exception inside\n                // localFieldsWriter.writeField, the\n                // contents of fdtLocal can be corrupt, so\n                // we must discard all stored fields for\n                // this document:\n                if (!success)\n                  fdtLocal.reset();\n              }\n            }\n\n            docFieldsFinal[j] = null;\n          }\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            // Add term vectors for this field\n            boolean success = false;\n            try {\n              writeVectors(fieldInfo);\n              success = true;\n            } finally {\n              if (!success) {\n                // If we hit an exception inside\n                // writeVectors, the contents of tvfLocal\n                // can be corrupt, so we must discard all\n                // term vectors for this document:\n                numVectorFields = 0;\n                tvfLocal.reset();\n              }\n              if (postingsVectorsUpto > maxPostingsVectors)\n                maxPostingsVectors = postingsVectorsUpto;\n              postingsVectorsUpto = 0;\n              vectorsPool.reset();\n            }\n          }\n        }\n      }\n\n","sourceOld":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored()) {\n              numStoredFields++;\n              boolean success = false;\n              try {\n                localFieldsWriter.writeField(fieldInfo, field);\n                success = true;\n              } finally {\n                // If we hit an exception inside\n                // localFieldsWriter.writeField, the\n                // contents of fdtLocal can be corrupt, so\n                // we must discard all stored fields for\n                // this document:\n                if (!success) {\n                  numStoredFields = 0;\n                  fdtLocal.reset();\n                }\n              }\n            }\n\n            docFieldsFinal[j] = null;\n          }\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            // Add term vectors for this field\n            boolean success = false;\n            try {\n              writeVectors(fieldInfo);\n              success = true;\n            } finally {\n              if (!success) {\n                // If we hit an exception inside\n                // writeVectors, the contents of tvfLocal\n                // can be corrupt, so we must discard all\n                // term vectors for this document:\n                numVectorFields = 0;\n                tvfLocal.reset();\n              }\n              if (postingsVectorsUpto > maxPostingsVectors)\n                maxPostingsVectors = postingsVectorsUpto;\n              postingsVectorsUpto = 0;\n              vectorsPool.reset();\n            }\n          }\n        }\n      }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c","c9a0deca56efc5191d6b3c41047fd538f3fae1d8"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"176324efd1eab6bd44a6d81c27c9b3a1a175ba3d","date":1202734547,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","sourceNew":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException, AbortException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        boolean doWriteVectors = true;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored()) {\n              numStoredFields++;\n              boolean success = false;\n              try {\n                localFieldsWriter.writeField(fieldInfo, field);\n                success = true;\n              } finally {\n                // If we hit an exception inside\n                // localFieldsWriter.writeField, the\n                // contents of fdtLocal can be corrupt, so\n                // we must discard all stored fields for\n                // this document:\n                if (!success)\n                  fdtLocal.reset();\n              }\n            }\n\n            docFieldsFinal[j] = null;\n          }\n        } catch (AbortException ae) {\n          doWriteVectors = false;\n          throw ae;\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            try {\n              if (doWriteVectors) {\n                // Add term vectors for this field\n                boolean success = false;\n                try {\n                  writeVectors(fieldInfo);\n                  success = true;\n                } finally {\n                  if (!success) {\n                    // If we hit an exception inside\n                    // writeVectors, the contents of tvfLocal\n                    // can be corrupt, so we must discard all\n                    // term vectors for this document:\n                    numVectorFields = 0;\n                    tvfLocal.reset();\n                  }\n                }\n              }\n            } finally {\n              if (postingsVectorsUpto > maxPostingsVectors)\n                maxPostingsVectors = postingsVectorsUpto;\n              postingsVectorsUpto = 0;\n              vectorsPool.reset();\n            }\n          }\n        }\n      }\n\n","sourceOld":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException, AbortException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored()) {\n              numStoredFields++;\n              boolean success = false;\n              try {\n                localFieldsWriter.writeField(fieldInfo, field);\n                success = true;\n              } finally {\n                // If we hit an exception inside\n                // localFieldsWriter.writeField, the\n                // contents of fdtLocal can be corrupt, so\n                // we must discard all stored fields for\n                // this document:\n                if (!success)\n                  fdtLocal.reset();\n              }\n            }\n\n            docFieldsFinal[j] = null;\n          }\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            // Add term vectors for this field\n            boolean success = false;\n            try {\n              writeVectors(fieldInfo);\n              success = true;\n            } finally {\n              if (!success) {\n                // If we hit an exception inside\n                // writeVectors, the contents of tvfLocal\n                // can be corrupt, so we must discard all\n                // term vectors for this document:\n                numVectorFields = 0;\n                tvfLocal.reset();\n              }\n              if (postingsVectorsUpto > maxPostingsVectors)\n                maxPostingsVectors = postingsVectorsUpto;\n              postingsVectorsUpto = 0;\n              vectorsPool.reset();\n            }\n          }\n        }\n      }\n\n","bugFix":["c9a0deca56efc5191d6b3c41047fd538f3fae1d8","8560794cda5bcd510c60e38ed553e9c5a6204983"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a0af3a442be522899177e5e11384a45a6784a3f","date":1205348952,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter.ThreadState.FieldData#processField(Analyzer).mjava","sourceNew":null,"sourceOld":"      /** Process all occurrences of one field in the document. */\n      public void processField(Analyzer analyzer) throws IOException, AbortException {\n        length = 0;\n        position = 0;\n        offset = 0;\n        boost = docBoost;\n\n        final int maxFieldLength = writer.getMaxFieldLength();\n\n        final int limit = fieldCount;\n        final Fieldable[] docFieldsFinal = docFields;\n\n        boolean doWriteVectors = true;\n\n        // Walk through all occurrences in this doc for this\n        // field:\n        try {\n          for(int j=0;j<limit;j++) {\n            Fieldable field = docFieldsFinal[j];\n\n            if (field.isIndexed())\n              invertField(field, analyzer, maxFieldLength);\n\n            if (field.isStored()) {\n              numStoredFields++;\n              boolean success = false;\n              try {\n                localFieldsWriter.writeField(fieldInfo, field);\n                success = true;\n              } finally {\n                // If we hit an exception inside\n                // localFieldsWriter.writeField, the\n                // contents of fdtLocal can be corrupt, so\n                // we must discard all stored fields for\n                // this document:\n                if (!success)\n                  fdtLocal.reset();\n              }\n            }\n\n            docFieldsFinal[j] = null;\n          }\n        } catch (AbortException ae) {\n          doWriteVectors = false;\n          throw ae;\n        } finally {\n          if (postingsVectorsUpto > 0) {\n            try {\n              if (doWriteVectors) {\n                // Add term vectors for this field\n                boolean success = false;\n                try {\n                  writeVectors(fieldInfo);\n                  success = true;\n                } finally {\n                  if (!success) {\n                    // If we hit an exception inside\n                    // writeVectors, the contents of tvfLocal\n                    // can be corrupt, so we must discard all\n                    // term vectors for this document:\n                    numVectorFields = 0;\n                    tvfLocal.reset();\n                  }\n                }\n              }\n            } finally {\n              if (postingsVectorsUpto > maxPostingsVectors)\n                maxPostingsVectors = postingsVectorsUpto;\n              postingsVectorsUpto = 0;\n              vectorsPool.reset();\n            }\n          }\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"83bbb041887bbef07b8a98d08a0e1713ce137039":["c9a0deca56efc5191d6b3c41047fd538f3fae1d8"],"c9a0deca56efc5191d6b3c41047fd538f3fae1d8":["8560794cda5bcd510c60e38ed553e9c5a6204983"],"176324efd1eab6bd44a6d81c27c9b3a1a175ba3d":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8560794cda5bcd510c60e38ed553e9c5a6204983":["b6a1f29c9b1051488fd5fa7d56c98db5f4388408"],"5a0af3a442be522899177e5e11384a45a6784a3f":["176324efd1eab6bd44a6d81c27c9b3a1a175ba3d"],"b6a1f29c9b1051488fd5fa7d56c98db5f4388408":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5a0af3a442be522899177e5e11384a45a6784a3f"]},"commit2Childs":{"83bbb041887bbef07b8a98d08a0e1713ce137039":["176324efd1eab6bd44a6d81c27c9b3a1a175ba3d"],"c9a0deca56efc5191d6b3c41047fd538f3fae1d8":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"176324efd1eab6bd44a6d81c27c9b3a1a175ba3d":["5a0af3a442be522899177e5e11384a45a6784a3f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"8560794cda5bcd510c60e38ed553e9c5a6204983":["c9a0deca56efc5191d6b3c41047fd538f3fae1d8"],"5a0af3a442be522899177e5e11384a45a6784a3f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b6a1f29c9b1051488fd5fa7d56c98db5f4388408":["8560794cda5bcd510c60e38ed553e9c5a6204983"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["b6a1f29c9b1051488fd5fa7d56c98db5f4388408"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}