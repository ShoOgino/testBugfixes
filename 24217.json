{"path":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,int).mjava","commits":[{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,int).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, int postingsFlags) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, postingsFlags);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,int).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, int postingsFlags) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, postingsFlags);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"954e59be3da8dc1b046646ad7af4b466852009d3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6a47d642ab24da1a811adce4bda9cc52c520ca13"]},"commit2Childs":{"6a47d642ab24da1a811adce4bda9cc52c520ca13":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["954e59be3da8dc1b046646ad7af4b466852009d3"],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}