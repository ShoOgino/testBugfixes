{"path":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","commits":[{"id":"f838187609fee3a1afa5f162f93c796046242c84","date":1406216791,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      // if (DEBUG) System.out.println(\"    writeBlock fp=\" + startFP + \" isFloor=\" + isFloor + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + suffixBytes);\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + suffixBytes);\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acca9f933f2900f374b672072ea9c159c5d72e83","date":1407403886,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      // if (DEBUG) System.out.println(\"    writeBlock fp=\" + startFP + \" isFloor=\" + isFloor + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + suffixBytes);\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + suffixBytes);\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":["f838187609fee3a1afa5f162f93c796046242c84"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6d238816bcdf9bbe4ec886226d89bd93834eb7e","date":1413925889,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasPrefixTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false && hasPrefixTerms == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert term.prefixTerm == null;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        boolean sawAutoPrefixTerm = false;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //  if (term.prefixTerm != null) {\n            //    System.out.println(\"        ** auto-prefix term: \" + term.prefixTerm);\n            //  }\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n            code = suffix<<2;\n            int floorLeadEnd = -1;\n            if (term.prefixTerm != null) {\n              sawAutoPrefixTerm = true;\n              PrefixTerm prefixTerm = term.prefixTerm;\n              floorLeadEnd = prefixTerm.floorLeadEnd;\n              assert floorLeadEnd != -1;\n\n              if (prefixTerm.floorLeadStart == -2) {\n                // Starts with empty string\n                code |= 2;\n              } else {\n                code |= 3;\n              }\n            }\n            suffixWriter.writeVInt(code);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            if (floorLeadEnd != -1) {\n              suffixWriter.writeByte((byte) floorLeadEnd);\n            }\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit (unset here) to\n            // record if it's a prefix term:\n            suffixWriter.writeVInt((suffix<<2)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0 || sawAutoPrefixTerm;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasPrefixTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false && hasPrefixTerms == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert term.prefixTerm == null;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        boolean sawAutoPrefixTerm = false;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //  if (term.prefixTerm != null) {\n            //    System.out.println(\"        ** auto-prefix term: \" + term.prefixTerm);\n            //  }\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n            code = suffix<<2;\n            int floorLeadEnd = -1;\n            if (term.prefixTerm != null) {\n              sawAutoPrefixTerm = true;\n              PrefixTerm prefixTerm = term.prefixTerm;\n              floorLeadEnd = prefixTerm.floorLeadEnd;\n              assert floorLeadEnd != -1;\n\n              if (prefixTerm.floorLeadStart == -2) {\n                // Starts with empty string\n                code |= 2;\n              } else {\n                code |= 3;\n              }\n            }\n            suffixWriter.writeVInt(code);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            if (floorLeadEnd != -1) {\n              suffixWriter.writeByte((byte) floorLeadEnd);\n            }\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit (unset here) to\n            // record if it's a prefix term:\n            suffixWriter.writeVInt((suffix<<2)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0 || sawAutoPrefixTerm;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","date":1466407389,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasPrefixTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false && hasPrefixTerms == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert term.prefixTerm == null;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        boolean sawAutoPrefixTerm = false;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //  if (term.prefixTerm != null) {\n            //    System.out.println(\"        ** auto-prefix term: \" + term.prefixTerm);\n            //  }\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            if (minItemsInAutoPrefix == 0) {\n              suffixWriter.writeVInt(suffix << 1);\n              suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            } else {\n              code = suffix<<2;\n              int floorLeadEnd = -1;\n              if (term.prefixTerm != null) {\n                assert minItemsInAutoPrefix > 0;\n                sawAutoPrefixTerm = true;\n                PrefixTerm prefixTerm = term.prefixTerm;\n                floorLeadEnd = prefixTerm.floorLeadEnd;\n                assert floorLeadEnd != -1;\n\n                if (prefixTerm.floorLeadStart == -2) {\n                  // Starts with empty string\n                  code |= 2;\n                } else {\n                  code |= 3;\n                }\n              }\n              suffixWriter.writeVInt(code);\n              suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n              if (floorLeadEnd != -1) {\n                suffixWriter.writeByte((byte) floorLeadEnd);\n              }\n              assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n            }\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit (unset here) to\n            // record if it's a prefix term:\n            if (minItemsInAutoPrefix == 0) {\n              suffixWriter.writeVInt((suffix<<1)|1);\n            } else {\n              suffixWriter.writeVInt((suffix<<2)|1);\n            }\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0 || sawAutoPrefixTerm;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6aaba221b22442bdf0ef28770c25fe259dfb3f55","date":1466496193,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasPrefixTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false && hasPrefixTerms == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert term.prefixTerm == null;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        boolean sawAutoPrefixTerm = false;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //  if (term.prefixTerm != null) {\n            //    System.out.println(\"        ** auto-prefix term: \" + term.prefixTerm);\n            //  }\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            if (minItemsInAutoPrefix == 0) {\n              suffixWriter.writeVInt(suffix << 1);\n              suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            } else {\n              code = suffix<<2;\n              int floorLeadEnd = -1;\n              if (term.prefixTerm != null) {\n                assert minItemsInAutoPrefix > 0;\n                sawAutoPrefixTerm = true;\n                PrefixTerm prefixTerm = term.prefixTerm;\n                floorLeadEnd = prefixTerm.floorLeadEnd;\n                assert floorLeadEnd != -1;\n\n                if (prefixTerm.floorLeadStart == -2) {\n                  // Starts with empty string\n                  code |= 2;\n                } else {\n                  code |= 3;\n                }\n              }\n              suffixWriter.writeVInt(code);\n              suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n              if (floorLeadEnd != -1) {\n                suffixWriter.writeByte((byte) floorLeadEnd);\n              }\n              assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n            }\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit (unset here) to\n            // record if it's a prefix term:\n            if (minItemsInAutoPrefix == 0) {\n              suffixWriter.writeVInt((suffix<<1)|1);\n            } else {\n              suffixWriter.writeVInt((suffix<<2)|1);\n            }\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0 || sawAutoPrefixTerm;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409da428f28953cf35fddd5c9ff5c7e4f5439863","date":1547556145,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.copyTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.copyTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb77022ef17ff655c519a3f6ecd393747ac88bcf","date":1578579386,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.copyTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.copyTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06ab276a5660cb79daae8c5ede063531c700a03a","date":1578587874,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.copyTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.copyTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08a5168e06e037794c0aba7f94f76ff3c09704d2","date":1579264785,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.copyTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.copyTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9407318969e8504257b4c5764c65755a043e5404","date":1579873617,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      if (suffixWriter.length() > 2L * numEntries) {\n        LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n        if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n          // LZ4 saved more than 25%, go for it\n          compressionAlg = CompressionAlgorithm.LZ4;\n        } else {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        // Still give LZ4 a chance, there might be runs of terms with the same length\n        termsOut.writeVInt(numSuffixBytes << 1);\n        LZ4.compress(spareBytes, 0, numSuffixBytes, termsOut, compressionHashTable);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numStatsBytes);\n      statsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      statsWriter.reset();\n      if (allEqual(spareBytes, 0, numStatsBytes, (byte) 1)) {\n        // ID fields would typically have blocks full of ones\n        // LZ4 would optimize this as well but we keep explicit specialization because the decoding logic is a bit faster\n        termsOut.writeVInt((numStatsBytes << 1) | 1);\n      } else {\n        // Still give LZ4 a chance otherwise, there might be runs of ones even if not all values are ones\n        termsOut.writeVInt(numStatsBytes << 1);\n        LZ4.compress(spareBytes, 0, numStatsBytes, termsOut, compressionHashTable);\n      }\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixWriter.writeVInt(suffix << 1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      termsOut.writeVInt((int) (suffixWriter.size() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.copyTo(termsOut);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      termsOut.writeVInt((int) statsWriter.size());\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a356e37aed258bcd168680472f8d1dbc6f396935","date":1580233110,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.add(state.docFreq, state.totalTermFreq);\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n        statsWriter.finish();\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.add(state.docFreq, state.totalTermFreq);\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n        statsWriter.finish();\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      if (suffixWriter.length() > 2L * numEntries) {\n        // LZ4 inserts references whenever it sees duplicate strings of 4 chars or more, so only try it out if the\n        // average suffix length is greater than 6.\n        if (suffixWriter.length() > 6L * numEntries) {\n          LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n          if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n            // LZ4 saved more than 25%, go for it\n            compressionAlg = CompressionAlgorithm.LZ4;\n          }\n        }\n        if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        termsOut.writeVInt(numSuffixBytes << 1);\n        termsOut.writeBytes(spareBytes, numSuffixBytes);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      termsOut.writeVInt(numStatsBytes);\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      if (suffixWriter.length() > 2L * numEntries) {\n        LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n        if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n          // LZ4 saved more than 25%, go for it\n          compressionAlg = CompressionAlgorithm.LZ4;\n        } else {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        // Still give LZ4 a chance, there might be runs of terms with the same length\n        termsOut.writeVInt(numSuffixBytes << 1);\n        LZ4.compress(spareBytes, 0, numSuffixBytes, termsOut, compressionHashTable);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numStatsBytes);\n      statsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      statsWriter.reset();\n      if (allEqual(spareBytes, 0, numStatsBytes, (byte) 1)) {\n        // ID fields would typically have blocks full of ones\n        // LZ4 would optimize this as well but we keep explicit specialization because the decoding logic is a bit faster\n        termsOut.writeVInt((numStatsBytes << 1) | 1);\n      } else {\n        // Still give LZ4 a chance otherwise, there might be runs of ones even if not all values are ones\n        termsOut.writeVInt(numStatsBytes << 1);\n        LZ4.compress(spareBytes, 0, numStatsBytes, termsOut, compressionHashTable);\n      }\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8cca5bde5afd378ed79e283669d20e7260169f15","date":1580377059,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.add(state.docFreq, state.totalTermFreq);\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n        statsWriter.finish();\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.add(state.docFreq, state.totalTermFreq);\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n        statsWriter.finish();\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      // We also only start compressing when the prefix length is greater than 2 since blocks whose prefix length is\n      // 1 or 2 always all get visited when running a fuzzy query whose max number of edits is 2.\n      if (suffixWriter.length() > 2L * numEntries && prefixLength > 2) {\n        // LZ4 inserts references whenever it sees duplicate strings of 4 chars or more, so only try it out if the\n        // average suffix length is greater than 6.\n        if (suffixWriter.length() > 6L * numEntries) {\n          LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n          if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n            // LZ4 saved more than 25%, go for it\n            compressionAlg = CompressionAlgorithm.LZ4;\n          }\n        }\n        if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        termsOut.writeVInt(numSuffixBytes << 1);\n        termsOut.writeBytes(spareBytes, numSuffixBytes);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      termsOut.writeVInt(numStatsBytes);\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.add(state.docFreq, state.totalTermFreq);\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n        statsWriter.finish();\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.add(state.docFreq, state.totalTermFreq);\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n        statsWriter.finish();\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      if (suffixWriter.length() > 2L * numEntries) {\n        // LZ4 inserts references whenever it sees duplicate strings of 4 chars or more, so only try it out if the\n        // average suffix length is greater than 6.\n        if (suffixWriter.length() > 6L * numEntries) {\n          LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n          if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n            // LZ4 saved more than 25%, go for it\n            compressionAlg = CompressionAlgorithm.LZ4;\n          }\n        }\n        if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        termsOut.writeVInt(numSuffixBytes << 1);\n        termsOut.writeBytes(spareBytes, numSuffixBytes);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      termsOut.writeVInt(numStatsBytes);\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9f94c392daa8f5708186bede16c84eafad4cdd2","date":1599578873,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): term + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.add(state.docFreq, state.totalTermFreq);\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n        statsWriter.finish();\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): term + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.add(state.docFreq, state.totalTermFreq);\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n        statsWriter.finish();\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      // We also only start compressing when the prefix length is greater than 2 since blocks whose prefix length is\n      // 1 or 2 always all get visited when running a fuzzy query whose max number of edits is 2.\n      if (suffixWriter.length() > 2L * numEntries && prefixLength > 2) {\n        // LZ4 inserts references whenever it sees duplicate strings of 4 chars or more, so only try it out if the\n        // average suffix length is greater than 6.\n        if (suffixWriter.length() > 6L * numEntries) {\n          LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n          if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n            // LZ4 saved more than 25%, go for it\n            compressionAlg = CompressionAlgorithm.LZ4;\n          }\n        }\n        if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        termsOut.writeVInt(numSuffixBytes << 1);\n        termsOut.writeBytes(spareBytes, numSuffixBytes);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      termsOut.writeVInt(numStatsBytes);\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end,\n                                    boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = termsOut.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      //if (DEBUG2) System.out.println(\"    writeBlock field=\" + fieldInfo.name + \" prefix=\" + brToString(prefix) + \" fp=\" + startFP + \" isFloor=\" + isFloor + \" isLastInFloor=\" + (end == pending.size()) + \" floorLeadLabel=\" + floorLeadLabel + \" start=\" + start + \" end=\" + end + \" hasTerms=\" + hasTerms + \" hasSubBlocks=\" + hasSubBlocks);\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      termsOut.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      //System.out.println(\"  isLeaf=\" + isLeafBlock);\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Block contains only ordinary terms:\n        subIndices = null;\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          //if (DEBUG2) {\n          //  BytesRef suffixBytes = new BytesRef(suffix);\n          //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //  suffixBytes.length = suffix;\n          //  System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          //}\n\n          // For leaf block we write suffix straight\n          suffixLengthsWriter.writeVInt(suffix);\n          suffixWriter.append(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.add(state.docFreq, state.totalTermFreq);\n\n          // Write term meta data\n          postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n          absolute = false;\n        }\n        statsWriter.finish();\n      } else {\n        // Block has at least one prefix term or a sub block:\n        subIndices = new ArrayList<>();\n        StatsWriter statsWriter = new StatsWriter(this.statsWriter, fieldInfo.getIndexOptions() != IndexOptions.DOCS);\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write term suffix=\" + brToString(suffixBytes));\n            //}\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block, and 1 bit to record if\n            // it's a prefix term.  Terms cannot be larger than ~32 KB\n            // so we won't run out of bits:\n\n            suffixLengthsWriter.writeVInt(suffix << 1);\n            suffixWriter.append(term.termBytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.add(state.docFreq, state.totalTermFreq);\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(metaWriter, fieldInfo, state, absolute);\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n            assert StringHelper.startsWith(block.prefix, prefix);\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block:f\n            suffixLengthsWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.append(block.prefix.bytes, prefixLength, suffix);\n\n            //if (DEBUG2) {\n            //  BytesRef suffixBytes = new BytesRef(suffix);\n            //  System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //  suffixBytes.length = suffix;\n            //  System.out.println(\"      write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            //}\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel: \"floorLeadLabel=\" + floorLeadLabel + \" suffixLead=\" + (block.prefix.bytes[prefixLength] & 0xff);\n            assert block.fp < startFP;\n\n            suffixLengthsWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n        statsWriter.finish();\n\n        assert subIndices.size() != 0;\n      }\n\n      // Write suffixes byte[] blob to terms dict output, either uncompressed, compressed with LZ4 or with LowercaseAsciiCompression.\n      CompressionAlgorithm compressionAlg = CompressionAlgorithm.NO_COMPRESSION;\n      // If there are 2 suffix bytes or less per term, then we don't bother compressing as suffix are unlikely what\n      // makes the terms dictionary large, and it also tends to be frequently the case for dense IDs like\n      // auto-increment IDs, so not compressing in that case helps not hurt ID lookups by too much.\n      // We also only start compressing when the prefix length is greater than 2 since blocks whose prefix length is\n      // 1 or 2 always all get visited when running a fuzzy query whose max number of edits is 2.\n      if (suffixWriter.length() > 2L * numEntries && prefixLength > 2) {\n        // LZ4 inserts references whenever it sees duplicate strings of 4 chars or more, so only try it out if the\n        // average suffix length is greater than 6.\n        if (suffixWriter.length() > 6L * numEntries) {\n          LZ4.compress(suffixWriter.bytes(), 0, suffixWriter.length(), spareWriter, compressionHashTable);\n          if (spareWriter.size() < suffixWriter.length() - (suffixWriter.length() >>> 2)) {\n            // LZ4 saved more than 25%, go for it\n            compressionAlg = CompressionAlgorithm.LZ4;\n          }\n        }\n        if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n          spareWriter.reset();\n          if (spareBytes.length < suffixWriter.length()) {\n            spareBytes = new byte[ArrayUtil.oversize(suffixWriter.length(), 1)];\n          }\n          if (LowercaseAsciiCompression.compress(suffixWriter.bytes(), suffixWriter.length(), spareBytes, spareWriter)) {\n            compressionAlg = CompressionAlgorithm.LOWERCASE_ASCII;\n          }\n        }\n      }\n      long token = ((long) suffixWriter.length()) << 3;\n      if (isLeafBlock) {\n        token |= 0x04;\n      }\n      token |= compressionAlg.code;\n      termsOut.writeVLong(token);\n      if (compressionAlg == CompressionAlgorithm.NO_COMPRESSION) {\n        termsOut.writeBytes(suffixWriter.bytes(), suffixWriter.length());\n      } else {\n        spareWriter.copyTo(termsOut);\n      }\n      suffixWriter.setLength(0);\n      spareWriter.reset();\n\n      // Write suffix lengths\n      final int numSuffixBytes = Math.toIntExact(suffixLengthsWriter.size());\n      spareBytes = ArrayUtil.grow(spareBytes, numSuffixBytes);\n      suffixLengthsWriter.copyTo(new ByteArrayDataOutput(spareBytes));\n      suffixLengthsWriter.reset();\n      if (allEqual(spareBytes, 1, numSuffixBytes, spareBytes[0])) {\n        // Structured fields like IDs often have most values of the same length\n        termsOut.writeVInt((numSuffixBytes << 1) | 1);\n        termsOut.writeByte(spareBytes[0]);\n      } else {\n        termsOut.writeVInt(numSuffixBytes << 1);\n        termsOut.writeBytes(spareBytes, numSuffixBytes);\n      }\n\n      // Stats\n      final int numStatsBytes = Math.toIntExact(statsWriter.size());\n      termsOut.writeVInt(numStatsBytes);\n      statsWriter.copyTo(termsOut);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      termsOut.writeVInt((int) metaWriter.size());\n      metaWriter.copyTo(termsOut);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c9f94c392daa8f5708186bede16c84eafad4cdd2":["8cca5bde5afd378ed79e283669d20e7260169f15"],"cb77022ef17ff655c519a3f6ecd393747ac88bcf":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["acca9f933f2900f374b672072ea9c159c5d72e83"],"a356e37aed258bcd168680472f8d1dbc6f396935":["9407318969e8504257b4c5764c65755a043e5404"],"f838187609fee3a1afa5f162f93c796046242c84":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["3e8715d826e588419327562287d5d6a8040d63d6","6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"c6d238816bcdf9bbe4ec886226d89bd93834eb7e":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["3e8715d826e588419327562287d5d6a8040d63d6","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["3e8715d826e588419327562287d5d6a8040d63d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d2638f781be724518ff6c2263d14a48cf6e68017":["2bb2842e561df4e8e9ad89010605fc86ac265465","3e8715d826e588419327562287d5d6a8040d63d6"],"8cca5bde5afd378ed79e283669d20e7260169f15":["a356e37aed258bcd168680472f8d1dbc6f396935"],"9407318969e8504257b4c5764c65755a043e5404":["08a5168e06e037794c0aba7f94f76ff3c09704d2"],"08a5168e06e037794c0aba7f94f76ff3c09704d2":["06ab276a5660cb79daae8c5ede063531c700a03a"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","c6d238816bcdf9bbe4ec886226d89bd93834eb7e"],"3e8715d826e588419327562287d5d6a8040d63d6":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"acca9f933f2900f374b672072ea9c159c5d72e83":["f838187609fee3a1afa5f162f93c796046242c84"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9f94c392daa8f5708186bede16c84eafad4cdd2"],"06ab276a5660cb79daae8c5ede063531c700a03a":["cb77022ef17ff655c519a3f6ecd393747ac88bcf"]},"commit2Childs":{"c9f94c392daa8f5708186bede16c84eafad4cdd2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cb77022ef17ff655c519a3f6ecd393747ac88bcf":["06ab276a5660cb79daae8c5ede063531c700a03a"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["d2638f781be724518ff6c2263d14a48cf6e68017","3e8715d826e588419327562287d5d6a8040d63d6"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["c6d238816bcdf9bbe4ec886226d89bd93834eb7e","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a356e37aed258bcd168680472f8d1dbc6f396935":["8cca5bde5afd378ed79e283669d20e7260169f15"],"f838187609fee3a1afa5f162f93c796046242c84":["acca9f933f2900f374b672072ea9c159c5d72e83"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"c6d238816bcdf9bbe4ec886226d89bd93834eb7e":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["cb77022ef17ff655c519a3f6ecd393747ac88bcf"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","409da428f28953cf35fddd5c9ff5c7e4f5439863"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f838187609fee3a1afa5f162f93c796046242c84"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"8cca5bde5afd378ed79e283669d20e7260169f15":["c9f94c392daa8f5708186bede16c84eafad4cdd2"],"9407318969e8504257b4c5764c65755a043e5404":["a356e37aed258bcd168680472f8d1dbc6f396935"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"08a5168e06e037794c0aba7f94f76ff3c09704d2":["9407318969e8504257b4c5764c65755a043e5404"],"acca9f933f2900f374b672072ea9c159c5d72e83":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"3e8715d826e588419327562287d5d6a8040d63d6":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","6aaba221b22442bdf0ef28770c25fe259dfb3f55","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","d2638f781be724518ff6c2263d14a48cf6e68017"],"06ab276a5660cb79daae8c5ede063531c700a03a":["08a5168e06e037794c0aba7f94f76ff3c09704d2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d2638f781be724518ff6c2263d14a48cf6e68017","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}