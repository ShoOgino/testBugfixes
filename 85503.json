{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter#nextInputToken().mjava","commits":[{"id":"6795c6bc2f5a6b2a2230cb20ff4744003faf7802","date":1333839972,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter#nextInputToken().mjava","pathOld":"/dev/null","sourceNew":"  private TOKEN_POS nextInputToken() throws IOException {\n    assert !end;\n    if (DEBUG) {\n      System.out.println(\"  call input.incr\");\n    }\n    final boolean result = input.incrementToken();\n    if (result) {\n      final int posInc = posIncAtt.getPositionIncrement();\n      final int posLength = posLengthAtt.getPositionLength();\n\n      // NOTE: when posLength > 1, we have a hole... we\n      // don't allow injected tokens to start or end\n      // \"inside\" a hole, so we don't need to make up\n      // offsets inside it\n\n      assert inputPos != -1 || posInc > 0;\n      inputPos += posInc;\n      if (DEBUG) {\n        System.out.println(\"    got token term=\" + termAtt + \" posLength=\" + posLength + \" posInc=\" + posInc + \" inputPos=\" + inputPos);\n      }\n      final Position posData = positions.get(inputPos);\n      if (posInc == 0) {\n        assert posData.startOffset == offsetAtt.startOffset();\n      } else {\n        assert posData.startOffset == -1;\n        posData.startOffset = offsetAtt.startOffset();\n        if (DEBUG) {\n          System.out.println(\"    record startOffset[\" + inputPos + \"]=\" + posData.startOffset);\n        }\n      }\n\n      final Position posEndData = positions.get(inputPos + posLength);\n      if (posEndData.endOffset == -1) {\n        // First time we are seeing a token that\n        // arrives to this position: record the\n        // endOffset\n        posEndData.endOffset = offsetAtt.endOffset();\n        if (DEBUG) {\n          System.out.println(\"    record endOffset[\" + (inputPos+posLength) + \"]=\" + posEndData.endOffset);\n        }\n      } else {\n        // We've already seen a token arriving there;\n        // make sure its endOffset is the same (NOTE:\n        // some tokenizers, eg WDF, will fail\n        // this...):\n        assert posEndData.endOffset == offsetAtt.endOffset(): \"posEndData.endOffset=\" + posEndData.endOffset + \" vs offsetAtt.endOffset()=\" + offsetAtt.endOffset();\n      }\n      if (posInc == 0) {\n        return TOKEN_POS.SAME;\n      } else {\n        return TOKEN_POS.NEXT;\n      }\n    } else {\n      if (DEBUG) {\n        System.out.println(\"    got END\");\n      }\n      return TOKEN_POS.END;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"914394e583f0258b2fe327df337ea44c908a0aab","date":1333904214,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter#nextInputToken().mjava","sourceNew":null,"sourceOld":"  private TOKEN_POS nextInputToken() throws IOException {\n    assert !end;\n    if (DEBUG) {\n      System.out.println(\"  call input.incr\");\n    }\n    final boolean result = input.incrementToken();\n    if (result) {\n      final int posInc = posIncAtt.getPositionIncrement();\n      final int posLength = posLengthAtt.getPositionLength();\n\n      // NOTE: when posLength > 1, we have a hole... we\n      // don't allow injected tokens to start or end\n      // \"inside\" a hole, so we don't need to make up\n      // offsets inside it\n\n      assert inputPos != -1 || posInc > 0;\n      inputPos += posInc;\n      if (DEBUG) {\n        System.out.println(\"    got token term=\" + termAtt + \" posLength=\" + posLength + \" posInc=\" + posInc + \" inputPos=\" + inputPos);\n      }\n      final Position posData = positions.get(inputPos);\n      if (posInc == 0) {\n        assert posData.startOffset == offsetAtt.startOffset();\n      } else {\n        assert posData.startOffset == -1;\n        posData.startOffset = offsetAtt.startOffset();\n        if (DEBUG) {\n          System.out.println(\"    record startOffset[\" + inputPos + \"]=\" + posData.startOffset);\n        }\n      }\n\n      final Position posEndData = positions.get(inputPos + posLength);\n      if (posEndData.endOffset == -1) {\n        // First time we are seeing a token that\n        // arrives to this position: record the\n        // endOffset\n        posEndData.endOffset = offsetAtt.endOffset();\n        if (DEBUG) {\n          System.out.println(\"    record endOffset[\" + (inputPos+posLength) + \"]=\" + posEndData.endOffset);\n        }\n      } else {\n        // We've already seen a token arriving there;\n        // make sure its endOffset is the same (NOTE:\n        // some tokenizers, eg WDF, will fail\n        // this...):\n        assert posEndData.endOffset == offsetAtt.endOffset(): \"posEndData.endOffset=\" + posEndData.endOffset + \" vs offsetAtt.endOffset()=\" + offsetAtt.endOffset();\n      }\n      if (posInc == 0) {\n        return TOKEN_POS.SAME;\n      } else {\n        return TOKEN_POS.NEXT;\n      }\n    } else {\n      if (DEBUG) {\n        System.out.println(\"    got END\");\n      }\n      return TOKEN_POS.END;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"914394e583f0258b2fe327df337ea44c908a0aab":["6795c6bc2f5a6b2a2230cb20ff4744003faf7802"],"6795c6bc2f5a6b2a2230cb20ff4744003faf7802":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["914394e583f0258b2fe327df337ea44c908a0aab"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6795c6bc2f5a6b2a2230cb20ff4744003faf7802"],"914394e583f0258b2fe327df337ea44c908a0aab":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6795c6bc2f5a6b2a2230cb20ff4744003faf7802":["914394e583f0258b2fe327df337ea44c908a0aab"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}