{"path":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = IndexReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = IndexReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = IndexReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = IndexReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = IndexReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = IndexReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = IndexReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = IndexReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = IndexReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = IndexReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.shutdown();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.shutdown();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2fb55c0777755badd3b46d8140f3d4301febed","date":1398881584,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.shutdown();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.shutdown();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.shutdown();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.shutdown();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.shutdown();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.shutdown();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.shutdown();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.shutdown();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.shutdown();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.shutdown();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.shutdown();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.maxDoc(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.maxDoc(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.maxDoc(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.getDocCount(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"feb4029567b43f074ed7b6eb8fb126d355075dfd","date":1544812585,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testMoreMerges().mjava","sourceNew":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.getDocStats().maxDoc);\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.getDocStats().maxDoc);\n    assertEquals(1000, writer.maxDoc(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  // case 5: tail segments, invariants not hold\n  public void testMoreMerges() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // auxiliary directory\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n\n    setUpDirs(dir, aux, true);\n\n    IndexWriter writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(100).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    writer.addIndexes(aux);\n    assertEquals(30, writer.maxDoc());\n    assertEquals(3, writer.getSegmentCount());\n    writer.close();\n\n    IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n      .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux, dontMergeConfig);\n    for (int i = 0; i < 27; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(aux);\n    assertEquals(3, reader.numDocs());\n    reader.close();\n\n    dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n    .setMergePolicy(NoMergePolicy.INSTANCE);\n    writer = new IndexWriter(aux2, dontMergeConfig);\n    for (int i = 0; i < 8; i++) {\n      writer.deleteDocuments(new Term(\"id\", \"\" + i));\n    }\n    writer.close();\n    reader = DirectoryReader.open(aux2);\n    assertEquals(22, reader.numDocs());\n    reader.close();\n\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setMaxBufferedDocs(6).\n            setMergePolicy(newLogMergePolicy(4))\n    );\n\n    writer.addIndexes(aux, aux2);\n    assertEquals(1040, writer.maxDoc());\n    assertEquals(1000, writer.maxDoc(0));\n    writer.close();\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2fb55c0777755badd3b46d8140f3d4301febed":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["7e2fb55c0777755badd3b46d8140f3d4301febed"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b0267c69e2456a3477a1ad785723f2135da3117e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["d0ef034a4f10871667ae75181537775ddcf8ade4","b0267c69e2456a3477a1ad785723f2135da3117e"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"b06445ae1731e049327712db0454e5643ca9b7fe":["d0ef034a4f10871667ae75181537775ddcf8ade4","b0267c69e2456a3477a1ad785723f2135da3117e"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["b0267c69e2456a3477a1ad785723f2135da3117e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["feb4029567b43f074ed7b6eb8fb126d355075dfd"]},"commit2Childs":{"7e2fb55c0777755badd3b46d8140f3d4301febed":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","feb4029567b43f074ed7b6eb8fb126d355075dfd"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["19275ba31e621f6da1b83bf13af75233876fd3d4","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["b0267c69e2456a3477a1ad785723f2135da3117e","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["7e2fb55c0777755badd3b46d8140f3d4301febed"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}