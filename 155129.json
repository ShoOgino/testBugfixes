{"path":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","commits":[{"id":"2070bf73ffa1039a505000f99ea245884ff19e11","date":1177653367,"type":0,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","pathOld":"/dev/null","sourceNew":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    TermEnum terms = reader.terms();\n    \n    while (terms.next()) {\n      String field = terms.term().field();\n      String t = terms.term().text();\n\n      // Compute distinct terms for every field\n      TopTermQueue tiq = info.get( field );\n      if( tiq == null ) {\n        tiq = new TopTermQueue( numTerms );\n        info.put( field, tiq );\n      }\n      tiq.distinctTerms++;\n      \n      // Only save the distinct terms for fields we worry about\n      if (fields != null && fields.size() > 0) {\n        if( !fields.contains( field ) ) {\n          continue;\n        }\n      }\n      if( junkWords != null && junkWords.contains( t ) ) {\n        continue;\n      }\n      \n      if( terms.docFreq() > tiq.minFreq ) {\n        tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n        if (tiq.size() >= numTerms) { // if tiq overfull\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n        }\n      }\n    }\n    return info;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["616ed7f9e598992da3e9e972bbb3d6cec6b1aed4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6511cb621c585259d6a1f2da408bad8c636c7035","date":1177826927,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","pathOld":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","sourceNew":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    TermEnum terms = reader.terms();\n    \n    while (terms.next()) {\n      String field = terms.term().field();\n      String t = terms.term().text();\n\n      // Compute distinct terms for every field\n      TopTermQueue tiq = info.get( field );\n      if( tiq == null ) {\n        tiq = new TopTermQueue( numTerms );\n        info.put( field, tiq );\n      }\n      tiq.distinctTerms++;\n      tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n      \n      // Only save the distinct terms for fields we worry about\n      if (fields != null && fields.size() > 0) {\n        if( !fields.contains( field ) ) {\n          continue;\n        }\n      }\n      if( junkWords != null && junkWords.contains( t ) ) {\n        continue;\n      }\n      \n      if( terms.docFreq() > tiq.minFreq ) {\n        tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n        if (tiq.size() >= numTerms) { // if tiq overfull\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n        }\n      }\n    }\n    return info;\n  }\n\n","sourceOld":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    TermEnum terms = reader.terms();\n    \n    while (terms.next()) {\n      String field = terms.term().field();\n      String t = terms.term().text();\n\n      // Compute distinct terms for every field\n      TopTermQueue tiq = info.get( field );\n      if( tiq == null ) {\n        tiq = new TopTermQueue( numTerms );\n        info.put( field, tiq );\n      }\n      tiq.distinctTerms++;\n      \n      // Only save the distinct terms for fields we worry about\n      if (fields != null && fields.size() > 0) {\n        if( !fields.contains( field ) ) {\n          continue;\n        }\n      }\n      if( junkWords != null && junkWords.contains( t ) ) {\n        continue;\n      }\n      \n      if( terms.docFreq() > tiq.minFreq ) {\n        tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n        if (tiq.size() >= numTerms) { // if tiq overfull\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n        }\n      }\n    }\n    return info;\n  }\n\n","bugFix":null,"bugIntro":["616ed7f9e598992da3e9e972bbb3d6cec6b1aed4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a3ba66d289fab97b1bad9db1f4be6bf42977499","date":1180032380,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","pathOld":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","sourceNew":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    TermEnum terms = reader.terms();\n    \n    while (terms.next()) {\n      String field = terms.term().field();\n      String t = terms.term().text();\n\n      // Compute distinct terms for every field\n      TopTermQueue tiq = info.get( field );\n      if( tiq == null ) {\n        tiq = new TopTermQueue( numTerms );\n        info.put( field, tiq );\n      }\n      tiq.distinctTerms++;\n      tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n      \n      // Only save the distinct terms for fields we worry about\n      if (fields != null && fields.size() > 0) {\n        if( !fields.contains( field ) ) {\n          continue;\n        }\n      }\n      if( junkWords != null && junkWords.contains( t ) ) {\n        continue;\n      }\n      \n      if( terms.docFreq() > tiq.minFreq ) {\n        tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n        if (tiq.size() >= numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n        }\n      }\n    }\n    return info;\n  }\n\n","sourceOld":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    TermEnum terms = reader.terms();\n    \n    while (terms.next()) {\n      String field = terms.term().field();\n      String t = terms.term().text();\n\n      // Compute distinct terms for every field\n      TopTermQueue tiq = info.get( field );\n      if( tiq == null ) {\n        tiq = new TopTermQueue( numTerms );\n        info.put( field, tiq );\n      }\n      tiq.distinctTerms++;\n      tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n      \n      // Only save the distinct terms for fields we worry about\n      if (fields != null && fields.size() > 0) {\n        if( !fields.contains( field ) ) {\n          continue;\n        }\n      }\n      if( junkWords != null && junkWords.contains( t ) ) {\n        continue;\n      }\n      \n      if( terms.docFreq() > tiq.minFreq ) {\n        tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n        if (tiq.size() >= numTerms) { // if tiq overfull\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n        }\n      }\n    }\n    return info;\n  }\n\n","bugFix":null,"bugIntro":["616ed7f9e598992da3e9e972bbb3d6cec6b1aed4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"616ed7f9e598992da3e9e972bbb3d6cec6b1aed4","date":1184068656,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","pathOld":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","sourceNew":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    \n    TermEnum terms = null;\n    try{\n      terms = reader.terms();    \n      while (terms.next()) {\n        String field = terms.term().field();\n        String t = terms.term().text();\n  \n        // Compute distinct terms for every field\n        TopTermQueue tiq = info.get( field );\n        if( tiq == null ) {\n          tiq = new TopTermQueue( numTerms+1 );\n          info.put( field, tiq );\n        }\n        tiq.distinctTerms++;\n        tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n        \n        // Only save the distinct terms for fields we worry about\n        if (fields != null && fields.size() > 0) {\n          if( !fields.contains( field ) ) {\n            continue;\n          }\n        }\n        if( junkWords != null && junkWords.contains( t ) ) {\n          continue;\n        }\n        \n        if( terms.docFreq() > tiq.minFreq ) {\n          tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n            if (tiq.size() > numTerms) { // if tiq full\n            tiq.pop(); // remove lowest in tiq\n            tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n          }\n        }\n      }\n    }\n    finally {\n      if( terms != null ) terms.close();\n    }\n    return info;\n  }\n\n","sourceOld":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    TermEnum terms = reader.terms();\n    \n    while (terms.next()) {\n      String field = terms.term().field();\n      String t = terms.term().text();\n\n      // Compute distinct terms for every field\n      TopTermQueue tiq = info.get( field );\n      if( tiq == null ) {\n        tiq = new TopTermQueue( numTerms );\n        info.put( field, tiq );\n      }\n      tiq.distinctTerms++;\n      tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n      \n      // Only save the distinct terms for fields we worry about\n      if (fields != null && fields.size() > 0) {\n        if( !fields.contains( field ) ) {\n          continue;\n        }\n      }\n      if( junkWords != null && junkWords.contains( t ) ) {\n        continue;\n      }\n      \n      if( terms.docFreq() > tiq.minFreq ) {\n        tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n        if (tiq.size() >= numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n        }\n      }\n    }\n    return info;\n  }\n\n","bugFix":["6511cb621c585259d6a1f2da408bad8c636c7035","6a3ba66d289fab97b1bad9db1f4be6bf42977499","2070bf73ffa1039a505000f99ea245884ff19e11"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ef28ac95f5f85bbf872801277448c0924b0a6827","date":1268600312,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","pathOld":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","sourceNew":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    \n    TermEnum terms = null;\n    try{\n      terms = reader.terms();    \n      while (terms.next()) {\n        String field = terms.term().field();\n        String t = terms.term().text();\n  \n        // Compute distinct terms for every field\n        TopTermQueue tiq = info.get( field );\n        if( tiq == null ) {\n          tiq = new TopTermQueue( numTerms+1 );\n          info.put( field, tiq );\n        }\n        tiq.distinctTerms++;\n        tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n        \n        // Only save the distinct terms for fields we worry about\n        if (fields != null && fields.size() > 0) {\n          if( !fields.contains( field ) ) {\n            continue;\n          }\n        }\n        if( junkWords != null && junkWords.contains( t ) ) {\n          continue;\n        }\n        \n        if( terms.docFreq() > tiq.minFreq ) {\n          tiq.add(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n            if (tiq.size() > numTerms) { // if tiq full\n            tiq.pop(); // remove lowest in tiq\n            tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n          }\n        }\n      }\n    }\n    finally {\n      if( terms != null ) terms.close();\n    }\n    return info;\n  }\n\n","sourceOld":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    \n    TermEnum terms = null;\n    try{\n      terms = reader.terms();    \n      while (terms.next()) {\n        String field = terms.term().field();\n        String t = terms.term().text();\n  \n        // Compute distinct terms for every field\n        TopTermQueue tiq = info.get( field );\n        if( tiq == null ) {\n          tiq = new TopTermQueue( numTerms+1 );\n          info.put( field, tiq );\n        }\n        tiq.distinctTerms++;\n        tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n        \n        // Only save the distinct terms for fields we worry about\n        if (fields != null && fields.size() > 0) {\n          if( !fields.contains( field ) ) {\n            continue;\n          }\n        }\n        if( junkWords != null && junkWords.contains( t ) ) {\n          continue;\n        }\n        \n        if( terms.docFreq() > tiq.minFreq ) {\n          tiq.put(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n            if (tiq.size() > numTerms) { // if tiq full\n            tiq.pop(); // remove lowest in tiq\n            tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n          }\n        }\n      }\n    }\n    finally {\n      if( terms != null ) terms.close();\n    }\n    return info;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","pathOld":"src/java/org/apache/solr/handler/admin/LukeRequestHandler#getTopTerms(IndexReader,Set[String],int,Set[String]).mjava","sourceNew":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    \n    TermEnum terms = null;\n    try{\n      terms = reader.terms();    \n      while (terms.next()) {\n        String field = terms.term().field();\n        String t = terms.term().text();\n  \n        // Compute distinct terms for every field\n        TopTermQueue tiq = info.get( field );\n        if( tiq == null ) {\n          tiq = new TopTermQueue( numTerms+1 );\n          info.put( field, tiq );\n        }\n        tiq.distinctTerms++;\n        tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n        \n        // Only save the distinct terms for fields we worry about\n        if (fields != null && fields.size() > 0) {\n          if( !fields.contains( field ) ) {\n            continue;\n          }\n        }\n        if( junkWords != null && junkWords.contains( t ) ) {\n          continue;\n        }\n        \n        if( terms.docFreq() > tiq.minFreq ) {\n          tiq.add(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n            if (tiq.size() > numTerms) { // if tiq full\n            tiq.pop(); // remove lowest in tiq\n            tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n          }\n        }\n      }\n    }\n    finally {\n      if( terms != null ) terms.close();\n    }\n    return info;\n  }\n\n","sourceOld":"  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception \n  {\n    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();\n    \n    TermEnum terms = null;\n    try{\n      terms = reader.terms();    \n      while (terms.next()) {\n        String field = terms.term().field();\n        String t = terms.term().text();\n  \n        // Compute distinct terms for every field\n        TopTermQueue tiq = info.get( field );\n        if( tiq == null ) {\n          tiq = new TopTermQueue( numTerms+1 );\n          info.put( field, tiq );\n        }\n        tiq.distinctTerms++;\n        tiq.histogram.add( terms.docFreq() );  // add the term to the histogram\n        \n        // Only save the distinct terms for fields we worry about\n        if (fields != null && fields.size() > 0) {\n          if( !fields.contains( field ) ) {\n            continue;\n          }\n        }\n        if( junkWords != null && junkWords.contains( t ) ) {\n          continue;\n        }\n        \n        if( terms.docFreq() > tiq.minFreq ) {\n          tiq.add(new TopTermQueue.TermInfo(terms.term(), terms.docFreq()));\n            if (tiq.size() > numTerms) { // if tiq full\n            tiq.pop(); // remove lowest in tiq\n            tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq\n          }\n        }\n      }\n    }\n    finally {\n      if( terms != null ) terms.close();\n    }\n    return info;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ef28ac95f5f85bbf872801277448c0924b0a6827":["616ed7f9e598992da3e9e972bbb3d6cec6b1aed4"],"2070bf73ffa1039a505000f99ea245884ff19e11":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"ad94625fb8d088209f46650c8097196fec67f00c":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"6a3ba66d289fab97b1bad9db1f4be6bf42977499":["6511cb621c585259d6a1f2da408bad8c636c7035"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"616ed7f9e598992da3e9e972bbb3d6cec6b1aed4":["6a3ba66d289fab97b1bad9db1f4be6bf42977499"],"6511cb621c585259d6a1f2da408bad8c636c7035":["2070bf73ffa1039a505000f99ea245884ff19e11"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["2070bf73ffa1039a505000f99ea245884ff19e11"],"ef28ac95f5f85bbf872801277448c0924b0a6827":["ad94625fb8d088209f46650c8097196fec67f00c"],"2070bf73ffa1039a505000f99ea245884ff19e11":["6511cb621c585259d6a1f2da408bad8c636c7035"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"6a3ba66d289fab97b1bad9db1f4be6bf42977499":["616ed7f9e598992da3e9e972bbb3d6cec6b1aed4"],"616ed7f9e598992da3e9e972bbb3d6cec6b1aed4":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"6511cb621c585259d6a1f2da408bad8c636c7035":["6a3ba66d289fab97b1bad9db1f4be6bf42977499"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}