{"path":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","commits":[{"id":"48bedd31c61edafb8baaff4bcbcac19449fb7c3a","date":1251468037,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c","date":1254521470,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f11899016a0460a7ea2e4b008d002e1e75c7d867","date":1256772085,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d57eb7c98c08c03af6e4cd83509df31c81ac16af","date":1257684312,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["f11899016a0460a7ea2e4b008d002e1e75c7d867"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"f11899016a0460a7ea2e4b008d002e1e75c7d867":["4625cb7ffd7c9caaf2d62b206ba9a382d68da82c"]},"commit2Childs":{"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["4625cb7ffd7c9caaf2d62b206ba9a382d68da82c"],"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c":["f11899016a0460a7ea2e4b008d002e1e75c7d867"],"f11899016a0460a7ea2e4b008d002e1e75c7d867":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}