{"path":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","commits":[{"id":"49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b","date":1444426023,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermsQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d73510b39df24d6b65de48e56f8dccb136b9d01","date":1483971905,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","sourceNew":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermInSetQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","sourceOld":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermsQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","sourceNew":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermInSetQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","sourceOld":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermsQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976","date":1500994164,"type":4,"author":"yonik","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","sourceNew":null,"sourceOld":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermInSetQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a52341299179de5479672f7cf518bf4b173f34b3","date":1501079746,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","sourceNew":null,"sourceOld":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermInSetQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#buildFrontierQuery(BytesRefHash,Integer).mjava","sourceNew":null,"sourceOld":"    /**\n     * This return a query that represents the documents that match the next hop in the query.\n     * \n     * collectorTerms - the terms that represent the edge ids for the current frontier.\n     * frontierSize - the size of the frontier query (number of unique edges)\n     *  \n     */\n    public FrontierQuery buildFrontierQuery(BytesRefHash collectorTerms, Integer frontierSize) {\n      if (collectorTerms == null || collectorTerms.size() == 0) {\n        // return null if there are no terms (edges) to traverse.\n        return null;\n      } else {\n        // Create a query\n        Query q = null;\n\n        // TODO: see if we should dynamically select this based on the frontier size.\n        if (useAutn) {\n          // build an automaton based query for the frontier.\n          Automaton autn = buildAutomaton(collectorTerms);\n          AutomatonQuery autnQuery = new AutomatonQuery(new Term(fromField), autn);\n          q = autnQuery;\n        } else {\n          List<BytesRef> termList = new ArrayList<>(collectorTerms.size());\n          for (int i = 0 ; i < collectorTerms.size(); i++) {\n            BytesRef ref = new BytesRef();\n            collectorTerms.get(i, ref);\n            termList.add(ref);\n          }\n          q = new TermInSetQuery(fromField, termList);\n        }\n        \n        // If there is a filter to be used while crawling the graph, add that.\n        if (traversalFilter != null) {\n          BooleanQuery.Builder builder = new BooleanQuery.Builder();\n          builder.add(q, Occur.MUST);\n          builder.add(traversalFilter, Occur.MUST);\n          q = builder.build();\n        } \n        // return the new query. \n        FrontierQuery frontier = new FrontierQuery(q, frontierSize);\n        return frontier;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976":["8d73510b39df24d6b65de48e56f8dccb136b9d01"],"a52341299179de5479672f7cf518bf4b173f34b3":["8d73510b39df24d6b65de48e56f8dccb136b9d01","a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["8d73510b39df24d6b65de48e56f8dccb136b9d01","a52341299179de5479672f7cf518bf4b173f34b3"],"49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8d73510b39df24d6b65de48e56f8dccb136b9d01":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b","8d73510b39df24d6b65de48e56f8dccb136b9d01"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a52341299179de5479672f7cf518bf4b173f34b3"]},"commit2Childs":{"a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976":["a52341299179de5479672f7cf518bf4b173f34b3"],"a52341299179de5479672f7cf518bf4b173f34b3":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b":["8d73510b39df24d6b65de48e56f8dccb136b9d01","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b"],"8d73510b39df24d6b65de48e56f8dccb136b9d01":["a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976","a52341299179de5479672f7cf518bf4b173f34b3","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}