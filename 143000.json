{"path":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      final boolean hasOffsets;\n      if (dpEnum == null) {\n        hasOffsets = false;\n        dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      } else {\n        hasOffsets = true;\n      }\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      final boolean hasOffsets;\n      if (dpEnum == null) {\n        hasOffsets = false;\n        dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      } else {\n        hasOffsets = true;\n      }\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      boolean hasOffsets = true;\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        hasOffsets &= dpEnum.startOffset() >= 0;\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      final boolean hasOffsets;\n      if (dpEnum == null) {\n        hasOffsets = false;\n        dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      } else {\n        hasOffsets = true;\n      }\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":["5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      boolean hasOffsets = true;\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        hasOffsets &= dpEnum.startOffset() >= 0;\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      final boolean hasOffsets;\n      if (dpEnum == null) {\n        hasOffsets = false;\n        dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      } else {\n        hasOffsets = true;\n      }\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      boolean hasOffsets = true;\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        hasOffsets &= dpEnum.startOffset() >= 0;\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      final boolean hasOffsets;\n      if (dpEnum == null) {\n        hasOffsets = false;\n        dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      } else {\n        hasOffsets = true;\n      }\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc","date":1344608180,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      boolean hasOffsets = true;\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        hasOffsets &= dpEnum.startOffset() >= 0;\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      boolean hasOffsets = true;\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        hasOffsets &= dpEnum.startOffset() >= 0;\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      boolean hasOffsets = true;\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        hasOffsets &= dpEnum.startOffset() >= 0;\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dcc555744b1a581a4beccd0b75f8d3fe49735a2f","date":1367588265,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.timSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.mergeSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"000498895a9d8c442dd10d03121bd753ec00bc0e","date":1389468193,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    payloadAttribute = addAttribute(PayloadAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final boolean hasPayloads = vector.hasPayloads();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        if (hasPayloads) {\n          // Must make a deep copy of the returned payload,\n          // since D&PEnum API is allowed to re-use on every\n          // call:\n          token.setPayload(BytesRef.deepCopyOf(dpEnum.getPayload()));\n        }\n\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.timSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.timSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae230518a1a68acc124bef8df61ef94bd7c1295e","date":1417181719,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and/or offsets.\n   */\n  public TokenStreamFromTermPositionVector(Terms vector) throws IOException {\n    if (!vector.hasPositions() && !vector.hasOffsets()) {\n      throw new IllegalArgumentException(\"The term vector needs positions and/or offsets.\");\n    }\n    assert vector.hasFreqs();\n    this.vector = vector;\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final Terms vector) throws IOException {\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    payloadAttribute = addAttribute(PayloadAttribute.class);\n    final boolean hasOffsets = vector.hasOffsets();\n    final boolean hasPayloads = vector.hasPayloads();\n    final TermsEnum termsEnum = vector.iterator(null);\n    BytesRef text;\n    DocsAndPositionsEnum dpEnum = null;\n    while((text = termsEnum.next()) != null) {\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier\n      dpEnum.nextDoc();\n      final int freq = dpEnum.freq();\n      for (int j = 0; j < freq; j++) {\n        int pos = dpEnum.nextPosition();\n        Token token;\n        if (hasOffsets) {\n          token = new Token(text.utf8ToString(),\n                            dpEnum.startOffset(),\n                            dpEnum.endOffset());\n        } else {\n          token = new Token();\n          token.setEmpty().append(text.utf8ToString());\n        }\n        if (hasPayloads) {\n          // Must make a deep copy of the returned payload,\n          // since D&PEnum API is allowed to re-use on every\n          // call:\n          token.setPayload(BytesRef.deepCopyOf(dpEnum.getPayload()));\n        }\n\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(pos);\n        this.positionedTokens.add(token);\n      }\n    }\n    CollectionUtil.timSort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"714aa8d007eef87d7203cfc6e0fe4dab8dd8a497","date":1417181893,"type":5,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#TokenStreamFromTermVector(Terms).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(Terms).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and/or offsets.\n   */\n  public TokenStreamFromTermVector(Terms vector) throws IOException {\n    if (!vector.hasPositions() && !vector.hasOffsets()) {\n      throw new IllegalArgumentException(\"The term vector needs positions and/or offsets.\");\n    }\n    assert vector.hasFreqs();\n    this.vector = vector;\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param vector Terms that contains the data for\n   *        creating the TokenStream. Must have positions and/or offsets.\n   */\n  public TokenStreamFromTermPositionVector(Terms vector) throws IOException {\n    if (!vector.hasPositions() && !vector.hasOffsets()) {\n      throw new IllegalArgumentException(\"The term vector needs positions and/or offsets.\");\n    }\n    assert vector.hasFreqs();\n    this.vector = vector;\n    termAttribute = addAttribute(CharTermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"714aa8d007eef87d7203cfc6e0fe4dab8dd8a497":["ae230518a1a68acc124bef8df61ef94bd7c1295e"],"5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"000498895a9d8c442dd10d03121bd753ec00bc0e":["dcc555744b1a581a4beccd0b75f8d3fe49735a2f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae230518a1a68acc124bef8df61ef94bd7c1295e":["000498895a9d8c442dd10d03121bd753ec00bc0e"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["b89678825b68eccaf09e6ab71675fc0b0af1e099","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"dcc555744b1a581a4beccd0b75f8d3fe49735a2f":["5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["b89678825b68eccaf09e6ab71675fc0b0af1e099","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["d6f074e73200c07d54f242d3880a8da5a35ff97b","5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["714aa8d007eef87d7203cfc6e0fe4dab8dd8a497"]},"commit2Childs":{"714aa8d007eef87d7203cfc6e0fe4dab8dd8a497":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc":["c7869f64c874ebf7f317d22c00baf2b6857797a6","dcc555744b1a581a4beccd0b75f8d3fe49735a2f","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"000498895a9d8c442dd10d03121bd753ec00bc0e":["ae230518a1a68acc124bef8df61ef94bd7c1295e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"ae230518a1a68acc124bef8df61ef94bd7c1295e":["714aa8d007eef87d7203cfc6e0fe4dab8dd8a497"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"dcc555744b1a581a4beccd0b75f8d3fe49735a2f":["000498895a9d8c442dd10d03121bd753ec00bc0e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["5699a2da08aaf5a165f2ceefe7cf8f5c70a12efc","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}