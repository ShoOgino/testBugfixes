{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","commits":[{"id":"d4ddf965cea25006a6e621cc031c3bc69863ff4d","date":1474564021,"type":0,"author":"Dennis Gove","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    \n    //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n    long count = 0;\n\n    for(Tuple tuple : tuples) {\n      count+=tuple.getLong(\"batchIndexed\");\n    }\n\n    assert(count == 5);\n\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"126d6ad24eed13163ba0959435d5a80e5672837c","date":1474567302,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    \n    //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n    long count = 0;\n\n    for(Tuple tuple : tuples) {\n      count+=tuple.getLong(\"batchIndexed\");\n    }\n\n    assert(count == 5);\n\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    \n    //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n    long count = 0;\n\n    for(Tuple tuple : tuples) {\n      count+=tuple.getLong(\"batchIndexed\");\n    }\n\n    assert(count == 5);\n\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    \n    //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n    long count = 0;\n\n    for(Tuple tuple : tuples) {\n      count+=tuple.getLong(\"batchIndexed\");\n    }\n\n    assert(count == 5);\n\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c405288c4553ffb50ab8ca5adbdde9881bcec4e4","date":1491938682,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    \n    //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n    long count = 0;\n\n    for(Tuple tuple : tuples) {\n      count+=tuple.getLong(\"batchIndexed\");\n    }\n\n    assert(count == 5);\n\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    \n    //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n    long count = 0;\n\n    for(Tuple tuple : tuples) {\n      count+=tuple.getLong(\"batchIndexed\");\n    }\n\n    assert(count == 5);\n\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":5,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelCommitStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelCommitStream().mjava","sourceNew":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelCommitStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"commit\", CommitStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"commit(parallelDestinationCollection, batchSize=0, zkHost=\\\"\" + cluster.getZkServer().getZkAddress() + \"\\\", update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"126d6ad24eed13163ba0959435d5a80e5672837c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d4ddf965cea25006a6e621cc031c3bc69863ff4d"],"d4ddf965cea25006a6e621cc031c3bc69863ff4d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","126d6ad24eed13163ba0959435d5a80e5672837c"],"c405288c4553ffb50ab8ca5adbdde9881bcec4e4":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["c405288c4553ffb50ab8ca5adbdde9881bcec4e4"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"126d6ad24eed13163ba0959435d5a80e5672837c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d4ddf965cea25006a6e621cc031c3bc69863ff4d":["126d6ad24eed13163ba0959435d5a80e5672837c"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","c405288c4553ffb50ab8ca5adbdde9881bcec4e4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["126d6ad24eed13163ba0959435d5a80e5672837c","d4ddf965cea25006a6e621cc031c3bc69863ff4d","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"c405288c4553ffb50ab8ca5adbdde9881bcec4e4":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}