{"path":"lucene/src/java/org/apache/lucene/index/SegmentMerger#copyVectorsNoDeletions(TermVectorsWriter,TermVectorsReader,IndexReader).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#copyVectorsNoDeletions(TermVectorsWriter,TermVectorsReader,IndexReader).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#copyVectorsNoDeletions(TermVectorsWriter,TermVectorsReader,IndexReader).mjava","sourceNew":"  private void copyVectorsNoDeletions(final TermVectorsWriter termVectorsWriter,\n                                      final TermVectorsReader matchingVectorsReader,\n                                      final IndexReader reader)\n      throws IOException, MergeAbortedException {\n    final int maxDoc = reader.maxDoc();\n    if (matchingVectorsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      int docCount = 0;\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        matchingVectorsReader.rawDocs(rawDocLengths, rawDocLengths2, docCount, len);\n        termVectorsWriter.addRawDocuments(matchingVectorsReader, rawDocLengths, rawDocLengths2, len);\n        docCount += len;\n        checkAbort.work(300 * len);\n      }\n    } else {\n      for (int docNum = 0; docNum < maxDoc; docNum++) {\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        TermFreqVector[] vectors = reader.getTermFreqVectors(docNum);\n        termVectorsWriter.addAllDocVectors(vectors);\n        checkAbort.work(300);\n      }\n    }\n  }\n\n","sourceOld":"  private void copyVectorsNoDeletions(final TermVectorsWriter termVectorsWriter,\n                                      final TermVectorsReader matchingVectorsReader,\n                                      final IndexReader reader)\n      throws IOException, MergeAbortedException {\n    final int maxDoc = reader.maxDoc();\n    if (matchingVectorsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      int docCount = 0;\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        matchingVectorsReader.rawDocs(rawDocLengths, rawDocLengths2, docCount, len);\n        termVectorsWriter.addRawDocuments(matchingVectorsReader, rawDocLengths, rawDocLengths2, len);\n        docCount += len;\n        checkAbort.work(300 * len);\n      }\n    } else {\n      for (int docNum = 0; docNum < maxDoc; docNum++) {\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        TermFreqVector[] vectors = reader.getTermFreqVectors(docNum);\n        termVectorsWriter.addAllDocVectors(vectors);\n        checkAbort.work(300);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0061262413ecc163d6eebba1b5c43ab91a0c2dc5","date":1311195279,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#copyVectorsNoDeletions(TermVectorsWriter,TermVectorsReader,MergeState.IndexReaderAndLiveDocs).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#copyVectorsNoDeletions(TermVectorsWriter,TermVectorsReader,IndexReader).mjava","sourceNew":"  private void copyVectorsNoDeletions(final TermVectorsWriter termVectorsWriter,\n                                      final TermVectorsReader matchingVectorsReader,\n                                      final MergeState.IndexReaderAndLiveDocs reader)\n      throws IOException, MergeAbortedException {\n    final int maxDoc = reader.reader.maxDoc();\n    if (matchingVectorsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      int docCount = 0;\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        matchingVectorsReader.rawDocs(rawDocLengths, rawDocLengths2, docCount, len);\n        termVectorsWriter.addRawDocuments(matchingVectorsReader, rawDocLengths, rawDocLengths2, len);\n        docCount += len;\n        checkAbort.work(300 * len);\n      }\n    } else {\n      for (int docNum = 0; docNum < maxDoc; docNum++) {\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        TermFreqVector[] vectors = reader.reader.getTermFreqVectors(docNum);\n        termVectorsWriter.addAllDocVectors(vectors);\n        checkAbort.work(300);\n      }\n    }\n  }\n\n","sourceOld":"  private void copyVectorsNoDeletions(final TermVectorsWriter termVectorsWriter,\n                                      final TermVectorsReader matchingVectorsReader,\n                                      final IndexReader reader)\n      throws IOException, MergeAbortedException {\n    final int maxDoc = reader.maxDoc();\n    if (matchingVectorsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      int docCount = 0;\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        matchingVectorsReader.rawDocs(rawDocLengths, rawDocLengths2, docCount, len);\n        termVectorsWriter.addRawDocuments(matchingVectorsReader, rawDocLengths, rawDocLengths2, len);\n        docCount += len;\n        checkAbort.work(300 * len);\n      }\n    } else {\n      for (int docNum = 0; docNum < maxDoc; docNum++) {\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        TermFreqVector[] vectors = reader.getTermFreqVectors(docNum);\n        termVectorsWriter.addAllDocVectors(vectors);\n        checkAbort.work(300);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}