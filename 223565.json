{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","commits":[{"id":"16ebfabc294f23b88b6a39722a02c9d39b353195","date":1464343867,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"thread\", threadID));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        assertEquals(expectedCounts[id], s.count(new TermQuery(new Term(\"id\", \"\"+id))));\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"122251c49e5a9fa95f056ea257ae3ab452099fc7","date":1464820065,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","sourceNew":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"thread\", threadID));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        assertEquals(expectedCounts[id], s.count(new TermQuery(new Term(\"id\", \"\"+id))));\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77","date":1464821470,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","sourceNew":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"thread\", threadID));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        assertEquals(expectedCounts[id], s.count(new TermQuery(new Term(\"id\", \"\"+id))));\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6483e4260c08168709c02238ae083a51519a28dd","date":1465117546,"type":0,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9dea8da13fd1a227ae1071e8f4ce66bff42174de","date":1471439735,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","sourceNew":"  @Slow\n  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","sourceNew":"  @Slow\n  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","sourceNew":"  @Slow\n  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexingSequenceNumbers#testStressConcurrentAddAndDeleteAndCommit().mjava","sourceNew":"  @Nightly\n  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  @Slow\n  public void testStressConcurrentAddAndDeleteAndCommit() throws Exception {\n    final int opCount = atLeast(10000);\n    final int idCount = TestUtil.nextInt(random(), 10, 1000);\n\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    iwc.setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE);\n\n    // Cannot use RIW since it randomly commits:\n    final IndexWriter w = new IndexWriter(dir, iwc);\n\n    final int numThreads = TestUtil.nextInt(random(), 2, 5);\n    Thread[] threads = new Thread[numThreads];\n    //System.out.println(\"TEST: iter=\" + iter + \" opCount=\" + opCount + \" idCount=\" + idCount + \" threadCount=\" + threads.length);\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    List<List<Operation>> threadOps = new ArrayList<>();\n\n    Object commitLock = new Object();\n    final List<Operation> commits = new ArrayList<>();\n\n    // multiple threads update the same set of documents, and we randomly commit\n    for(int i=0;i<threads.length;i++) {\n      final List<Operation> ops = new ArrayList<>();\n      threadOps.add(ops);\n      final int threadID = i;\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              for(int i=0;i<opCount;i++) {\n                Operation op = new Operation();\n                op.threadID = threadID;\n                if (random().nextInt(500) == 17) {\n                  op.what = 2;\n                  synchronized(commitLock) {\n                    op.seqNo = w.commit();\n                    if (op.seqNo != -1) {\n                      commits.add(op);\n                    }\n                  }\n                } else {\n                  op.id = random().nextInt(idCount);\n                  Term idTerm = new Term(\"id\", \"\" + op.id);\n                  if (random().nextInt(10) == 1) {\n                    op.what = 1;\n                    if (random().nextBoolean()) {\n                      op.seqNo = w.deleteDocuments(idTerm);\n                    } else {\n                      op.seqNo = w.deleteDocuments(new TermQuery(idTerm));\n                    }\n                  } else {\n                    Document doc = new Document();\n                    doc.add(new StoredField(\"threadop\", threadID + \"-\" + ops.size()));\n                    doc.add(new StringField(\"id\", \"\" + op.id, Field.Store.NO));\n                    if (random().nextBoolean()) {\n                      List<Document> docs = new ArrayList<>();\n                      docs.add(doc);\n                      op.seqNo = w.addDocuments(docs);\n                    } else {\n                      op.seqNo = w.addDocument(doc);\n                    }\n                    op.what = 3;\n                  }\n                  ops.add(op);\n                }\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[i].setName(\"thread\" + threadID);\n      threads[i].start();\n    }\n    startingGun.countDown();\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    Operation commitOp = new Operation();\n    commitOp.seqNo = w.commit();\n    if (commitOp.seqNo != -1) {\n      commits.add(commitOp);\n    }\n\n    List<IndexCommit> indexCommits = DirectoryReader.listCommits(dir);\n    assertEquals(commits.size(), indexCommits.size());\n\n    // how many docs with this id are expected:\n    int[] expectedCounts = new int[idCount];\n    long[] lastDelSeqNos = new long[idCount];\n      \n    //System.out.println(\"TEST: \" + commits.size() + \" commits\");\n    for(int i=0;i<commits.size();i++) {\n      // this commit point should reflect all operations <= this seqNo\n      long commitSeqNo = commits.get(i).seqNo;\n      //System.out.println(\"  commit \" + i + \": seqNo=\" + commitSeqNo + \" segs=\" + indexCommits.get(i));\n\n      // first find the highest seqNo of the last delete op, for each id, prior to this commit:\n      Arrays.fill(lastDelSeqNos, -1);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        long lastSeqNo = 0;\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 1 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            lastDelSeqNos[op.id] = op.seqNo;\n          }\n\n          // within one thread the seqNos must only increase:\n          assertTrue(op.seqNo > lastSeqNo);\n          lastSeqNo = op.seqNo;\n        }\n      }\n\n      // then count how many adds happened since the last delete and before this commit:\n      Arrays.fill(expectedCounts, 0);\n      for(int threadID=0;threadID<threadOps.size();threadID++) {\n        for(Operation op : threadOps.get(threadID)) {\n          if (op.what == 3 && op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id]) {\n            expectedCounts[op.id]++;\n          }\n        }\n      }\n\n      DirectoryReader r = DirectoryReader.open(indexCommits.get(i));\n      IndexSearcher s = new IndexSearcher(r);\n\n      for(int id=0;id<idCount;id++) {\n        //System.out.println(\"TEST: check id=\" + id + \" expectedThreadID=\" + expectedThreadIDs[id]);\n        int actualCount = s.count(new TermQuery(new Term(\"id\", \"\"+id)));\n        if (expectedCounts[id] != actualCount) {\n          System.out.println(\"TEST: FAIL r=\" + r + \" id=\" + id + \" commitSeqNo=\" + commitSeqNo);\n          for(int threadID=0;threadID<threadOps.size();threadID++) {\n            int opCount2 = 0;\n            for(Operation op : threadOps.get(threadID)) {\n              if (op.id == id) {\n                boolean shouldCount = op.seqNo <= commitSeqNo && op.seqNo > lastDelSeqNos[op.id];\n                System.out.println(\"  id=\" + id + \" what=\" + op.what + \" threadop=\" + threadID + \"-\" + opCount2 + \" seqNo=\" + op.seqNo + \" vs lastDelSeqNo=\" + lastDelSeqNos[op.id] + \" shouldCount=\" + shouldCount);\n              }\n              opCount2++;\n            }\n          }\n          TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1+actualCount);\n          for(ScoreDoc hit : hits.scoreDocs) {\n            System.out.println(\"  hit: \" + s.doc(hit.doc).get(\"threadop\"));\n          }\n\n          for(LeafReaderContext ctx : r.leaves()) {\n            System.out.println(\"  sub=\" + ctx.reader());\n            Bits liveDocs = ctx.reader().getLiveDocs();\n            for(int docID=0;docID<ctx.reader().maxDoc();docID++) {\n              System.out.println(\"    docID=\" + docID + \" threadop=\" + ctx.reader().document(docID).get(\"threadop\") + (liveDocs != null && liveDocs.get(docID) == false ? \" (deleted)\" : \"\"));\n            }\n          }\n\n          assertEquals(\"commit \" + i + \" of \" + commits.size() + \" id=\" + id + \" reader=\" + r, expectedCounts[id], actualCount);\n        }\n      }\n      w.close();\n      r.close();\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["191128ac5b85671b1671e2c857437694283b6ebf","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6483e4260c08168709c02238ae083a51519a28dd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["191128ac5b85671b1671e2c857437694283b6ebf","9dea8da13fd1a227ae1071e8f4ce66bff42174de"],"191128ac5b85671b1671e2c857437694283b6ebf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6483e4260c08168709c02238ae083a51519a28dd"],"9dea8da13fd1a227ae1071e8f4ce66bff42174de":["191128ac5b85671b1671e2c857437694283b6ebf"],"16ebfabc294f23b88b6a39722a02c9d39b353195":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77":["16ebfabc294f23b88b6a39722a02c9d39b353195","122251c49e5a9fa95f056ea257ae3ab452099fc7"],"122251c49e5a9fa95f056ea257ae3ab452099fc7":["16ebfabc294f23b88b6a39722a02c9d39b353195"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"]},"commit2Childs":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6483e4260c08168709c02238ae083a51519a28dd","191128ac5b85671b1671e2c857437694283b6ebf","16ebfabc294f23b88b6a39722a02c9d39b353195","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"6483e4260c08168709c02238ae083a51519a28dd":["191128ac5b85671b1671e2c857437694283b6ebf"],"191128ac5b85671b1671e2c857437694283b6ebf":["403d05f7f8d69b65659157eff1bc1d2717f04c66","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","9dea8da13fd1a227ae1071e8f4ce66bff42174de"],"9dea8da13fd1a227ae1071e8f4ce66bff42174de":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"16ebfabc294f23b88b6a39722a02c9d39b353195":["b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77","122251c49e5a9fa95f056ea257ae3ab452099fc7"],"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77":["6483e4260c08168709c02238ae083a51519a28dd"],"122251c49e5a9fa95f056ea257ae3ab452099fc7":["b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}