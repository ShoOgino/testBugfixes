{"path":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","commits":[{"id":"ddc1ae5ff40afa2c5136ee382632ebe602e050e6","date":1474097671,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n    if (core != null) {\n      try {\n        String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n        if (dirNames == null || dirNames.length == 0) {\n          String[] sources = params.getParams(\"srcCore\");\n          if (sources == null || sources.length == 0)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"At least one indexDir or srcCore must be specified\");\n\n          for (int i = 0; i < sources.length; i++) {\n            String source = sources[i];\n            SolrCore srcCore = it.handler.coreContainer.getCore(source);\n            if (srcCore == null)\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                  \"Core: \" + source + \" does not exist\");\n            sourceCores.add(srcCore);\n          }\n        } else {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          for (int i = 0; i < dirNames.length; i++) {\n            boolean markAsDone = false;\n            if (dirFactory instanceof CachingDirectoryFactory) {\n              if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n                markAsDone = true;\n              }\n            }\n            Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n            dirsToBeReleased.put(dir, markAsDone);\n            // TODO: why doesn't this use the IR factory? what is going on here?\n            readersToBeClosed.add(DirectoryReader.open(dir));\n          }\n        }\n\n        List<DirectoryReader> readers = null;\n        if (readersToBeClosed.size() > 0) {\n          readers = readersToBeClosed;\n        } else {\n          readers = Lists.newArrayList();\n          for (SolrCore solrCore : sourceCores) {\n            // record the searchers so that we can decref\n            RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n            searchers.add(searcher);\n            readers.add(searcher.get().getIndexReader());\n          }\n        }\n\n        UpdateRequestProcessorChain processorChain =\n            core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n        wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n        UpdateRequestProcessor processor =\n            processorChain.createProcessor(wrappedReq, it.rsp);\n        processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n      } catch (Exception e) {\n        // log and rethrow so that if the finally fails we don't lose the original problem\n        log.error(\"ERROR executing merge:\", e);\n        throw e;\n      } finally {\n        for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n          if (searcher != null) searcher.decref();\n        }\n        for (SolrCore solrCore : sourceCores) {\n          if (solrCore != null) solrCore.close();\n        }\n        IOUtils.closeWhileHandlingException(readersToBeClosed);\n        Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n        for (Map.Entry<Directory, Boolean> entry : entries) {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          Directory dir = entry.getKey();\n          boolean markAsDone = entry.getValue();\n          if (markAsDone) {\n            dirFactory.doneWithDirectory(dir);\n          }\n          dirFactory.release(dir);\n        }\n        if (wrappedReq != null) wrappedReq.close();\n        core.close();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["63a1a94d02abb8cde5dd6ea0defbbc751ce71603"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n    if (core != null) {\n      try {\n        String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n        if (dirNames == null || dirNames.length == 0) {\n          String[] sources = params.getParams(\"srcCore\");\n          if (sources == null || sources.length == 0)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"At least one indexDir or srcCore must be specified\");\n\n          for (int i = 0; i < sources.length; i++) {\n            String source = sources[i];\n            SolrCore srcCore = it.handler.coreContainer.getCore(source);\n            if (srcCore == null)\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                  \"Core: \" + source + \" does not exist\");\n            sourceCores.add(srcCore);\n          }\n        } else {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          for (int i = 0; i < dirNames.length; i++) {\n            boolean markAsDone = false;\n            if (dirFactory instanceof CachingDirectoryFactory) {\n              if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n                markAsDone = true;\n              }\n            }\n            Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n            dirsToBeReleased.put(dir, markAsDone);\n            // TODO: why doesn't this use the IR factory? what is going on here?\n            readersToBeClosed.add(DirectoryReader.open(dir));\n          }\n        }\n\n        List<DirectoryReader> readers = null;\n        if (readersToBeClosed.size() > 0) {\n          readers = readersToBeClosed;\n        } else {\n          readers = Lists.newArrayList();\n          for (SolrCore solrCore : sourceCores) {\n            // record the searchers so that we can decref\n            RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n            searchers.add(searcher);\n            readers.add(searcher.get().getIndexReader());\n          }\n        }\n\n        UpdateRequestProcessorChain processorChain =\n            core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n        wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n        UpdateRequestProcessor processor =\n            processorChain.createProcessor(wrappedReq, it.rsp);\n        processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n      } catch (Exception e) {\n        // log and rethrow so that if the finally fails we don't lose the original problem\n        log.error(\"ERROR executing merge:\", e);\n        throw e;\n      } finally {\n        for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n          if (searcher != null) searcher.decref();\n        }\n        for (SolrCore solrCore : sourceCores) {\n          if (solrCore != null) solrCore.close();\n        }\n        IOUtils.closeWhileHandlingException(readersToBeClosed);\n        Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n        for (Map.Entry<Directory, Boolean> entry : entries) {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          Directory dir = entry.getKey();\n          boolean markAsDone = entry.getValue();\n          if (markAsDone) {\n            dirFactory.doneWithDirectory(dir);\n          }\n          dirFactory.release(dir);\n        }\n        if (wrappedReq != null) wrappedReq.close();\n        core.close();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n    if (core != null) {\n      try {\n        String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n        if (dirNames == null || dirNames.length == 0) {\n          String[] sources = params.getParams(\"srcCore\");\n          if (sources == null || sources.length == 0)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"At least one indexDir or srcCore must be specified\");\n\n          for (int i = 0; i < sources.length; i++) {\n            String source = sources[i];\n            SolrCore srcCore = it.handler.coreContainer.getCore(source);\n            if (srcCore == null)\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                  \"Core: \" + source + \" does not exist\");\n            sourceCores.add(srcCore);\n          }\n        } else {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          for (int i = 0; i < dirNames.length; i++) {\n            boolean markAsDone = false;\n            if (dirFactory instanceof CachingDirectoryFactory) {\n              if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n                markAsDone = true;\n              }\n            }\n            Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n            dirsToBeReleased.put(dir, markAsDone);\n            // TODO: why doesn't this use the IR factory? what is going on here?\n            readersToBeClosed.add(DirectoryReader.open(dir));\n          }\n        }\n\n        List<DirectoryReader> readers = null;\n        if (readersToBeClosed.size() > 0) {\n          readers = readersToBeClosed;\n        } else {\n          readers = Lists.newArrayList();\n          for (SolrCore solrCore : sourceCores) {\n            // record the searchers so that we can decref\n            RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n            searchers.add(searcher);\n            readers.add(searcher.get().getIndexReader());\n          }\n        }\n\n        UpdateRequestProcessorChain processorChain =\n            core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n        wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n        UpdateRequestProcessor processor =\n            processorChain.createProcessor(wrappedReq, it.rsp);\n        processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n      } catch (Exception e) {\n        // log and rethrow so that if the finally fails we don't lose the original problem\n        log.error(\"ERROR executing merge:\", e);\n        throw e;\n      } finally {\n        for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n          if (searcher != null) searcher.decref();\n        }\n        for (SolrCore solrCore : sourceCores) {\n          if (solrCore != null) solrCore.close();\n        }\n        IOUtils.closeWhileHandlingException(readersToBeClosed);\n        Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n        for (Map.Entry<Directory, Boolean> entry : entries) {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          Directory dir = entry.getKey();\n          boolean markAsDone = entry.getValue();\n          if (markAsDone) {\n            dirFactory.doneWithDirectory(dir);\n          }\n          dirFactory.release(dir);\n        }\n        if (wrappedReq != null) wrappedReq.close();\n        core.close();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63a1a94d02abb8cde5dd6ea0defbbc751ce71603","date":1521902895,"type":3,"author":"Jason Gerlowski","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","sourceNew":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n    if (core == null) return;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n\n    try {\n      String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n      if (dirNames == null || dirNames.length == 0) {\n        String[] sources = params.getParams(\"srcCore\");\n        if (sources == null || sources.length == 0)\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n              \"At least one indexDir or srcCore must be specified\");\n\n        for (int i = 0; i < sources.length; i++) {\n          String source = sources[i];\n          SolrCore srcCore = it.handler.coreContainer.getCore(source);\n          if (srcCore == null)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"Core: \" + source + \" does not exist\");\n          sourceCores.add(srcCore);\n        }\n      } else {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        for (int i = 0; i < dirNames.length; i++) {\n          boolean markAsDone = false;\n          if (dirFactory instanceof CachingDirectoryFactory) {\n            if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n              markAsDone = true;\n            }\n          }\n          Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n          dirsToBeReleased.put(dir, markAsDone);\n          // TODO: why doesn't this use the IR factory? what is going on here?\n          readersToBeClosed.add(DirectoryReader.open(dir));\n        }\n      }\n\n      List<DirectoryReader> readers = null;\n      if (readersToBeClosed.size() > 0) {\n        readers = readersToBeClosed;\n      } else {\n        readers = Lists.newArrayList();\n        for (SolrCore solrCore : sourceCores) {\n          // record the searchers so that we can decref\n          RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n          searchers.add(searcher);\n          readers.add(searcher.get().getIndexReader());\n        }\n      }\n\n      UpdateRequestProcessorChain processorChain =\n          core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n      wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n      UpdateRequestProcessor processor =\n          processorChain.createProcessor(wrappedReq, it.rsp);\n      processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n    } catch (Exception e) {\n      // log and rethrow so that if the finally fails we don't lose the original problem\n      log.error(\"ERROR executing merge:\", e);\n      throw e;\n    } finally {\n      for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n        if (searcher != null) searcher.decref();\n      }\n      for (SolrCore solrCore : sourceCores) {\n        if (solrCore != null) solrCore.close();\n      }\n      IOUtils.closeWhileHandlingException(readersToBeClosed);\n      Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n      for (Map.Entry<Directory, Boolean> entry : entries) {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        Directory dir = entry.getKey();\n        boolean markAsDone = entry.getValue();\n        if (markAsDone) {\n          dirFactory.doneWithDirectory(dir);\n        }\n        dirFactory.release(dir);\n      }\n      if (wrappedReq != null) wrappedReq.close();\n      core.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n    if (core != null) {\n      try {\n        String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n        if (dirNames == null || dirNames.length == 0) {\n          String[] sources = params.getParams(\"srcCore\");\n          if (sources == null || sources.length == 0)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"At least one indexDir or srcCore must be specified\");\n\n          for (int i = 0; i < sources.length; i++) {\n            String source = sources[i];\n            SolrCore srcCore = it.handler.coreContainer.getCore(source);\n            if (srcCore == null)\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                  \"Core: \" + source + \" does not exist\");\n            sourceCores.add(srcCore);\n          }\n        } else {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          for (int i = 0; i < dirNames.length; i++) {\n            boolean markAsDone = false;\n            if (dirFactory instanceof CachingDirectoryFactory) {\n              if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n                markAsDone = true;\n              }\n            }\n            Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n            dirsToBeReleased.put(dir, markAsDone);\n            // TODO: why doesn't this use the IR factory? what is going on here?\n            readersToBeClosed.add(DirectoryReader.open(dir));\n          }\n        }\n\n        List<DirectoryReader> readers = null;\n        if (readersToBeClosed.size() > 0) {\n          readers = readersToBeClosed;\n        } else {\n          readers = Lists.newArrayList();\n          for (SolrCore solrCore : sourceCores) {\n            // record the searchers so that we can decref\n            RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n            searchers.add(searcher);\n            readers.add(searcher.get().getIndexReader());\n          }\n        }\n\n        UpdateRequestProcessorChain processorChain =\n            core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n        wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n        UpdateRequestProcessor processor =\n            processorChain.createProcessor(wrappedReq, it.rsp);\n        processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n      } catch (Exception e) {\n        // log and rethrow so that if the finally fails we don't lose the original problem\n        log.error(\"ERROR executing merge:\", e);\n        throw e;\n      } finally {\n        for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n          if (searcher != null) searcher.decref();\n        }\n        for (SolrCore solrCore : sourceCores) {\n          if (solrCore != null) solrCore.close();\n        }\n        IOUtils.closeWhileHandlingException(readersToBeClosed);\n        Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n        for (Map.Entry<Directory, Boolean> entry : entries) {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          Directory dir = entry.getKey();\n          boolean markAsDone = entry.getValue();\n          if (markAsDone) {\n            dirFactory.doneWithDirectory(dir);\n          }\n          dirFactory.release(dir);\n        }\n        if (wrappedReq != null) wrappedReq.close();\n        core.close();\n      }\n    }\n  }\n\n","bugFix":["ddc1ae5ff40afa2c5136ee382632ebe602e050e6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3fa95fb629298e03fe5e3d71a0ce792f1256f711","date":1521903809,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","sourceNew":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n    if (core == null) return;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n\n    try {\n      String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n      if (dirNames == null || dirNames.length == 0) {\n        String[] sources = params.getParams(\"srcCore\");\n        if (sources == null || sources.length == 0)\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n              \"At least one indexDir or srcCore must be specified\");\n\n        for (int i = 0; i < sources.length; i++) {\n          String source = sources[i];\n          SolrCore srcCore = it.handler.coreContainer.getCore(source);\n          if (srcCore == null)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"Core: \" + source + \" does not exist\");\n          sourceCores.add(srcCore);\n        }\n      } else {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        for (int i = 0; i < dirNames.length; i++) {\n          boolean markAsDone = false;\n          if (dirFactory instanceof CachingDirectoryFactory) {\n            if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n              markAsDone = true;\n            }\n          }\n          Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n          dirsToBeReleased.put(dir, markAsDone);\n          // TODO: why doesn't this use the IR factory? what is going on here?\n          readersToBeClosed.add(DirectoryReader.open(dir));\n        }\n      }\n\n      List<DirectoryReader> readers = null;\n      if (readersToBeClosed.size() > 0) {\n        readers = readersToBeClosed;\n      } else {\n        readers = Lists.newArrayList();\n        for (SolrCore solrCore : sourceCores) {\n          // record the searchers so that we can decref\n          RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n          searchers.add(searcher);\n          readers.add(searcher.get().getIndexReader());\n        }\n      }\n\n      UpdateRequestProcessorChain processorChain =\n          core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n      wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n      UpdateRequestProcessor processor =\n          processorChain.createProcessor(wrappedReq, it.rsp);\n      processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n    } catch (Exception e) {\n      // log and rethrow so that if the finally fails we don't lose the original problem\n      log.error(\"ERROR executing merge:\", e);\n      throw e;\n    } finally {\n      for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n        if (searcher != null) searcher.decref();\n      }\n      for (SolrCore solrCore : sourceCores) {\n        if (solrCore != null) solrCore.close();\n      }\n      IOUtils.closeWhileHandlingException(readersToBeClosed);\n      Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n      for (Map.Entry<Directory, Boolean> entry : entries) {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        Directory dir = entry.getKey();\n        boolean markAsDone = entry.getValue();\n        if (markAsDone) {\n          dirFactory.doneWithDirectory(dir);\n        }\n        dirFactory.release(dir);\n      }\n      if (wrappedReq != null) wrappedReq.close();\n      core.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n    if (core != null) {\n      try {\n        String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n        if (dirNames == null || dirNames.length == 0) {\n          String[] sources = params.getParams(\"srcCore\");\n          if (sources == null || sources.length == 0)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"At least one indexDir or srcCore must be specified\");\n\n          for (int i = 0; i < sources.length; i++) {\n            String source = sources[i];\n            SolrCore srcCore = it.handler.coreContainer.getCore(source);\n            if (srcCore == null)\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                  \"Core: \" + source + \" does not exist\");\n            sourceCores.add(srcCore);\n          }\n        } else {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          for (int i = 0; i < dirNames.length; i++) {\n            boolean markAsDone = false;\n            if (dirFactory instanceof CachingDirectoryFactory) {\n              if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n                markAsDone = true;\n              }\n            }\n            Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n            dirsToBeReleased.put(dir, markAsDone);\n            // TODO: why doesn't this use the IR factory? what is going on here?\n            readersToBeClosed.add(DirectoryReader.open(dir));\n          }\n        }\n\n        List<DirectoryReader> readers = null;\n        if (readersToBeClosed.size() > 0) {\n          readers = readersToBeClosed;\n        } else {\n          readers = Lists.newArrayList();\n          for (SolrCore solrCore : sourceCores) {\n            // record the searchers so that we can decref\n            RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n            searchers.add(searcher);\n            readers.add(searcher.get().getIndexReader());\n          }\n        }\n\n        UpdateRequestProcessorChain processorChain =\n            core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n        wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n        UpdateRequestProcessor processor =\n            processorChain.createProcessor(wrappedReq, it.rsp);\n        processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n      } catch (Exception e) {\n        // log and rethrow so that if the finally fails we don't lose the original problem\n        log.error(\"ERROR executing merge:\", e);\n        throw e;\n      } finally {\n        for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n          if (searcher != null) searcher.decref();\n        }\n        for (SolrCore solrCore : sourceCores) {\n          if (solrCore != null) solrCore.close();\n        }\n        IOUtils.closeWhileHandlingException(readersToBeClosed);\n        Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n        for (Map.Entry<Directory, Boolean> entry : entries) {\n          DirectoryFactory dirFactory = core.getDirectoryFactory();\n          Directory dir = entry.getKey();\n          boolean markAsDone = entry.getValue();\n          if (markAsDone) {\n            dirFactory.doneWithDirectory(dir);\n          }\n          dirFactory.release(dir);\n        }\n        if (wrappedReq != null) wrappedReq.close();\n        core.close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6b17e67903ace8abb1d4d602bfc40d1994692ff","date":1593429504,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/MergeIndexesOp#execute(CoreAdminHandler.CallInfo).mjava","sourceNew":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n    if (core == null) return;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n\n    try {\n      String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n      if (dirNames == null || dirNames.length == 0) {\n        String[] sources = params.getParams(\"srcCore\");\n        if (sources == null || sources.length == 0)\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n              \"At least one indexDir or srcCore must be specified\");\n\n        for (int i = 0; i < sources.length; i++) {\n          String source = sources[i];\n          SolrCore srcCore = it.handler.coreContainer.getCore(source);\n          if (srcCore == null)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"Core: \" + source + \" does not exist\");\n          sourceCores.add(srcCore);\n        }\n      } else {\n        // Validate each 'indexDir' input as valid\n        Arrays.stream(dirNames).forEach(indexDir -> core.getCoreContainer().assertPathAllowed(Paths.get(indexDir)));\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        for (int i = 0; i < dirNames.length; i++) {\n          boolean markAsDone = false;\n          if (dirFactory instanceof CachingDirectoryFactory) {\n            if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n              markAsDone = true;\n            }\n          }\n          Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n          dirsToBeReleased.put(dir, markAsDone);\n          // TODO: why doesn't this use the IR factory? what is going on here?\n          readersToBeClosed.add(DirectoryReader.open(dir));\n        }\n      }\n\n      List<DirectoryReader> readers = null;\n      if (readersToBeClosed.size() > 0) {\n        readers = readersToBeClosed;\n      } else {\n        readers = Lists.newArrayList();\n        for (SolrCore solrCore : sourceCores) {\n          // record the searchers so that we can decref\n          RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n          searchers.add(searcher);\n          readers.add(searcher.get().getIndexReader());\n        }\n      }\n\n      UpdateRequestProcessorChain processorChain =\n          core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n      wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n      UpdateRequestProcessor processor =\n          processorChain.createProcessor(wrappedReq, it.rsp);\n      processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n    } catch (Exception e) {\n      // log and rethrow so that if the finally fails we don't lose the original problem\n      log.error(\"ERROR executing merge:\", e);\n      throw e;\n    } finally {\n      for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n        if (searcher != null) searcher.decref();\n      }\n      for (SolrCore solrCore : sourceCores) {\n        if (solrCore != null) solrCore.close();\n      }\n      IOUtils.closeWhileHandlingException(readersToBeClosed);\n      Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n      for (Map.Entry<Directory, Boolean> entry : entries) {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        Directory dir = entry.getKey();\n        boolean markAsDone = entry.getValue();\n        if (markAsDone) {\n          dirFactory.doneWithDirectory(dir);\n        }\n        dirFactory.release(dir);\n      }\n      if (wrappedReq != null) wrappedReq.close();\n      core.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void execute(CoreAdminHandler.CallInfo it) throws Exception {\n    SolrParams params = it.req.getParams();\n    String cname = params.required().get(CoreAdminParams.CORE);\n    SolrCore core = it.handler.coreContainer.getCore(cname);\n    SolrQueryRequest wrappedReq = null;\n    if (core == null) return;\n\n    List<SolrCore> sourceCores = Lists.newArrayList();\n    List<RefCounted<SolrIndexSearcher>> searchers = Lists.newArrayList();\n    // stores readers created from indexDir param values\n    List<DirectoryReader> readersToBeClosed = Lists.newArrayList();\n    Map<Directory, Boolean> dirsToBeReleased = new HashMap<>();\n\n    try {\n      String[] dirNames = params.getParams(CoreAdminParams.INDEX_DIR);\n      if (dirNames == null || dirNames.length == 0) {\n        String[] sources = params.getParams(\"srcCore\");\n        if (sources == null || sources.length == 0)\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n              \"At least one indexDir or srcCore must be specified\");\n\n        for (int i = 0; i < sources.length; i++) {\n          String source = sources[i];\n          SolrCore srcCore = it.handler.coreContainer.getCore(source);\n          if (srcCore == null)\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                \"Core: \" + source + \" does not exist\");\n          sourceCores.add(srcCore);\n        }\n      } else {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        for (int i = 0; i < dirNames.length; i++) {\n          boolean markAsDone = false;\n          if (dirFactory instanceof CachingDirectoryFactory) {\n            if (!((CachingDirectoryFactory) dirFactory).getLivePaths().contains(dirNames[i])) {\n              markAsDone = true;\n            }\n          }\n          Directory dir = dirFactory.get(dirNames[i], DirectoryFactory.DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n          dirsToBeReleased.put(dir, markAsDone);\n          // TODO: why doesn't this use the IR factory? what is going on here?\n          readersToBeClosed.add(DirectoryReader.open(dir));\n        }\n      }\n\n      List<DirectoryReader> readers = null;\n      if (readersToBeClosed.size() > 0) {\n        readers = readersToBeClosed;\n      } else {\n        readers = Lists.newArrayList();\n        for (SolrCore solrCore : sourceCores) {\n          // record the searchers so that we can decref\n          RefCounted<SolrIndexSearcher> searcher = solrCore.getSearcher();\n          searchers.add(searcher);\n          readers.add(searcher.get().getIndexReader());\n        }\n      }\n\n      UpdateRequestProcessorChain processorChain =\n          core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_CHAIN));\n      wrappedReq = new LocalSolrQueryRequest(core, it.req.getParams());\n      UpdateRequestProcessor processor =\n          processorChain.createProcessor(wrappedReq, it.rsp);\n      processor.processMergeIndexes(new MergeIndexesCommand(readers, it.req));\n    } catch (Exception e) {\n      // log and rethrow so that if the finally fails we don't lose the original problem\n      log.error(\"ERROR executing merge:\", e);\n      throw e;\n    } finally {\n      for (RefCounted<SolrIndexSearcher> searcher : searchers) {\n        if (searcher != null) searcher.decref();\n      }\n      for (SolrCore solrCore : sourceCores) {\n        if (solrCore != null) solrCore.close();\n      }\n      IOUtils.closeWhileHandlingException(readersToBeClosed);\n      Set<Map.Entry<Directory, Boolean>> entries = dirsToBeReleased.entrySet();\n      for (Map.Entry<Directory, Boolean> entry : entries) {\n        DirectoryFactory dirFactory = core.getDirectoryFactory();\n        Directory dir = entry.getKey();\n        boolean markAsDone = entry.getValue();\n        if (markAsDone) {\n          dirFactory.doneWithDirectory(dir);\n        }\n        dirFactory.release(dir);\n      }\n      if (wrappedReq != null) wrappedReq.close();\n      core.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a6b17e67903ace8abb1d4d602bfc40d1994692ff":["3fa95fb629298e03fe5e3d71a0ce792f1256f711"],"ddc1ae5ff40afa2c5136ee382632ebe602e050e6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3fa95fb629298e03fe5e3d71a0ce792f1256f711":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","63a1a94d02abb8cde5dd6ea0defbbc751ce71603"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ddc1ae5ff40afa2c5136ee382632ebe602e050e6"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a6b17e67903ace8abb1d4d602bfc40d1994692ff"],"63a1a94d02abb8cde5dd6ea0defbbc751ce71603":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"]},"commit2Childs":{"a6b17e67903ace8abb1d4d602bfc40d1994692ff":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ddc1ae5ff40afa2c5136ee382632ebe602e050e6":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"3fa95fb629298e03fe5e3d71a0ce792f1256f711":["a6b17e67903ace8abb1d4d602bfc40d1994692ff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ddc1ae5ff40afa2c5136ee382632ebe602e050e6","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["3fa95fb629298e03fe5e3d71a0ce792f1256f711","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","63a1a94d02abb8cde5dd6ea0defbbc751ce71603"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"63a1a94d02abb8cde5dd6ea0defbbc751ce71603":["3fa95fb629298e03fe5e3d71a0ce792f1256f711"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}