{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7523dd562634d9145b67eb4c8b3b3db2340532b","date":1330467618,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd659803551ebd8ca09b9e4ad7abd18d3d558f9d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cd659803551ebd8ca09b9e4ad7abd18d3d558f9d","date":1336650316,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","fa0f44f887719e97183771e977cfc4bfb485b766"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ecb9a70c11e1f9dea44bb46bc2f75ed0c2603b57","date":1338306244,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":["5eae7c5ddae4b9692a6691d2d252ab6a4229457b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":["5eae7c5ddae4b9692a6691d2d252ab6a4229457b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddadc5a8439c906a65bfba5ce15166b5d5b58d82","date":1358287870,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n      DocValuesType type = DocValuesType.SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef();\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      SortedDocValues docValues = MultiSimpleDocValues.simpleSortedValues(reader, \"field\");\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), docValues.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        docValues.lookupOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = docValues.lookupTerm(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        docValues.get(docId, actual);\n        assertEquals(expected, actual);\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200","date":1358521790,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n      DocValuesType type = DocValuesType.SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef();\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      SortedDocValues docValues = MultiDocValues.getSortedValues(reader, \"field\");\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), docValues.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        docValues.lookupOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = docValues.lookupTerm(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        docValues.get(docId, actual);\n        assertEquals(expected, actual);\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n      DocValuesType type = DocValuesType.SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef();\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      SortedDocValues docValues = MultiSimpleDocValues.simpleSortedValues(reader, \"field\");\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), docValues.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        docValues.lookupOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = docValues.lookupTerm(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        docValues.get(docId, actual);\n        assertEquals(expected, actual);\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"423d89a2b3cc419b647c07c2b3fdbc54311d07f9","date":1358836612,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n      DocValuesType type = DocValuesType.SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedDocValuesField(\"field\", br));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef();\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedDocValuesField(\"field\", br));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      SortedDocValues docValues = MultiDocValues.getSortedValues(reader, \"field\");\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), docValues.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        docValues.lookupOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = docValues.lookupTerm(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        docValues.get(docId, actual);\n        assertEquals(expected, actual);\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n      DocValuesType type = DocValuesType.SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef();\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      SortedDocValues docValues = MultiDocValues.getSortedValues(reader, \"field\");\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), docValues.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        docValues.lookupOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = docValues.lookupTerm(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        docValues.get(docId, actual);\n        assertEquals(expected, actual);\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17c1f75cbc80446a0380e76b64210cdf8e3858d7","date":1359394908,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":null,"sourceOld":"  public void testSortedBytes() throws IOException {\n      DocValuesType type = DocValuesType.SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedDocValuesField(\"field\", br));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef();\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedDocValuesField(\"field\", br));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      SortedDocValues docValues = MultiDocValues.getSortedValues(reader, \"field\");\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), docValues.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        docValues.lookupOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = docValues.lookupTerm(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        docValues.get(docId, actual);\n        assertEquals(expected, actual);\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":null,"sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random()));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random().nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"\" + i, Field.Store.YES));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newTextField(\"id\", \"noValue\", Field.Store.YES));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newTextField(\"id\", id, Field.Store.YES));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random(),\n            len) : _TestUtil.randomRealisticUnicodeString(random(), 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add(new SortedBytesDocValuesField(\"field\", br, type == Type.BYTES_FIXED_SORTED));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getOrdByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected = new BytesRef(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"17c1f75cbc80446a0380e76b64210cdf8e3858d7":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","b7523dd562634d9145b67eb4c8b3b3db2340532b"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["ecb9a70c11e1f9dea44bb46bc2f75ed0c2603b57"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["ddadc5a8439c906a65bfba5ce15166b5d5b58d82"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["04f07771a2a7dd3a395700665ed839c3dae2def2","17c1f75cbc80446a0380e76b64210cdf8e3858d7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b7523dd562634d9145b67eb4c8b3b3db2340532b"],"b7523dd562634d9145b67eb4c8b3b3db2340532b":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"ecb9a70c11e1f9dea44bb46bc2f75ed0c2603b57":["cd659803551ebd8ca09b9e4ad7abd18d3d558f9d"],"cd659803551ebd8ca09b9e4ad7abd18d3d558f9d":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"ddadc5a8439c906a65bfba5ce15166b5d5b58d82":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"]},"commit2Childs":{"17c1f75cbc80446a0380e76b64210cdf8e3858d7":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7523dd562634d9145b67eb4c8b3b3db2340532b"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["d4d69c535930b5cce125cff868d40f6373dc27d4","ddadc5a8439c906a65bfba5ce15166b5d5b58d82"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["17c1f75cbc80446a0380e76b64210cdf8e3858d7"],"b7523dd562634d9145b67eb4c8b3b3db2340532b":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["cd659803551ebd8ca09b9e4ad7abd18d3d558f9d"],"ecb9a70c11e1f9dea44bb46bc2f75ed0c2603b57":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"ddadc5a8439c906a65bfba5ce15166b5d5b58d82":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"cd659803551ebd8ca09b9e4ad7abd18d3d558f9d":["ecb9a70c11e1f9dea44bb46bc2f75ed0c2603b57"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}