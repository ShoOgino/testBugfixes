{"path":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","commits":[{"id":"f20bb72b0dfa147c6f1fcd7693102c63a2714eae","date":1303767270,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0663cc678850ea2c51151f9fd217342ea35b8568","date":1303828523,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21486a8058ee8d7503c7d7a5e55b6c3a218d0942","date":1303841712,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a405e749df166cf8c456ac9381f77f6c99a6270","date":1303842176,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8f944ac3fe3f9d40d825177507fb381d2b106b3","date":1303868525,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d5df8e07c035d62d982894b439322da40e0938","date":1303923139,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"/dev/null","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"843b845d397272dbafe8b80ebb8f9336d94568ef","date":1305726695,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"/dev/null","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term())));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.liveDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = upto==0 ? DocSet.EMPTY : new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d4d5df8e07c035d62d982894b439322da40e0938":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"7a405e749df166cf8c456ac9381f77f6c99a6270":["21486a8058ee8d7503c7d7a5e55b6c3a218d0942"],"f20bb72b0dfa147c6f1fcd7693102c63a2714eae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["843b845d397272dbafe8b80ebb8f9336d94568ef"],"c26f00b574427b55127e869b935845554afde1fa":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"0663cc678850ea2c51151f9fd217342ea35b8568":["f20bb72b0dfa147c6f1fcd7693102c63a2714eae"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"f8f944ac3fe3f9d40d825177507fb381d2b106b3":["7a405e749df166cf8c456ac9381f77f6c99a6270"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["843b845d397272dbafe8b80ebb8f9336d94568ef","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["135621f3a0670a9394eb563224a3b76cc4dddc0f","843b845d397272dbafe8b80ebb8f9336d94568ef"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","843b845d397272dbafe8b80ebb8f9336d94568ef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"843b845d397272dbafe8b80ebb8f9336d94568ef":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"21486a8058ee8d7503c7d7a5e55b6c3a218d0942":["0663cc678850ea2c51151f9fd217342ea35b8568"]},"commit2Childs":{"d4d5df8e07c035d62d982894b439322da40e0938":[],"7a405e749df166cf8c456ac9381f77f6c99a6270":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"f20bb72b0dfa147c6f1fcd7693102c63a2714eae":["0663cc678850ea2c51151f9fd217342ea35b8568"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["c26f00b574427b55127e869b935845554afde1fa","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","a258fbb26824fd104ed795e5d9033d2d040049ee"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"0663cc678850ea2c51151f9fd217342ea35b8568":["21486a8058ee8d7503c7d7a5e55b6c3a218d0942"],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"f8f944ac3fe3f9d40d825177507fb381d2b106b3":["d4d5df8e07c035d62d982894b439322da40e0938","135621f3a0670a9394eb563224a3b76cc4dddc0f","843b845d397272dbafe8b80ebb8f9336d94568ef"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d4d5df8e07c035d62d982894b439322da40e0938","f20bb72b0dfa147c6f1fcd7693102c63a2714eae","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"843b845d397272dbafe8b80ebb8f9336d94568ef":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","d083e83f225b11e5fdd900e83d26ddb385b6955c","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233"],"21486a8058ee8d7503c7d7a5e55b6c3a218d0942":["7a405e749df166cf8c456ac9381f77f6c99a6270"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d4d5df8e07c035d62d982894b439322da40e0938","d083e83f225b11e5fdd900e83d26ddb385b6955c","c3a8a449466c1ff7ce2274fe73dab487256964b4","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}