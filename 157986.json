{"path":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","commits":[{"id":"6620df8541b174097b1133a4fc370adb2e570524","date":1319544675,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final IndexReader.AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        IndexReader reader = context.reader;\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96d207426bd26fa5c1014e26d21d87603aea68b7","date":1327944562,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        IndexReader reader = context.reader();\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final IndexReader.AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        IndexReader reader = context.reader;\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        IndexReader reader = context.reader();\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final IndexReader.AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        IndexReader reader = context.reader;\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8e5663809fccfda938d8d46f0106a5301cdd5cf0","date":1328146670,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        IndexReader reader = context.reader();\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":["96d207426bd26fa5c1014e26d21d87603aea68b7","6620df8541b174097b1133a4fc370adb2e570524"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() throws IOException {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() throws IOException {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) throws IOException {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() throws IOException {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a","date":1363294103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it\n                if (size != -1) {\n                  return size;\n                } else {\n                  return bs.capacity();\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bde94df914e38596e2ce6907c04bcca8925e19","date":1385775146,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((OpenBitSet.bits2words(maxDoc)<<6) / (float)bs.capacity()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it\n                if (size != -1) {\n                  return size;\n                } else {\n                  return bs.capacity();\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((OpenBitSet.bits2words(maxDoc)<<6) / (float)bs.capacity()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it\n                if (size != -1) {\n                  return size;\n                } else {\n                  return bs.capacity();\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a69cf7f1b4cac5d5b1363402b565cd535f13e6a1","date":1392536197,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final OpenBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos=base-1;\n              int adjustedDoc=-1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                pos = bs.nextSetBit(pos+1);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target==NO_MORE_DOCS) return adjustedDoc=NO_MORE_DOCS;\n                pos = bs.nextSetBit(target+base);\n                return adjustedDoc = (pos>=0 && pos<max) ? pos-base : NO_MORE_DOCS;\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((OpenBitSet.bits2words(maxDoc)<<6) / (float)bs.capacity()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.fastGet(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453","date":1402659583,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final AtomicReaderContext context, final Bits acceptDocs) {\n        AtomicReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80c55596a764e2d397e982828e75fcac5ce430a0","date":1413987559,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new FixedBitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(bs, acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0abcec02c9851c46c70a75bd42fb6e4d5348ac9e","date":1414135939,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new FixedBitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = (pos >= 0 && pos < max) ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if its already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6","date":1424027250,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60596f28be69b10c37a56a303c2dbea07b2ca4ba","date":1425060541,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public boolean isCacheable() {\n            return true;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16b25963ad38ed289ebf0f7af31269fa1ce80a11","date":1442083896,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int max = base + reader.maxDoc();   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                int next = pos+1;\n                if (next >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(next);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                int maxDoc = max-base;\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return max-base;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int maxDoc = reader.maxDoc();\n        final int max = base + maxDoc;   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                if (pos >= bs.length() - 1) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(pos + 1);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= bs.length()) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return maxDoc;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7bc21595222ae4f75509300fbb7726691f387f","date":1464078795,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      final FixedBitSet bs = bits;\n\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int max = base + reader.maxDoc();   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                int next = pos+1;\n                if (next >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(next);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                int maxDoc = max-base;\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return max-base;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n\n      @Override\n      public boolean equals(Object other) {\n        return sameClassAs(other) &&\n               Objects.equals(bs, getClass().cast(other).bs);\n      }\n      \n      @Override\n      public int hashCode() {\n        return classHash() * 31 + bs.hashCode();\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int max = base + reader.maxDoc();   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                int next = pos+1;\n                if (next >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(next);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                int maxDoc = max-base;\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return max-base;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/BitDocSet#getTopFilter().mjava","sourceNew":"  @Override\n  public Filter getTopFilter() {\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      final FixedBitSet bs = bits;\n\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int max = base + reader.maxDoc();   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                int next = pos+1;\n                if (next >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(next);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                int maxDoc = max-base;\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return max-base;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n\n      @Override\n      public boolean equals(Object other) {\n        return sameClassAs(other) &&\n               Objects.equals(bs, getClass().cast(other).bs);\n      }\n      \n      @Override\n      public int hashCode() {\n        return classHash() * 31 + bs.hashCode();\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Filter getTopFilter() {\n    final FixedBitSet bs = bits;\n    // TODO: if cardinality isn't cached, do a quick measure of sparseness\n    // and return null from bits() if too sparse.\n\n    return new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) {\n        LeafReader reader = context.reader();\n        // all Solr DocSets that are used as filters only include live docs\n        final Bits acceptDocs2 = acceptDocs == null ? null : (reader.getLiveDocs() == acceptDocs ? null : acceptDocs);\n\n        if (context.isTopLevel) {\n          return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bs), acceptDocs);\n        }\n\n        final int base = context.docBase;\n        final int max = base + reader.maxDoc();   // one past the max doc in this segment.\n\n        return BitsFilteredDocIdSet.wrap(new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return new DocIdSetIterator() {\n              int pos = base - 1;\n              int adjustedDoc = -1;\n\n              @Override\n              public int docID() {\n                return adjustedDoc;\n              }\n\n              @Override\n              public int nextDoc() {\n                int next = pos+1;\n                if (next >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(next);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public int advance(int target) {\n                if (target == NO_MORE_DOCS) return adjustedDoc = NO_MORE_DOCS;\n                int adjusted = target + base;\n                if (adjusted >= max) {\n                  return adjustedDoc = NO_MORE_DOCS;\n                } else {\n                  pos = bs.nextSetBit(adjusted);\n                  return adjustedDoc = pos < max ? pos - base : NO_MORE_DOCS;\n                }\n              }\n\n              @Override\n              public long cost() {\n                // we don't want to actually compute cardinality, but\n                // if it's already been computed, we use it (pro-rated for the segment)\n                int maxDoc = max-base;\n                if (size != -1) {\n                  return (long)(size * ((FixedBitSet.bits2words(maxDoc)<<6) / (float)bs.length()));\n                } else {\n                  return maxDoc;\n                }\n              }\n            };\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return bs.ramBytesUsed();\n          }\n\n          @Override\n          public Bits bits() {\n            return new Bits() {\n              @Override\n              public boolean get(int index) {\n                return bs.get(index + base);\n              }\n\n              @Override\n              public int length() {\n                return max-base;\n              }\n            };\n          }\n\n        }, acceptDocs2);\n      }\n      @Override\n      public String toString(String field) {\n        return \"BitSetDocTopFilter\";\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"16b25963ad38ed289ebf0f7af31269fa1ce80a11":["60596f28be69b10c37a56a303c2dbea07b2ca4ba"],"6620df8541b174097b1133a4fc370adb2e570524":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453":["a69cf7f1b4cac5d5b1363402b565cd535f13e6a1"],"60596f28be69b10c37a56a303c2dbea07b2ca4ba":["fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6"],"8e5663809fccfda938d8d46f0106a5301cdd5cf0":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"96d207426bd26fa5c1014e26d21d87603aea68b7":["6620df8541b174097b1133a4fc370adb2e570524"],"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["a69cf7f1b4cac5d5b1363402b565cd535f13e6a1","54ea8c8c94ae9da9a366175e2abbe1dde3aa0453"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["54ea8c8c94ae9da9a366175e2abbe1dde3aa0453"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["6620df8541b174097b1133a4fc370adb2e570524","96d207426bd26fa5c1014e26d21d87603aea68b7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["16b25963ad38ed289ebf0f7af31269fa1ce80a11","0e7bc21595222ae4f75509300fbb7726691f387f"],"c7bde94df914e38596e2ce6907c04bcca8925e19":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6","60596f28be69b10c37a56a303c2dbea07b2ca4ba"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["0abcec02c9851c46c70a75bd42fb6e4d5348ac9e"],"a69cf7f1b4cac5d5b1363402b565cd535f13e6a1":["c7bde94df914e38596e2ce6907c04bcca8925e19"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["8e5663809fccfda938d8d46f0106a5301cdd5cf0","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0e7bc21595222ae4f75509300fbb7726691f387f":["16b25963ad38ed289ebf0f7af31269fa1ce80a11"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a","c7bde94df914e38596e2ce6907c04bcca8925e19"],"80c55596a764e2d397e982828e75fcac5ce430a0":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["8e5663809fccfda938d8d46f0106a5301cdd5cf0"],"0abcec02c9851c46c70a75bd42fb6e4d5348ac9e":["80c55596a764e2d397e982828e75fcac5ce430a0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0e7bc21595222ae4f75509300fbb7726691f387f"]},"commit2Childs":{"16b25963ad38ed289ebf0f7af31269fa1ce80a11":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","0e7bc21595222ae4f75509300fbb7726691f387f"],"6620df8541b174097b1133a4fc370adb2e570524":["96d207426bd26fa5c1014e26d21d87603aea68b7","5cab9a86bd67202d20b6adc463008c8e982b070a"],"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","c9fb5f46e264daf5ba3860defe623a89d202dd87"],"60596f28be69b10c37a56a303c2dbea07b2ca4ba":["16b25963ad38ed289ebf0f7af31269fa1ce80a11","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"8e5663809fccfda938d8d46f0106a5301cdd5cf0":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"96d207426bd26fa5c1014e26d21d87603aea68b7":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a":["c7bde94df914e38596e2ce6907c04bcca8925e19","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["8e5663809fccfda938d8d46f0106a5301cdd5cf0"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["80c55596a764e2d397e982828e75fcac5ce430a0"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"c7bde94df914e38596e2ce6907c04bcca8925e19":["a69cf7f1b4cac5d5b1363402b565cd535f13e6a1","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6":["60596f28be69b10c37a56a303c2dbea07b2ca4ba","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6"],"a69cf7f1b4cac5d5b1363402b565cd535f13e6a1":["54ea8c8c94ae9da9a366175e2abbe1dde3aa0453","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6620df8541b174097b1133a4fc370adb2e570524"],"0e7bc21595222ae4f75509300fbb7726691f387f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"80c55596a764e2d397e982828e75fcac5ce430a0":["0abcec02c9851c46c70a75bd42fb6e4d5348ac9e"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"0abcec02c9851c46c70a75bd42fb6e4d5348ac9e":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","fe33227f6805edab2036cbb80645cc4e2d1fa424","74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}