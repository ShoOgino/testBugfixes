{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","commits":[{"id":"ee59f646cf24586a449cad77391a60a3ac8d8959","date":1408015131,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cefe924a3b76c22b7df9a075329750871699af6b","date":1409757963,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"949847c0040cd70a68222d526cb0da7bf6cbb3c2","date":1410997182,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        tragicEvent(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","date":1414017220,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        tragicEvent(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        tragicEvent(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        tragicEvent(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["c48871ed951104729f5e17a8ee1091b43fa18980"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"901d103ab7c2eeae92b111fc91bb1b00580a3fd7","date":1422827173,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["f241b963c5bcd6c2293a928059dd2d64988a6042"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fba839b7548159227edcb740033d0f814b323d8d","date":1424455904,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["71e1a70f18d64b93db3ef618e606d6df5062f747"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b869e42fbd9c52c4728652ba51faf7266b239a6f","date":1428140988,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f695337371af9f2554c2d7ecc301f4306bd864b","date":1433621466,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c48871ed951104729f5e17a8ee1091b43fa18980","date":1446564542,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | OutOfMemoryError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f492fe129985750df09c8dac738aecc503158bb3","date":1464099630,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        return seqNo;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9972d96003bc59c07a44e73de3cdd505dc08fd17","date":1464216081,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        return seqNo;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6483e4260c08168709c02238ae083a51519a28dd","date":1465117546,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"71e1a70f18d64b93db3ef618e606d6df5062f747","date":1466156390,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["fba839b7548159227edcb740033d0f814b323d8d"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddaef9c801f985de924507f0cceea9786b55ac1f","date":1481326890,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b869e42fbd9c52c4728652ba51faf7266b239a6f":["fba839b7548159227edcb740033d0f814b323d8d"],"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"71e1a70f18d64b93db3ef618e606d6df5062f747":["191128ac5b85671b1671e2c857437694283b6ebf"],"cefe924a3b76c22b7df9a075329750871699af6b":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"fba839b7548159227edcb740033d0f814b323d8d":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6483e4260c08168709c02238ae083a51519a28dd":["c48871ed951104729f5e17a8ee1091b43fa18980","9972d96003bc59c07a44e73de3cdd505dc08fd17"],"ddaef9c801f985de924507f0cceea9786b55ac1f":["71e1a70f18d64b93db3ef618e606d6df5062f747"],"191128ac5b85671b1671e2c857437694283b6ebf":["c48871ed951104729f5e17a8ee1091b43fa18980","6483e4260c08168709c02238ae083a51519a28dd"],"901d103ab7c2eeae92b111fc91bb1b00580a3fd7":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["c48871ed951104729f5e17a8ee1091b43fa18980","71e1a70f18d64b93db3ef618e606d6df5062f747"],"c48871ed951104729f5e17a8ee1091b43fa18980":["4f695337371af9f2554c2d7ecc301f4306bd864b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f492fe129985750df09c8dac738aecc503158bb3":["c48871ed951104729f5e17a8ee1091b43fa18980"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4"],"9856095f7afb5a607bf5e65077615ed91273508c":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","ddaef9c801f985de924507f0cceea9786b55ac1f"],"9972d96003bc59c07a44e73de3cdd505dc08fd17":["f492fe129985750df09c8dac738aecc503158bb3"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["cefe924a3b76c22b7df9a075329750871699af6b"],"4f695337371af9f2554c2d7ecc301f4306bd864b":["b869e42fbd9c52c4728652ba51faf7266b239a6f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ddaef9c801f985de924507f0cceea9786b55ac1f"]},"commit2Childs":{"b869e42fbd9c52c4728652ba51faf7266b239a6f":["4f695337371af9f2554c2d7ecc301f4306bd864b"],"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"71e1a70f18d64b93db3ef618e606d6df5062f747":["ddaef9c801f985de924507f0cceea9786b55ac1f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cefe924a3b76c22b7df9a075329750871699af6b":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"fba839b7548159227edcb740033d0f814b323d8d":["b869e42fbd9c52c4728652ba51faf7266b239a6f"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["cefe924a3b76c22b7df9a075329750871699af6b"],"6483e4260c08168709c02238ae083a51519a28dd":["191128ac5b85671b1671e2c857437694283b6ebf"],"191128ac5b85671b1671e2c857437694283b6ebf":["71e1a70f18d64b93db3ef618e606d6df5062f747"],"ddaef9c801f985de924507f0cceea9786b55ac1f":["9856095f7afb5a607bf5e65077615ed91273508c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"901d103ab7c2eeae92b111fc91bb1b00580a3fd7":["fba839b7548159227edcb740033d0f814b323d8d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["9856095f7afb5a607bf5e65077615ed91273508c"],"c48871ed951104729f5e17a8ee1091b43fa18980":["6483e4260c08168709c02238ae083a51519a28dd","191128ac5b85671b1671e2c857437694283b6ebf","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f492fe129985750df09c8dac738aecc503158bb3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"f492fe129985750df09c8dac738aecc503158bb3":["9972d96003bc59c07a44e73de3cdd505dc08fd17"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"9972d96003bc59c07a44e73de3cdd505dc08fd17":["6483e4260c08168709c02238ae083a51519a28dd"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4"],"4f695337371af9f2554c2d7ecc301f4306bd864b":["c48871ed951104729f5e17a8ee1091b43fa18980"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9856095f7afb5a607bf5e65077615ed91273508c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}