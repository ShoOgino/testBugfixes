{"path":"src/java/org/apache/solr/util/MultiValueTokenStream[SolrPluginUtils]#next().mjava","commits":[{"id":"0452863ee588101738d341e6e97eb87eb010052a","date":1152814944,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/util/MultiValueTokenStream[SolrPluginUtils]#next().mjava","pathOld":"/dev/null","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09b389e81c6f6d4cd07c05a8189081bc814b01ce","date":1152976365,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/util/MultiValueTokenStream[SolrPluginUtils]#next().mjava","pathOld":"src/java/org/apache/solr/util/MultiValueTokenStream[SolrPluginUtils]#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"090f8d702b753c18c64a6fd5fb550596c68861ce","date":1172108327,"type":5,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","pathOld":"src/java/org/apache/solr/util/MultiValueTokenStream[SolrPluginUtils]#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"09b389e81c6f6d4cd07c05a8189081bc814b01ce":["0452863ee588101738d341e6e97eb87eb010052a"],"0452863ee588101738d341e6e97eb87eb010052a":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"090f8d702b753c18c64a6fd5fb550596c68861ce":["09b389e81c6f6d4cd07c05a8189081bc814b01ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"09b389e81c6f6d4cd07c05a8189081bc814b01ce":["090f8d702b753c18c64a6fd5fb550596c68861ce"],"0452863ee588101738d341e6e97eb87eb010052a":["09b389e81c6f6d4cd07c05a8189081bc814b01ce"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["0452863ee588101738d341e6e97eb87eb010052a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"090f8d702b753c18c64a6fd5fb550596c68861ce":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["090f8d702b753c18c64a6fd5fb550596c68861ce","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}