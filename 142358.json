{"path":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest#testBasic().mjava","commits":[{"id":"4e622d1d7e4496e3a8c1709c84e5be91ced69889","date":1311534411,"type":0,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testBasic() throws Exception {\n    final String groupField = \"author\";\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 7 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"7\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n    int maxDoc = indexSearcher.maxDoc();\n\n    Sort sortWithinGroup = new Sort(new SortField(\"id\", SortField.Type.INT, true));\n    AbstractAllGroupHeadsCollector c1 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c2 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c3 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));\n\n    // STRING sort type triggers different implementation\n    Sort sortWithinGroup2 = new Sort(new SortField(\"id\", SortField.Type.STRING, true));\n    AbstractAllGroupHeadsCollector c4 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup2);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c4);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));\n\n    Sort sortWithinGroup3 = new Sort(new SortField(\"id\", SortField.Type.STRING, false));\n    AbstractAllGroupHeadsCollector c5 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup3);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c5);\n    // 7 b/c higher doc id wins, even if order of field is in not in reverse.\n    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    final String groupField = \"author\";\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // 0\n    Document doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"2\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"3\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(newField(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"4\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(newField(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"5\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(newField(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"6\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(newField(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"6\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 7 -- no author field\n    doc = new Document();\n    doc.add(newField(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"7\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n    int maxDoc = indexSearcher.maxDoc();\n\n    Sort sortWithinGroup = new Sort(new SortField(\"id\", SortField.Type.INT, true));\n    AbstractAllGroupHeadsCollector c1 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c2 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c3 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));\n\n    // STRING sort type triggers different implementation\n    Sort sortWithinGroup2 = new Sort(new SortField(\"id\", SortField.Type.STRING, true));\n    AbstractAllGroupHeadsCollector c4 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup2);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c4);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));\n\n    Sort sortWithinGroup3 = new Sort(new SortField(\"id\", SortField.Type.STRING, false));\n    AbstractAllGroupHeadsCollector c5 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup3);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c5);\n    // 7 b/c higher doc id wins, even if order of field is in not in reverse.\n    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    final String groupField = \"author\";\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    // 7 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"7\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n    int maxDoc = indexSearcher.maxDoc();\n\n    Sort sortWithinGroup = new Sort(new SortField(\"id\", SortField.Type.INT, true));\n    AbstractAllGroupHeadsCollector c1 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c2 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c3 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));\n\n    // STRING sort type triggers different implementation\n    Sort sortWithinGroup2 = new Sort(new SortField(\"id\", SortField.Type.STRING, true));\n    AbstractAllGroupHeadsCollector c4 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup2);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c4);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));\n\n    Sort sortWithinGroup3 = new Sort(new SortField(\"id\", SortField.Type.STRING, false));\n    AbstractAllGroupHeadsCollector c5 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup3);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c5);\n    // 7 b/c higher doc id wins, even if order of field is in not in reverse.\n    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00","date":1317931776,"type":5,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    final String groupField = \"author\";\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // 0\n    Document doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"2\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"3\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(newField(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"4\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(newField(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"5\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(newField(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"6\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(newField(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"6\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 7 -- no author field\n    doc = new Document();\n    doc.add(newField(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"7\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n    int maxDoc = indexSearcher.maxDoc();\n\n    Sort sortWithinGroup = new Sort(new SortField(\"id\", SortField.Type.INT, true));\n    AbstractAllGroupHeadsCollector c1 = createRandomCollector(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c2 = createRandomCollector(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c3 = createRandomCollector(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));\n\n    // STRING sort type triggers different implementation\n    Sort sortWithinGroup2 = new Sort(new SortField(\"id\", SortField.Type.STRING, true));\n    AbstractAllGroupHeadsCollector c4 = createRandomCollector(groupField, sortWithinGroup2);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c4);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));\n\n    Sort sortWithinGroup3 = new Sort(new SortField(\"id\", SortField.Type.STRING, false));\n    AbstractAllGroupHeadsCollector c5 = createRandomCollector(groupField, sortWithinGroup3);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c5);\n    // 7 b/c higher doc id wins, even if order of field is in not in reverse.\n    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    final String groupField = \"author\";\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // 0\n    Document doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"2\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(newField(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"3\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(newField(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"4\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(newField(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"5\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(newField(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(newField(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"6\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(newField(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"6\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    // 7 -- no author field\n    doc = new Document();\n    doc.add(newField(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(newField(\"id\", \"7\", StringField.TYPE_STORED));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n    int maxDoc = indexSearcher.maxDoc();\n\n    Sort sortWithinGroup = new Sort(new SortField(\"id\", SortField.Type.INT, true));\n    AbstractAllGroupHeadsCollector c1 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c2 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));\n\n    AbstractAllGroupHeadsCollector c3 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));\n\n    // STRING sort type triggers different implementation\n    Sort sortWithinGroup2 = new Sort(new SortField(\"id\", SortField.Type.STRING, true));\n    AbstractAllGroupHeadsCollector c4 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup2);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c4);\n    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));\n\n    Sort sortWithinGroup3 = new Sort(new SortField(\"id\", SortField.Type.STRING, false));\n    AbstractAllGroupHeadsCollector c5 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup3);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c5);\n    // 7 b/c higher doc id wins, even if order of field is in not in reverse.\n    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));\n    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"4e622d1d7e4496e3a8c1709c84e5be91ced69889":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["4e622d1d7e4496e3a8c1709c84e5be91ced69889"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"]},"commit2Childs":{"4e622d1d7e4496e3a8c1709c84e5be91ced69889":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4e622d1d7e4496e3a8c1709c84e5be91ced69889"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}