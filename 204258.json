{"path":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","commits":[{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","pathOld":"/dev/null","sourceNew":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    TermsEnum termsEnum = null;\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      termsEnum = terms.iterator(termsEnum);\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","pathOld":"/dev/null","sourceNew":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    TermsEnum termsEnum = null;\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      termsEnum = terms.iterator(termsEnum);\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"372b4e16bc7ce0e14dccdc44b8cb31888f7402ab","date":1428224042,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","sourceNew":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    TermsEnum termsEnum = null;\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      termsEnum = terms.iterator(termsEnum);\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      //System.out.println(\"    count=\" + termCount);\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","sourceOld":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    TermsEnum termsEnum = null;\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      termsEnum = terms.iterator(termsEnum);\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","sourceNew":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      TermsEnum termsEnum = terms.iterator();\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      //System.out.println(\"    count=\" + termCount);\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","sourceOld":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    TermsEnum termsEnum = null;\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      termsEnum = terms.iterator(termsEnum);\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      //System.out.println(\"    count=\" + termCount);\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"158039752283f0c5acd00ec298d83fad2a0a1971","date":1456478848,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","sourceNew":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      TermsEnum termsEnum = terms.iterator();\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      //System.out.println(\"    count=\" + termCount);\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","sourceOld":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      TermsEnum termsEnum = terms.iterator();\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      //System.out.println(\"    count=\" + termCount);\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd96a930cc08d72beee719cc11ce465b9d9861c3","date":1535640296,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#checkTermRanges(String,int,Terms,long).mjava","sourceNew":null,"sourceOld":"  /** Make an effort to visit \"fake\" (e.g. auto-prefix) terms.  We do this by running term range intersections across an initially wide\n   *  interval of terms, at different boundaries, and then gradually decrease the interval.  This is not guaranteed to hit all non-real\n   *  terms (doing that in general is non-trivial), but it should hit many of them, and validate their postings against the postings for the\n   *  real terms. */\n  private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n    // We'll target this many terms in our interval for the current level:\n    double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    //System.out.println(\"CI.checkTermRanges field=\" + field + \" numTerms=\" + numTerms);\n\n    while (currentInterval >= 10.0) {\n      //System.out.println(\"  cycle interval=\" + currentInterval);\n\n      // We iterate this terms enum to locate min/max term for each sliding/overlapping interval we test at the current level:\n      TermsEnum termsEnum = terms.iterator();\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        //System.out.println(\"  top: term=\" + term.utf8ToString());\n        if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm.get() + \" term=\" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      //System.out.println(\"    count=\" + termCount);\n\n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["372b4e16bc7ce0e14dccdc44b8cb31888f7402ab"],"dd96a930cc08d72beee719cc11ce465b9d9861c3":["158039752283f0c5acd00ec298d83fad2a0a1971"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d2638f781be724518ff6c2263d14a48cf6e68017":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e8715d826e588419327562287d5d6a8040d63d6"],"372b4e16bc7ce0e14dccdc44b8cb31888f7402ab":["3e8715d826e588419327562287d5d6a8040d63d6"],"3e8715d826e588419327562287d5d6a8040d63d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"158039752283f0c5acd00ec298d83fad2a0a1971":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dd96a930cc08d72beee719cc11ce465b9d9861c3"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["158039752283f0c5acd00ec298d83fad2a0a1971"],"dd96a930cc08d72beee719cc11ce465b9d9861c3":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2638f781be724518ff6c2263d14a48cf6e68017","3e8715d826e588419327562287d5d6a8040d63d6"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"372b4e16bc7ce0e14dccdc44b8cb31888f7402ab":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"3e8715d826e588419327562287d5d6a8040d63d6":["d2638f781be724518ff6c2263d14a48cf6e68017","372b4e16bc7ce0e14dccdc44b8cb31888f7402ab"],"158039752283f0c5acd00ec298d83fad2a0a1971":["dd96a930cc08d72beee719cc11ce465b9d9861c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d2638f781be724518ff6c2263d14a48cf6e68017","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}