{"path":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String).mjava","commits":[{"id":"816521ebaad5add9cb96bb88c577394e2938c40b","date":1491931343,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Provide statistics on HDFS block locality, both in terms of bytes and block counts.\n   */\n  @Override\n  public void initializeMetrics(SolrMetricManager manager, String registryName, String scope) {\n    registry = manager.registry(registryName);\n    MetricsMap metricsMap = new MetricsMap((detailed, map) -> {\n      long totalBytes = 0;\n      long localBytes = 0;\n      int totalCount = 0;\n      int localCount = 0;\n\n      for (Iterator<HdfsDirectory> iterator = cache.keySet().iterator(); iterator.hasNext();) {\n        HdfsDirectory hdfsDirectory = iterator.next();\n\n        if (hdfsDirectory.isClosed()) {\n          iterator.remove();\n        } else {\n          try {\n            refreshDirectory(hdfsDirectory);\n            Map<FileStatus,BlockLocation[]> blockMap = cache.get(hdfsDirectory);\n\n            // For every block in every file in this directory, count it\n            for (BlockLocation[] locations : blockMap.values()) {\n              for (BlockLocation bl : locations) {\n                totalBytes += bl.getLength();\n                totalCount++;\n\n                if (Arrays.asList(bl.getHosts()).contains(hostname)) {\n                  localBytes += bl.getLength();\n                  localCount++;\n                }\n              }\n            }\n          } catch (IOException e) {\n            logger.warn(\"Could not retrieve locality information for {} due to exception: {}\",\n                hdfsDirectory.getHdfsDirPath(), e);\n          }\n        }\n      }\n      map.put(LOCALITY_BYTES_TOTAL, totalBytes);\n      map.put(LOCALITY_BYTES_LOCAL, localBytes);\n      if (localBytes == 0) {\n        map.put(LOCALITY_BYTES_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BYTES_RATIO, localBytes / (double) totalBytes);\n      }\n      map.put(LOCALITY_BLOCKS_TOTAL, totalCount);\n      map.put(LOCALITY_BLOCKS_LOCAL, localCount);\n      if (localCount == 0) {\n        map.put(LOCALITY_BLOCKS_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BLOCKS_RATIO, localCount / (double) totalCount);\n      }\n    });\n    manager.registerGauge(this, registryName, metricsMap, true, \"hdfsLocality\", getCategory().toString(), scope);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Provide statistics on HDFS block locality, both in terms of bytes and block counts.\n   */\n  @Override\n  public void initializeMetrics(SolrMetricManager manager, String registryName, String scope) {\n    registry = manager.registry(registryName);\n    MetricsMap metricsMap = new MetricsMap((detailed, map) -> {\n      long totalBytes = 0;\n      long localBytes = 0;\n      int totalCount = 0;\n      int localCount = 0;\n\n      for (Iterator<HdfsDirectory> iterator = cache.keySet().iterator(); iterator.hasNext();) {\n        HdfsDirectory hdfsDirectory = iterator.next();\n\n        if (hdfsDirectory.isClosed()) {\n          iterator.remove();\n        } else {\n          try {\n            refreshDirectory(hdfsDirectory);\n            Map<FileStatus,BlockLocation[]> blockMap = cache.get(hdfsDirectory);\n\n            // For every block in every file in this directory, count it\n            for (BlockLocation[] locations : blockMap.values()) {\n              for (BlockLocation bl : locations) {\n                totalBytes += bl.getLength();\n                totalCount++;\n\n                if (Arrays.asList(bl.getHosts()).contains(hostname)) {\n                  localBytes += bl.getLength();\n                  localCount++;\n                }\n              }\n            }\n          } catch (IOException e) {\n            logger.warn(\"Could not retrieve locality information for {} due to exception: {}\",\n                hdfsDirectory.getHdfsDirPath(), e);\n          }\n        }\n      }\n      map.put(LOCALITY_BYTES_TOTAL, totalBytes);\n      map.put(LOCALITY_BYTES_LOCAL, localBytes);\n      if (localBytes == 0) {\n        map.put(LOCALITY_BYTES_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BYTES_RATIO, localBytes / (double) totalBytes);\n      }\n      map.put(LOCALITY_BLOCKS_TOTAL, totalCount);\n      map.put(LOCALITY_BLOCKS_LOCAL, localCount);\n      if (localCount == 0) {\n        map.put(LOCALITY_BLOCKS_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BLOCKS_RATIO, localCount / (double) totalCount);\n      }\n    });\n    manager.registerGauge(this, registryName, metricsMap, true, \"hdfsLocality\", getCategory().toString(), scope);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bfc52860e6d13d034226a760813c59d984c6817a","date":1522229027,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String).mjava","sourceNew":"  /**\n   * Provide statistics on HDFS block locality, both in terms of bytes and block counts.\n   */\n  @Override\n  public void initializeMetrics(SolrMetricManager manager, String registryName, String tag, String scope) {\n    this.metricManager = manager;\n    this.registryName = registryName;\n    registry = manager.registry(registryName);\n    MetricsMap metricsMap = new MetricsMap((detailed, map) -> {\n      long totalBytes = 0;\n      long localBytes = 0;\n      int totalCount = 0;\n      int localCount = 0;\n\n      for (Iterator<HdfsDirectory> iterator = cache.keySet().iterator(); iterator.hasNext();) {\n        HdfsDirectory hdfsDirectory = iterator.next();\n\n        if (hdfsDirectory.isClosed()) {\n          iterator.remove();\n        } else {\n          try {\n            refreshDirectory(hdfsDirectory);\n            Map<FileStatus,BlockLocation[]> blockMap = cache.get(hdfsDirectory);\n\n            // For every block in every file in this directory, count it\n            for (BlockLocation[] locations : blockMap.values()) {\n              for (BlockLocation bl : locations) {\n                totalBytes += bl.getLength();\n                totalCount++;\n\n                if (Arrays.asList(bl.getHosts()).contains(hostname)) {\n                  localBytes += bl.getLength();\n                  localCount++;\n                }\n              }\n            }\n          } catch (IOException e) {\n            logger.warn(\"Could not retrieve locality information for {} due to exception: {}\",\n                hdfsDirectory.getHdfsDirPath(), e);\n          }\n        }\n      }\n      map.put(LOCALITY_BYTES_TOTAL, totalBytes);\n      map.put(LOCALITY_BYTES_LOCAL, localBytes);\n      if (localBytes == 0) {\n        map.put(LOCALITY_BYTES_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BYTES_RATIO, localBytes / (double) totalBytes);\n      }\n      map.put(LOCALITY_BLOCKS_TOTAL, totalCount);\n      map.put(LOCALITY_BLOCKS_LOCAL, localCount);\n      if (localCount == 0) {\n        map.put(LOCALITY_BLOCKS_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BLOCKS_RATIO, localCount / (double) totalCount);\n      }\n    });\n    manager.registerGauge(this, registryName, metricsMap, tag, true, \"hdfsLocality\", getCategory().toString(), scope);\n  }\n\n","sourceOld":"  /**\n   * Provide statistics on HDFS block locality, both in terms of bytes and block counts.\n   */\n  @Override\n  public void initializeMetrics(SolrMetricManager manager, String registryName, String scope) {\n    registry = manager.registry(registryName);\n    MetricsMap metricsMap = new MetricsMap((detailed, map) -> {\n      long totalBytes = 0;\n      long localBytes = 0;\n      int totalCount = 0;\n      int localCount = 0;\n\n      for (Iterator<HdfsDirectory> iterator = cache.keySet().iterator(); iterator.hasNext();) {\n        HdfsDirectory hdfsDirectory = iterator.next();\n\n        if (hdfsDirectory.isClosed()) {\n          iterator.remove();\n        } else {\n          try {\n            refreshDirectory(hdfsDirectory);\n            Map<FileStatus,BlockLocation[]> blockMap = cache.get(hdfsDirectory);\n\n            // For every block in every file in this directory, count it\n            for (BlockLocation[] locations : blockMap.values()) {\n              for (BlockLocation bl : locations) {\n                totalBytes += bl.getLength();\n                totalCount++;\n\n                if (Arrays.asList(bl.getHosts()).contains(hostname)) {\n                  localBytes += bl.getLength();\n                  localCount++;\n                }\n              }\n            }\n          } catch (IOException e) {\n            logger.warn(\"Could not retrieve locality information for {} due to exception: {}\",\n                hdfsDirectory.getHdfsDirPath(), e);\n          }\n        }\n      }\n      map.put(LOCALITY_BYTES_TOTAL, totalBytes);\n      map.put(LOCALITY_BYTES_LOCAL, localBytes);\n      if (localBytes == 0) {\n        map.put(LOCALITY_BYTES_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BYTES_RATIO, localBytes / (double) totalBytes);\n      }\n      map.put(LOCALITY_BLOCKS_TOTAL, totalCount);\n      map.put(LOCALITY_BLOCKS_LOCAL, localCount);\n      if (localCount == 0) {\n        map.put(LOCALITY_BLOCKS_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BLOCKS_RATIO, localCount / (double) totalCount);\n      }\n    });\n    manager.registerGauge(this, registryName, metricsMap, true, \"hdfsLocality\", getCategory().toString(), scope);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43564cbb30b064675027cfb569564e8531096e97","date":1522334265,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#initializeMetrics(SolrMetricManager,String,String).mjava","sourceNew":"  /**\n   * Provide statistics on HDFS block locality, both in terms of bytes and block counts.\n   */\n  @Override\n  public void initializeMetrics(SolrMetricManager manager, String registryName, String tag, String scope) {\n    this.metricManager = manager;\n    this.registryName = registryName;\n    registry = manager.registry(registryName);\n    MetricsMap metricsMap = new MetricsMap((detailed, map) -> {\n      long totalBytes = 0;\n      long localBytes = 0;\n      int totalCount = 0;\n      int localCount = 0;\n\n      for (Iterator<HdfsDirectory> iterator = cache.keySet().iterator(); iterator.hasNext();) {\n        HdfsDirectory hdfsDirectory = iterator.next();\n\n        if (hdfsDirectory.isClosed()) {\n          iterator.remove();\n        } else {\n          try {\n            refreshDirectory(hdfsDirectory);\n            Map<FileStatus,BlockLocation[]> blockMap = cache.get(hdfsDirectory);\n\n            // For every block in every file in this directory, count it\n            for (BlockLocation[] locations : blockMap.values()) {\n              for (BlockLocation bl : locations) {\n                totalBytes += bl.getLength();\n                totalCount++;\n\n                if (Arrays.asList(bl.getHosts()).contains(hostname)) {\n                  localBytes += bl.getLength();\n                  localCount++;\n                }\n              }\n            }\n          } catch (IOException e) {\n            logger.warn(\"Could not retrieve locality information for {} due to exception: {}\",\n                hdfsDirectory.getHdfsDirPath(), e);\n          }\n        }\n      }\n      map.put(LOCALITY_BYTES_TOTAL, totalBytes);\n      map.put(LOCALITY_BYTES_LOCAL, localBytes);\n      if (localBytes == 0) {\n        map.put(LOCALITY_BYTES_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BYTES_RATIO, localBytes / (double) totalBytes);\n      }\n      map.put(LOCALITY_BLOCKS_TOTAL, totalCount);\n      map.put(LOCALITY_BLOCKS_LOCAL, localCount);\n      if (localCount == 0) {\n        map.put(LOCALITY_BLOCKS_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BLOCKS_RATIO, localCount / (double) totalCount);\n      }\n    });\n    manager.registerGauge(this, registryName, metricsMap, tag, true, \"hdfsLocality\", getCategory().toString(), scope);\n  }\n\n","sourceOld":"  /**\n   * Provide statistics on HDFS block locality, both in terms of bytes and block counts.\n   */\n  @Override\n  public void initializeMetrics(SolrMetricManager manager, String registryName, String scope) {\n    registry = manager.registry(registryName);\n    MetricsMap metricsMap = new MetricsMap((detailed, map) -> {\n      long totalBytes = 0;\n      long localBytes = 0;\n      int totalCount = 0;\n      int localCount = 0;\n\n      for (Iterator<HdfsDirectory> iterator = cache.keySet().iterator(); iterator.hasNext();) {\n        HdfsDirectory hdfsDirectory = iterator.next();\n\n        if (hdfsDirectory.isClosed()) {\n          iterator.remove();\n        } else {\n          try {\n            refreshDirectory(hdfsDirectory);\n            Map<FileStatus,BlockLocation[]> blockMap = cache.get(hdfsDirectory);\n\n            // For every block in every file in this directory, count it\n            for (BlockLocation[] locations : blockMap.values()) {\n              for (BlockLocation bl : locations) {\n                totalBytes += bl.getLength();\n                totalCount++;\n\n                if (Arrays.asList(bl.getHosts()).contains(hostname)) {\n                  localBytes += bl.getLength();\n                  localCount++;\n                }\n              }\n            }\n          } catch (IOException e) {\n            logger.warn(\"Could not retrieve locality information for {} due to exception: {}\",\n                hdfsDirectory.getHdfsDirPath(), e);\n          }\n        }\n      }\n      map.put(LOCALITY_BYTES_TOTAL, totalBytes);\n      map.put(LOCALITY_BYTES_LOCAL, localBytes);\n      if (localBytes == 0) {\n        map.put(LOCALITY_BYTES_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BYTES_RATIO, localBytes / (double) totalBytes);\n      }\n      map.put(LOCALITY_BLOCKS_TOTAL, totalCount);\n      map.put(LOCALITY_BLOCKS_LOCAL, localCount);\n      if (localCount == 0) {\n        map.put(LOCALITY_BLOCKS_RATIO, 0);\n      } else {\n        map.put(LOCALITY_BLOCKS_RATIO, localCount / (double) totalCount);\n      }\n    });\n    manager.registerGauge(this, registryName, metricsMap, true, \"hdfsLocality\", getCategory().toString(), scope);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bfc52860e6d13d034226a760813c59d984c6817a":["816521ebaad5add9cb96bb88c577394e2938c40b"],"43564cbb30b064675027cfb569564e8531096e97":["816521ebaad5add9cb96bb88c577394e2938c40b","bfc52860e6d13d034226a760813c59d984c6817a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"816521ebaad5add9cb96bb88c577394e2938c40b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["43564cbb30b064675027cfb569564e8531096e97"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"bfc52860e6d13d034226a760813c59d984c6817a":["43564cbb30b064675027cfb569564e8531096e97"],"43564cbb30b064675027cfb569564e8531096e97":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","816521ebaad5add9cb96bb88c577394e2938c40b"],"816521ebaad5add9cb96bb88c577394e2938c40b":["bfc52860e6d13d034226a760813c59d984c6817a","43564cbb30b064675027cfb569564e8531096e97"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}