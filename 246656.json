{"path":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","commits":[{"id":"85eb75e0c0203e44dcf686f35876cf6080f3a671","date":1317221550,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"/dev/null","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      final int size = hash.size();\n      final long[] addresses = new long[size+1];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 1;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i+1] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr - 1);\n      writeIndex(idxOut, docCount, addresses[size], addresses, docToEntry);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e128967bca58657bc0039d4bfe631e63e81f1977","date":1317978310,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      final int size = hash.size();\n      final long[] addresses = new long[size+1];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 1;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i+1] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr - 1);\n      writeIndex(idxOut, docCount, addresses[size], addresses, docToEntry);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9efc72acdea22f5285be0a808f8bba51bb8e367","date":1323217280,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d638301ad1cfcae567b681b893bc8781f0ee48a5","date":1323801546,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"85eb75e0c0203e44dcf686f35876cf6080f3a671":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["e128967bca58657bc0039d4bfe631e63e81f1977"],"e128967bca58657bc0039d4bfe631e63e81f1977":["85eb75e0c0203e44dcf686f35876cf6080f3a671"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["e128967bca58657bc0039d4bfe631e63e81f1977","f9efc72acdea22f5285be0a808f8bba51bb8e367"]},"commit2Childs":{"85eb75e0c0203e44dcf686f35876cf6080f3a671":["e128967bca58657bc0039d4bfe631e63e81f1977"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["85eb75e0c0203e44dcf686f35876cf6080f3a671"],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"e128967bca58657bc0039d4bfe631e63e81f1977":["f9efc72acdea22f5285be0a808f8bba51bb8e367","d638301ad1cfcae567b681b893bc8781f0ee48a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}