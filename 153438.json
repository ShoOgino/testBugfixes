{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","commits":[{"id":"7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e","date":1476167489,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","pathOld":"/dev/null","sourceNew":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","pathOld":"/dev/null","sourceNew":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","sourceNew":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = applyCreatedVersionMajor(newDirectory());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","sourceNew":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = applyCreatedVersionMajor(newDirectory());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","sourceNew":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = applyCreatedVersionMajor(newDirectory());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(value == 0 ? \"\" : \"a\");\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = applyCreatedVersionMajor(newDirectory());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(Long.toString(value));\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dbc046116d49cd3d0c50f7169cabaa295bc23a4a","date":1552989114,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#testThreads().mjava","sourceNew":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = applyCreatedVersionMajor(newDirectory());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(value == 0 ? \"\" : \"a\");\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = maybeWrapWithMergingReader(writer.getReader());\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testThreads() throws Exception {\n    float density = codecSupportsSparsity() == false || random().nextBoolean() ? 1f : random().nextFloat();\n    int numDocs = atLeast(500);\n    final FixedBitSet docsWithField = new FixedBitSet(numDocs);\n    final int numDocsWithField = Math.max(1, (int) (density * numDocs));\n    if (numDocsWithField == numDocs) {\n      docsWithField.set(0, numDocs);\n    } else {\n      int i = 0;\n      while (i < numDocsWithField) {\n        int doc = random().nextInt(numDocs);\n        if (docsWithField.get(doc) == false) {\n          docsWithField.set(doc);\n          ++i;\n        }\n      }\n    }\n\n    long norms[] = new long[numDocsWithField];\n    for (int i = 0; i < numDocsWithField; i++) {\n      norms[i] = random().nextLong();\n    }\n\n    Directory dir = applyCreatedVersionMajor(newDirectory());\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0, j = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      if (docsWithField.get(i) == false) {\n        Document doc2 = new Document();\n        doc2.add(idField);\n        writer.addDocument(doc2);\n      } else {\n        long value = norms[j++];\n        dvField.setLongValue(value);\n        indexedField.setStringValue(value == 0 ? \"\" : \"a\");\n        writer.addDocument(doc);\n      }\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n\n    DirectoryReader reader = writer.getReader();\n    writer.close();\n\n    final int numThreads = TestUtil.nextInt(random(), 3, 30);\n    Thread[] threads = new Thread[numThreads];\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (int i = 0; i < numThreads; ++i) {\n      threads[i] = new Thread(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            latch.await();\n            checkNormsVsDocValues(reader);\n            TestUtil.checkReader(reader);\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n    }\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n    latch.countDown();\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"dbc046116d49cd3d0c50f7169cabaa295bc23a4a":["622a708571e534680618b3c5e0c28ac539a47776"],"622a708571e534680618b3c5e0c28ac539a47776":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dbc046116d49cd3d0c50f7169cabaa295bc23a4a"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e"]},"commit2Childs":{"7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e":["92212fd254551a0b1156aafc3a1a6ed1a43932ad","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","31741cf1390044e38a2ec3127cf302ba841bfd75"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7ca1fe3f1f5edea2339f7e7a31f0754878a72b0e","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"dbc046116d49cd3d0c50f7169cabaa295bc23a4a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"622a708571e534680618b3c5e0c28ac539a47776":["dbc046116d49cd3d0c50f7169cabaa295bc23a4a"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"31741cf1390044e38a2ec3127cf302ba841bfd75":["622a708571e534680618b3c5e0c28ac539a47776"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["92212fd254551a0b1156aafc3a1a6ed1a43932ad","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}