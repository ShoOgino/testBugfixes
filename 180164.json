{"path":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","commits":[{"id":"6ce825e9276493231308229152c48f755ce1a0a5","date":1348871483,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"/dev/null","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n\n    return a;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"65621ac5927a7c2f23e9cd59b09f56addd5ed2bf","date":1348876189,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc41b743423981e7ec17a024ce7e107096e472fe","date":1349975327,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","date":1351615637,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"70728fc5d87dc51506cd3f763d68d2c16948e127","date":1363037076,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        posData.arriving.setAccept(true);\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eafa8c5eabc3dacd34680054e6a33bda024080ac","date":1367691488,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","date":1374158194,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp))\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final State nextState = byteIDX == termLen-1 ? endPosData.arriving : new State();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        state.addTransition(new Transition(c, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":["6ce825e9276493231308229152c48f755ce1a0a5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp))\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final State nextState = byteIDX == termLen-1 ? endPosData.arriving : new State();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        state.addTransition(new Transition(c, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef term2 = changeToken(term);\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      for(int byteIDX=0;byteIDX<term2.length;byteIDX++) {\n        final State nextState = byteIDX == term2.length-1 ? endPosData.arriving : new State();\n        state.addTransition(new Transition(term2.bytes[term2.offset + byteIDX] & 0xff, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75ac8571c2d82c574e446c3729251b994c69a55c","date":1402523781,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public LightAutomaton toAutomaton(TokenStream in) throws IOException {\n    final LightAutomaton.Builder builder = new LightAutomaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp))\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final State nextState = byteIDX == termLen-1 ? endPosData.arriving : new State();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        state.addTransition(new Transition(c, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":["41279c9c61cefe411b381a57a01aa6e619a1015b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public LightAutomaton toAutomaton(TokenStream in) throws IOException {\n    final LightAutomaton.Builder builder = new LightAutomaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton a = new Automaton();\n    boolean deterministic = true;\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == null;\n\n        if (posData.arriving == null) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = a.getInitialState();\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = new State();\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        } else {\n          posData.leaving = new State();\n          posData.arriving.addTransition(new Transition(POS_SEP, posData.leaving));\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(a.getInitialState(), positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      } else {\n        // note: this isn't necessarily true. its just that we aren't surely det.\n        // we could optimize this further (e.g. buffer and sort synonyms at a position)\n        // but thats probably overkill. this is cheap and dirty\n        deterministic = false;\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == null) {\n        endPosData.arriving = new State();\n      }\n\n      State state = posData.leaving;\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp))\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final State nextState = byteIDX == termLen-1 ? endPosData.arriving : new State();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        state.addTransition(new Transition(c, nextState));\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    State endState = null;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = new State();\n      endState.setAccept(true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != null) {\n        if (endState != null) {\n          posData.arriving.addTransition(new Transition(POS_SEP, endState));\n        } else {\n          posData.arriving.setAccept(true);\n        }\n      }\n      pos++;\n    }\n\n    //toDot(a);\n    a.setDeterministic(deterministic);\n    return a;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"804b857d1066ab5185b3b9101bde41b0b71426ec","date":1435846169,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      termBytesAtt.fillBytesRef();\n      final BytesRef termUTF8 = changeToken(term);\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02bb26fb0bcbf774b42d0f5322026124d24e2390","date":1483874768,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        positions.freeBefore(pos);\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"098528909bb70948871fd7ed865fafb87ed73964","date":1484667487,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endState = -1;\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    }\n    \n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":["41279c9c61cefe411b381a57a01aa6e619a1015b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endState = -1;\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    }\n    \n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (!preservePositionIncrements && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n    int endState = -1;\n    if (offsetAtt.endOffset() > maxOffset) {\n      endState = builder.createState();\n      builder.setAccept(endState, true);\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n\n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41279c9c61cefe411b381a57a01aa6e619a1015b","date":1528947344,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    } else if (endPosInc > 0 && preservePositionIncrements==false) {\n      endPosInc = 0;\n    }\n\n    int endState;\n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endState = -1;\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    }\n    \n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","bugFix":["75ac8571c2d82c574e446c3729251b994c69a55c","098528909bb70948871fd7ed865fafb87ed73964"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    } else if (endPosInc > 0 && preservePositionIncrements==false) {\n      endPosInc = 0;\n    }\n\n    int endState;\n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endState = -1;\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    }\n    \n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton#toAutomaton(TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    } else if (endPosInc > 0 && preservePositionIncrements==false) {\n      endPosInc = 0;\n    }\n\n    int endState;\n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public Automaton toAutomaton(TokenStream in) throws IOException {\n    final Automaton.Builder builder = new Automaton.Builder();\n    builder.createState();\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    // Only temporarily holds states ahead of our current\n    // position:\n\n    final RollingBuffer<Position> positions = new Positions();\n\n    int pos = -1;\n    int freedPos = 0;\n    Position posData = null;\n    int maxOffset = 0;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 0) {\n\n        // New node:\n        pos += posInc;\n\n        posData = positions.get(pos);\n        assert posData.leaving == -1;\n\n        if (posData.arriving == -1) {\n          // No token ever arrived to this position\n          if (pos == 0) {\n            // OK: this is the first token\n            posData.leaving = 0;\n          } else {\n            // This means there's a hole (eg, StopFilter\n            // does this):\n            posData.leaving = builder.createState();\n            addHoles(builder, positions, pos);\n          }\n        } else {\n          posData.leaving = builder.createState();\n          builder.addTransition(posData.arriving, posData.leaving, POS_SEP);\n          if (posInc > 1) {\n            // A token spanned over a hole; add holes\n            // \"under\" it:\n            addHoles(builder, positions, pos);\n          }\n        }\n        while (freedPos <= pos) {\n          Position freePosData = positions.get(freedPos);\n          // don't free this position yet if we may still need to fill holes over it:\n          if (freePosData.arriving == -1 || freePosData.leaving == -1) {\n            break;\n          }\n          positions.freeBefore(freedPos);\n          freedPos++;\n        }\n      }\n\n      final int endPos = pos + posLengthAtt.getPositionLength();\n\n      final BytesRef termUTF8 = changeToken(termBytesAtt.getBytesRef());\n      int[] termUnicode = null;\n      final Position endPosData = positions.get(endPos);\n      if (endPosData.arriving == -1) {\n        endPosData.arriving = builder.createState();\n      }\n\n      int termLen;\n      if (unicodeArcs) {\n        final String utf16 = termUTF8.utf8ToString();\n        termUnicode = new int[utf16.codePointCount(0, utf16.length())];\n        termLen = termUnicode.length;\n        for (int cp, i = 0, j = 0; i < utf16.length(); i += Character.charCount(cp)) {\n          termUnicode[j++] = cp = utf16.codePointAt(i);\n        }\n      } else {\n        termLen = termUTF8.length;\n      }\n\n      int state = posData.leaving;\n\n      for(int byteIDX=0;byteIDX<termLen;byteIDX++) {\n        final int nextState = byteIDX == termLen-1 ? endPosData.arriving : builder.createState();\n        int c;\n        if (unicodeArcs) {\n          c = termUnicode[byteIDX];\n        } else {\n          c = termUTF8.bytes[termUTF8.offset + byteIDX] & 0xff;\n        }\n        builder.addTransition(state, nextState, c);\n        state = nextState;\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n    }\n\n    in.end();\n\n    int endState = -1;\n\n    int endPosInc = posIncAtt.getPositionIncrement();\n\n    if (endPosInc == 0 && finalOffsetGapAsHole && offsetAtt.endOffset() > maxOffset) {\n      endPosInc = 1;\n    }\n    \n    if (endPosInc > 0) {\n      // there were hole(s) after the last token\n      endState = builder.createState();\n\n      // add trailing holes now:\n      int lastState = endState;\n      while (true) {\n        int state1 = builder.createState();\n        builder.addTransition(lastState, state1, HOLE);\n        endPosInc--;\n        if (endPosInc == 0) {\n          builder.setAccept(state1, true);\n          break;\n        }\n        int state2 = builder.createState();\n        builder.addTransition(state1, state2, POS_SEP);\n        lastState = state2;\n      }\n    } else {\n      endState = -1;\n    }\n\n    pos++;\n    while (pos <= positions.getMaxPos()) {\n      posData = positions.get(pos);\n      if (posData.arriving != -1) {\n        if (endState != -1) {\n          builder.addTransition(posData.arriving, endState, POS_SEP);\n        } else {\n          builder.setAccept(posData.arriving, true);\n        }\n      }\n      pos++;\n    }\n    \n    return builder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["5c84485629d80d203608e8975a1139de9933cc38"],"75ac8571c2d82c574e446c3729251b994c69a55c":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6"],"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["804b857d1066ab5185b3b9101bde41b0b71426ec","02bb26fb0bcbf774b42d0f5322026124d24e2390"],"41279c9c61cefe411b381a57a01aa6e619a1015b":["098528909bb70948871fd7ed865fafb87ed73964"],"302d34f2c66e8d489ee13078305c330cbf67b226":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","098528909bb70948871fd7ed865fafb87ed73964"],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["65621ac5927a7c2f23e9cd59b09f56addd5ed2bf","cc41b743423981e7ec17a024ce7e107096e472fe"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["098528909bb70948871fd7ed865fafb87ed73964","41279c9c61cefe411b381a57a01aa6e619a1015b"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"65621ac5927a7c2f23e9cd59b09f56addd5ed2bf":["6ce825e9276493231308229152c48f755ce1a0a5"],"cc41b743423981e7ec17a024ce7e107096e472fe":["65621ac5927a7c2f23e9cd59b09f56addd5ed2bf"],"098528909bb70948871fd7ed865fafb87ed73964":["02bb26fb0bcbf774b42d0f5322026124d24e2390"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["75ac8571c2d82c574e446c3729251b994c69a55c"],"02bb26fb0bcbf774b42d0f5322026124d24e2390":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"6ce825e9276493231308229152c48f755ce1a0a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5c84485629d80d203608e8975a1139de9933cc38":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["41279c9c61cefe411b381a57a01aa6e619a1015b"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["098528909bb70948871fd7ed865fafb87ed73964","41279c9c61cefe411b381a57a01aa6e619a1015b"]},"commit2Childs":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","02bb26fb0bcbf774b42d0f5322026124d24e2390"],"75ac8571c2d82c574e446c3729251b994c69a55c":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6":["75ac8571c2d82c574e446c3729251b994c69a55c","5c84485629d80d203608e8975a1139de9933cc38"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["302d34f2c66e8d489ee13078305c330cbf67b226"],"41279c9c61cefe411b381a57a01aa6e619a1015b":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"302d34f2c66e8d489ee13078305c330cbf67b226":[],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"70728fc5d87dc51506cd3f763d68d2c16948e127":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"65621ac5927a7c2f23e9cd59b09f56addd5ed2bf":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","cc41b743423981e7ec17a024ce7e107096e472fe"],"cc41b743423981e7ec17a024ce7e107096e472fe":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"098528909bb70948871fd7ed865fafb87ed73964":["41279c9c61cefe411b381a57a01aa6e619a1015b","302d34f2c66e8d489ee13078305c330cbf67b226","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6ce825e9276493231308229152c48f755ce1a0a5"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"02bb26fb0bcbf774b42d0f5322026124d24e2390":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","098528909bb70948871fd7ed865fafb87ed73964"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"6ce825e9276493231308229152c48f755ce1a0a5":["65621ac5927a7c2f23e9cd59b09f56addd5ed2bf"],"5c84485629d80d203608e8975a1139de9933cc38":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["302d34f2c66e8d489ee13078305c330cbf67b226","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}