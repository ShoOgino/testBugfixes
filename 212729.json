{"path":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"9274621789ce990dbfef455dabdf026bb3184821","date":1400046684,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FieldCacheRewriteMethod.MultiTermQueryFieldCacheWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = DocValues.getSorted(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = DocValues.getSorted(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FieldCacheRewriteMethod.MultiTermQueryFieldCacheWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = DocValues.getSorted(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = FieldCache.DEFAULT.getTermsIndex(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":1,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FieldCacheRewriteMethod.MultiTermQueryFieldCacheWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = DocValues.getSorted(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = FieldCache.DEFAULT.getTermsIndex(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":4,"author":"Ryan Ernst","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedDocValues fcsi = DocValues.getSorted(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return fcsi.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          long ord = termsEnum.ord();\n          if (ord >= 0) {\n            termSet.set(ord);\n          }\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          int ord = fcsi.getOrd(doc);\n          if (ord == -1) {\n            return false;\n          }\n          return termSet.get(ord);\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9274621789ce990dbfef455dabdf026bb3184821":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9274621789ce990dbfef455dabdf026bb3184821"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"56572ec06f1407c066d6b7399413178b33176cd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","93dd449115a9247533e44bab47e8429e5dccbc6d"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9fb5f46e264daf5ba3860defe623a89d202dd87"]},"commit2Childs":{"9274621789ce990dbfef455dabdf026bb3184821":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["56572ec06f1407c066d6b7399413178b33176cd8","c9fb5f46e264daf5ba3860defe623a89d202dd87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9274621789ce990dbfef455dabdf026bb3184821","93dd449115a9247533e44bab47e8429e5dccbc6d","56572ec06f1407c066d6b7399413178b33176cd8"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}