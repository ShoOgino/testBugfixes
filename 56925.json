{"path":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","commits":[{"id":"8a341947b8c97354c225eb5460c7f4b2cf454c0a","date":1398888860,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    for (String f : cachingDir.listAll()) System.out.println(f + \" \" + cachingDir.fileLength(f));\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0567bdc5c86c94ced64201187cfcef2417d76dda","date":1400678298,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    for (String f : cachingDir.listAll()) System.out.println(f + \" \" + cachingDir.fileLength(f));\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":["8a341947b8c97354c225eb5460c7f4b2cf454c0a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a656b32c3aa151037a8c52e9b134acc3cbf482bc","date":1400688195,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    for (String f : cachingDir.listAll()) System.out.println(f + \" \" + cachingDir.fileLength(f));\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    for (String f : cachingDir.listAll()) System.out.println(f + \" \" + cachingDir.fileLength(f));\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cfc45818441587d8004ff1a119fb60ac9ecb9a14","date":1401437797,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf.clone());\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    writer = new IndexWriter(cachingDir, conf.clone());\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868bd094d931bf6a614e43a8e65d53b643e2e64c","date":1401446698,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer, true); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testIOContext().mjava","sourceNew":"  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","sourceOld":"  @Test\n  public void testIOContext() throws Exception {\n    // LUCENE-5591: make sure we pass an IOContext with an approximate\n    // segmentSize in FlushInfo\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    for (int i = 0; i < 100; i++) {\n      writer.addDocument(doc(i));\n    }\n    writer.commit();\n    writer.close();\n    \n    NRTCachingDirectory cachingDir = new NRTCachingDirectory(dir, 100, 1/(1024.*1024.));\n    conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // we want a single large enough segment so that a doc-values update writes a large file\n    conf.setMergePolicy(NoMergePolicy.INSTANCE);\n    conf.setMaxBufferedDocs(Integer.MAX_VALUE); // manually flush\n    conf.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    writer = new IndexWriter(cachingDir, conf);\n    writer.updateNumericDocValue(new Term(\"id\", \"doc-0\"), \"val\", 100L);\n    DirectoryReader reader = DirectoryReader.open(writer); // flush\n    assertEquals(0, cachingDir.listCachedFiles().length);\n    \n    IOUtils.close(reader, writer, cachingDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["868bd094d931bf6a614e43a8e65d53b643e2e64c"],"cfc45818441587d8004ff1a119fb60ac9ecb9a14":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["2a1862266772deb28cdcb7d996b64d2177022687"],"0567bdc5c86c94ced64201187cfcef2417d76dda":["8a341947b8c97354c225eb5460c7f4b2cf454c0a"],"b7605579001505896d48b07160075a5c8b8e128e":["8a341947b8c97354c225eb5460c7f4b2cf454c0a","0567bdc5c86c94ced64201187cfcef2417d76dda"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["2a1862266772deb28cdcb7d996b64d2177022687","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["2a1862266772deb28cdcb7d996b64d2177022687","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"8a341947b8c97354c225eb5460c7f4b2cf454c0a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2a1862266772deb28cdcb7d996b64d2177022687":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":["8a341947b8c97354c225eb5460c7f4b2cf454c0a","0567bdc5c86c94ced64201187cfcef2417d76dda"],"868bd094d931bf6a614e43a8e65d53b643e2e64c":["cfc45818441587d8004ff1a119fb60ac9ecb9a14"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["2a1862266772deb28cdcb7d996b64d2177022687"],"cfc45818441587d8004ff1a119fb60ac9ecb9a14":["868bd094d931bf6a614e43a8e65d53b643e2e64c"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"0567bdc5c86c94ced64201187cfcef2417d76dda":["cfc45818441587d8004ff1a119fb60ac9ecb9a14","b7605579001505896d48b07160075a5c8b8e128e","a656b32c3aa151037a8c52e9b134acc3cbf482bc"],"b7605579001505896d48b07160075a5c8b8e128e":[],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8a341947b8c97354c225eb5460c7f4b2cf454c0a":["0567bdc5c86c94ced64201187cfcef2417d76dda","b7605579001505896d48b07160075a5c8b8e128e","a656b32c3aa151037a8c52e9b134acc3cbf482bc"],"2a1862266772deb28cdcb7d996b64d2177022687":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8a341947b8c97354c225eb5460c7f4b2cf454c0a"],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":[],"868bd094d931bf6a614e43a8e65d53b643e2e64c":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7605579001505896d48b07160075a5c8b8e128e","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","a656b32c3aa151037a8c52e9b134acc3cbf482bc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}