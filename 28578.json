{"path":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","commits":[{"id":"339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67","date":1348934182,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf8086c7e11dc41303ef1b8050bd355ddfaee76d","date":1350007219,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e","date":1358793943,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d33aeb9ed95127e3cb6b2abce6c4b0441e6c3633","date":1359743129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"088a7ef694fd43d5d9a4d200c4005865f773d1e7","date":1371136274,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24f89e8a6aac05753cde4c83d62a74356098200d","date":1525768331,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"feb4029567b43f074ed7b6eb8fb126d355075dfd","date":1544812585,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.getDocStats().maxDoc);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.getDocStats().maxDoc);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.getDocStats().maxDoc);\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setNoCFSRatio(0.0);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"d33aeb9ed95127e3cb6b2abce6c4b0441e6c3633":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67","cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["d33aeb9ed95127e3cb6b2abce6c4b0441e6c3633"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67"],"3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"24f89e8a6aac05753cde4c83d62a74356098200d":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["24f89e8a6aac05753cde4c83d62a74356098200d"],"339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["feb4029567b43f074ed7b6eb8fb126d355075dfd"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"d33aeb9ed95127e3cb6b2abce6c4b0441e6c3633":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","d33aeb9ed95127e3cb6b2abce6c4b0441e6c3633","3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e":[],"24f89e8a6aac05753cde4c83d62a74356098200d":["feb4029567b43f074ed7b6eb8fb126d355075dfd"],"339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","c7492bcb52be51e55d596134b95b2e53cc4ffb91","cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["339cf89fb32d53dacb17aa56f2b6bf87eb4a3a67"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["24f89e8a6aac05753cde4c83d62a74356098200d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}