{"path":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","commits":[{"id":"8ff728f0ac9112fac26f50ef2a8e7580c2525e6c","date":1389897879,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","pathOld":"/dev/null","sourceNew":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","sourceNew":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.shutdown();\n    reader.close();\n    dir.close();    \n  }\n\n","sourceOld":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","sourceNew":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","sourceOld":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.shutdown();\n    reader.close();\n    dir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","sourceNew":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","sourceOld":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9e1499c5d26c936238506df90a3c02c76707722","date":1434449920,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","sourceNew":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery(\"indexed_not_tokenized\", \"test1\", \"test2\");\n    \n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","sourceOld":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"indexed_not_tokenized\", \"test1\"));\n    query.add(new Term(\"indexed_not_tokenized\", \"test2\"));\n    \n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/document/TestDocument#testPositionIncrementMultiFields().mjava","sourceNew":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery(\"indexed_not_tokenized\", \"test1\", \"test2\");\n    \n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc), true);\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","sourceOld":"  public void testPositionIncrementMultiFields() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    writer.addDocument(makeDocumentWithFields());\n    IndexReader reader = writer.getReader();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    PhraseQuery query = new PhraseQuery(\"indexed_not_tokenized\", \"test1\", \"test2\");\n    \n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    \n    doAssert(searcher.doc(hits[0].doc));\n    writer.close();\n    reader.close();\n    dir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e9e1499c5d26c936238506df90a3c02c76707722":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["8ff728f0ac9112fac26f50ef2a8e7580c2525e6c"],"8ff728f0ac9112fac26f50ef2a8e7580c2525e6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["e9e1499c5d26c936238506df90a3c02c76707722"]},"commit2Childs":{"e9e1499c5d26c936238506df90a3c02c76707722":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["e9e1499c5d26c936238506df90a3c02c76707722"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8ff728f0ac9112fac26f50ef2a8e7580c2525e6c"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"8ff728f0ac9112fac26f50ef2a8e7580c2525e6c":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}