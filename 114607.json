{"path":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","commits":[{"id":"3cdc80a62bb2b084e97738303ef870bcea0310ac","date":1352398860,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"/dev/null","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      final Source source = reader.docValues(mergeState.fieldInfo.name).getDirectSource();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25e6d305c838339e588b0a8f3cf8f868d8597a0b","date":1352566882,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      DocValues docvalues = reader.docValues(mergeState.fieldInfo.name);\n      final Source source;\n      if (docvalues == null) {\n        source = DocValues.getDefaultSource(mergeState.fieldInfo.getDocValuesType());\n      } else {\n        source = docvalues.getDirectSource();\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      final Source source = reader.docValues(mergeState.fieldInfo.name).getDirectSource();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f45b94f31bcc0de4497b99f7b51993765f64c601","date":1352745246,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      DocValues docValues = reader.docValues(mergeState.fieldInfo.name);\n      final Source source;\n      if (docValues == null) {\n        source = DocValues.getDefaultSource(mergeState.fieldInfo.getDocValuesType());\n      } else {\n        source = docValues.getDirectSource();\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      DocValues docvalues = reader.docValues(mergeState.fieldInfo.name);\n      final Source source;\n      if (docvalues == null) {\n        source = DocValues.getDefaultSource(mergeState.fieldInfo.getDocValuesType());\n      } else {\n        source = docvalues.getDirectSource();\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce73f585d17f53055185a19beb46db23d76e0ad9","date":1353077110,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      DocValues docValues = reader.docValues(mergeState.fieldInfo.name);\n      final Source source;\n      if (docValues == null) {\n        source = DocValues.getDefaultSource(mergeState.fieldInfo.getDocValuesType());\n      } else {\n        source = docValues.getDirectSource();\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength, mergeState.segmentInfo.getDocCount());\n    field.merge(mergeState);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      DocValues docValues = reader.docValues(mergeState.fieldInfo.name);\n      final Source source;\n      if (docValues == null) {\n        source = DocValues.getDefaultSource(mergeState.fieldInfo.getDocValuesType());\n      } else {\n        source = docValues.getDirectSource();\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6295f14d43685811599f8a8f02a63d75ec6bd8fe","date":1353248103,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);\n      if (docValues == null) {\n        docValues = BinaryDocValues.DEFAULT;\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          docValues.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength, mergeState.segmentInfo.getDocCount());\n    field.merge(mergeState);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      DocValues docValues = reader.docValues(mergeState.fieldInfo.name);\n      final Source source;\n      if (docValues == null) {\n        source = DocValues.getDefaultSource(mergeState.fieldInfo.getDocValuesType());\n      } else {\n        source = docValues.getDirectSource();\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          source.getBytes(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength, mergeState.segmentInfo.getDocCount());\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f176b7bac2a187d69335c079b1f923449fb2881f","date":1353257308,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);\n      if (docValues == null) {\n        docValues = BinaryDocValues.DEFAULT;\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          docValues.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);\n      if (docValues == null) {\n        docValues = BinaryDocValues.DEFAULT;\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          docValues.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength, mergeState.segmentInfo.getDocCount());\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e05b279040cd7b938223b77c3772786678160cf6","date":1353297629,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    // nocommit: messy, and can be simplified by using docValues.maxLength/fixedLength in many cases.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);\n      if (docValues == null) {\n        docValues = new BinaryDocValues.EMPTY(maxDoc);\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          docValues.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);\n      if (docValues == null) {\n        docValues = BinaryDocValues.DEFAULT;\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          docValues.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b53a9a930ee01857178a1b512fbab24642f3fa8","date":1354471097,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(FieldInfo,MergeState,List[BinaryDocValues]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer#mergeBinaryField(MergeState).mjava","sourceNew":"  // dead simple impl: codec can optimize\n  public void mergeBinaryField(FieldInfo fieldInfo, MergeState mergeState, List<BinaryDocValues> toMerge) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    // nocommit: messy, and can be simplified by using docValues.maxLength/fixedLength in many cases.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (int readerIDX=0;readerIDX<toMerge.size();readerIDX++) {\n      AtomicReader reader = mergeState.readers.get(readerIDX);      \n      int maxDoc = reader.maxDoc();\n      Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues values = toMerge.get(readerIDX);\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          values.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState, toMerge);\n  }\n\n","sourceOld":"  // dead simple impl: codec can optimize\n  protected void mergeBinaryField(MergeState mergeState) throws IOException {\n    // first compute fixedLength and maxLength of live ones to be merged.\n    // nocommit: messy, and can be simplified by using docValues.maxLength/fixedLength in many cases.\n    boolean fixedLength = true;\n    int maxLength = -1;\n    BytesRef bytes = new BytesRef();\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);\n      if (docValues == null) {\n        docValues = new BinaryDocValues.EMPTY(maxDoc);\n      }\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          docValues.get(i, bytes);\n          if (maxLength == -1) {\n            maxLength = bytes.length;\n          } else {\n            fixedLength &= bytes.length == maxLength;\n            maxLength = Math.max(bytes.length, maxLength);\n          }\n        }\n        mergeState.checkAbort.work(300);\n      }\n    }\n    // now we can merge\n    assert maxLength >= 0; // could this happen (nothing to do?)\n    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);\n    field.merge(mergeState);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e05b279040cd7b938223b77c3772786678160cf6":["f176b7bac2a187d69335c079b1f923449fb2881f"],"ce73f585d17f53055185a19beb46db23d76e0ad9":["f45b94f31bcc0de4497b99f7b51993765f64c601"],"3cdc80a62bb2b084e97738303ef870bcea0310ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6295f14d43685811599f8a8f02a63d75ec6bd8fe":["ce73f585d17f53055185a19beb46db23d76e0ad9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"25e6d305c838339e588b0a8f3cf8f868d8597a0b":["3cdc80a62bb2b084e97738303ef870bcea0310ac"],"4b53a9a930ee01857178a1b512fbab24642f3fa8":["e05b279040cd7b938223b77c3772786678160cf6"],"f176b7bac2a187d69335c079b1f923449fb2881f":["6295f14d43685811599f8a8f02a63d75ec6bd8fe"],"f45b94f31bcc0de4497b99f7b51993765f64c601":["25e6d305c838339e588b0a8f3cf8f868d8597a0b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"e05b279040cd7b938223b77c3772786678160cf6":["4b53a9a930ee01857178a1b512fbab24642f3fa8"],"ce73f585d17f53055185a19beb46db23d76e0ad9":["6295f14d43685811599f8a8f02a63d75ec6bd8fe"],"3cdc80a62bb2b084e97738303ef870bcea0310ac":["25e6d305c838339e588b0a8f3cf8f868d8597a0b"],"6295f14d43685811599f8a8f02a63d75ec6bd8fe":["f176b7bac2a187d69335c079b1f923449fb2881f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3cdc80a62bb2b084e97738303ef870bcea0310ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"25e6d305c838339e588b0a8f3cf8f868d8597a0b":["f45b94f31bcc0de4497b99f7b51993765f64c601"],"4b53a9a930ee01857178a1b512fbab24642f3fa8":[],"f176b7bac2a187d69335c079b1f923449fb2881f":["e05b279040cd7b938223b77c3772786678160cf6"],"f45b94f31bcc0de4497b99f7b51993765f64c601":["ce73f585d17f53055185a19beb46db23d76e0ad9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4b53a9a930ee01857178a1b512fbab24642f3fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}