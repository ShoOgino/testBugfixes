{"path":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#refreshDirectory(HdfsDirectory).mjava","commits":[{"id":"1ce8283f367b946e5dd6300887294d7d115f2b9f","date":1433955116,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#refreshDirectory(HdfsDirectory).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Update the cached block locations for the given directory. This includes deleting any files that no longer exist in\n   * the file system and adding any new files that have shown up.\n   * \n   * @param dir\n   *          The directory to refresh\n   * @throws IOException\n   *           If there is a problem getting info from HDFS\n   */\n  private void refreshDirectory(HdfsDirectory dir) throws IOException {\n    Map<FileStatus,BlockLocation[]> directoryCache = cache.get(dir);\n    Set<FileStatus> cachedStatuses = directoryCache.keySet();\n\n    FileSystem fs = dir.getFileSystem();\n    FileStatus[] statuses = fs.listStatus(dir.getHdfsDirPath());\n    List<FileStatus> statusList = Arrays.asList(statuses);\n\n    logger.debug(\"Updating locality information for: {}\", statusList);\n\n    // Keep only the files that still exist\n    cachedStatuses.retainAll(statusList);\n\n    // Fill in missing entries in the cache\n    for (FileStatus status : statusList) {\n      if (!status.isDirectory() && !directoryCache.containsKey(status)) {\n        BlockLocation[] locations = fs.getFileBlockLocations(status, 0, status.getLen());\n        directoryCache.put(status, locations);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c80f6f4fe2e841ba56e6ce200951063ab91196d3","date":1533052731,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#refreshDirectory(HdfsDirectory).mjava","pathOld":"solr/core/src/java/org/apache/solr/store/hdfs/HdfsLocalityReporter#refreshDirectory(HdfsDirectory).mjava","sourceNew":"  /**\n   * Update the cached block locations for the given directory. This includes deleting any files that no longer exist in\n   * the file system and adding any new files that have shown up.\n   * \n   * @param dir\n   *          The directory to refresh\n   * @throws IOException\n   *           If there is a problem getting info from HDFS\n   */\n  private void refreshDirectory(HdfsDirectory dir) throws IOException {\n    Map<FileStatus,BlockLocation[]> directoryCache = cache.get(dir);\n    Set<FileStatus> cachedStatuses = directoryCache.keySet();\n\n    FileSystem fs = dir.getFileSystem();\n    FileStatus[] statuses = fs.listStatus(dir.getHdfsDirPath());\n    List<FileStatus> statusList = Arrays.asList(statuses);\n\n    log.debug(\"Updating locality information for: {}\", statusList);\n\n    // Keep only the files that still exist\n    cachedStatuses.retainAll(statusList);\n\n    // Fill in missing entries in the cache\n    for (FileStatus status : statusList) {\n      if (!status.isDirectory() && !directoryCache.containsKey(status)) {\n        BlockLocation[] locations = fs.getFileBlockLocations(status, 0, status.getLen());\n        directoryCache.put(status, locations);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Update the cached block locations for the given directory. This includes deleting any files that no longer exist in\n   * the file system and adding any new files that have shown up.\n   * \n   * @param dir\n   *          The directory to refresh\n   * @throws IOException\n   *           If there is a problem getting info from HDFS\n   */\n  private void refreshDirectory(HdfsDirectory dir) throws IOException {\n    Map<FileStatus,BlockLocation[]> directoryCache = cache.get(dir);\n    Set<FileStatus> cachedStatuses = directoryCache.keySet();\n\n    FileSystem fs = dir.getFileSystem();\n    FileStatus[] statuses = fs.listStatus(dir.getHdfsDirPath());\n    List<FileStatus> statusList = Arrays.asList(statuses);\n\n    logger.debug(\"Updating locality information for: {}\", statusList);\n\n    // Keep only the files that still exist\n    cachedStatuses.retainAll(statusList);\n\n    // Fill in missing entries in the cache\n    for (FileStatus status : statusList) {\n      if (!status.isDirectory() && !directoryCache.containsKey(status)) {\n        BlockLocation[] locations = fs.getFileBlockLocations(status, 0, status.getLen());\n        directoryCache.put(status, locations);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1ce8283f367b946e5dd6300887294d7d115f2b9f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c80f6f4fe2e841ba56e6ce200951063ab91196d3":["1ce8283f367b946e5dd6300887294d7d115f2b9f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c80f6f4fe2e841ba56e6ce200951063ab91196d3"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1ce8283f367b946e5dd6300887294d7d115f2b9f"],"1ce8283f367b946e5dd6300887294d7d115f2b9f":["c80f6f4fe2e841ba56e6ce200951063ab91196d3"],"c80f6f4fe2e841ba56e6ce200951063ab91196d3":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}