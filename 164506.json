{"path":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","commits":[{"id":"e147cce225492338f15a94a427f51f867da574ee","date":1346365916,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"/dev/null","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, 0x0);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["a5cd9341c578f132de886964218bbefe52bdcd83"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"/dev/null","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, 0x0);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, 0x0);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, 0x0);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0beaed456aa3358e5e4a99ea2aea994ef6c81de3","date":1365434191,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      // TODO: performance implications of using indexedToReadable?\n      CharsRef ref = new CharsRef(term.length);\n      ref = field.getType().indexedToReadable(term, ref);\n      int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      int hash = Hash.murmurhash3_x86_32(term.bytes, term.offset, term.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":["a5cd9341c578f132de886964218bbefe52bdcd83"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7ba13b1e8eb54daafdac40183a898b820ac9f73b","date":1365684595,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      // TODO: performance implications of using indexedToReadable?\n      CharsRef ref = new CharsRef(term.length);\n      ref = field.getType().indexedToReadable(term, ref);\n      int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[ranges.size()];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      // TODO: performance implications of using indexedToReadable?\n      CharsRef ref = new CharsRef(term.length);\n      ref = field.getType().indexedToReadable(term, ref);\n      int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n          if (rangesArr[i].includes(hash)) {\n            docSets[i].fastSet(doc);\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a5cd9341c578f132de886964218bbefe52bdcd83","date":1368036656,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null);\n      }\n      // int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n      // TODO: hook in custom hashes (or store hashes)\n      // TODO: performance implications of using indexedToReadable?\n      CharsRef ref = new CharsRef(term.length);\n      ref = field.getType().indexedToReadable(term, ref);\n      int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":["e147cce225492338f15a94a427f51f867da574ee","0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cdd2d639986db5a5a6f3703a8b4136a6473a5f81","date":1376372957,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n      // int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null);\n      }\n      // int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n      // int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null);\n      }\n      // int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbe8b2974b783dfe1b0160f39e4de0315fa51adb","date":1382029739,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      if (splitKey != null) {\n        // todo have composite routers support these kind of things instead\n        String part1 = getRouteKey(idString);\n        if (part1 == null)\n          continue;\n        if (!splitKey.equals(part1))  {\n          continue;\n        }\n      }\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n      // int hash = Hash.murmurhash3_x86_32(ref, ref.offset, ref.length, 0);\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a69cf7f1b4cac5d5b1363402b565cd535f13e6a1","date":1392536197,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  FixedBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    FixedBitSet[] docSets = new FixedBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new FixedBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      if (splitKey != null) {\n        // todo have composite routers support these kind of things instead\n        String part1 = getRouteKey(idString);\n        if (part1 == null)\n          continue;\n        if (!splitKey.equals(part1))  {\n          continue;\n        }\n      }\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocIdSetIterator.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].set(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].set(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  OpenBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    OpenBitSet[] docSets = new OpenBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new OpenBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      if (splitKey != null) {\n        // todo have composite routers support these kind of things instead\n        String part1 = getRouteKey(idString);\n        if (part1 == null)\n          continue;\n        if (!splitKey.equals(part1))  {\n          continue;\n        }\n      }\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocsEnum.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].fastSet(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].fastSet(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":"  FixedBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    FixedBitSet[] docSets = new FixedBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new FixedBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRefBuilder idRef = new CharsRefBuilder();\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      if (splitKey != null) {\n        // todo have composite routers support these kind of things instead\n        String part1 = getRouteKey(idString);\n        if (part1 == null)\n          continue;\n        if (!splitKey.equals(part1))  {\n          continue;\n        }\n      }\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocIdSetIterator.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].set(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].set(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","sourceOld":"  FixedBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    FixedBitSet[] docSets = new FixedBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new FixedBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRef idRef = new CharsRef(100);\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      idRef = field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      if (splitKey != null) {\n        // todo have composite routers support these kind of things instead\n        String part1 = getRouteKey(idString);\n        if (part1 == null)\n          continue;\n        if (!splitKey.equals(part1))  {\n          continue;\n        }\n      }\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocIdSetIterator.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].set(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].set(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":["a5cd9341c578f132de886964218bbefe52bdcd83"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":4,"author":"Ryan Ernst","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/update/SolrIndexSplitter#split(AtomicReaderContext).mjava","sourceNew":null,"sourceOld":"  FixedBitSet[] split(AtomicReaderContext readerContext) throws IOException {\n    AtomicReader reader = readerContext.reader();\n    FixedBitSet[] docSets = new FixedBitSet[numPieces];\n    for (int i=0; i<docSets.length; i++) {\n      docSets[i] = new FixedBitSet(reader.maxDoc());\n    }\n    Bits liveDocs = reader.getLiveDocs();\n\n    Fields fields = reader.fields();\n    Terms terms = fields==null ? null : fields.terms(field.getName());\n    TermsEnum termsEnum = terms==null ? null : terms.iterator(null);\n    if (termsEnum == null) return docSets;\n\n    BytesRef term = null;\n    DocsEnum docsEnum = null;\n\n    CharsRefBuilder idRef = new CharsRefBuilder();\n    for (;;) {\n      term = termsEnum.next();\n      if (term == null) break;\n\n      // figure out the hash for the term\n\n      // FUTURE: if conversion to strings costs too much, we could\n      // specialize and use the hash function that can work over bytes.\n      field.getType().indexedToReadable(term, idRef);\n      String idString = idRef.toString();\n\n      if (splitKey != null) {\n        // todo have composite routers support these kind of things instead\n        String part1 = getRouteKey(idString);\n        if (part1 == null)\n          continue;\n        if (!splitKey.equals(part1))  {\n          continue;\n        }\n      }\n\n      int hash = 0;\n      if (hashRouter != null) {\n        hash = hashRouter.sliceHash(idString, null, null, null);\n      }\n\n      docsEnum = termsEnum.docs(liveDocs, docsEnum, DocsEnum.FLAG_NONE);\n      for (;;) {\n        int doc = docsEnum.nextDoc();\n        if (doc == DocIdSetIterator.NO_MORE_DOCS) break;\n        if (ranges == null) {\n          docSets[currPartition].set(doc);\n          currPartition = (currPartition + 1) % numPieces;\n        } else  {\n          for (int i=0; i<rangesArr.length; i++) {      // inner-loop: use array here for extra speed.\n            if (rangesArr[i].includes(hash)) {\n              docSets[i].set(doc);\n            }\n          }\n        }\n      }\n    }\n\n    return docSets;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["e147cce225492338f15a94a427f51f867da574ee","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"fbe8b2974b783dfe1b0160f39e4de0315fa51adb":["cdd2d639986db5a5a6f3703a8b4136a6473a5f81"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["a5cd9341c578f132de886964218bbefe52bdcd83","cdd2d639986db5a5a6f3703a8b4136a6473a5f81"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["a69cf7f1b4cac5d5b1363402b565cd535f13e6a1"],"e147cce225492338f15a94a427f51f867da574ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e147cce225492338f15a94a427f51f867da574ee"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a69cf7f1b4cac5d5b1363402b565cd535f13e6a1":["fbe8b2974b783dfe1b0160f39e4de0315fa51adb"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["e147cce225492338f15a94a427f51f867da574ee"],"a5cd9341c578f132de886964218bbefe52bdcd83":["7ba13b1e8eb54daafdac40183a898b820ac9f73b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cdd2d639986db5a5a6f3703a8b4136a6473a5f81":["a5cd9341c578f132de886964218bbefe52bdcd83"],"7ba13b1e8eb54daafdac40183a898b820ac9f73b":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9fb5f46e264daf5ba3860defe623a89d202dd87"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"fbe8b2974b783dfe1b0160f39e4de0315fa51adb":["a69cf7f1b4cac5d5b1363402b565cd535f13e6a1"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"e147cce225492338f15a94a427f51f867da574ee":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","05a14b2611ead08655a2b2bdc61632eb31316e57","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["7ba13b1e8eb54daafdac40183a898b820ac9f73b"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"a69cf7f1b4cac5d5b1363402b565cd535f13e6a1":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a5cd9341c578f132de886964218bbefe52bdcd83":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cdd2d639986db5a5a6f3703a8b4136a6473a5f81"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e147cce225492338f15a94a427f51f867da574ee","05a14b2611ead08655a2b2bdc61632eb31316e57"],"cdd2d639986db5a5a6f3703a8b4136a6473a5f81":["fbe8b2974b783dfe1b0160f39e4de0315fa51adb","3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"7ba13b1e8eb54daafdac40183a898b820ac9f73b":["a5cd9341c578f132de886964218bbefe52bdcd83"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","05a14b2611ead08655a2b2bdc61632eb31316e57","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}