{"path":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","commits":[{"id":"11f75174865a8734695cd60a4093339a4e63fcbb","date":1323039567,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"/dev/null","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = info.getNormFileName(fi.number);\n          Directory d = info.hasSeparateNorms(fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.put(singleNormStream, Boolean.TRUE);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.put(normInput, Boolean.TRUE);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // nocommit: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles.keySet());\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"10acb7e55ffd7d041a1028653d0defa4a50bfec3","date":1323041492,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.put(singleNormStream, Boolean.TRUE);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.put(normInput, Boolean.TRUE);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // nocommit: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles.keySet());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = info.getNormFileName(fi.number);\n          Directory d = info.hasSeparateNorms(fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.put(singleNormStream, Boolean.TRUE);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.put(normInput, Boolean.TRUE);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // nocommit: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles.keySet());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"091eda9854cc9e0ece4516ce6bc0bcac3a10226a","date":1323046561,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.put(singleNormStream, Boolean.TRUE);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.put(normInput, Boolean.TRUE);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // nocommit: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles.keySet());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.put(singleNormStream, Boolean.TRUE);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.put(normInput, Boolean.TRUE);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // nocommit: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles.keySet());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d6c554455db6752562dfe09614cdf3fd06062c3","date":1323301343,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.put(singleNormStream, Boolean.TRUE);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.put(normInput, Boolean.TRUE);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // nocommit: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles.keySet());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"968c91176bd0af7259bb4d6ae6f15ab0b530d613","date":1323302672,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        if (openFiles != null) {\n          IOUtils.closeWhileHandlingException(openFiles);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"/dev/null","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"/dev/null","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"10acb7e55ffd7d041a1028653d0defa4a50bfec3":["11f75174865a8734695cd60a4093339a4e63fcbb"],"11f75174865a8734695cd60a4093339a4e63fcbb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","968c91176bd0af7259bb4d6ae6f15ab0b530d613"],"7d6c554455db6752562dfe09614cdf3fd06062c3":["091eda9854cc9e0ece4516ce6bc0bcac3a10226a"],"968c91176bd0af7259bb4d6ae6f15ab0b530d613":["7d6c554455db6752562dfe09614cdf3fd06062c3"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"091eda9854cc9e0ece4516ce6bc0bcac3a10226a":["10acb7e55ffd7d041a1028653d0defa4a50bfec3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"10acb7e55ffd7d041a1028653d0defa4a50bfec3":["091eda9854cc9e0ece4516ce6bc0bcac3a10226a"],"11f75174865a8734695cd60a4093339a4e63fcbb":["10acb7e55ffd7d041a1028653d0defa4a50bfec3"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["11f75174865a8734695cd60a4093339a4e63fcbb","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"7d6c554455db6752562dfe09614cdf3fd06062c3":["968c91176bd0af7259bb4d6ae6f15ab0b530d613"],"968c91176bd0af7259bb4d6ae6f15ab0b530d613":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"091eda9854cc9e0ece4516ce6bc0bcac3a10226a":["7d6c554455db6752562dfe09614cdf3fd06062c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}