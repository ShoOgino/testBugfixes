{"path":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","commits":[{"id":"8493925b2e70246f0961df584c01a8c2e61ee52f","date":1523611602,"type":0,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","pathOld":"/dev/null","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c6453827f947004a68ad9db7418781e9df2f660","date":1523626811,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","pathOld":"/dev/null","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"12136ebc45a29f27a6ab47b007873d0f630f8d11","date":1540542517,"type":3,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3010cab237afb0b81c042f263115756e3cc6d67","date":1564503244,"type":5,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":5,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"12136ebc45a29f27a6ab47b007873d0f630f8d11":["5c6453827f947004a68ad9db7418781e9df2f660"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8493925b2e70246f0961df584c01a8c2e61ee52f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e3010cab237afb0b81c042f263115756e3cc6d67":["12136ebc45a29f27a6ab47b007873d0f630f8d11"],"f8061ddd97f3352007d927dae445884a6f3d857b":["12136ebc45a29f27a6ab47b007873d0f630f8d11","e3010cab237afb0b81c042f263115756e3cc6d67"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e3010cab237afb0b81c042f263115756e3cc6d67"],"5c6453827f947004a68ad9db7418781e9df2f660":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8493925b2e70246f0961df584c01a8c2e61ee52f"]},"commit2Childs":{"12136ebc45a29f27a6ab47b007873d0f630f8d11":["e3010cab237afb0b81c042f263115756e3cc6d67","f8061ddd97f3352007d927dae445884a6f3d857b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8493925b2e70246f0961df584c01a8c2e61ee52f","5c6453827f947004a68ad9db7418781e9df2f660"],"8493925b2e70246f0961df584c01a8c2e61ee52f":["5c6453827f947004a68ad9db7418781e9df2f660"],"e3010cab237afb0b81c042f263115756e3cc6d67":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"5c6453827f947004a68ad9db7418781e9df2f660":["12136ebc45a29f27a6ab47b007873d0f630f8d11"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}