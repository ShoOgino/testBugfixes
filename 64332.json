{"path":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","commits":[{"id":"a076c3c721f685b7559308fdc2cd72d91bba67e5","date":1464168992,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","sourceNew":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","sourceOld":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e121d43b5a10f2df530f406f935102656e9c4e8","date":1464198131,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","sourceNew":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","sourceOld":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83870855d82aba6819217abeff5a40779dbb28b4","date":1464291012,"type":1,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","sourceNew":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","sourceOld":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","pathOld":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","sourceNew":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix));\n    return dto.iterator(reader);\n  }\n\n","sourceOld":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","pathOld":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","sourceNew":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix));\n    return dto.iterator(reader);\n  }\n\n","sourceOld":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix), false);\n    return dto.iterator(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/FieldCacheImpl#getDocTermOrds(LeafReader,String,BytesRef).mjava","pathOld":"/dev/null","sourceNew":"  // TODO: this if DocTermsIndex was already created, we\n  // should share it...\n  public SortedSetDocValues getDocTermOrds(LeafReader reader, String field, BytesRef prefix) throws IOException {\n    // not a general purpose filtering mechanism...\n    assert prefix == null || prefix == INT32_TERM_PREFIX || prefix == INT64_TERM_PREFIX;\n    \n    SortedSetDocValues dv = reader.getSortedSetDocValues(field);\n    if (dv != null) {\n      return dv;\n    }\n    \n    SortedDocValues sdv = reader.getSortedDocValues(field);\n    if (sdv != null) {\n      return DocValues.singleton(sdv);\n    }\n    \n    final FieldInfo info = reader.getFieldInfos().fieldInfo(field);\n    if (info == null) {\n      return DocValues.emptySortedSet();\n    } else if (info.getDocValuesType() != DocValuesType.NONE) {\n      throw new IllegalStateException(\"Type mismatch: \" + field + \" was indexed as \" + info.getDocValuesType());\n    } else if (info.getIndexOptions() == IndexOptions.NONE) {\n      return DocValues.emptySortedSet();\n    }\n    \n    // ok we need to uninvert. check if we can optimize a bit.\n    \n    Terms terms = reader.terms(field);\n    if (terms == null) {\n      return DocValues.emptySortedSet();\n    } else {\n      // if #postings = #docswithfield we know that the field is \"single valued enough\".\n      // it's possible the same term might appear twice in the same document, but SORTED_SET discards frequency.\n      // it's still ok with filtering (which we limit to numerics), it just means precisionStep = Inf\n      long numPostings = terms.getSumDocFreq();\n      if (numPostings != -1 && numPostings == terms.getDocCount()) {\n        return DocValues.singleton(getTermsIndex(reader, field));\n      }\n    }\n    \n    DocTermOrds dto = (DocTermOrds) caches.get(DocTermOrds.class).get(reader, new CacheKey(field, prefix));\n    return dto.iterator(reader);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a076c3c721f685b7559308fdc2cd72d91bba67e5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a076c3c721f685b7559308fdc2cd72d91bba67e5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["0e121d43b5a10f2df530f406f935102656e9c4e8","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"83870855d82aba6819217abeff5a40779dbb28b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0e121d43b5a10f2df530f406f935102656e9c4e8"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"]},"commit2Childs":{"a076c3c721f685b7559308fdc2cd72d91bba67e5":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d","83870855d82aba6819217abeff5a40779dbb28b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a076c3c721f685b7559308fdc2cd72d91bba67e5","0e121d43b5a10f2df530f406f935102656e9c4e8","83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"83870855d82aba6819217abeff5a40779dbb28b4":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}