{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ab99e8c71442b92c320e218141dee04a9b91ce8","date":1269203801,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28427ef110c4c5bf5b4057731b83110bd1e13724","date":1276701452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      TermDocs tdocs = reader.termDocs(new Term(\"field\", \"aaa\"));\n      int count = 0;\n      while(tdocs.next()) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = newDirectory(random);\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory(random);\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = newDirectory(random);\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory(random);\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84b590669deb3d3a471cec6cb13b104b2ee94418","date":1288889547,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads#testCloseWithThreads().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCloseWithThreads().mjava","sourceNew":null,"sourceOld":"  // LUCENE-1130: make sure we can close() even while\n  // threads are trying to add documents.  Strictly\n  // speaking, this isn't valid us of Lucene's APIs, but we\n  // still want to be robust to this case:\n  public void testCloseWithThreads() throws Exception {\n    int NUM_THREADS = 3;\n\n    for(int iter=0;iter<7;iter++) {\n      MockRAMDirectory dir = new MockRAMDirectory();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n      // We expect AlreadyClosedException\n      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();\n      IndexWriter writer = new IndexWriter(dir, conf);\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      IndexerThread[] threads = new IndexerThread[NUM_THREADS];\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i] = new IndexerThread(writer, false);\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      boolean done = false;\n      while(!done) {\n        Thread.sleep(100);\n        for(int i=0;i<NUM_THREADS;i++)\n          // only stop when at least one thread has added a doc\n          if (threads[i].addCount > 0) {\n            done = true;\n            break;\n          }\n      }\n\n      writer.close(false);\n\n      // Make sure threads that are adding docs are not hung:\n      for(int i=0;i<NUM_THREADS;i++) {\n        // Without fix for LUCENE-1130: one of the\n        // threads will hang\n        threads[i].join();\n        if (threads[i].isAlive())\n          fail(\"thread seems to be hung\");\n      }\n\n      // Quick test to make sure index is not corrupt:\n      IndexReader reader = IndexReader.open(dir, true);\n      DocsEnum tdocs = MultiFields.getTermDocsEnum(reader,\n                                                  MultiFields.getDeletedDocs(reader),\n                                                  \"field\",\n                                                  new BytesRef(\"aaa\"));\n      int count = 0;\n      while(tdocs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        count++;\n      }\n      assertTrue(count > 0);\n      reader.close();\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"7ab99e8c71442b92c320e218141dee04a9b91ce8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"85a883878c0af761245ab048babc63d099f835f3":["1f653cfcf159baeaafe5d01682a911e95bba4012","84b590669deb3d3a471cec6cb13b104b2ee94418"],"d572389229127c297dd1fa5ce4758e1cec41e799":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"5f4e87790277826a2aea119328600dfb07761f32":["d572389229127c297dd1fa5ce4758e1cec41e799","28427ef110c4c5bf5b4057731b83110bd1e13724"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","84b590669deb3d3a471cec6cb13b104b2ee94418"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["d572389229127c297dd1fa5ce4758e1cec41e799"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["84b590669deb3d3a471cec6cb13b104b2ee94418"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"7ab99e8c71442b92c320e218141dee04a9b91ce8":["d572389229127c297dd1fa5ce4758e1cec41e799"],"85a883878c0af761245ab048babc63d099f835f3":[],"d572389229127c297dd1fa5ce4758e1cec41e799":["5f4e87790277826a2aea119328600dfb07761f32","28427ef110c4c5bf5b4057731b83110bd1e13724"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"84b590669deb3d3a471cec6cb13b104b2ee94418":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["85a883878c0af761245ab048babc63d099f835f3","84b590669deb3d3a471cec6cb13b104b2ee94418"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["5f4e87790277826a2aea119328600dfb07761f32","b21422ff1d1d56499dec481f193b402e5e8def5b"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}