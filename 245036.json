{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","commits":[{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.dir.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.dir.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ede45a461a2dcb573505ed9b6a5182dfebd3688f","date":1353338494,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.dir.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.dir.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","bugFix":["7b91922b55d15444d554721b352861d028eb8278"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a93d0c51fc69418718fea466699e1790d145ae32","date":1378756747,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<String,TermsReader>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n    CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n    CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2f1be37edabc0456a3eb6d87ac545671bd8573b","date":1408837718,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n    CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0936055c0eed56be3e4ae5c9db5b0e355390736a","date":1410874015,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6fa5babdf54832351c1e9c77942f3d8402acf793","date":1412436540,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkSegmentHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkSegmentHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n    final ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try {\n      CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);\n      while(true) {\n        final int termCount = in.readVInt();\n        if (termCount == 0) {\n          break;\n        }\n        final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n        // System.out.println(\"load field=\" + termsReader.field.name);\n        fields.put(termsReader.field.name, termsReader);\n      }\n      CodecUtil.checkFooter(in);\n    } finally {\n      in.close();\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkSegmentHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkSegmentHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fca6c8418a91a6d30730ad418791ddf59ec3d07a","date":1418666585,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<? extends Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ba6ae8e3c153347cbb605024ca7550f5c91b178","date":1420215916,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Collection<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Iterable<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f226a8b088dd9c8f6ab287a77237c4aa00a238e5","date":1456187572,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * Character.BYTES);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Collection<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Collection<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"419a8f52c6635419beb951255cacbbb281044c57","date":1456189353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * Character.BYTES);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Collection<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * RamUsageEstimator.NUM_BYTES_CHAR);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Collection<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24f89e8a6aac05753cde4c83d62a74356098200d","date":1525768331,"type":4,"author":"Dawid Weiss","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":null,"sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, EXTENSION);\n\n    final SortedMap<String,TermsReader> fields = new TreeMap<>();\n\n    try (ChecksumIndexInput in = state.directory.openChecksumInput(fileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        CodecUtil.checkIndexHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        while(true) {\n          final int termCount = in.readVInt();\n          if (termCount == 0) {\n            break;\n          }\n          final TermsReader termsReader = new TermsReader(state.fieldInfos, in, termCount);\n          // System.out.println(\"load field=\" + termsReader.field.name);\n          fields.put(termsReader.field.name, termsReader);\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(in, priorE);\n      }\n    }\n\n    return new FieldsProducer() {\n      @Override\n      public Iterator<String> iterator() {\n        return Collections.unmodifiableSet(fields.keySet()).iterator();\n      }\n\n      @Override\n      public Terms terms(String field) {\n        return fields.get(field);\n      }\n      \n      @Override\n      public int size() {\n        return fields.size();\n      }\n\n      @Override\n      public void close() {\n        // Drop ref to FST:\n        for(TermsReader termsReader : fields.values()) {\n          termsReader.fst = null;\n        }\n      }\n\n      @Override\n      public long ramBytesUsed() {\n        long sizeInBytes = 0;\n        for(Map.Entry<String,TermsReader> entry: fields.entrySet()) {\n          sizeInBytes += (entry.getKey().length() * Character.BYTES);\n          sizeInBytes += entry.getValue().ramBytesUsed();\n        }\n        return sizeInBytes;\n      }\n\n      @Override\n      public Collection<Accountable> getChildResources() {\n        return Accountables.namedAccountables(\"field\", fields);\n      }\n\n      @Override\n      public String toString() {\n        return \"MemoryPostings(fields=\" + fields.size() + \")\";\n      }\n\n      @Override\n      public void checkIntegrity() throws IOException {}\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["a93d0c51fc69418718fea466699e1790d145ae32"],"ede45a461a2dcb573505ed9b6a5182dfebd3688f":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"fca6c8418a91a6d30730ad418791ddf59ec3d07a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"419a8f52c6635419beb951255cacbbb281044c57":["8ba6ae8e3c153347cbb605024ca7550f5c91b178","f226a8b088dd9c8f6ab287a77237c4aa00a238e5"],"f226a8b088dd9c8f6ab287a77237c4aa00a238e5":["8ba6ae8e3c153347cbb605024ca7550f5c91b178"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["6fa5babdf54832351c1e9c77942f3d8402acf793"],"d2f1be37edabc0456a3eb6d87ac545671bd8573b":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"a93d0c51fc69418718fea466699e1790d145ae32":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"8ba6ae8e3c153347cbb605024ca7550f5c91b178":["fca6c8418a91a6d30730ad418791ddf59ec3d07a"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","ede45a461a2dcb573505ed9b6a5182dfebd3688f"],"24f89e8a6aac05753cde4c83d62a74356098200d":["419a8f52c6635419beb951255cacbbb281044c57"],"9bb9a29a5e71a90295f175df8919802993142c9a":["0936055c0eed56be3e4ae5c9db5b0e355390736a","6fa5babdf54832351c1e9c77942f3d8402acf793"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["d2f1be37edabc0456a3eb6d87ac545671bd8573b"],"6fa5babdf54832351c1e9c77942f3d8402acf793":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["24f89e8a6aac05753cde4c83d62a74356098200d"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","d2f1be37edabc0456a3eb6d87ac545671bd8573b"],"ede45a461a2dcb573505ed9b6a5182dfebd3688f":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"fca6c8418a91a6d30730ad418791ddf59ec3d07a":["8ba6ae8e3c153347cbb605024ca7550f5c91b178"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["ede45a461a2dcb573505ed9b6a5182dfebd3688f","d4d69c535930b5cce125cff868d40f6373dc27d4"],"419a8f52c6635419beb951255cacbbb281044c57":["24f89e8a6aac05753cde4c83d62a74356098200d"],"f226a8b088dd9c8f6ab287a77237c4aa00a238e5":["419a8f52c6635419beb951255cacbbb281044c57"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"d2f1be37edabc0456a3eb6d87ac545671bd8573b":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"a93d0c51fc69418718fea466699e1790d145ae32":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"8ba6ae8e3c153347cbb605024ca7550f5c91b178":["419a8f52c6635419beb951255cacbbb281044c57","f226a8b088dd9c8f6ab287a77237c4aa00a238e5"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a93d0c51fc69418718fea466699e1790d145ae32"],"24f89e8a6aac05753cde4c83d62a74356098200d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["fca6c8418a91a6d30730ad418791ddf59ec3d07a"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["9bb9a29a5e71a90295f175df8919802993142c9a","6fa5babdf54832351c1e9c77942f3d8402acf793"],"6fa5babdf54832351c1e9c77942f3d8402acf793":["3384e6013a93e4d11b7d75388693f8d0388602bf","9bb9a29a5e71a90295f175df8919802993142c9a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}