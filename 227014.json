{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs#testAddTooManyIndexesDir().mjava","commits":[{"id":"98b44240f64a2d6935543ff25faee750b29204eb","date":1424972040,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs#testAddTooManyIndexesDir().mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * LUCENE-6299: Test if addindexes(Dir[]) prevents exceeding max docs.\n   */\n  public void testAddTooManyIndexesDir() throws Exception {\n    // we cheat and add the same one over again... IW wants a write lock on each\n    Directory dir = newDirectory(random(), NoLockFactory.INSTANCE);\n    Document doc = new Document();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(null));\n    for (int i = 0; i < 100000; i++) {\n      w.addDocument(doc);\n    }\n    w.forceMerge(1);\n    w.commit();\n    w.close();\n    \n    // wrap this with disk full, so test fails faster and doesn't fill up real disks.\n    MockDirectoryWrapper dir2 = newMockDirectory();\n    w = new IndexWriter(dir2, new IndexWriterConfig(null));\n    w.commit(); // don't confuse checkindex\n    dir2.setMaxSizeInBytes(dir2.sizeInBytes() + 65536); // 64KB\n    Directory dirs[] = new Directory[1 + (IndexWriter.MAX_DOCS / 100000)];\n    for (int i = 0; i < dirs.length; i++) {\n      // bypass iw check for duplicate dirs\n      dirs[i] = new FilterDirectory(dir) {};\n    }\n\n    try {\n      w.addIndexes(dirs);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {\n      // pass\n    } catch (IOException fakeDiskFull) {\n      final Exception e;\n      if (fakeDiskFull.getMessage() != null && fakeDiskFull.getMessage().startsWith(\"fake disk full\")) {\n        e = new RuntimeException(\"test failed: IW checks aren't working and we are executing addIndexes\");\n        e.addSuppressed(fakeDiskFull);\n      } else {\n        e = fakeDiskFull;\n      }\n      throw e;\n    }\n    \n    w.close();\n    dir.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"98a04f56464afdffd4c430d6c47a0c868a38354e","date":1424985833,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs#testAddTooManyIndexesDir().mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * LUCENE-6299: Test if addindexes(Dir[]) prevents exceeding max docs.\n   */\n  public void testAddTooManyIndexesDir() throws Exception {\n    // we cheat and add the same one over again... IW wants a write lock on each\n    Directory dir = newDirectory(random(), NoLockFactory.INSTANCE);\n    Document doc = new Document();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(null));\n    for (int i = 0; i < 100000; i++) {\n      w.addDocument(doc);\n    }\n    w.forceMerge(1);\n    w.commit();\n    w.close();\n    \n    // wrap this with disk full, so test fails faster and doesn't fill up real disks.\n    MockDirectoryWrapper dir2 = newMockDirectory();\n    w = new IndexWriter(dir2, new IndexWriterConfig(null));\n    w.commit(); // don't confuse checkindex\n    dir2.setMaxSizeInBytes(dir2.sizeInBytes() + 65536); // 64KB\n    Directory dirs[] = new Directory[1 + (IndexWriter.MAX_DOCS / 100000)];\n    for (int i = 0; i < dirs.length; i++) {\n      // bypass iw check for duplicate dirs\n      dirs[i] = new FilterDirectory(dir) {};\n    }\n\n    try {\n      w.addIndexes(dirs);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {\n      // pass\n    } catch (IOException fakeDiskFull) {\n      final Exception e;\n      if (fakeDiskFull.getMessage() != null && fakeDiskFull.getMessage().startsWith(\"fake disk full\")) {\n        e = new RuntimeException(\"test failed: IW checks aren't working and we are executing addIndexes\");\n        e.addSuppressed(fakeDiskFull);\n      } else {\n        e = fakeDiskFull;\n      }\n      throw e;\n    }\n    \n    w.close();\n    dir.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs#testAddTooManyIndexesDir().mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * LUCENE-6299: Test if addindexes(Dir[]) prevents exceeding max docs.\n   */\n  public void testAddTooManyIndexesDir() throws Exception {\n    // we cheat and add the same one over again... IW wants a write lock on each\n    Directory dir = newDirectory(random(), NoLockFactory.INSTANCE);\n    Document doc = new Document();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(null));\n    for (int i = 0; i < 100000; i++) {\n      w.addDocument(doc);\n    }\n    w.forceMerge(1);\n    w.commit();\n    w.close();\n    \n    // wrap this with disk full, so test fails faster and doesn't fill up real disks.\n    MockDirectoryWrapper dir2 = newMockDirectory();\n    w = new IndexWriter(dir2, new IndexWriterConfig(null));\n    w.commit(); // don't confuse checkindex\n    dir2.setMaxSizeInBytes(dir2.sizeInBytes() + 65536); // 64KB\n    Directory dirs[] = new Directory[1 + (IndexWriter.MAX_DOCS / 100000)];\n    for (int i = 0; i < dirs.length; i++) {\n      // bypass iw check for duplicate dirs\n      dirs[i] = new FilterDirectory(dir) {};\n    }\n\n    try {\n      w.addIndexes(dirs);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {\n      // pass\n    } catch (IOException fakeDiskFull) {\n      final Exception e;\n      if (fakeDiskFull.getMessage() != null && fakeDiskFull.getMessage().startsWith(\"fake disk full\")) {\n        e = new RuntimeException(\"test failed: IW checks aren't working and we are executing addIndexes\");\n        e.addSuppressed(fakeDiskFull);\n      } else {\n        e = fakeDiskFull;\n      }\n      throw e;\n    }\n    \n    w.close();\n    dir.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71da933d30aea361ccc224d6544c451cbf49916d","date":1579874339,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs#testAddTooManyIndexesDir().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs#testAddTooManyIndexesDir().mjava","sourceNew":"  /** \n   * LUCENE-6299: Test if addindexes(Dir[]) prevents exceeding max docs.\n   */\n  // TODO: can we use the setter to lower the amount of docs to be written here?\n  @Nightly\n  public void testAddTooManyIndexesDir() throws Exception {\n    // we cheat and add the same one over again... IW wants a write lock on each\n    Directory dir = newDirectory(random(), NoLockFactory.INSTANCE);\n    Document doc = new Document();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(null));\n    for (int i = 0; i < 100000; i++) {\n      w.addDocument(doc);\n    }\n    w.forceMerge(1);\n    w.commit();\n    w.close();\n    \n    // wrap this with disk full, so test fails faster and doesn't fill up real disks.\n    MockDirectoryWrapper dir2 = newMockDirectory();\n    w = new IndexWriter(dir2, new IndexWriterConfig(null));\n    w.commit(); // don't confuse checkindex\n    dir2.setMaxSizeInBytes(dir2.sizeInBytes() + 65536); // 64KB\n    Directory dirs[] = new Directory[1 + (IndexWriter.MAX_DOCS / 100000)];\n    for (int i = 0; i < dirs.length; i++) {\n      // bypass iw check for duplicate dirs\n      dirs[i] = new FilterDirectory(dir) {};\n    }\n\n    try {\n      w.addIndexes(dirs);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {\n      // pass\n    } catch (IOException fakeDiskFull) {\n      final Exception e;\n      if (fakeDiskFull.getMessage() != null && fakeDiskFull.getMessage().startsWith(\"fake disk full\")) {\n        e = new RuntimeException(\"test failed: IW checks aren't working and we are executing addIndexes\");\n        e.addSuppressed(fakeDiskFull);\n      } else {\n        e = fakeDiskFull;\n      }\n      throw e;\n    }\n    \n    w.close();\n    dir.close();\n    dir2.close();\n  }\n\n","sourceOld":"  /** \n   * LUCENE-6299: Test if addindexes(Dir[]) prevents exceeding max docs.\n   */\n  public void testAddTooManyIndexesDir() throws Exception {\n    // we cheat and add the same one over again... IW wants a write lock on each\n    Directory dir = newDirectory(random(), NoLockFactory.INSTANCE);\n    Document doc = new Document();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(null));\n    for (int i = 0; i < 100000; i++) {\n      w.addDocument(doc);\n    }\n    w.forceMerge(1);\n    w.commit();\n    w.close();\n    \n    // wrap this with disk full, so test fails faster and doesn't fill up real disks.\n    MockDirectoryWrapper dir2 = newMockDirectory();\n    w = new IndexWriter(dir2, new IndexWriterConfig(null));\n    w.commit(); // don't confuse checkindex\n    dir2.setMaxSizeInBytes(dir2.sizeInBytes() + 65536); // 64KB\n    Directory dirs[] = new Directory[1 + (IndexWriter.MAX_DOCS / 100000)];\n    for (int i = 0; i < dirs.length; i++) {\n      // bypass iw check for duplicate dirs\n      dirs[i] = new FilterDirectory(dir) {};\n    }\n\n    try {\n      w.addIndexes(dirs);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {\n      // pass\n    } catch (IOException fakeDiskFull) {\n      final Exception e;\n      if (fakeDiskFull.getMessage() != null && fakeDiskFull.getMessage().startsWith(\"fake disk full\")) {\n        e = new RuntimeException(\"test failed: IW checks aren't working and we are executing addIndexes\");\n        e.addSuppressed(fakeDiskFull);\n      } else {\n        e = fakeDiskFull;\n      }\n      throw e;\n    }\n    \n    w.close();\n    dir.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","98a04f56464afdffd4c430d6c47a0c868a38354e"],"98a04f56464afdffd4c430d6c47a0c868a38354e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","98b44240f64a2d6935543ff25faee750b29204eb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"98b44240f64a2d6935543ff25faee750b29204eb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71da933d30aea361ccc224d6544c451cbf49916d"],"71da933d30aea361ccc224d6544c451cbf49916d":["98a04f56464afdffd4c430d6c47a0c868a38354e"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"98a04f56464afdffd4c430d6c47a0c868a38354e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","71da933d30aea361ccc224d6544c451cbf49916d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","98a04f56464afdffd4c430d6c47a0c868a38354e","98b44240f64a2d6935543ff25faee750b29204eb"],"98b44240f64a2d6935543ff25faee750b29204eb":["98a04f56464afdffd4c430d6c47a0c868a38354e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"71da933d30aea361ccc224d6544c451cbf49916d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}