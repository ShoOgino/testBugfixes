{"path":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","commits":[{"id":"db36d4499cafd89fde36f3772ecc148d710071d8","date":1307128660,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c03daa6ddcb4768a702115ec63799cab5fff3d92","date":1307140842,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e7c99bd45fa88a3d93a03fdd773053bef72268e","date":1307218088,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random text\"));\n    doc.add(new Field(\"id\", customType, \"1\"));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text blob\"));\n    doc.add(new Field(\"id\", customType, \"2\"));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random textual data\"));\n    doc.add(new Field(\"id\", customType, \"3\"));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author2\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some random text\"));\n    doc.add(new Field(\"id\", customType, \"4\"));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text\"));\n    doc.add(new Field(\"id\", customType, \"5\"));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random blob\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random word stuck in alot of other text\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd","date":1317197236,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random text\"));\n    doc.add(new Field(\"id\", customType, \"1\"));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text blob\"));\n    doc.add(new Field(\"id\", customType, \"2\"));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random textual data\"));\n    doc.add(new Field(\"id\", customType, \"3\"));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author2\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some random text\"));\n    doc.add(new Field(\"id\", customType, \"4\"));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text\"));\n    doc.add(new Field(\"id\", customType, \"5\"));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random blob\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random word stuck in alot of other text\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00","date":1317931776,"type":5,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector c1 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AbstractAllGroupsCollector c2 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AbstractAllGroupsCollector c3 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["db36d4499cafd89fde36f3772ecc148d710071d8"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"db36d4499cafd89fde36f3772ecc148d710071d8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c03daa6ddcb4768a702115ec63799cab5fff3d92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","db36d4499cafd89fde36f3772ecc148d710071d8"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","db36d4499cafd89fde36f3772ecc148d710071d8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["db36d4499cafd89fde36f3772ecc148d710071d8","c03daa6ddcb4768a702115ec63799cab5fff3d92","1e7c99bd45fa88a3d93a03fdd773053bef72268e"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"db36d4499cafd89fde36f3772ecc148d710071d8":["1509f151d7692d84fae414b2b799ac06ba60fcb4","c03daa6ddcb4768a702115ec63799cab5fff3d92","1e7c99bd45fa88a3d93a03fdd773053bef72268e"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c03daa6ddcb4768a702115ec63799cab5fff3d92":[],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":[],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c03daa6ddcb4768a702115ec63799cab5fff3d92","1e7c99bd45fa88a3d93a03fdd773053bef72268e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}