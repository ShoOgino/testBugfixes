{"path":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","commits":[{"id":"2c30e4c1cee08b3b229a77991882594fe7250b66","date":1344448871,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"/dev/null","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":1,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6378064655e76cd7b908b1cab4ce425b384b508","date":1347656715,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1525b4dfbc0d413b8d7247da232009778e624836","date":1351101135,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9405f486872f1e416304dfe389741f4ee2f8a4d","date":1351276739,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // wait till live nodes drops by 1\n    int liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    int tries = 50;\n    while(oldLiveNodes == liveNodes) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"We expected a node to drop...\");\n      }\n      liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    }\n    assertEquals(4, liveNodes);\n\n    int cnt = 0;\n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard, cnt++);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":["a935e32f3b1ffa13f8c6bb6301853a05d2b01a89"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f2126b84bd093fa3d921582a109a0ee578c28126","date":1351522501,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // wait till live nodes drops by 1\n    int liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    int tries = 50;\n    while(oldLiveNodes == liveNodes) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"We expected a node to drop...\");\n      }\n      liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    }\n    assertEquals(4, liveNodes);\n\n    int cnt = 0;\n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard, cnt++);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a69439d0df009e0bb0038d1e427159f449dd670d","date":1355704683,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // wait till live nodes drops by 1\n    int liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    int tries = 50;\n    while(oldLiveNodes == liveNodes) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"We expected a node to drop...\");\n      }\n      liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    }\n    assertEquals(4, liveNodes);\n\n    int cnt = 0;\n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard, cnt++);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"40e1d548a3a5d44b9c73ac34a3e93a1d80b5cf41","date":1356021696,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"34efe37e5314525b1f3e373269e95bcdec2ceb2f","date":1357610514,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    System.out.println(\"base url: \"+ client.getBaseURL());\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    System.out.println(\"results:\" + results);\n    \n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":["7ea7454b4afcb5dc9f7504f83d77b134df2b7c57"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    System.out.println(\"base url: \"+ client.getBaseURL());\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    System.out.println(\"results:\" + results);\n    \n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // wait till live nodes drops by 1\n    int liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    int tries = 50;\n    while(oldLiveNodes == liveNodes) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"We expected a node to drop...\");\n      }\n      liveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    }\n    assertEquals(4, liveNodes);\n\n    int cnt = 0;\n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard, cnt++);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0c9480c6807676b2e3a9ed82b59395a98253bfe3","date":1362081860,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(4, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 15000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    printLayout();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    System.out.println(\"base url: \"+ client.getBaseURL());\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    System.out.println(\"results:\" + results);\n    \n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":["a935e32f3b1ffa13f8c6bb6301853a05d2b01a89"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"00fee1a12fd88b734d0a6f4ba0499eb0f1a17986","date":1362931485,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(4, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 30000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(4, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 15000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"981229bffd22692e7b375551d711a2ebde302ce2","date":1362951472,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 45000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(4, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 30000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2ba328f7d453c70b167d21f2e69104ea53703f0e","date":1363530959,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 45000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"52b83bf101b0cb676a87e2f49cdf679d4049c671","date":1363927165,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(15);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a935e32f3b1ffa13f8c6bb6301853a05d2b01a89","date":1388373865,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n    \n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD1));\n    jetties.remove(deadShard);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n    \n  }\n\n","bugFix":["0c9480c6807676b2e3a9ed82b59395a98253bfe3","d9405f486872f1e416304dfe389741f4ee2f8a4d","8a65836c18a62c7b1b404fcb1bba729fd4c29e81"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7ea7454b4afcb5dc9f7504f83d77b134df2b7c57","date":1391252295,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n    \n  }\n\n","bugFix":["34efe37e5314525b1f3e373269e95bcdec2ceb2f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eede925c2b8a6533ba1adf912aaff6a3d05d891","date":1392825224,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = TestUtil.createTempDir(LuceneTestCase.getTestClass().getSimpleName() + \"-backupdir\");\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1416f9d09d016a6894cd17e1caac137dad2bba59","date":1395941020,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(dataDir, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(TEMP_DIR, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb1f22cfa77230b5f05b7784feae5367f6bbb488","date":1395968145,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = TestUtil.createTempDir(LuceneTestCase.getTestClass().getSimpleName() + \"-backupdir\");\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = new File(dataDir, BasicDistributedZk2Test.class.getName() + \"-backupdir-\" + System.currentTimeMillis());\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir().toFile();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir().toFile();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir().toFile();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9e550c812db35e006a8eb3b5b092ffe2d8f5bb4d","date":1421017461,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir().toFile();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(45);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir().toFile();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5939c5b1ac54c5b24bd7dbcaf6c68b510470e2c6","date":1423132645,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    Path location = createTempDir();\n    location = FilterPath.unwrap(location).toRealPath();\n    params.set(\"location\", location.toString());\n\n    QueryRequest request = new QueryRequest(params);\n    client.request(request);\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    File location = createTempDir().toFile();\n    params.set(\"location\", location.getAbsolutePath());\n\n    QueryRequest request = new QueryRequest(params);\n    NamedList<Object> results = client.request(request );\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"71475d88ea48a7d9a847f209667255318b3ea4c7","date":1461758968,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", ReplicationHandler.PATH);\n    params.set(\"command\", \"backup\");\n    Path location = createTempDir();\n    location = FilterPath.unwrap(location).toRealPath();\n    params.set(\"location\", location.toString());\n\n    QueryRequest request = new QueryRequest(params);\n    client.request(request);\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", \"/replication\");\n    params.set(\"command\", \"backup\");\n    Path location = createTempDir();\n    location = FilterPath.unwrap(location).toRealPath();\n    params.set(\"location\", location.toString());\n\n    QueryRequest request = new QueryRequest(params);\n    client.request(request);\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","date":1466705968,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", ReplicationHandler.PATH);\n    params.set(\"command\", \"backup\");\n    Path location = createTempDir();\n    location = FilterPath.unwrap(location).toRealPath();\n    params.set(\"location\", location.toString());\n\n    QueryRequest request = new QueryRequest(params);\n    client.request(request);\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"qt\", ReplicationHandler.PATH);\n    params.set(\"command\", \"backup\");\n    Path location = createTempDir();\n    location = FilterPath.unwrap(location).toRealPath();\n    params.set(\"location\", location.toString());\n\n    QueryRequest request = new QueryRequest(params);\n    client.request(request);\n    \n    checkForBackupSuccess(client, location);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92f789dbd1886e4b468e61b0def88b29a3f55228","date":1533844010,"type":3,"author":"Jason Gerlowski","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n    \n    assertEquals(5, oldLiveNodes);\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n    \n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","bugFix":["6ef6348b84bf0f8a649826b69a70ac815ff560e2"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddee31af447625e4c8d45717e27ffa784cf4c70f","date":1544528712,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec54bd926c45854b5a1599685b0f7d2bfbfe177f","date":1573838246,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      final String backupName = \"the_backup\";\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      params.set(\"name\", backupName);\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n\n      final BackupStatusChecker backupStatus\n        = new BackupStatusChecker(client, \"/\" + DEFAULT_TEST_COLLECTION_NAME + \"/replication\");\n      final String backupDirName = backupStatus.waitForBackupSuccess(backupName, 30);\n      assertTrue(\"Backup dir does not exist: \" + backupDirName,\n                 Files.exists(location.resolve(backupDirName)));\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n      checkForBackupSuccess(client, location);\n      client.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(1, TimeUnit.MINUTES);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      final String backupName = \"the_backup\";\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      params.set(\"name\", backupName);\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n\n      final BackupStatusChecker backupStatus\n        = new BackupStatusChecker(client, \"/\" + DEFAULT_TEST_COLLECTION_NAME + \"/replication\");\n      final String backupDirName = backupStatus.waitForBackupSuccess(backupName, 30);\n      assertTrue(\"Backup dir does not exist: \" + backupDirName,\n                 Files.exists(location.resolve(backupDirName)));\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(60);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      final String backupName = \"the_backup\";\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      params.set(\"name\", backupName);\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n\n      final BackupStatusChecker backupStatus\n        = new BackupStatusChecker(client, \"/\" + DEFAULT_TEST_COLLECTION_NAME + \"/replication\");\n      final String backupDirName = backupStatus.waitForBackupSuccess(backupName, 30);\n      assertTrue(\"Backup dir does not exist: \" + backupDirName,\n                 Files.exists(location.resolve(backupDirName)));\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6b17e67903ace8abb1d4d602bfc40d1994692ff","date":1593429504,"type":3,"author":"Jan Hydahl","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(1, TimeUnit.MINUTES);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      final String backupName = \"the_backup\";\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      params.set(\"name\", backupName);\n      final Path location = FilterPath.unwrap(createTempDir()).toRealPath();\n      // Allow non-standard location outside SOLR_HOME\n      jettys.forEach(j -> j.getCoreContainer().getAllowPaths().add(location));\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n\n      final BackupStatusChecker backupStatus\n        = new BackupStatusChecker(client, \"/\" + DEFAULT_TEST_COLLECTION_NAME + \"/replication\");\n      final String backupDirName = backupStatus.waitForBackupSuccess(backupName, 30);\n      assertTrue(\"Backup dir does not exist: \" + backupDirName,\n                 Files.exists(location.resolve(backupDirName)));\n    }\n\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n\n    commit();\n\n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n\n    int oldLiveNodes = cloudClient.getZkStateReader().getZkClient().getChildren(ZkStateReader.LIVE_NODES_ZKNODE, null, true).size();\n\n    assertEquals(5, oldLiveNodes);\n\n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD1, 0);\n\n    // ensure shard is dead\n    expectThrows(SolrServerException.class,\n        \"This server should be down and this update should have failed\",\n        () -> index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1, \"specific doc!\")\n    );\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    cloudClient.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1, 60000);\n    \n    try {\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    } catch (Exception e) {\n      // wait and try again\n      Thread.sleep(4000);\n      index_specific(shardToJetty.get(SHARD1).get(1).client.solrClient, id, 1000, i1, 108, t1,\n          \"specific doc!\");\n    }\n\n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    // try adding a doc with CloudSolrServer\n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    \n    try {\n      ureq.process(cloudClient);\n    } catch(SolrServerException e){\n      // try again\n      Thread.sleep(3500);\n      ureq.process(cloudClient);\n    }\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrClient client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD1).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n\n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    deadShard.jetty.start();\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForThingsToLevelOut(1, TimeUnit.MINUTES);\n    \n    Thread.sleep(500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n    \n    // try a backup command\n    try(final HttpSolrClient client = getHttpSolrClient((String) shardToJetty.get(SHARD2).get(0).info.get(\"base_url\"))) {\n      final String backupName = \"the_backup\";\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(\"qt\", ReplicationHandler.PATH);\n      params.set(\"command\", \"backup\");\n      params.set(\"name\", backupName);\n      Path location = createTempDir();\n      location = FilterPath.unwrap(location).toRealPath();\n      params.set(\"location\", location.toString());\n\n      QueryRequest request = new QueryRequest(params);\n      client.request(request, DEFAULT_TEST_COLLECTION_NAME);\n\n\n      final BackupStatusChecker backupStatus\n        = new BackupStatusChecker(client, \"/\" + DEFAULT_TEST_COLLECTION_NAME + \"/replication\");\n      final String backupDirName = backupStatus.waitForBackupSuccess(backupName, 30);\n      assertTrue(\"Backup dir does not exist: \" + backupDirName,\n                 Files.exists(location.resolve(backupDirName)));\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ddee31af447625e4c8d45717e27ffa784cf4c70f":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["d9405f486872f1e416304dfe389741f4ee2f8a4d","34efe37e5314525b1f3e373269e95bcdec2ceb2f"],"9e550c812db35e006a8eb3b5b092ffe2d8f5bb4d":["bafca15d8e408346a67f4282ad1143b88023893b"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["1416f9d09d016a6894cd17e1caac137dad2bba59","bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["52b83bf101b0cb676a87e2f49cdf679d4049c671","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["92f789dbd1886e4b468e61b0def88b29a3f55228"],"a935e32f3b1ffa13f8c6bb6301853a05d2b01a89":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a69439d0df009e0bb0038d1e427159f449dd670d":["d9405f486872f1e416304dfe389741f4ee2f8a4d"],"bafca15d8e408346a67f4282ad1143b88023893b":["f4abec28b874149a7223e32cc7a01704c27790de"],"d9405f486872f1e416304dfe389741f4ee2f8a4d":["1525b4dfbc0d413b8d7247da232009778e624836"],"a6b17e67903ace8abb1d4d602bfc40d1994692ff":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"7ea7454b4afcb5dc9f7504f83d77b134df2b7c57":["a935e32f3b1ffa13f8c6bb6301853a05d2b01a89"],"0c9480c6807676b2e3a9ed82b59395a98253bfe3":["34efe37e5314525b1f3e373269e95bcdec2ceb2f"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c30e4c1cee08b3b229a77991882594fe7250b66"],"52b83bf101b0cb676a87e2f49cdf679d4049c671":["2ba328f7d453c70b167d21f2e69104ea53703f0e"],"1416f9d09d016a6894cd17e1caac137dad2bba59":["5eede925c2b8a6533ba1adf912aaff6a3d05d891"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["ec54bd926c45854b5a1599685b0f7d2bfbfe177f"],"92f789dbd1886e4b468e61b0def88b29a3f55228":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"f2126b84bd093fa3d921582a109a0ee578c28126":["a6378064655e76cd7b908b1cab4ce425b384b508","d9405f486872f1e416304dfe389741f4ee2f8a4d"],"2c30e4c1cee08b3b229a77991882594fe7250b66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["d0d579490a72f2e6297eaa648940611234c57cf1"],"981229bffd22692e7b375551d711a2ebde302ce2":["00fee1a12fd88b734d0a6f4ba0499eb0f1a17986"],"5939c5b1ac54c5b24bd7dbcaf6c68b510470e2c6":["9e550c812db35e006a8eb3b5b092ffe2d8f5bb4d"],"00fee1a12fd88b734d0a6f4ba0499eb0f1a17986":["0c9480c6807676b2e3a9ed82b59395a98253bfe3"],"f4abec28b874149a7223e32cc7a01704c27790de":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"d0d579490a72f2e6297eaa648940611234c57cf1":["5eede925c2b8a6533ba1adf912aaff6a3d05d891"],"40e1d548a3a5d44b9c73ac34a3e93a1d80b5cf41":["a69439d0df009e0bb0038d1e427159f449dd670d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["71475d88ea48a7d9a847f209667255318b3ea4c7","a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["52b83bf101b0cb676a87e2f49cdf679d4049c671"],"5eede925c2b8a6533ba1adf912aaff6a3d05d891":["7ea7454b4afcb5dc9f7504f83d77b134df2b7c57"],"a6378064655e76cd7b908b1cab4ce425b384b508":["2c30e4c1cee08b3b229a77991882594fe7250b66"],"ec54bd926c45854b5a1599685b0f7d2bfbfe177f":["ddee31af447625e4c8d45717e27ffa784cf4c70f"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["71475d88ea48a7d9a847f209667255318b3ea4c7"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c30e4c1cee08b3b229a77991882594fe7250b66"],"34efe37e5314525b1f3e373269e95bcdec2ceb2f":["40e1d548a3a5d44b9c73ac34a3e93a1d80b5cf41"],"2ba328f7d453c70b167d21f2e69104ea53703f0e":["981229bffd22692e7b375551d711a2ebde302ce2"],"71475d88ea48a7d9a847f209667255318b3ea4c7":["5939c5b1ac54c5b24bd7dbcaf6c68b510470e2c6"],"1525b4dfbc0d413b8d7247da232009778e624836":["a6378064655e76cd7b908b1cab4ce425b384b508"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a6b17e67903ace8abb1d4d602bfc40d1994692ff"]},"commit2Childs":{"ddee31af447625e4c8d45717e27ffa784cf4c70f":["ec54bd926c45854b5a1599685b0f7d2bfbfe177f"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"9e550c812db35e006a8eb3b5b092ffe2d8f5bb4d":["5939c5b1ac54c5b24bd7dbcaf6c68b510470e2c6"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["f4abec28b874149a7223e32cc7a01704c27790de"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["ddee31af447625e4c8d45717e27ffa784cf4c70f"],"a935e32f3b1ffa13f8c6bb6301853a05d2b01a89":["7ea7454b4afcb5dc9f7504f83d77b134df2b7c57"],"a69439d0df009e0bb0038d1e427159f449dd670d":["40e1d548a3a5d44b9c73ac34a3e93a1d80b5cf41"],"bafca15d8e408346a67f4282ad1143b88023893b":["9e550c812db35e006a8eb3b5b092ffe2d8f5bb4d"],"d9405f486872f1e416304dfe389741f4ee2f8a4d":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a69439d0df009e0bb0038d1e427159f449dd670d","f2126b84bd093fa3d921582a109a0ee578c28126"],"a6b17e67903ace8abb1d4d602bfc40d1994692ff":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7ea7454b4afcb5dc9f7504f83d77b134df2b7c57":["5eede925c2b8a6533ba1adf912aaff6a3d05d891"],"0c9480c6807676b2e3a9ed82b59395a98253bfe3":["00fee1a12fd88b734d0a6f4ba0499eb0f1a17986"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"52b83bf101b0cb676a87e2f49cdf679d4049c671":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"1416f9d09d016a6894cd17e1caac137dad2bba59":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c7869f64c874ebf7f317d22c00baf2b6857797a6","2c30e4c1cee08b3b229a77991882594fe7250b66","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"92f789dbd1886e4b468e61b0def88b29a3f55228":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["a6b17e67903ace8abb1d4d602bfc40d1994692ff"],"f2126b84bd093fa3d921582a109a0ee578c28126":[],"2c30e4c1cee08b3b229a77991882594fe7250b66":["c7869f64c874ebf7f317d22c00baf2b6857797a6","a6378064655e76cd7b908b1cab4ce425b384b508","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"981229bffd22692e7b375551d711a2ebde302ce2":["2ba328f7d453c70b167d21f2e69104ea53703f0e"],"00fee1a12fd88b734d0a6f4ba0499eb0f1a17986":["981229bffd22692e7b375551d711a2ebde302ce2"],"5939c5b1ac54c5b24bd7dbcaf6c68b510470e2c6":["71475d88ea48a7d9a847f209667255318b3ea4c7"],"f4abec28b874149a7223e32cc7a01704c27790de":["bafca15d8e408346a67f4282ad1143b88023893b"],"d0d579490a72f2e6297eaa648940611234c57cf1":["bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"40e1d548a3a5d44b9c73ac34a3e93a1d80b5cf41":["34efe37e5314525b1f3e373269e95bcdec2ceb2f"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a935e32f3b1ffa13f8c6bb6301853a05d2b01a89"],"5eede925c2b8a6533ba1adf912aaff6a3d05d891":["1416f9d09d016a6894cd17e1caac137dad2bba59","d0d579490a72f2e6297eaa648940611234c57cf1"],"a6378064655e76cd7b908b1cab4ce425b384b508":["f2126b84bd093fa3d921582a109a0ee578c28126","1525b4dfbc0d413b8d7247da232009778e624836"],"ec54bd926c45854b5a1599685b0f7d2bfbfe177f":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["92f789dbd1886e4b468e61b0def88b29a3f55228","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"34efe37e5314525b1f3e373269e95bcdec2ceb2f":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","0c9480c6807676b2e3a9ed82b59395a98253bfe3"],"2ba328f7d453c70b167d21f2e69104ea53703f0e":["52b83bf101b0cb676a87e2f49cdf679d4049c671"],"1525b4dfbc0d413b8d7247da232009778e624836":["d9405f486872f1e416304dfe389741f4ee2f8a4d"],"71475d88ea48a7d9a847f209667255318b3ea4c7":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","37a0f60745e53927c4c876cfe5b5a58170f0646c","c7869f64c874ebf7f317d22c00baf2b6857797a6","f2126b84bd093fa3d921582a109a0ee578c28126","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}