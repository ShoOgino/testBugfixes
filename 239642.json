{"path":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","commits":[{"id":"0c3e228bf650e96f3002a8fb73dd0c13d55af077","date":1138253849,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"/dev/null","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",true,true,false));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      BitSet bits = both.docSet.getBits();\n      BitSet neg = ((BitSet)bits.clone());\n      neg.flip(0, bits.length());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c7040334a42400ca67824559be90a1f2f2c9e63","date":1142276541,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      BitSet bits = both.docSet.getBits();\n      BitSet neg = ((BitSet)bits.clone());\n      neg.flip(0, bits.length());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",true,true,false));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      BitSet bits = both.docSet.getBits();\n      BitSet neg = ((BitSet)bits.clone());\n      neg.flip(0, bits.length());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"18d06c030cb0a920c116ec6e16933a4590a70bb9","date":1144087994,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      BitSet bits = both.docSet.getBits();\n      BitSet neg = ((BitSet)bits.clone());\n      neg.flip(0, bits.length());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      BitSet bits = both.docSet.getBits();\n      BitSet neg = ((BitSet)bits.clone());\n      neg.flip(0, bits.length());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21400778a0bf704d187a4848279049f5d90276c8","date":1149955512,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      BitSet bits = both.docSet.getBits();\n      BitSet neg = ((BitSet)bits.clone());\n      neg.flip(0, bits.length());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996","date":1180477701,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException(400,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6075cf7db5ebb03b013c9110fca8f1013ba6a72","date":1196271697,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        QueryParsing.SortSpec sortSpec = QueryParsing.parseSort(commands.get(1), req.getSchema());\n        if (sortSpec != null) {\n          sort = sortSpec.getSort();\n          // ignore the count for now... it's currently only controlled by start & limit on req\n          // count = sortSpec.getCount();\n        }\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ef28ac95f5f85bbf872801277448c0924b0a6827","date":1268600312,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n      test(hits.totalHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f824fc682d760b1e10b1ac8238be69e9de08198","date":1268605446,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n      test(hits.totalHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"18d06c030cb0a920c116ec6e16933a4590a70bb9":["7c7040334a42400ca67824559be90a1f2f2c9e63"],"21400778a0bf704d187a4848279049f5d90276c8":["18d06c030cb0a920c116ec6e16933a4590a70bb9"],"0c3e228bf650e96f3002a8fb73dd0c13d55af077":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1f824fc682d760b1e10b1ac8238be69e9de08198":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ef28ac95f5f85bbf872801277448c0924b0a6827":["c6075cf7db5ebb03b013c9110fca8f1013ba6a72"],"ad94625fb8d088209f46650c8097196fec67f00c":["1f824fc682d760b1e10b1ac8238be69e9de08198"],"c6075cf7db5ebb03b013c9110fca8f1013ba6a72":["c4abe53aaee39b5f2f41dd9a0b905c1ddf880996"],"7c7040334a42400ca67824559be90a1f2f2c9e63":["0c3e228bf650e96f3002a8fb73dd0c13d55af077"],"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996":["21400778a0bf704d187a4848279049f5d90276c8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"18d06c030cb0a920c116ec6e16933a4590a70bb9":["21400778a0bf704d187a4848279049f5d90276c8"],"21400778a0bf704d187a4848279049f5d90276c8":["c4abe53aaee39b5f2f41dd9a0b905c1ddf880996"],"0c3e228bf650e96f3002a8fb73dd0c13d55af077":["7c7040334a42400ca67824559be90a1f2f2c9e63"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["0c3e228bf650e96f3002a8fb73dd0c13d55af077"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1f824fc682d760b1e10b1ac8238be69e9de08198":["ad94625fb8d088209f46650c8097196fec67f00c"],"ef28ac95f5f85bbf872801277448c0924b0a6827":["1f824fc682d760b1e10b1ac8238be69e9de08198"],"7c7040334a42400ca67824559be90a1f2f2c9e63":["18d06c030cb0a920c116ec6e16933a4590a70bb9"],"c6075cf7db5ebb03b013c9110fca8f1013ba6a72":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996":["c6075cf7db5ebb03b013c9110fca8f1013ba6a72"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}