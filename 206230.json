{"path":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","commits":[{"id":"519ac3b8f2711b5bfeb1c90c77bb007032270a41","date":1384456090,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getDim(\"Publish Date\", 10).toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getDim(\"Author\", 10).toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getDim(\"Author\", 10).toString());\n\n    assertEquals(1, facets.getSpecificCount(new CategoryPath(\"Author\", \"Lisa\")));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93bee32f95de853915b2f9402e76ed24ef97f43e","date":1384460894,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getDim(\"Publish Date\", 10).toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getDim(\"Author\", 10).toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getDim(\"Author\", 10).toString());\n\n    assertEquals(1, facets.getSpecificCount(new CategoryPath(\"Author\", \"Lisa\")));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c190847801a50f4dd20fd639bdc29b54ea3b288b","date":1384461522,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28ac5cee8abf30398e12bc016a5ce9d441831a63","date":1384691298,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"798b82b2c9877fae10a0a7d2025c05cac832bda2","date":1384710991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    Facets facets = new FastTaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new FastTaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    TaxonomyFacetCounts facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new TaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fdb15e93058f718a65d564872aadbed5ca78296","date":1384720267,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, config);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(config);\n    q2.add(\"Publish Date\", \"2010\");\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new FastTaxonomyFacetCounts(taxoReader, config, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig fts = new FacetsConfig();\n    fts.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, fts);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    Facets facets = new FastTaxonomyFacetCounts(taxoReader, fts, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date\", \"2010\"));\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new FastTaxonomyFacetCounts(taxoReader, fts, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"441c188ff9fd7da36e0e4d8a9b51cebe63b31192","date":1384814749,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testBasic().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, config);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(config);\n    q2.add(\"Publish Date\", \"2010\");\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new FastTaxonomyFacetCounts(taxoReader, config, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setHierarchical(\"Publish Date\");\n\n    IndexWriter writer = new FacetIndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())), taxoWriter, config);\n\n    Document doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Bob\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"15\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2010\", \"10\", \"20\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Lisa\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"1\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Susan\"));\n    doc.add(new FacetField(\"Publish Date\", \"2012\", \"1\", \"7\"));\n    writer.addDocument(doc);\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n    writer.addDocument(doc);\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(DirectoryReader.open(writer, true));\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, c);\n\n    // Retrieve & verify results:\n    assertEquals(\"Publish Date (5)\\n  2010 (2)\\n  2012 (2)\\n  1999 (1)\\n\", facets.getTopChildren(10, \"Publish Date\").toString());\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Bob (1)\\n  Susan (1)\\n  Frank (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    // Now user drills down on Publish Date/2010:\n    SimpleDrillDownQuery q2 = new SimpleDrillDownQuery(config);\n    q2.add(\"Publish Date\", \"2010\");\n    c = new SimpleFacetsCollector();\n    searcher.search(q2, c);\n    facets = new FastTaxonomyFacetCounts(taxoReader, config, c);\n    assertEquals(\"Author (2)\\n  Bob (1)\\n  Lisa (1)\\n\", facets.getTopChildren(10, \"Author\").toString());\n\n    assertEquals(1, facets.getSpecificValue(\"Author\", \"Lisa\"));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"28ac5cee8abf30398e12bc016a5ce9d441831a63":["c190847801a50f4dd20fd639bdc29b54ea3b288b"],"9fdb15e93058f718a65d564872aadbed5ca78296":["798b82b2c9877fae10a0a7d2025c05cac832bda2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"798b82b2c9877fae10a0a7d2025c05cac832bda2":["28ac5cee8abf30398e12bc016a5ce9d441831a63"],"519ac3b8f2711b5bfeb1c90c77bb007032270a41":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"93bee32f95de853915b2f9402e76ed24ef97f43e":["519ac3b8f2711b5bfeb1c90c77bb007032270a41"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"441c188ff9fd7da36e0e4d8a9b51cebe63b31192":["9fdb15e93058f718a65d564872aadbed5ca78296"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["93bee32f95de853915b2f9402e76ed24ef97f43e"]},"commit2Childs":{"28ac5cee8abf30398e12bc016a5ce9d441831a63":["798b82b2c9877fae10a0a7d2025c05cac832bda2"],"9fdb15e93058f718a65d564872aadbed5ca78296":["441c188ff9fd7da36e0e4d8a9b51cebe63b31192"],"798b82b2c9877fae10a0a7d2025c05cac832bda2":["9fdb15e93058f718a65d564872aadbed5ca78296"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["519ac3b8f2711b5bfeb1c90c77bb007032270a41","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"519ac3b8f2711b5bfeb1c90c77bb007032270a41":["93bee32f95de853915b2f9402e76ed24ef97f43e"],"93bee32f95de853915b2f9402e76ed24ef97f43e":["c190847801a50f4dd20fd639bdc29b54ea3b288b"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["28ac5cee8abf30398e12bc016a5ce9d441831a63"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"441c188ff9fd7da36e0e4d8a9b51cebe63b31192":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","441c188ff9fd7da36e0e4d8a9b51cebe63b31192"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}