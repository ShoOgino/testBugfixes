{"path":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","commits":[{"id":"b305cb92ee47ddf7b15c6eeefe489c04d05b22ba","date":1199456955,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"/dev/null","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"95692f9a6440b2a1c83c2c8ae5224be54319db4c","date":1199477722,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n  }\n\n","sourceOld":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"decc8a7344e9231708f9991fa09db2cafec7a2dd","date":1201187153,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    token = tf.next();\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n\n    token = tf.next();\n    assertTrue(\"token is not null and it should be\", token == null);\n\n  }\n\n","sourceOld":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    final Token reusableToken = new Token();\n    Token nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n    assertTrue(nextToken.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            nextToken.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(nextToken.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, nextToken.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(reusableToken);//skip here\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n    assertTrue(nextToken.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            nextToken.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(nextToken.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, nextToken.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(reusableToken);//skip here\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n    assertTrue(nextToken.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n            nextToken.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(nextToken.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, nextToken.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is not null and it should be\", nextToken == null);\n\n  }\n\n","sourceOld":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(token);//skip here\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(token.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, token.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    token = tf.next();\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n\n    token = tf.next();\n    assertTrue(\"token is not null and it should be\", token == null);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) tf.addAttribute(TypeAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    \n    assertTrue(tf.incrementToken());\n    assertFalse(tf.incrementToken());\n  }\n\n","sourceOld":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    final Token reusableToken = new Token();\n    Token nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n    assertTrue(nextToken.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n            nextToken.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(nextToken.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, nextToken.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(reusableToken);//skip here\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n    assertTrue(nextToken.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n            nextToken.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(nextToken.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, nextToken.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.next(reusableToken);//skip here\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n    assertTrue(nextToken.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n            nextToken.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(nextToken.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, nextToken.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is null and it shouldn't be\", nextToken != null);\n\n    nextToken = tf.next(reusableToken);\n    assertTrue(\"nextToken is not null and it should be\", nextToken == null);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    \n    assertTrue(tf.incrementToken());\n    assertFalse(tf.incrementToken());\n  }\n\n","sourceOld":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) tf.addAttribute(TypeAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    \n    assertTrue(tf.incrementToken());\n    assertFalse(tf.incrementToken());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinks().mjava","sourceNew":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    \n    assertTrue(tf.incrementToken());\n    assertFalse(tf.incrementToken());\n  }\n\n","sourceOld":"  public void testLinks() throws Exception {\n    String test = \"[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html#news\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html#news\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"http://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"http://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    tf.incrementToken();//skip here\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"https://lucene.apache.org/java/docs/index.html?b=c\",\n        termAtt.term().equals(\"https://lucene.apache.org/java/docs/index.html?b=c\") == true);\n    assertTrue(typeAtt.type() + \" is not equal to \" + WikipediaTokenizer.EXTERNAL_LINK_URL, typeAtt.type().equals(WikipediaTokenizer.EXTERNAL_LINK_URL) == true);\n    \n    assertTrue(tf.incrementToken());\n    assertFalse(tf.incrementToken());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["decc8a7344e9231708f9991fa09db2cafec7a2dd"],"decc8a7344e9231708f9991fa09db2cafec7a2dd":["95692f9a6440b2a1c83c2c8ae5224be54319db4c"],"b305cb92ee47ddf7b15c6eeefe489c04d05b22ba":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"95692f9a6440b2a1c83c2c8ae5224be54319db4c":["b305cb92ee47ddf7b15c6eeefe489c04d05b22ba"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["8d78f014fded44fbde905f4f84cdc21907b371e8"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"decc8a7344e9231708f9991fa09db2cafec7a2dd":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"b305cb92ee47ddf7b15c6eeefe489c04d05b22ba":["95692f9a6440b2a1c83c2c8ae5224be54319db4c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b305cb92ee47ddf7b15c6eeefe489c04d05b22ba"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"95692f9a6440b2a1c83c2c8ae5224be54319db4c":["decc8a7344e9231708f9991fa09db2cafec7a2dd"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}