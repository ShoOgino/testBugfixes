{"path":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","commits":[{"id":"f6dba7919de4ff4ed6ff17f90619203772722f08","date":1180451647,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream==null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream==null) {\n            singleNormStream = d.openInput(fileName);\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b9d7142a399ac70a71ce5b40ee66695eda5b7e8","date":1195335263,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream==null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, singleNormFile, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream==null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6db660b56f04fdb2853d25cdee8ee0d36559a521","date":1233313968,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new Ref();\n          } else {\n            singleNormRef.incRef();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream==null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, singleNormFile, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"66f3dadb253a44f4cccc81c8a21b685b18b201fb","date":1247245699,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new Ref();\n          } else {\n            singleNormRef.incRef();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new Ref();\n          } else {\n            singleNormRef.incRef();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d8514024f885b40613b5ec91876ce5e9d2167d89","date":1260313529,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new Ref();\n          } else {\n            singleNormRef.incRef();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"775efee7f959e0dd3df7960b93767d9e00b78751","date":1267203159,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6db660b56f04fdb2853d25cdee8ee0d36559a521":["3b9d7142a399ac70a71ce5b40ee66695eda5b7e8"],"775efee7f959e0dd3df7960b93767d9e00b78751":["d8514024f885b40613b5ec91876ce5e9d2167d89"],"f6dba7919de4ff4ed6ff17f90619203772722f08":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d8514024f885b40613b5ec91876ce5e9d2167d89":["66f3dadb253a44f4cccc81c8a21b685b18b201fb"],"3b9d7142a399ac70a71ce5b40ee66695eda5b7e8":["f6dba7919de4ff4ed6ff17f90619203772722f08"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["775efee7f959e0dd3df7960b93767d9e00b78751"],"66f3dadb253a44f4cccc81c8a21b685b18b201fb":["6db660b56f04fdb2853d25cdee8ee0d36559a521"]},"commit2Childs":{"6db660b56f04fdb2853d25cdee8ee0d36559a521":["66f3dadb253a44f4cccc81c8a21b685b18b201fb"],"775efee7f959e0dd3df7960b93767d9e00b78751":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"f6dba7919de4ff4ed6ff17f90619203772722f08":["3b9d7142a399ac70a71ce5b40ee66695eda5b7e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f6dba7919de4ff4ed6ff17f90619203772722f08"],"3b9d7142a399ac70a71ce5b40ee66695eda5b7e8":["6db660b56f04fdb2853d25cdee8ee0d36559a521"],"d8514024f885b40613b5ec91876ce5e9d2167d89":["775efee7f959e0dd3df7960b93767d9e00b78751"],"66f3dadb253a44f4cccc81c8a21b685b18b201fb":["d8514024f885b40613b5ec91876ce5e9d2167d89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}