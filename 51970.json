{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","commits":[{"id":"11a746437bc5c0a0b3df0337ed249c387c812871","date":1376687959,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/cheapbastard/CheapBastardDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(field, ords.get(field.number));\n    NumericEntry entry = ordIndexes.get(field.number);\n    IndexInput data = this.data.clone();\n    data.seek(entry.offset);\n    final MonotonicBlockPackedReader ordIndex = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, true);\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a7bf5332d569e3d07c4b248462f5d212e26e9af","date":1376929683,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","date":1377034255,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e56be5c9792e4a329cf6468240a4f8ff532f426c","date":1382600931,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return new SingletonSortedSetDocValues(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["8429ddf2214f2bf8abcbb5484fefef6aaf5c417e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d50d971859a3c7841c17117b0aac14e733441ebf","date":1384264257,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return new SingletonSortedSetDocValues(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return new SingletonSortedSetDocValues(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc45495cddab770758da8a7fe79f01747b83c9ee","date":1392859277,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return new SingletonSortedSetDocValues(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return new SingletonSortedSetDocValues(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8429ddf2214f2bf8abcbb5484fefef6aaf5c417e","date":1397206443,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return new SingletonSortedSetDocValues(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":["e56be5c9792e4a329cf6468240a4f8ff532f426c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["8429ddf2214f2bf8abcbb5484fefef6aaf5c417e"],"bc45495cddab770758da8a7fe79f01747b83c9ee":["d50d971859a3c7841c17117b0aac14e733441ebf"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1a7bf5332d569e3d07c4b248462f5d212e26e9af"],"8429ddf2214f2bf8abcbb5484fefef6aaf5c417e":["bc45495cddab770758da8a7fe79f01747b83c9ee"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","4cc45c615dbb82bf79d5f9550286098367874fbf"],"d50d971859a3c7841c17117b0aac14e733441ebf":["e56be5c9792e4a329cf6468240a4f8ff532f426c"],"11a746437bc5c0a0b3df0337ed249c387c812871":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"1a7bf5332d569e3d07c4b248462f5d212e26e9af":["11a746437bc5c0a0b3df0337ed249c387c812871"],"e56be5c9792e4a329cf6468240a4f8ff532f426c":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"]},"commit2Childs":{"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb","4cc45c615dbb82bf79d5f9550286098367874fbf"],"bc45495cddab770758da8a7fe79f01747b83c9ee":["8429ddf2214f2bf8abcbb5484fefef6aaf5c417e"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","e56be5c9792e4a329cf6468240a4f8ff532f426c"],"8429ddf2214f2bf8abcbb5484fefef6aaf5c417e":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d50d971859a3c7841c17117b0aac14e733441ebf":["bc45495cddab770758da8a7fe79f01747b83c9ee"],"11a746437bc5c0a0b3df0337ed249c387c812871":["1a7bf5332d569e3d07c4b248462f5d212e26e9af"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","11a746437bc5c0a0b3df0337ed249c387c812871"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"1a7bf5332d569e3d07c4b248462f5d212e26e9af":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"e56be5c9792e4a329cf6468240a4f8ff532f426c":["d50d971859a3c7841c17117b0aac14e733441ebf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}