{"path":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenize(String).mjava","commits":[{"id":"134a24d0cb66520908d88384f1a559875704ed25","date":1445326601,"type":1,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenize(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenizeDoc(String).mjava","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  protected String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","sourceOld":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param doc the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  protected String[] tokenizeDoc(String doc) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, doc)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33bfee30277584028170135002def66f9d57732b","date":1547842233,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenize(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenize(String).mjava","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  protected String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[0]);\n  }\n\n","sourceOld":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  protected String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","date":1548322018,"type":3,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenize(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#tokenize(String).mjava","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  protected String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[0]);\n  }\n\n","sourceOld":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  protected String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["134a24d0cb66520908d88384f1a559875704ed25","33bfee30277584028170135002def66f9d57732b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"134a24d0cb66520908d88384f1a559875704ed25":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"33bfee30277584028170135002def66f9d57732b":["134a24d0cb66520908d88384f1a559875704ed25"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"]},"commit2Childs":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["134a24d0cb66520908d88384f1a559875704ed25"],"134a24d0cb66520908d88384f1a559875704ed25":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","33bfee30277584028170135002def66f9d57732b"],"33bfee30277584028170135002def66f9d57732b":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}