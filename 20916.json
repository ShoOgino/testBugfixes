{"path":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","commits":[{"id":"3a2591037a85ef083e6588e0b846a5a34ff9b5a3","date":1326403130,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"/dev/null","sourceNew":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<K, V>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<K, V>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca83400a04ed1cbfa09560d2e7184f93f5d75363","date":1428921124,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc69baf14413994ccde897681e5ce1d393cf7156","date":1468245555,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71ca10e7131e1f01868c80d228f26a855e79dd0","date":1562166223,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","date":1568645407,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, timeSource.getEpochTimeNs());\n    return putCacheEntry(e);\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K, V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d7d3943904804560937e6239effeebda0f920e4","date":1573762904,"type":4,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#put(K,V).mjava","sourceNew":null,"sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, timeSource.getEpochTimeNs());\n    return putCacheEntry(e);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["3a2591037a85ef083e6588e0b846a5a34ff9b5a3"],"ca83400a04ed1cbfa09560d2e7184f93f5d75363":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["a71ca10e7131e1f01868c80d228f26a855e79dd0"],"4d7d3943904804560937e6239effeebda0f920e4":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"a71ca10e7131e1f01868c80d228f26a855e79dd0":["cc69baf14413994ccde897681e5ce1d393cf7156"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc69baf14413994ccde897681e5ce1d393cf7156":["ca83400a04ed1cbfa09560d2e7184f93f5d75363"],"3a2591037a85ef083e6588e0b846a5a34ff9b5a3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ca83400a04ed1cbfa09560d2e7184f93f5d75363","cc69baf14413994ccde897681e5ce1d393cf7156"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4d7d3943904804560937e6239effeebda0f920e4"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ca83400a04ed1cbfa09560d2e7184f93f5d75363"],"ca83400a04ed1cbfa09560d2e7184f93f5d75363":["cc69baf14413994ccde897681e5ce1d393cf7156","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["4d7d3943904804560937e6239effeebda0f920e4"],"a71ca10e7131e1f01868c80d228f26a855e79dd0":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"4d7d3943904804560937e6239effeebda0f920e4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a2591037a85ef083e6588e0b846a5a34ff9b5a3"],"cc69baf14413994ccde897681e5ce1d393cf7156":["a71ca10e7131e1f01868c80d228f26a855e79dd0","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"3a2591037a85ef083e6588e0b846a5a34ff9b5a3":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}