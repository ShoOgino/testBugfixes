{"path":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","commits":[{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlyLeafReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"]},"commit2Childs":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}