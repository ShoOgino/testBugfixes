{"path":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"modules/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eafa8c5eabc3dacd34680054e6a33bda024080ac","date":1367691488,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f4ef381bf0c2d618c6db830d3dd668c6901c05a","date":1402592253,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeStringLight(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(Automata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeStringLight(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(Automata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dfdf766e55e943d942055d7de53c7ad6bc45283","date":1441632886,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(Automata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(((BoostQuery) q).getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(((BoostQuery) q).getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(Automata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["7f4ef381bf0c2d618c6db830d3dd668c6901c05a"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["5c84485629d80d203608e8975a1139de9933cc38"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7f4ef381bf0c2d618c6db830d3dd668c6901c05a":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"5c84485629d80d203608e8975a1139de9933cc38":["eafa8c5eabc3dacd34680054e6a33bda024080ac","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2dfdf766e55e943d942055d7de53c7ad6bc45283"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["7f4ef381bf0c2d618c6db830d3dd668c6901c05a","5c84485629d80d203608e8975a1139de9933cc38"],"7f4ef381bf0c2d618c6db830d3dd668c6901c05a":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"5c84485629d80d203608e8975a1139de9933cc38":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}