{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","commits":[{"id":"cefe924a3b76c22b7df9a075329750871699af6b","date":1409757963,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"949847c0040cd70a68222d526cb0da7bf6cbb3c2","date":1410997182,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c298728fd021733b62c1c36a0236f0b83b8e50ee","date":1411169096,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if (exc instanceof AlreadyClosedException && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57595f9a4a3582c49fa576cb9366d18a0c128e4d","date":1411388311,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if (exc instanceof AlreadyClosedException && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5faf65b6692f15cca0f87bf8666c87899afc619f","date":1420468108,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      suppressFakeFail.setMergeThreadPriority(cms.getMergeThreadPriority());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d9e22bdf0692bfa61e342b04a6ac7078670c1e16","date":1436866730,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || t.getCause().toString().contains(\"fake fail\")) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Exception {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (IOException ioe) {\n        if (ioe.getMessage().contains(\"background merge hit exception\")) {\n          Throwable cause = ioe.getCause();\n          if (cause != null && cause instanceof RuntimeException && ((RuntimeException) cause).getMessage().equals(\"fake fail\")) {\n            // ok\n          } else {\n            throw ioe;\n          }\n        } else {\n          throw ioe;\n        }\n      } catch (RuntimeException re) {\n        if (re.getMessage().equals(\"fake fail\")) {\n          // ok\n        } else if (re instanceof AlreadyClosedException && re.getCause() != null && \"fake fail\".equals(re.getCause().getMessage())) {\n          break; // our test got unlucky, triggered our strange exception after successful finishCommit, caused a disaster!\n        } else {\n          throw re;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75898c93098dedfa8424bb301860314cb61f7216","date":1438095542,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || t.getCause().toString().contains(\"fake fail\")) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2916966cc9815e973c01452a0d76c98c5e0d0926","date":1577444040,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            if (callStackContains(IndexFileDeleter.class, \"decRef\")) {\n              throw new RuntimeException(\"fake fail\");\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"94ec73c5617c177b1d81ddfe04bbff1d08fccecc","date":1577456244,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            if (callStackContains(IndexFileDeleter.class, \"decRef\")) {\n              throw new RuntimeException(\"fake fail\");\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexFileDeleter.class.getName()) && stack[i].getMethodName().equals(\"decRef\")) {\n                throw new RuntimeException(\"fake fail\");\n              }\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89697e7abc9807639c384eecf5a2a6eef1080426","date":1587733375,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter#testExcInDecRef().mjava","sourceNew":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            if (callStackContains(IndexFileDeleter.class, \"decRef\")) {\n              throw new RuntimeException(\"fake fail\");\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException( exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-5919\n  public void testExcInDecRef() throws Throwable {\n    MockDirectoryWrapper dir = newMockDirectory();\n\n    // disable slow things: we don't rely upon sleeps here.\n    dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    dir.setUseSlowOpenClosers(false);\n\n    final AtomicBoolean doFailExc = new AtomicBoolean();\n\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n        @Override\n        public void eval(MockDirectoryWrapper dir) throws IOException {\n          if (doFailExc.get() && random().nextInt(4) == 1) {\n            if (callStackContains(IndexFileDeleter.class, \"decRef\")) {\n              throw new RuntimeException(\"fake fail\");\n            }\n          }\n        }\n      });\n\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    //iwc.setMergeScheduler(new SerialMergeScheduler());\n    MergeScheduler ms = iwc.getMergeScheduler();\n    if (ms instanceof ConcurrentMergeScheduler) {\n      final ConcurrentMergeScheduler suppressFakeFail = new ConcurrentMergeScheduler() {\n          @Override\n          protected void handleMergeException(Directory dir, Throwable exc) {\n            // suppress only FakeIOException:\n            if (exc instanceof RuntimeException && exc.getMessage().equals(\"fake fail\")) {\n              // ok to ignore\n            } else if ((exc instanceof AlreadyClosedException || exc instanceof IllegalStateException) \n                        && exc.getCause() != null && \"fake fail\".equals(exc.getCause().getMessage())) {\n              // also ok to ignore\n            } else {\n              super.handleMergeException(dir, exc);\n            }\n          }\n        };\n      final ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler) ms;\n      suppressFakeFail.setMaxMergesAndThreads(cms.getMaxMergeCount(), cms.getMaxThreadCount());\n      iwc.setMergeScheduler(suppressFakeFail);\n    }\n\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    // Since we hit exc during merging, a partial\n    // forceMerge can easily return when there are still\n    // too many segments in the index:\n    w.setDoRandomForceMergeAssert(false);\n\n    doFailExc.set(true);\n    int ITERS = atLeast(1000);\n    for(int iter=0;iter<ITERS;iter++) {\n      try {\n        if (random().nextInt(10) == 5) {\n          w.commit();\n        } else if (random().nextInt(10) == 7) {\n          w.getReader().close();\n        } else {\n          Document doc = new Document();\n          doc.add(newTextField(\"field\", \"some text\", Field.Store.NO));\n          w.addDocument(doc);\n        }\n      } catch (Throwable t) {\n        if (t.toString().contains(\"fake fail\") || (t.getCause() != null && t.getCause().toString().contains(\"fake fail\"))) {\n          // ok\n        } else {\n          throw t;\n        }\n      }\n    }\n\n    doFailExc.set(false);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"89697e7abc9807639c384eecf5a2a6eef1080426":["2916966cc9815e973c01452a0d76c98c5e0d0926"],"57595f9a4a3582c49fa576cb9366d18a0c128e4d":["c298728fd021733b62c1c36a0236f0b83b8e50ee"],"d9e22bdf0692bfa61e342b04a6ac7078670c1e16":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"cefe924a3b76c22b7df9a075329750871699af6b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"75898c93098dedfa8424bb301860314cb61f7216":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2916966cc9815e973c01452a0d76c98c5e0d0926":["75898c93098dedfa8424bb301860314cb61f7216"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["57595f9a4a3582c49fa576cb9366d18a0c128e4d"],"c298728fd021733b62c1c36a0236f0b83b8e50ee":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["cefe924a3b76c22b7df9a075329750871699af6b"],"94ec73c5617c177b1d81ddfe04bbff1d08fccecc":["75898c93098dedfa8424bb301860314cb61f7216","2916966cc9815e973c01452a0d76c98c5e0d0926"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["89697e7abc9807639c384eecf5a2a6eef1080426"]},"commit2Childs":{"89697e7abc9807639c384eecf5a2a6eef1080426":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"57595f9a4a3582c49fa576cb9366d18a0c128e4d":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"d9e22bdf0692bfa61e342b04a6ac7078670c1e16":["75898c93098dedfa8424bb301860314cb61f7216"],"cefe924a3b76c22b7df9a075329750871699af6b":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cefe924a3b76c22b7df9a075329750871699af6b"],"75898c93098dedfa8424bb301860314cb61f7216":["2916966cc9815e973c01452a0d76c98c5e0d0926","94ec73c5617c177b1d81ddfe04bbff1d08fccecc"],"2916966cc9815e973c01452a0d76c98c5e0d0926":["89697e7abc9807639c384eecf5a2a6eef1080426","94ec73c5617c177b1d81ddfe04bbff1d08fccecc"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16"],"c298728fd021733b62c1c36a0236f0b83b8e50ee":["57595f9a4a3582c49fa576cb9366d18a0c128e4d"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["c298728fd021733b62c1c36a0236f0b83b8e50ee"],"94ec73c5617c177b1d81ddfe04bbff1d08fccecc":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["94ec73c5617c177b1d81ddfe04bbff1d08fccecc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}