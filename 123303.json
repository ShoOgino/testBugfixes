{"path":"solr/core/src/test/org/apache/solr/handler/admin/SplitHandlerTest#testHistogramBuilding().mjava","commits":[{"id":"a97a72dc16d01fda8ca5c9e0264b3604e30ab539","date":1565639985,"type":1,"author":"Megan Carey","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/admin/SplitHandlerTest#testHistogramBuilding().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/admin/SplitHandlerTest#testHistoramBuilding().mjava","sourceNew":"  @Test\n  public void testHistogramBuilding() throws Exception {\n    List<Prefix> prefixes = SplitByPrefixTest.findPrefixes(20, 0, 0x00ffffff);\n    List<Prefix> uniquePrefixes = SplitByPrefixTest.removeDups(prefixes);\n    assertTrue(prefixes.size() > uniquePrefixes.size());  // make sure we have some duplicates to test hash collisions\n\n    String prefixField = \"id_prefix_s\";\n    String idField = \"id\";\n    DocRouter router = new CompositeIdRouter();\n\n\n    for (int i=0; i<100; i++) {\n      SolrQueryRequest req = req(\"myquery\");\n      try {\n        // the first time through the loop we do this before adding docs to test an empty index\n        Collection<SplitOp.RangeCount> counts1 = SplitOp.getHashHistogram(req.getSearcher(), prefixField, router, null);\n        Collection<SplitOp.RangeCount> counts2 = SplitOp.getHashHistogramFromId(req.getSearcher(), idField, router, null);\n        assertTrue(eqCount(counts1, counts2));\n\n        if (i>0) {\n          assertTrue(counts1.size() > 0);  // make sure we are testing something\n        }\n\n\n        // index a few random documents\n        int ndocs = random().nextInt(10) + 1;\n        for (int j=0; j<ndocs; j++) {\n          String prefix = prefixes.get( random().nextInt(prefixes.size()) ).key;\n          if (random().nextBoolean()) {\n            prefix = prefix + Integer.toString(random().nextInt(3)) + \"!\";\n          }\n          String id = prefix + \"doc\" + i + \"_\" + j;\n          updateJ(jsonAdd(sdoc(idField, id, prefixField, prefix)), null);\n        }\n\n        assertU(commit());\n\n\n      } finally {\n        req.close();\n      }\n\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testHistoramBuilding() throws Exception {\n    List<Prefix> prefixes = SplitByPrefixTest.findPrefixes(20, 0, 0x00ffffff);\n    List<Prefix> uniquePrefixes = SplitByPrefixTest.removeDups(prefixes);\n    assertTrue(prefixes.size() > uniquePrefixes.size());  // make sure we have some duplicates to test hash collisions\n\n    String prefixField = \"id_prefix_s\";\n    String idField = \"id\";\n    DocRouter router = new CompositeIdRouter();\n\n\n    for (int i=0; i<100; i++) {\n      SolrQueryRequest req = req(\"myquery\");\n      try {\n        // the first time through the loop we do this before adding docs to test an empty index\n        Collection<SplitOp.RangeCount> counts1 = SplitOp.getHashHistogram(req.getSearcher(), prefixField, router, null);\n        Collection<SplitOp.RangeCount> counts2 = SplitOp.getHashHistogramFromId(req.getSearcher(), idField, router, null);\n        assertTrue(eqCount(counts1, counts2));\n\n        if (i>0) {\n          assertTrue(counts1.size() > 0);  // make sure we are testing something\n        }\n\n\n        // index a few random documents\n        int ndocs = random().nextInt(10) + 1;\n        for (int j=0; j<ndocs; j++) {\n          String prefix = prefixes.get( random().nextInt(prefixes.size()) ).key;\n          if (random().nextBoolean()) {\n            prefix = prefix + Integer.toString(random().nextInt(3)) + \"!\";\n          }\n          String id = prefix + \"doc\" + i + \"_\" + j;\n          updateJ(jsonAdd(sdoc(idField, id, prefixField, prefix)), null);\n        }\n\n        assertU(commit());\n\n\n      } finally {\n        req.close();\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539"],"a97a72dc16d01fda8ca5c9e0264b3604e30ab539":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"a97a72dc16d01fda8ca5c9e0264b3604e30ab539":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}