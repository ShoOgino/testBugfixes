{"path":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","commits":[{"id":"6013b4c7388f1627659c8f96c44abd10a294d3a6","date":1346343796,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @param coreName\n   * @param desc\n   * @param recoverReloadedCores\n   * @param afterExpiration\n   * @return the shardId for the SolrCore\n   * @throws Exception\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,String> props = new HashMap<String,String>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @param coreName\n   * @param desc\n   * @param recoverReloadedCores\n   * @return the shardId for the SolrCore\n   * @throws Exception\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,String> props = new HashMap<String,String>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    // rather than look in the cluster state file, we go straight to the zknodes\n    // here, because on cluster restart there could be stale leader info in the\n    // cluster state node that won't be updated for a moment\n    String leaderUrl = getLeaderProps(collection, cloudDesc.getShardId()).getCoreUrl();\n    \n    // now wait until our currently cloud state contains the latest leader\n    String clusterStateLeader = zkStateReader.getLeaderUrl(collection, shardId, 30000);\n    int tries = 0;\n    while (!leaderUrl.equals(clusterStateLeader)) {\n      if (tries == 60) {\n        throw new SolrException(ErrorCode.SERVER_ERROR,\n            \"There is conflicting information about the leader of shard: \"\n                + cloudDesc.getShardId() + \" our state says:\" + clusterStateLeader + \" but zookeeper says:\" + leaderUrl);\n      }\n      Thread.sleep(1000);\n      tries++;\n      clusterStateLeader = zkStateReader.getLeaderUrl(collection, shardId, 30000);\n      leaderUrl = getLeaderProps(collection, cloudDesc.getShardId()).getCoreUrl();\n    }\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }\n      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @param coreName\n   * @param desc\n   * @param recoverReloadedCores\n   * @param afterExpiration\n   * @return the shardId for the SolrCore\n   * @throws Exception\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,String> props = new HashMap<String,String>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa64435b5902ce266c23755a4a00691a3285dab8","date":1347243290,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @param coreName\n   * @param desc\n   * @param recoverReloadedCores\n   * @param afterExpiration\n   * @return the shardId for the SolrCore\n   * @throws Exception\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @param coreName\n   * @param desc\n   * @param recoverReloadedCores\n   * @param afterExpiration\n   * @return the shardId for the SolrCore\n   * @throws Exception\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,String> props = new HashMap<String,String>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @param coreName\n   * @param desc\n   * @param recoverReloadedCores\n   * @param afterExpiration\n   * @return the shardId for the SolrCore\n   * @throws Exception\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b57979cb590291ca31b9384e4d78a6799d29becc","date":1351214721,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f2126b84bd093fa3d921582a109a0ee578c28126","date":1351522501,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peerync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9a98541130dbb2dd570f39bd89ced65760cad80","date":1355032328,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 1000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":["6013b4c7388f1627659c8f96c44abd10a294d3a6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 1000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n    String leaderUrl = getLeader(cloudDesc);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"513a0d1afdd0a58de1fc3a87654e66fb6694d02a","date":1355808434,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 1000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 1000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f70f627ed5d724ec67fa283565a5ab0fdf37488","date":1356803993,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 1000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register shard - core:\" + coreName + \" address:\"\n            + baseUrl + \" shardId:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 1000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d","date":1361851792,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getNodeName() + \"_\" + coreName;\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0beaed456aa3358e5e4a99ea2aea994ef6c81de3","date":1365434191,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          core.getUpdateHandler().getUpdateLog().bufferUpdates();\n          publish(desc, ZkStateReader.ACTIVE);\n\n        } else  {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      }      \n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5bd6aa52c560df7d631f1e5182265481bbb883ff","date":1365451215,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          publish(desc, ZkStateReader.ACTIVE);\n        } else {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          core.getUpdateHandler().getUpdateLog().bufferUpdates();\n          publish(desc, ZkStateReader.ACTIVE);\n\n        } else  {\n        Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n            .getUpdateLog().recoverFromLog();\n        if (recoveryFuture != null) {\n          recoveryFuture.get(); // NOTE: this could potentially block for\n          // minutes or more!\n          // TODO: public as recovering in the mean time?\n          // TODO: in the future we could do peersync in parallel with recoverFromLog\n        } else {\n          log.info(\"No LogReplay needed for core=\"+core.getName() + \" baseURL=\" + baseUrl);\n        }\n      boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n          collection, coreZkNodeName, shardId, leaderProps, core, cc);\n      if (!didRecovery) {\n        publish(desc, ZkStateReader.ACTIVE);\n      }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":["d0e67453ef2c855797898e384afc5dd4a4d6bac5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          publish(desc, ZkStateReader.ACTIVE);\n        } else {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          publish(desc, ZkStateReader.ACTIVE);\n        } else {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96adbab674ae121f8b6b3e10474070b4bd97a219","date":1373614333,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) && !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          publish(desc, ZkStateReader.ACTIVE);\n        } else {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":["990f72fe460ff33682207a677ea743d2ce48ea21"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"990f72fe460ff33682207a677ea743d2ce48ea21","date":1373906868,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) && !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":["96adbab674ae121f8b6b3e10474070b4bd97a219"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = getCoreNodeName(desc);\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (Slice.CONSTRUCTION.equals(slice.getState())) {\n          publish(desc, ZkStateReader.ACTIVE);\n        } else {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92a4da96826f502cf1a56a096929b37ce73e523a","date":1374584011,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, Integer.parseInt(leaderVoteWait) + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"97bd2b0da4beced82821b752b29576be986cf1ff","date":1387747012,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n      // TODO: if I'm the leader, ensure that a replica that is trying to recover waits until I'm\n      // active (or don't make me the\n      // leader until my local replay is done.\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<String,Object>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e332392bbbdd01cb69ad6a89051f483cda38e15e","date":1395758779,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n    \n\n    SolrCore core = null;\n    try {\n      core = cc.getCore(desc.getName());\n\n \n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    } finally {\n      if (core != null) {\n        core.close();\n      }\n    }\n\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"14d5815ecbef89580f5c48990bcd433f04f8563a","date":1399564106,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5455c7b3fed6c1671990a44c19071cb0488c2c25","date":1413557414,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(Overseer.preferredLeaderProp, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a22eafe3f72a4c2945eaad9547e6c78816978f4","date":1413956657,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(Overseer.preferredLeaderProp, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      joinElection(desc, afterExpiration);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24a5da2a0d397ff29f3de8f6cf451d3412c2509a","date":1417276391,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(Overseer.preferredLeaderProp, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c6e1dc1bb4254226c8d7151b596cc1be40671751","date":1421876355,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException | IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n\n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    \n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dbf528c0e702c5cbd1339b2da1cdc823fd44a925","date":1427230904,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n                .getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException | IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n\n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":["344b0840364d990b29b97467bfcc766ff8325d11","d0e67453ef2c855797898e384afc5dd4a4d6bac5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbcfc050b9f253136eaa5950b57248b2109eac11","date":1427308993,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n                .getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n                .getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n                .getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   * \n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {  \n    // pre register has published our down state\n    \n    final String baseUrl = getBaseUrl();\n    \n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n    \n    String shardId = cloudDesc.getShardId();\n\n    Map<String,Object> props = new HashMap<>();\n // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\"\n            + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n    \n    try {\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) {\n        joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    } catch (KeeperException | IOException e) {\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n    }\n\n\n    // in this case, we want to wait for the leader as long as the leader might \n    // wait for a vote, at least - but also long enough that a large cluster has\n    // time to get its act together\n    String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n    \n    String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n    log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n    boolean isLeader = leaderUrl.equals(ourUrl);\n\n    try (SolrCore core = cc.getCore(desc.getName())) {\n\n      // recover from local transaction log and wait for it to complete before\n      // going active\n      // TODO: should this be moved to another thread? To recoveryStrat?\n      // TODO: should this actually be done earlier, before (or as part of)\n      // leader election perhaps?\n\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      if (!core.isReloaded() && ulog != null) {\n        // disable recovery in case shard is in construction state (for shard splits)\n        Slice slice = getClusterState().getSlice(collection, shardId);\n        if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n          Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n              .getUpdateLog().recoverFromLog();\n          if (recoveryFuture != null) {\n            log.info(\"Replaying tlog for \"+ourUrl+\" during startup... NOTE: This can take a while.\");\n            recoveryFuture.get(); // NOTE: this could potentially block for\n            // minutes or more!\n            // TODO: public as recovering in the mean time?\n            // TODO: in the future we could do peersync in parallel with recoverFromLog\n          } else {\n            log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc);\n        if (!didRecovery) {\n          publish(desc, ZkStateReader.ACTIVE);\n        }\n      }\n    }\n    \n    // make sure we have an update cluster state right away\n    zkStateReader.updateClusterState(true);\n    return shardId;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296","date":1427866967,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n                .getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0c924d4069ef5a5bc479a493befe0121aada6896","date":1427901860,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (!Slice.CONSTRUCTION.equals(slice.getState()) || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler()\n                .getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a219f1dcad1700e84807666bdbd2b573e8de7021","date":1428130940,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, Replica.State.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, ZkStateReader.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","bugFix":null,"bugIntro":["d0e67453ef2c855797898e384afc5dd4a4d6bac5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0e67453ef2c855797898e384afc5dd4a4d6bac5","date":1428334932,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        if (!core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n          boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n              collection, coreZkNodeName, shardId, leaderProps, core, cc);\n          if (!didRecovery) {\n            publish(desc, Replica.State.ACTIVE);\n          }\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","bugFix":["dbf528c0e702c5cbd1339b2da1cdc823fd44a925","5bd6aa52c560df7d631f1e5182265481bbb883ff","a219f1dcad1700e84807666bdbd2b573e8de7021"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"439c63ae5d22132fca810a0029a854e97d2c1a3e","date":1432733612,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    // pre register has published our down state\n    final String baseUrl = getBaseUrl();\n\n    final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n    final String collection = cloudDesc.getCollectionName();\n\n    Map previousMDCContext = MDC.getCopyOfContextMap();\n    MDCUtils.setCollection(collection);\n\n    final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n    assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n    String shardId = cloudDesc.getShardId();\n    MDCUtils.setShard(shardId);\n    Map<String, Object> props = new HashMap<>();\n    // we only put a subset of props into the leader node\n    props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n    props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n    props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Register replica - core:\" + coreName + \" address:\"\n          + baseUrl + \" collection:\" + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n    }\n\n    ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n    try {\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n\n      // in this case, we want to wait for the leader as long as the leader might \n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc,\n            collection, coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCUtils.cleanupMDC(previousMDCContext);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"102da6baafc0f534a59f31729343dbab9d3b9e9a","date":1438410244,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState();\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState(true);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"605f94f466b936ef47220109e97eea240dff2442","date":1447425207,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState();\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState();\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","date":1457343183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.updateClusterState();\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962cd4f5e313777f35da8f521265323e84184929","date":1474533758,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d528fd7ae22865015b756e0a03832e2051de2a9c","date":1476721105,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":null,"sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      if (log.isInfoEnabled()) {\n        log.info(\"Register replica - core:\" + coreName + \" address:\" + baseUrl + \" collection:\"\n            + cloudDesc.getCollectionName() + \" shard:\" + shardId);\n      }\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.info(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.info(\"No LogReplay needed for core=\" + core.getName() + \" baseURL=\" + baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","7f70f627ed5d724ec67fa283565a5ab0fdf37488"],"605f94f466b936ef47220109e97eea240dff2442":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"97bd2b0da4beced82821b752b29576be986cf1ff":["92a4da96826f502cf1a56a096929b37ce73e523a"],"d0e67453ef2c855797898e384afc5dd4a4d6bac5":["a219f1dcad1700e84807666bdbd2b573e8de7021"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["5bd6aa52c560df7d631f1e5182265481bbb883ff","990f72fe460ff33682207a677ea743d2ce48ea21"],"d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296":["fbcfc050b9f253136eaa5950b57248b2109eac11"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["605f94f466b936ef47220109e97eea240dff2442"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["d0e67453ef2c855797898e384afc5dd4a4d6bac5"],"6013b4c7388f1627659c8f96c44abd10a294d3a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0c924d4069ef5a5bc479a493befe0121aada6896":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["c6e1dc1bb4254226c8d7151b596cc1be40671751","fbcfc050b9f253136eaa5950b57248b2109eac11"],"24a5da2a0d397ff29f3de8f6cf451d3412c2509a":["5455c7b3fed6c1671990a44c19071cb0488c2c25"],"5bd6aa52c560df7d631f1e5182265481bbb883ff":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"96adbab674ae121f8b6b3e10474070b4bd97a219":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"f9a98541130dbb2dd570f39bd89ced65760cad80":["b57979cb590291ca31b9384e4d78a6799d29becc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","962cd4f5e313777f35da8f521265323e84184929"],"e332392bbbdd01cb69ad6a89051f483cda38e15e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"14d5815ecbef89580f5c48990bcd433f04f8563a":["e332392bbbdd01cb69ad6a89051f483cda38e15e"],"f2126b84bd093fa3d921582a109a0ee578c28126":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","b57979cb590291ca31b9384e4d78a6799d29becc"],"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["fa64435b5902ce266c23755a4a00691a3285dab8"],"c6e1dc1bb4254226c8d7151b596cc1be40671751":["24a5da2a0d397ff29f3de8f6cf451d3412c2509a"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["97bd2b0da4beced82821b752b29576be986cf1ff"],"962cd4f5e313777f35da8f521265323e84184929":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["37a0f60745e53927c4c876cfe5b5a58170f0646c","92a4da96826f502cf1a56a096929b37ce73e523a"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"fa64435b5902ce266c23755a4a00691a3285dab8":["6013b4c7388f1627659c8f96c44abd10a294d3a6"],"92a4da96826f502cf1a56a096929b37ce73e523a":["990f72fe460ff33682207a677ea743d2ce48ea21"],"407687e67faf6e1f02a211ca078d8e3eed631027":["b57979cb590291ca31b9384e4d78a6799d29becc","f9a98541130dbb2dd570f39bd89ced65760cad80"],"5455c7b3fed6c1671990a44c19071cb0488c2c25":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"7f70f627ed5d724ec67fa283565a5ab0fdf37488":["513a0d1afdd0a58de1fc3a87654e66fb6694d02a"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["cb4a195b8dc1808cd01748bd2e0fba26ca915d4d"],"513a0d1afdd0a58de1fc3a87654e66fb6694d02a":["f9a98541130dbb2dd570f39bd89ced65760cad80"],"b57979cb590291ca31b9384e4d78a6799d29becc":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6013b4c7388f1627659c8f96c44abd10a294d3a6"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","d528fd7ae22865015b756e0a03832e2051de2a9c"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["5bd6aa52c560df7d631f1e5182265481bbb883ff"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["14d5815ecbef89580f5c48990bcd433f04f8563a","5455c7b3fed6c1671990a44c19071cb0488c2c25"],"990f72fe460ff33682207a677ea743d2ce48ea21":["96adbab674ae121f8b6b3e10474070b4bd97a219"],"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d":["7f70f627ed5d724ec67fa283565a5ab0fdf37488"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"fbcfc050b9f253136eaa5950b57248b2109eac11":["dbf528c0e702c5cbd1339b2da1cdc823fd44a925"],"dbf528c0e702c5cbd1339b2da1cdc823fd44a925":["c6e1dc1bb4254226c8d7151b596cc1be40671751"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"605f94f466b936ef47220109e97eea240dff2442":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"97bd2b0da4beced82821b752b29576be986cf1ff":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"d0e67453ef2c855797898e384afc5dd4a4d6bac5":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296":["0c924d4069ef5a5bc479a493befe0121aada6896","a219f1dcad1700e84807666bdbd2b573e8de7021"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","962cd4f5e313777f35da8f521265323e84184929","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"6013b4c7388f1627659c8f96c44abd10a294d3a6":["fa64435b5902ce266c23755a4a00691a3285dab8","05a14b2611ead08655a2b2bdc61632eb31316e57"],"0c924d4069ef5a5bc479a493befe0121aada6896":[],"a219f1dcad1700e84807666bdbd2b573e8de7021":["d0e67453ef2c855797898e384afc5dd4a4d6bac5"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["0c924d4069ef5a5bc479a493befe0121aada6896"],"24a5da2a0d397ff29f3de8f6cf451d3412c2509a":["c6e1dc1bb4254226c8d7151b596cc1be40671751"],"5bd6aa52c560df7d631f1e5182265481bbb883ff":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"96adbab674ae121f8b6b3e10474070b4bd97a219":["990f72fe460ff33682207a677ea743d2ce48ea21"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6013b4c7388f1627659c8f96c44abd10a294d3a6","05a14b2611ead08655a2b2bdc61632eb31316e57"],"f9a98541130dbb2dd570f39bd89ced65760cad80":["407687e67faf6e1f02a211ca078d8e3eed631027","513a0d1afdd0a58de1fc3a87654e66fb6694d02a"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"e332392bbbdd01cb69ad6a89051f483cda38e15e":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"14d5815ecbef89580f5c48990bcd433f04f8563a":["5455c7b3fed6c1671990a44c19071cb0488c2c25","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"f2126b84bd093fa3d921582a109a0ee578c28126":[],"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["f2126b84bd093fa3d921582a109a0ee578c28126","b57979cb590291ca31b9384e4d78a6799d29becc"],"c6e1dc1bb4254226c8d7151b596cc1be40671751":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","dbf528c0e702c5cbd1339b2da1cdc823fd44a925"],"962cd4f5e313777f35da8f521265323e84184929":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e332392bbbdd01cb69ad6a89051f483cda38e15e"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":[],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["605f94f466b936ef47220109e97eea240dff2442"],"fa64435b5902ce266c23755a4a00691a3285dab8":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"92a4da96826f502cf1a56a096929b37ce73e523a":["97bd2b0da4beced82821b752b29576be986cf1ff","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"7f70f627ed5d724ec67fa283565a5ab0fdf37488":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cb4a195b8dc1808cd01748bd2e0fba26ca915d4d"],"5455c7b3fed6c1671990a44c19071cb0488c2c25":["24a5da2a0d397ff29f3de8f6cf451d3412c2509a","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["5bd6aa52c560df7d631f1e5182265481bbb883ff"],"b57979cb590291ca31b9384e4d78a6799d29becc":["f9a98541130dbb2dd570f39bd89ced65760cad80","f2126b84bd093fa3d921582a109a0ee578c28126","407687e67faf6e1f02a211ca078d8e3eed631027"],"513a0d1afdd0a58de1fc3a87654e66fb6694d02a":["7f70f627ed5d724ec67fa283565a5ab0fdf37488"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["96adbab674ae121f8b6b3e10474070b4bd97a219"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":[],"990f72fe460ff33682207a677ea743d2ce48ea21":["37a0f60745e53927c4c876cfe5b5a58170f0646c","92a4da96826f502cf1a56a096929b37ce73e523a"],"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"fbcfc050b9f253136eaa5950b57248b2109eac11":["d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"dbf528c0e702c5cbd1339b2da1cdc823fd44a925":["fbcfc050b9f253136eaa5950b57248b2109eac11"]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","0c924d4069ef5a5bc479a493befe0121aada6896","f2126b84bd093fa3d921582a109a0ee578c28126","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","05a14b2611ead08655a2b2bdc61632eb31316e57","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","0a22eafe3f72a4c2945eaad9547e6c78816978f4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}