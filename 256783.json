{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","commits":[{"id":"7f936b67ab4a872d22231aae4f63608e7f411071","date":1412266152,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String name) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    final String entriesFileName = IndexFileNames.segmentFileName(IndexFileNames.stripExtension(name), \"\",\n                                                                  IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    final String entriesFileName = IndexFileNames.segmentFileName(IndexFileNames.stripExtension(name), \"\",\n                                                                  IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, \n                                                              CompoundFileWriter.VERSION_START, \n                                                              CompoundFileWriter.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c34e07420c03a037d73169b35f349c2ad6fd8c7","date":1412304383,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String name) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    final String entriesFileName = IndexFileNames.segmentFileName(IndexFileNames.stripExtension(name), \"\",\n                                                                  IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"/dev/null","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkSegmentHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71488d7f5786ae87541276121ecb69705a11a295","date":1465498138,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50CompoundReader#readEntries(byte[],Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, \"\");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9bb9a29a5e71a90295f175df8919802993142c9a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9c34e07420c03a037d73169b35f349c2ad6fd8c7"],"9c34e07420c03a037d73169b35f349c2ad6fd8c7":["7f936b67ab4a872d22231aae4f63608e7f411071"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"71488d7f5786ae87541276121ecb69705a11a295":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["9c34e07420c03a037d73169b35f349c2ad6fd8c7"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"7f936b67ab4a872d22231aae4f63608e7f411071":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238","71488d7f5786ae87541276121ecb69705a11a295"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71488d7f5786ae87541276121ecb69705a11a295"]},"commit2Childs":{"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"9c34e07420c03a037d73169b35f349c2ad6fd8c7":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9bb9a29a5e71a90295f175df8919802993142c9a","7f936b67ab4a872d22231aae4f63608e7f411071"],"71488d7f5786ae87541276121ecb69705a11a295":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["71488d7f5786ae87541276121ecb69705a11a295","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"7f936b67ab4a872d22231aae4f63608e7f411071":["9c34e07420c03a037d73169b35f349c2ad6fd8c7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}