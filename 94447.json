{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","commits":[{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":1,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(Version,TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.charUtils = CharacterUtils.getInstance();\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param version the Lucene match version\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(Version version, TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (version == null) {\n      throw new IllegalArgumentException(\"version must not be null\");\n    }\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","date":1465824262,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.charUtils = CharacterUtils.getInstance();\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","date":1465913303,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.charUtils = CharacterUtils.getInstance();\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.charUtils = CharacterUtils.getInstance();\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a255765a5625ff80fba75863de5a16ea392015e","date":1528161860,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram.\n   * \n   * <p>\n   * Behaves the same as\n   * {@link #EdgeNGramTokenFilter(TokenStream, int, int, boolean)\n   * NGramTokenFilter(input, minGram, maxGram, false)}\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   *\n   * @deprecated since 7.4. Use\n   * {@link #EdgeNGramTokenFilter(TokenStream, int, int, boolean)} instead.\n   */\n  @Deprecated\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    this(input, minGram, maxGram, DEFAULT_PRESERVE_ORIGINAL);\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f9d9185dd79758c4a333e1856adfe1388f008e3","date":1528166448,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram.\n   * \n   * <p>\n   * Behaves the same as\n   * {@link #EdgeNGramTokenFilter(TokenStream, int, int, boolean)\n   * NGramTokenFilter(input, minGram, maxGram, false)}\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   *\n   * @deprecated since 7.4. Use\n   * {@link #EdgeNGramTokenFilter(TokenStream, int, int, boolean)} instead.\n   */\n  @Deprecated\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    this(input, minGram, maxGram, DEFAULT_PRESERVE_ORIGINAL);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":5,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is outside the min/max size range.\n   */\n  public EdgeNGramTokenFilter(\n      TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":5,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is outside the min/max size range.\n   */\n  public EdgeNGramTokenFilter(\n      TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7f9d9185dd79758c4a333e1856adfe1388f008e3":["8a255765a5625ff80fba75863de5a16ea392015e"],"8a255765a5625ff80fba75863de5a16ea392015e":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","7f9d9185dd79758c4a333e1856adfe1388f008e3"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["379db3ad24c4f0214f30a122265a6d6be003a99d","fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc"],"f592209545c71895260367152601e9200399776d":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","7f9d9185dd79758c4a333e1856adfe1388f008e3"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["379db3ad24c4f0214f30a122265a6d6be003a99d","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7f9d9185dd79758c4a333e1856adfe1388f008e3"]},"commit2Childs":{"7f9d9185dd79758c4a333e1856adfe1388f008e3":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8a255765a5625ff80fba75863de5a16ea392015e":["7f9d9185dd79758c4a333e1856adfe1388f008e3"],"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["8a255765a5625ff80fba75863de5a16ea392015e","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"f592209545c71895260367152601e9200399776d":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}