{"path":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"/dev/null","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    // ensure shard is dead\n    try {\n      // TODO: ignore fail\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    // TODO: this can fail with connection refused !????\n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n    SolrQuery query = new SolrQuery(\"*:*\");\n    long numFound1 = cloudClient.query(query).getResults().getNumFound();\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound2 = cloudClient.query(query).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound1 + 1, numFound2);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          System.out.println(client.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recoverying\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    List<SolrServer> s2c = shardToClient.get(SHARD2);\n    \n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    assertEquals(s2c.get(0).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound(), s2c.get(1).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","a6378064655e76cd7b908b1cab4ce425b384b508","a6378064655e76cd7b908b1cab4ce425b384b508"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"/dev/null","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    // ensure shard is dead\n    try {\n      // TODO: ignore fail\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    // TODO: this can fail with connection refused !????\n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n    SolrQuery query = new SolrQuery(\"*:*\");\n    long numFound1 = cloudClient.query(query).getResults().getNumFound();\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound2 = cloudClient.query(query).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound1 + 1, numFound2);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          System.out.println(client.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recoverying\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    List<SolrServer> s2c = shardToClient.get(SHARD2);\n    \n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    assertEquals(s2c.get(0).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound(), s2c.get(1).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"/dev/null","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    // ensure shard is dead\n    try {\n      // TODO: ignore fail\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    // TODO: this can fail with connection refused !????\n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n    SolrQuery query = new SolrQuery(\"*:*\");\n    long numFound1 = cloudClient.query(query).getResults().getNumFound();\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound2 = cloudClient.query(query).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound1 + 1, numFound2);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          System.out.println(client.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recoverying\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    List<SolrServer> s2c = shardToClient.get(SHARD2);\n    \n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    assertEquals(s2c.get(0).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound(), s2c.get(1).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd42302937647d55b8d6149a0b7cf1633ab4a59e","date":1328908518,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      // TODO: ignore fail\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n    SolrQuery query = new SolrQuery(\"*:*\");\n    long numFound1 = cloudClient.query(query).getResults().getNumFound();\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound2 = cloudClient.query(query).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound1 + 1, numFound2);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          System.out.println(client.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recoverying\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    List<SolrServer> s2c = shardToClient.get(SHARD2);\n    \n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    assertEquals(s2c.get(0).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound(), s2c.get(1).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound());\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    // ensure shard is dead\n    try {\n      // TODO: ignore fail\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    // TODO: this can fail with connection refused !????\n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n    SolrQuery query = new SolrQuery(\"*:*\");\n    long numFound1 = cloudClient.query(query).getResults().getNumFound();\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound2 = cloudClient.query(query).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound1 + 1, numFound2);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          System.out.println(client.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recoverying\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    List<SolrServer> s2c = shardToClient.get(SHARD2);\n    \n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    assertEquals(s2c.get(0).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound(), s2c.get(1).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a752b89ed4b8bfa40e21a23601fbc376340bb3f4","date":1329246954,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.out.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.out.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      // TODO: ignore fail\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n    SolrQuery query = new SolrQuery(\"*:*\");\n    long numFound1 = cloudClient.query(query).getResults().getNumFound();\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound2 = cloudClient.query(query).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound1 + 1, numFound2);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          System.out.println(client.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recoverying\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    List<SolrServer> s2c = shardToClient.get(SHARD2);\n    \n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    assertEquals(s2c.get(0).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound(), s2c.get(1).query(new SolrQuery(\"*:*\")).getResults()\n        .getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"94f787671ca16d65e86976f99bd603595f757a91","date":1330045652,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.out.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.out.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":["933fa8f09adfcd1a858cd0fc7912e21ee993b7fc"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.out.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.out.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.out.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd491a899b691365f6256c8e5e8b26f87d2e1cb7","date":1338988534,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is not longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,\n      SolrServerException, IOException, InterruptedException {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"933fa8f09adfcd1a858cd0fc7912e21ee993b7fc","date":1342989037,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":["94f787671ca16d65e86976f99bd603595f757a91"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a4832dd71c05dbe472b77241bb751f6612e7e44f","date":1343039572,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ef6348b84bf0f8a649826b69a70ac815ff560e2","date":1343106054,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"217c5e3cedf564c6d370670858e1b1edab16fcac","date":1343114420,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient\n        .getZkStateReader()\n        .getCloudState()\n        .liveNodesContain(\n            shardToJetty.get(SHARD2).get(0).info\n                .get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty\n        .getDispatchFilter().getFilter())\n        .getCores()\n        .getZkController()\n        .getZkStateReader()\n        .getCloudState()\n        .liveNodesContain(\n            shardToJetty.get(SHARD2).get(0).info\n                .get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8a65836c18a62c7b1b404fcb1bba729fd4c29e81","date":1343190777,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient\n        .getZkStateReader()\n        .getCloudState()\n        .liveNodesContain(\n            shardToJetty.get(SHARD2).get(0).info\n                .get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty\n        .getDispatchFilter().getFilter())\n        .getCores()\n        .getZkController()\n        .getZkStateReader()\n        .getCloudState()\n        .liveNodesContain(\n            shardToJetty.get(SHARD2).get(0).info\n                .get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":["a935e32f3b1ffa13f8c6bb6301853a05d2b01a89","a935e32f3b1ffa13f8c6bb6301853a05d2b01a89"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","date":1343203827,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    System.err.println(\"dsc:\" + deadShardCount);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n    int tries = 0;\n    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 60) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    // ensure shard is dead\n    try {\n      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n    \n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    tries = 0;\n    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {\n      if (tries++ == 120) {\n        fail(\"Shard still reported as live in zk\");\n      }\n      Thread.sleep(1000);\n    }\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToClient.get(SHARD2).get(0).query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    deadShard.start(true);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c30e4c1cee08b3b229a77991882594fe7250b66","date":1344448871,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":null,"sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":5,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test#brindDownShardIndexSomeDocsAndRecover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/FullSolrCloudTest#brindDownShardIndexSomeDocsAndRecover().mjava","sourceNew":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n  \n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","sourceOld":"  private void brindDownShardIndexSomeDocsAndRecover() throws Exception {\n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.set(\"distrib\", false);\n    \n    commit();\n    \n    long deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // kill a shard\n    CloudJettyRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);\n    cloudClient.connect();\n\n    // we are careful to make sure the downed node is no longer in the state,\n    // because on some systems (especially freebsd w/ blackhole enabled), trying\n    // to talk to a downed node causes grief\n    Set<CloudJettyRunner> jetties = new HashSet<CloudJettyRunner>();\n    jetties.addAll(shardToJetty.get(SHARD2));\n    jetties.remove(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n\n    // ensure shard is dead\n    try {\n      index_specific(deadShard.client.solrClient, id, 999, i1, 107, t1,\n          \"specific doc!\");\n      fail(\"This server should be down and this update should have failed\");\n    } catch (SolrServerException e) {\n      // expected..\n    }\n    \n    commit();\n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // long cloudClientDocs = cloudClient.query(new\n    // SolrQuery(\"*:*\")).getResults().getNumFound();\n    // System.out.println(\"clouddocs:\" + cloudClientDocs);\n    \n    // try to index to a living shard at shard2\n\n\t\n    long numFound1 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    index_specific(shardToJetty.get(SHARD2).get(1).client.solrClient, id, 1000, i1, 108, t1,\n        \"specific doc!\");\n    \n    commit();\n    \n    checkShardConsistency(true, false);\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    // try adding a doc with CloudSolrServer\n    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);\n\n    long numFound2 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    assertEquals(numFound1 + 1, numFound2);\n    \n    SolrInputDocument doc = new SolrInputDocument();\n    doc.addField(\"id\", 1001);\n    \n    controlClient.add(doc);\n    \n    UpdateRequest ureq = new UpdateRequest();\n    ureq.add(doc);\n    // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n    ureq.process(cloudClient);\n    \n    commit();\n    \n    query(\"q\", \"*:*\", \"sort\", \"n_tl1 desc\");\n    \n    long numFound3 = cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound();\n    \n    // lets just check that the one doc since last commit made it in...\n    assertEquals(numFound2 + 1, numFound3);\n    \n    // test debugging\n    testDebugQueries();\n    \n    if (VERBOSE) {\n      System.err.println(controlClient.query(new SolrQuery(\"*:*\")).getResults()\n          .getNumFound());\n      \n      for (SolrServer client : clients) {\n        try {\n          SolrQuery q = new SolrQuery(\"*:*\");\n          q.set(\"distrib\", false);\n          System.err.println(client.query(q).getResults()\n              .getNumFound());\n        } catch (Exception e) {\n          \n        }\n      }\n    }\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // this should trigger a recovery phase on deadShard\n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    deadShardCount = shardToJetty.get(SHARD2).get(0).client.solrClient\n        .query(query).getResults().getNumFound();\n    // if we properly recovered, we should now have the couple missing docs that\n    // came in while shard was down\n    checkShardConsistency(true, false);\n    \n    \n    // recover over 100 docs so we do more than just peer sync (replicate recovery)\n    chaosMonkey.stopJetty(deadShard);\n    \n    for (CloudJettyRunner cjetty : jetties) {\n      waitToSeeNotLive(((SolrDispatchFilter) cjetty.jetty.getDispatchFilter()\n          .getFilter()).getCores().getZkController().getZkStateReader(),\n          deadShard);\n    }\n    waitToSeeNotLive(cloudClient.getZkStateReader(), deadShard);\n    \n    for (int i = 0; i < 226; i++) {\n      doc = new SolrInputDocument();\n      doc.addField(\"id\", 2000 + i);\n      controlClient.add(doc);\n      ureq = new UpdateRequest();\n      ureq.add(doc);\n      // ureq.setParam(\"update.chain\", DISTRIB_UPDATE_CHAIN);\n      ureq.process(cloudClient);\n    }\n    commit();\n    \n    Thread.sleep(1500);\n    \n    ChaosMonkey.start(deadShard.jetty);\n    \n    // make sure we have published we are recovering\n    Thread.sleep(1500);\n    \n    waitForRecoveriesToFinish(false);\n    \n    checkShardConsistency(true, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bd42302937647d55b8d6149a0b7cf1633ab4a59e":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["a752b89ed4b8bfa40e21a23601fbc376340bb3f4","94f787671ca16d65e86976f99bd603595f757a91"],"a752b89ed4b8bfa40e21a23601fbc376340bb3f4":["bd42302937647d55b8d6149a0b7cf1633ab4a59e"],"fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b":["a4832dd71c05dbe472b77241bb751f6612e7e44f","8a65836c18a62c7b1b404fcb1bba729fd4c29e81"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"8a65836c18a62c7b1b404fcb1bba729fd4c29e81":["217c5e3cedf564c6d370670858e1b1edab16fcac"],"6ef6348b84bf0f8a649826b69a70ac815ff560e2":["a4832dd71c05dbe472b77241bb751f6612e7e44f"],"a4832dd71c05dbe472b77241bb751f6612e7e44f":["933fa8f09adfcd1a858cd0fc7912e21ee993b7fc"],"933fa8f09adfcd1a858cd0fc7912e21ee993b7fc":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"94f787671ca16d65e86976f99bd603595f757a91":["a752b89ed4b8bfa40e21a23601fbc376340bb3f4"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","2c30e4c1cee08b3b229a77991882594fe7250b66"],"aba371508186796cc6151d8223a5b4e16d02e26e":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","8a65836c18a62c7b1b404fcb1bba729fd4c29e81"],"217c5e3cedf564c6d370670858e1b1edab16fcac":["6ef6348b84bf0f8a649826b69a70ac815ff560e2"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["dd491a899b691365f6256c8e5e8b26f87d2e1cb7","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","8a65836c18a62c7b1b404fcb1bba729fd4c29e81"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["aba371508186796cc6151d8223a5b4e16d02e26e","2c30e4c1cee08b3b229a77991882594fe7250b66"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["fe33227f6805edab2036cbb80645cc4e2d1fa424","a4832dd71c05dbe472b77241bb751f6612e7e44f"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["dd491a899b691365f6256c8e5e8b26f87d2e1cb7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2c30e4c1cee08b3b229a77991882594fe7250b66"],"2c30e4c1cee08b3b229a77991882594fe7250b66":["8a65836c18a62c7b1b404fcb1bba729fd4c29e81"],"dd491a899b691365f6256c8e5e8b26f87d2e1cb7":["94f787671ca16d65e86976f99bd603595f757a91"]},"commit2Childs":{"bd42302937647d55b8d6149a0b7cf1633ab4a59e":["a752b89ed4b8bfa40e21a23601fbc376340bb3f4"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"a752b89ed4b8bfa40e21a23601fbc376340bb3f4":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","94f787671ca16d65e86976f99bd603595f757a91"],"fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"8a65836c18a62c7b1b404fcb1bba729fd4c29e81":["fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","aba371508186796cc6151d8223a5b4e16d02e26e","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","2c30e4c1cee08b3b229a77991882594fe7250b66"],"6ef6348b84bf0f8a649826b69a70ac815ff560e2":["217c5e3cedf564c6d370670858e1b1edab16fcac"],"a4832dd71c05dbe472b77241bb751f6612e7e44f":["fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","6ef6348b84bf0f8a649826b69a70ac815ff560e2","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"94f787671ca16d65e86976f99bd603595f757a91":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","dd491a899b691365f6256c8e5e8b26f87d2e1cb7"],"933fa8f09adfcd1a858cd0fc7912e21ee993b7fc":["a4832dd71c05dbe472b77241bb751f6612e7e44f"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"aba371508186796cc6151d8223a5b4e16d02e26e":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"217c5e3cedf564c6d370670858e1b1edab16fcac":["8a65836c18a62c7b1b404fcb1bba729fd4c29e81"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["bd42302937647d55b8d6149a0b7cf1633ab4a59e","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["933fa8f09adfcd1a858cd0fc7912e21ee993b7fc","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"2c30e4c1cee08b3b229a77991882594fe7250b66":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"dd491a899b691365f6256c8e5e8b26f87d2e1cb7":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}