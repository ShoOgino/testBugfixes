{"path":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7edb20114e86ec883b0b08bd624eee852c565c06","date":1273941247,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockAnalyzer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ade882efb2f2235dafb176284c1e35dbdb1c126","date":1274043418,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockAnalyzer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c084e47df29de3330311d69dabf515ceaa989512","date":1279030906,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, true);\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      String[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0]);\n      assertEquals(\"here\", terms[1]);\n      assertEquals(\"some\", terms[2]);\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true)));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();;\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    doc.add(new Field(\"c\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"a\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"b\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    doc.add(new Field(\"x\", \"some content here\", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6eb141f80638abdb6ffaa5149877f36ea39b6ad5","date":1315714072,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();;\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    Fields v = reader.getTermVectors(0);\n    assertEquals(4, v.getUniqueFieldCount());\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    FieldsEnum fieldsEnum = v.iterator();\n    for(int i=0;i<expectedFields.length;i++) {\n      assertEquals(expectedFields[i], fieldsEnum.next());\n      assertEquals(3, v.terms(expectedFields[i]).getUniqueTermCount());\n\n      DocsAndPositionsEnum dpEnum = null;\n      Terms terms = fieldsEnum.terms();\n      assertNotNull(terms);\n      TermsEnum termsEnum = terms.iterator(null);\n      assertEquals(\"content\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[0], dpEnum.nextPosition());\n\n      assertEquals(\"here\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[1], dpEnum.nextPosition());\n\n      assertEquals(\"some\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[2], dpEnum.nextPosition());\n\n      assertNull(termsEnum.next());\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    TermFreqVector[] v = reader.getTermFreqVectors(0);\n    assertEquals(4, v.length);\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    for(int i=0;i<v.length;i++) {\n      TermPositionVector posVec = (TermPositionVector) v[i];\n      assertEquals(expectedFields[i], posVec.getField());\n      BytesRef[] terms = posVec.getTerms();\n      assertEquals(3, terms.length);\n      assertEquals(\"content\", terms[0].utf8ToString());\n      assertEquals(\"here\", terms[1].utf8ToString());\n      assertEquals(\"some\", terms[2].utf8ToString());\n      for(int j=0;j<3;j++) {\n        int[] positions = posVec.getTermPositions(j);\n        assertEquals(1, positions.length);\n        assertEquals(expectedPositions[j], positions[0]);\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31f025ae60076ae95274433f3fe8e6ace2857a87","date":1326669465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    Fields v = reader.getTermVectors(0);\n    assertEquals(4, v.getUniqueFieldCount());\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    FieldsEnum fieldsEnum = v.iterator();\n    for(int i=0;i<expectedFields.length;i++) {\n      assertEquals(expectedFields[i], fieldsEnum.next());\n      assertEquals(3, v.terms(expectedFields[i]).getUniqueTermCount());\n\n      DocsAndPositionsEnum dpEnum = null;\n      Terms terms = fieldsEnum.terms();\n      assertNotNull(terms);\n      TermsEnum termsEnum = terms.iterator(null);\n      assertEquals(\"content\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[0], dpEnum.nextPosition());\n\n      assertEquals(\"here\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[1], dpEnum.nextPosition());\n\n      assertEquals(\"some\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[2], dpEnum.nextPosition());\n\n      assertNull(termsEnum.next());\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    Fields v = reader.getTermVectors(0);\n    assertEquals(4, v.getUniqueFieldCount());\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    FieldsEnum fieldsEnum = v.iterator();\n    for(int i=0;i<expectedFields.length;i++) {\n      assertEquals(expectedFields[i], fieldsEnum.next());\n      assertEquals(3, v.terms(expectedFields[i]).getUniqueTermCount());\n\n      DocsAndPositionsEnum dpEnum = null;\n      Terms terms = fieldsEnum.terms();\n      assertNotNull(terms);\n      TermsEnum termsEnum = terms.iterator(null);\n      assertEquals(\"content\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[0], dpEnum.nextPosition());\n\n      assertEquals(\"here\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[1], dpEnum.nextPosition());\n\n      assertEquals(\"some\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[2], dpEnum.nextPosition());\n\n      assertNull(termsEnum.next());\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectorsFieldOrder().mjava","sourceNew":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    Fields v = reader.getTermVectors(0);\n    assertEquals(4, v.getUniqueFieldCount());\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    FieldsEnum fieldsEnum = v.iterator();\n    for(int i=0;i<expectedFields.length;i++) {\n      assertEquals(expectedFields[i], fieldsEnum.next());\n      assertEquals(3, v.terms(expectedFields[i]).getUniqueTermCount());\n\n      DocsAndPositionsEnum dpEnum = null;\n      Terms terms = fieldsEnum.terms();\n      assertNotNull(terms);\n      TermsEnum termsEnum = terms.iterator(null);\n      assertEquals(\"content\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[0], dpEnum.nextPosition());\n\n      assertEquals(\"here\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[1], dpEnum.nextPosition());\n\n      assertEquals(\"some\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[2], dpEnum.nextPosition());\n\n      assertNull(termsEnum.next());\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTermVectorsFieldOrder() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    doc.add(newField(\"c\", \"some content here\", ft));\n    doc.add(newField(\"a\", \"some content here\", ft));\n    doc.add(newField(\"b\", \"some content here\", ft));\n    doc.add(newField(\"x\", \"some content here\", ft));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    Fields v = reader.getTermVectors(0);\n    assertEquals(4, v.getUniqueFieldCount());\n    String[] expectedFields = new String[]{\"a\", \"b\", \"c\", \"x\"};\n    int[] expectedPositions = new int[]{1, 2, 0};\n    FieldsEnum fieldsEnum = v.iterator();\n    for(int i=0;i<expectedFields.length;i++) {\n      assertEquals(expectedFields[i], fieldsEnum.next());\n      assertEquals(3, v.terms(expectedFields[i]).getUniqueTermCount());\n\n      DocsAndPositionsEnum dpEnum = null;\n      Terms terms = fieldsEnum.terms();\n      assertNotNull(terms);\n      TermsEnum termsEnum = terms.iterator(null);\n      assertEquals(\"content\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[0], dpEnum.nextPosition());\n\n      assertEquals(\"here\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[1], dpEnum.nextPosition());\n\n      assertEquals(\"some\", termsEnum.next().utf8ToString());\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(1, dpEnum.freq());\n      assertEquals(expectedPositions[2], dpEnum.nextPosition());\n\n      assertNull(termsEnum.next());\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["2ade882efb2f2235dafb176284c1e35dbdb1c126"],"7edb20114e86ec883b0b08bd624eee852c565c06":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","4b103252dee6afa1b6d7a622c773d178788eb85a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["c084e47df29de3330311d69dabf515ceaa989512","15bbd254c1506df5299c4df8c148262c7bd6301e"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"6eb141f80638abdb6ffaa5149877f36ea39b6ad5":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["c084e47df29de3330311d69dabf515ceaa989512"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["1f653cfcf159baeaafe5d01682a911e95bba4012","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3cc749c053615f5871f3b95715fe292f34e70a53":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5"],"5f4e87790277826a2aea119328600dfb07761f32":["2ade882efb2f2235dafb176284c1e35dbdb1c126","c084e47df29de3330311d69dabf515ceaa989512"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","1f653cfcf159baeaafe5d01682a911e95bba4012"],"c084e47df29de3330311d69dabf515ceaa989512":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1f653cfcf159baeaafe5d01682a911e95bba4012","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"2ade882efb2f2235dafb176284c1e35dbdb1c126":["7edb20114e86ec883b0b08bd624eee852c565c06"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["c084e47df29de3330311d69dabf515ceaa989512"],"7edb20114e86ec883b0b08bd624eee852c565c06":["2ade882efb2f2235dafb176284c1e35dbdb1c126"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["3242a09f703274d3b9283f2064a1a33064b53a1b","ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"6eb141f80638abdb6ffaa5149877f36ea39b6ad5":["3cc749c053615f5871f3b95715fe292f34e70a53"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"c084e47df29de3330311d69dabf515ceaa989512":["4b103252dee6afa1b6d7a622c773d178788eb85a","15bbd254c1506df5299c4df8c148262c7bd6301e","5f4e87790277826a2aea119328600dfb07761f32"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["135621f3a0670a9394eb563224a3b76cc4dddc0f","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5"],"2ade882efb2f2235dafb176284c1e35dbdb1c126":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","5f4e87790277826a2aea119328600dfb07761f32"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7edb20114e86ec883b0b08bd624eee852c565c06"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}