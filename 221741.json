{"path":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","commits":[{"id":"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","date":1399816179,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              FieldCache.Longs ndv = FieldCache.DEFAULT.getLongs(ar, \"number\", false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals((int) numbers.get(docID).longValue(), FieldCache.DEFAULT.getInts(ar, \"number\", false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getLongs(ar, \"number\", false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(Float.intBitsToFloat((int) numbers.get(docID).longValue()), FieldCache.DEFAULT.getFloats(ar, \"number\", false).get(docID), 0.0f);\n                  break;\n                case 3:\n                  assertEquals(Double.longBitsToDouble(numbers.get(docID).longValue()), FieldCache.DEFAULT.getDoubles(ar, \"number\", false).get(docID), 0.0);\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              FieldCache.Longs ndv = FieldCache.DEFAULT.getLongs(ar, \"number\", false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals((int) numbers.get(docID).longValue(), FieldCache.DEFAULT.getInts(ar, \"number\", false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getLongs(ar, \"number\", false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(Float.intBitsToFloat((int) numbers.get(docID).longValue()), FieldCache.DEFAULT.getFloats(ar, \"number\", false).get(docID), 0.0f);\n                  break;\n                case 3:\n                  assertEquals(Double.longBitsToDouble(numbers.get(docID).longValue()), FieldCache.DEFAULT.getDoubles(ar, \"number\", false).get(docID), 0.0);\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":1,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              FieldCache.Longs ndv = FieldCache.DEFAULT.getLongs(ar, \"number\", false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals((int) numbers.get(docID).longValue(), FieldCache.DEFAULT.getInts(ar, \"number\", false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getLongs(ar, \"number\", false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(Float.intBitsToFloat((int) numbers.get(docID).longValue()), FieldCache.DEFAULT.getFloats(ar, \"number\", false).get(docID), 0.0f);\n                  break;\n                case 3:\n                  assertEquals(Double.longBitsToDouble(numbers.get(docID).longValue()), FieldCache.DEFAULT.getDoubles(ar, \"number\", false).get(docID), 0.0);\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              BytesRef scratch = new BytesRef();\n              BytesRef scratch2 = new BytesRef();\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                bdv.get(docID, scratch);\n                assertEquals(binary.get(docID), scratch);\n                // Cannot share a single scratch against two \"sources\":\n                sdv.get(docID, scratch2);\n                assertEquals(sorted.get(docID), scratch2);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.shutdown();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final AtomicReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w, true);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8c146731a64debc22c115bbf11ee1a060aa7ea02","date":1457616596,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_INT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_LONG_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a076c3c721f685b7559308fdc2cd72d91bba67e5","date":1464168992,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e121d43b5a10f2df530f406f935102656e9c4e8","date":1464198131,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83870855d82aba6819217abeff5a40779dbb28b4","date":1464291012,"type":5,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestFieldCacheWithThreads#test().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheWithThreads#test().mjava","sourceNew":null,"sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n\n    final List<Long> numbers = new ArrayList<>();\n    final List<BytesRef> binary = new ArrayList<>();\n    final List<BytesRef> sorted = new ArrayList<>();\n    final int numDocs = atLeast(100);\n    for(int i=0;i<numDocs;i++) {\n      Document d = new Document();\n      long number = random().nextLong();\n      d.add(new NumericDocValuesField(\"number\", number));\n      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new BinaryDocValuesField(\"bytes\", bytes));\n      binary.add(bytes);\n      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));\n      d.add(new SortedDocValuesField(\"sorted\", bytes));\n      sorted.add(bytes);\n      w.addDocument(d);\n      numbers.add(number);\n    }\n\n    w.forceMerge(1);\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n\n    assertEquals(1, r.leaves().size());\n    final LeafReader ar = r.leaves().get(0).reader();\n\n    int numThreads = TestUtil.nextInt(random(), 2, 5);\n    List<Thread> threads = new ArrayList<>();\n    final CountDownLatch startingGun = new CountDownLatch(1);\n    for(int t=0;t<numThreads;t++) {\n      final Random threadRandom = new Random(random().nextLong());\n      Thread thread = new Thread() {\n          @Override\n          public void run() {\n            try {\n              //NumericDocValues ndv = ar.getNumericDocValues(\"number\");\n              NumericDocValues ndv = FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false);\n              //BinaryDocValues bdv = ar.getBinaryDocValues(\"bytes\");\n              BinaryDocValues bdv = FieldCache.DEFAULT.getTerms(ar, \"bytes\", false);\n              SortedDocValues sdv = FieldCache.DEFAULT.getTermsIndex(ar, \"sorted\");\n              startingGun.await();\n              int iters = atLeast(1000);\n              for(int iter=0;iter<iters;iter++) {\n                int docID = threadRandom.nextInt(numDocs);\n                switch(threadRandom.nextInt(4)) {\n                case 0:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.INT_POINT_PARSER, false).get(docID));\n                  break;\n                case 1:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.LONG_POINT_PARSER, false).get(docID));\n                  break;\n                case 2:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.FLOAT_POINT_PARSER, false).get(docID));\n                  break;\n                case 3:\n                  assertEquals(numbers.get(docID).longValue(), FieldCache.DEFAULT.getNumerics(ar, \"number\", FieldCache.DOUBLE_POINT_PARSER, false).get(docID));\n                  break;\n                }\n                BytesRef term = bdv.get(docID);\n                assertEquals(binary.get(docID), term);\n                term = sdv.get(docID);\n                assertEquals(sorted.get(docID), term);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      thread.start();\n      threads.add(thread);\n    }\n\n    startingGun.countDown();\n\n    for(Thread thread : threads) {\n      thread.join();\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a076c3c721f685b7559308fdc2cd72d91bba67e5":["8c146731a64debc22c115bbf11ee1a060aa7ea02"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["8c146731a64debc22c115bbf11ee1a060aa7ea02","a076c3c721f685b7559308fdc2cd72d91bba67e5"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"83870855d82aba6819217abeff5a40779dbb28b4":["8c146731a64debc22c115bbf11ee1a060aa7ea02","0e121d43b5a10f2df530f406f935102656e9c4e8"],"56572ec06f1407c066d6b7399413178b33176cd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","93dd449115a9247533e44bab47e8429e5dccbc6d"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["8c146731a64debc22c115bbf11ee1a060aa7ea02","0e121d43b5a10f2df530f406f935102656e9c4e8"],"2a1862266772deb28cdcb7d996b64d2177022687":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"8c146731a64debc22c115bbf11ee1a060aa7ea02":["2a1862266772deb28cdcb7d996b64d2177022687"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0e121d43b5a10f2df530f406f935102656e9c4e8"]},"commit2Childs":{"a076c3c721f685b7559308fdc2cd72d91bba67e5":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"83870855d82aba6819217abeff5a40779dbb28b4":[],"56572ec06f1407c066d6b7399413178b33176cd8":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["2a1862266772deb28cdcb7d996b64d2177022687"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"2a1862266772deb28cdcb7d996b64d2177022687":["8c146731a64debc22c115bbf11ee1a060aa7ea02"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","56572ec06f1407c066d6b7399413178b33176cd8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","56572ec06f1407c066d6b7399413178b33176cd8","93dd449115a9247533e44bab47e8429e5dccbc6d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"8c146731a64debc22c115bbf11ee1a060aa7ea02":["a076c3c721f685b7559308fdc2cd72d91bba67e5","0e121d43b5a10f2df530f406f935102656e9c4e8","83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["83870855d82aba6819217abeff5a40779dbb28b4","56572ec06f1407c066d6b7399413178b33176cd8","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}