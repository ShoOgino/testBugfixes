{"path":"lucene/backwards/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/backwards/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int).mjava","pathOld":"backwards/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.segmentInfos = infos;\n    segmentInfosStart = (SegmentInfos) infos.clone();\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n    int upto = 0;\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(upto);\n        if (info.dir == dir) {\n          readers[upto++] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(upto--;upto>=0;upto--) {\n            try {\n              readers[upto].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    if (upto < readers.length) {\n      // This means some segments were in a foreign Directory\n      SegmentReader[] newReaders = new SegmentReader[upto];\n      System.arraycopy(readers, 0, newReaders, 0, upto);\n      readers = newReaders;\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.segmentInfos = infos;\n    segmentInfosStart = (SegmentInfos) infos.clone();\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n    int upto = 0;\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(upto);\n        if (info.dir == dir) {\n          readers[upto++] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(upto--;upto>=0;upto--) {\n            try {\n              readers[upto].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    if (upto < readers.length) {\n      // This means some segments were in a foreign Directory\n      SegmentReader[] newReaders = new SegmentReader[upto];\n      System.arraycopy(readers, 0, newReaders, 0, upto);\n      readers = newReaders;\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6","date":1272983566,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backwards/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int).mjava","sourceNew":null,"sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.segmentInfos = infos;\n    segmentInfosStart = (SegmentInfos) infos.clone();\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n    int upto = 0;\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(upto);\n        if (info.dir == dir) {\n          readers[upto++] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(upto--;upto>=0;upto--) {\n            try {\n              readers[upto].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    if (upto < readers.length) {\n      // This means some segments were in a foreign Directory\n      SegmentReader[] newReaders = new SegmentReader[upto];\n      System.arraycopy(readers, 0, newReaders, 0, upto);\n      readers = newReaders;\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}