{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testDaemonStream().mjava","commits":[{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":1,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testDaemonStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testDaemonStream().mjava","sourceNew":"  @Test\n  public void testDaemonStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(COLLECTIONORALIAS, cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"rollup\", RollupStream.class)\n        .withFunctionName(\"sum\", SumMetric.class)\n        .withFunctionName(\"min\", MinMetric.class)\n        .withFunctionName(\"max\", MaxMetric.class)\n        .withFunctionName(\"avg\", MeanMetric.class)\n        .withFunctionName(\"count\", CountMetric.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    StreamExpression expression;\n    DaemonStream daemonStream;\n\n    expression = StreamExpressionParser.parse(\"daemon(rollup(\"\n        + \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"a_i,a_s\\\", sort=\\\"a_s asc\\\"),\"\n        + \"over=\\\"a_s\\\",\"\n        + \"sum(a_i)\"\n        + \"), id=\\\"test\\\", runInterval=\\\"1000\\\", queueSize=\\\"9\\\")\");\n    daemonStream = (DaemonStream)factory.constructStream(expression);\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    daemonStream.setStreamContext(streamContext);\n    try {\n      //Test Long and Double Sums\n\n      daemonStream.open(); // This will start the daemon thread\n\n      for (int i = 0; i < 4; i++) {\n        Tuple tuple = daemonStream.read(); // Reads from the queue\n        String bucket = tuple.getString(\"a_s\");\n        Double sumi = tuple.getDouble(\"sum(a_i)\");\n\n        //System.out.println(\"#################################### Bucket 1:\"+bucket);\n        assertTrue(bucket.equals(\"hello0\"));\n        assertTrue(sumi.doubleValue() == 17.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n\n        //System.out.println(\"#################################### Bucket 2:\"+bucket);\n        assertTrue(bucket.equals(\"hello3\"));\n        assertTrue(sumi.doubleValue() == 38.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n        //System.out.println(\"#################################### Bucket 3:\"+bucket);\n        assertTrue(bucket.equals(\"hello4\"));\n        assertTrue(sumi.longValue() == 15);\n      }\n\n      //Now lets wait until the internal queue fills up\n\n      while (daemonStream.remainingCapacity() > 0) {\n        try {\n          Thread.sleep(1000);\n        } catch (Exception e) {\n\n        }\n      }\n\n      //OK capacity is full, let's index a new doc\n\n      new UpdateRequest()\n          .add(id, \"10\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"10\")\n          .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n      //Now lets clear the existing docs in the queue 9, plus 3 more to get passed the run that was blocked. The next run should\n      //have the tuples with the updated count.\n      for (int i = 0; i < 12; i++) {\n        daemonStream.read();\n      }\n\n      //And rerun the loop. It should have a new count for hello0\n      for (int i = 0; i < 4; i++) {\n        Tuple tuple = daemonStream.read(); // Reads from the queue\n        String bucket = tuple.getString(\"a_s\");\n        Double sumi = tuple.getDouble(\"sum(a_i)\");\n\n        assertTrue(bucket.equals(\"hello0\"));\n        assertTrue(sumi.doubleValue() == 18.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n\n        assertTrue(bucket.equals(\"hello3\"));\n        assertTrue(sumi.doubleValue() == 38.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n        assertTrue(bucket.equals(\"hello4\"));\n        assertTrue(sumi.longValue() == 15);\n      }\n    } finally {\n      daemonStream.close(); //This should stop the daemon thread\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testDaemonStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(COLLECTIONORALIAS, cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"rollup\", RollupStream.class)\n        .withFunctionName(\"sum\", SumMetric.class)\n        .withFunctionName(\"min\", MinMetric.class)\n        .withFunctionName(\"max\", MaxMetric.class)\n        .withFunctionName(\"avg\", MeanMetric.class)\n        .withFunctionName(\"count\", CountMetric.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    StreamExpression expression;\n    DaemonStream daemonStream;\n\n    expression = StreamExpressionParser.parse(\"daemon(rollup(\"\n        + \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"a_i,a_s\\\", sort=\\\"a_s asc\\\"),\"\n        + \"over=\\\"a_s\\\",\"\n        + \"sum(a_i)\"\n        + \"), id=\\\"test\\\", runInterval=\\\"1000\\\", queueSize=\\\"9\\\")\");\n    daemonStream = (DaemonStream)factory.constructStream(expression);\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    daemonStream.setStreamContext(streamContext);\n    try {\n      //Test Long and Double Sums\n\n      daemonStream.open(); // This will start the daemon thread\n\n      for (int i = 0; i < 4; i++) {\n        Tuple tuple = daemonStream.read(); // Reads from the queue\n        String bucket = tuple.getString(\"a_s\");\n        Double sumi = tuple.getDouble(\"sum(a_i)\");\n\n        //System.out.println(\"#################################### Bucket 1:\"+bucket);\n        assertTrue(bucket.equals(\"hello0\"));\n        assertTrue(sumi.doubleValue() == 17.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n\n        //System.out.println(\"#################################### Bucket 2:\"+bucket);\n        assertTrue(bucket.equals(\"hello3\"));\n        assertTrue(sumi.doubleValue() == 38.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n        //System.out.println(\"#################################### Bucket 3:\"+bucket);\n        assertTrue(bucket.equals(\"hello4\"));\n        assertTrue(sumi.longValue() == 15);\n      }\n\n      //Now lets wait until the internal queue fills up\n\n      while (daemonStream.remainingCapacity() > 0) {\n        try {\n          Thread.sleep(1000);\n        } catch (Exception e) {\n\n        }\n      }\n\n      //OK capacity is full, let's index a new doc\n\n      new UpdateRequest()\n          .add(id, \"10\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"10\")\n          .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n      //Now lets clear the existing docs in the queue 9, plus 3 more to get passed the run that was blocked. The next run should\n      //have the tuples with the updated count.\n      for (int i = 0; i < 12; i++) {\n        daemonStream.read();\n      }\n\n      //And rerun the loop. It should have a new count for hello0\n      for (int i = 0; i < 4; i++) {\n        Tuple tuple = daemonStream.read(); // Reads from the queue\n        String bucket = tuple.getString(\"a_s\");\n        Double sumi = tuple.getDouble(\"sum(a_i)\");\n\n        //System.out.println(\"#################################### Bucket 1:\"+bucket);\n        assertTrue(bucket.equals(\"hello0\"));\n        assertTrue(sumi.doubleValue() == 18.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n\n        //System.out.println(\"#################################### Bucket 2:\"+bucket);\n        assertTrue(bucket.equals(\"hello3\"));\n        assertTrue(sumi.doubleValue() == 38.0D);\n\n        tuple = daemonStream.read();\n        bucket = tuple.getString(\"a_s\");\n        sumi = tuple.getDouble(\"sum(a_i)\");\n        //System.out.println(\"#################################### Bucket 3:\"+bucket);\n        assertTrue(bucket.equals(\"hello4\"));\n        assertTrue(sumi.longValue() == 15);\n      }\n    } finally {\n      daemonStream.close(); //This should stop the daemon thread\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}