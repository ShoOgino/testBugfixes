{"path":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","commits":[{"id":"1d2ec95cdc45879e188017e6e9b00a9a23e5e8c3","date":1354172806,"type":0,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"/dev/null","sourceNew":"  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(new Random());\n\n    Document doc;\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, new Random().toString(), ft));\n      doc.add(new Field(textFieldName, new StringBuilder(new Random().toString()).append(new Random().toString()).append(\n          new Random().toString()).toString(), ft));\n      doc.add(new Field(classFieldName, new Random().toString(), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a3e5484ad53b0938b88384f6c41f658a3971edd","date":1354176947,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":"  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(new Random());\n\n    Document doc;\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, new Random().toString(), ft));\n      doc.add(new Field(textFieldName, new StringBuilder(new Random().toString()).append(new Random().toString()).append(\n          new Random().toString()).toString(), ft));\n      doc.add(new Field(classFieldName, new Random().toString(), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"/dev/null","sourceNew":"  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":"  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":"  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0","date":1422781929,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc, analyzer);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n\n    originalIndex = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());\n\n  }\n\n","bugFix":["1d2ec95cdc45879e188017e6e9b00a9a23e5e8c3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e2d06d853b2be7aee1c9d69a6b36d26410459a9","date":1460361562,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, Integer.toString(rnd.nextInt(10)), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 100; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8","date":1462567286,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, Integer.toString(rnd.nextInt(10)), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, Integer.toString(rnd.nextInt(10)), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, Integer.toString(rnd.nextInt(10)), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, Integer.toString(rnd.nextInt(10)), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      doc.add(new Field(classFieldName, Integer.toString(rnd.nextInt(10)), ft));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c6c784f777a2cc8fa014507ea129526822714d","date":1579733373,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest#setUp().mjava","sourceNew":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","sourceOld":"  @Override\n  @Before\n  public void setUp() throws Exception {\n    super.setUp();\n    dir = newDirectory();\n    indexWriter = new RandomIndexWriter(random(), dir);\n\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n\n    Document doc;\n    Random rnd = random();\n    for (int i = 0; i < 1000; i++) {\n      doc = new Document();\n      doc.add(new Field(idFieldName, \"id\" + Integer.toString(i), ft));\n      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));\n      String className = Integer.toString(rnd.nextInt(10));\n      doc.add(new Field(classFieldName, className, ft));\n      doc.add(new SortedDocValuesField(classFieldName, new BytesRef(className)));\n      indexWriter.addDocument(doc);\n    }\n\n    indexWriter.commit();\n    indexWriter.forceMerge(1);\n\n    originalIndex = getOnlyLeafReader(indexWriter.getReader());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","7530de27b87b961b51f01bd1299b7004d46e8823"],"6613659748fe4411a7dcf85266e55db1f95f7315":["7530de27b87b961b51f01bd1299b7004d46e8823"],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a3e5484ad53b0938b88384f6c41f658a3971edd"],"0ad30c6a479e764150a3316e57263319775f1df2":["4e2d06d853b2be7aee1c9d69a6b36d26410459a9","3d33e731a93d4b57e662ff094f64f94a745422d4"],"1d2ec95cdc45879e188017e6e9b00a9a23e5e8c3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["4e2d06d853b2be7aee1c9d69a6b36d26410459a9","d470c8182e92b264680e34081b75e70a9f2b3c89"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["6613659748fe4411a7dcf85266e55db1f95f7315"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4e2d06d853b2be7aee1c9d69a6b36d26410459a9","0ad30c6a479e764150a3316e57263319775f1df2"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"57c6c784f777a2cc8fa014507ea129526822714d":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7a3e5484ad53b0938b88384f6c41f658a3971edd":["1d2ec95cdc45879e188017e6e9b00a9a23e5e8c3"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["4e2d06d853b2be7aee1c9d69a6b36d26410459a9","fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8"],"7530de27b87b961b51f01bd1299b7004d46e8823":["7a3e5484ad53b0938b88384f6c41f658a3971edd"],"4e2d06d853b2be7aee1c9d69a6b36d26410459a9":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8":["4e2d06d853b2be7aee1c9d69a6b36d26410459a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57c6c784f777a2cc8fa014507ea129526822714d"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"6613659748fe4411a7dcf85266e55db1f95f7315":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"1d2ec95cdc45879e188017e6e9b00a9a23e5e8c3":["7a3e5484ad53b0938b88384f6c41f658a3971edd"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","57c6c784f777a2cc8fa014507ea129526822714d"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["4e2d06d853b2be7aee1c9d69a6b36d26410459a9"],"57c6c784f777a2cc8fa014507ea129526822714d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["407687e67faf6e1f02a211ca078d8e3eed631027","1d2ec95cdc45879e188017e6e9b00a9a23e5e8c3"],"7a3e5484ad53b0938b88384f6c41f658a3971edd":["407687e67faf6e1f02a211ca078d8e3eed631027","7530de27b87b961b51f01bd1299b7004d46e8823"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","6613659748fe4411a7dcf85266e55db1f95f7315"],"4e2d06d853b2be7aee1c9d69a6b36d26410459a9":["0ad30c6a479e764150a3316e57263319775f1df2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","3d33e731a93d4b57e662ff094f64f94a745422d4","fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8"],"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}