{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newField(\"repeated\", \"repeated one\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"repeated two\", TextField.TYPE_STORED));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"), false);\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),\n                                                                          \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()), Collections.emptyMap());\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()), Collections.emptyMap());\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testPositionIncrementGap().mjava","sourceNew":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","sourceOld":"  public void testPositionIncrementGap() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 500;\n      }\n    };\n\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n\n    Document doc = new Document();\n    doc.add(newTextField(\"repeated\", \"repeated one\", Field.Store.YES));\n    doc.add(newTextField(\"repeated\", \"repeated two\", Field.Store.YES));\n\n    writer.addDocument(doc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n\n    PostingsEnum termPositions = MultiTerms.getTermPostingsEnum(reader, \"repeated\", new BytesRef(\"repeated\"));\n    assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    int freq = termPositions.freq();\n    assertEquals(2, freq);\n    assertEquals(0, termPositions.nextPosition());\n    assertEquals(502, termPositions.nextPosition());\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["a45bec74b98f6fc05f52770cfb425739e6563960"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bec68e7c41fed133827595747d853cad504e481e":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"51f5280f31484820499077f41fcdfe92d527d9dc":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["51f5280f31484820499077f41fcdfe92d527d9dc"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","9d153abcf92dc5329d98571a8c3035df9bd80648"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["04f07771a2a7dd3a395700665ed839c3dae2def2","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["04f07771a2a7dd3a395700665ed839c3dae2def2","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"]},"commit2Childs":{"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["bec68e7c41fed133827595747d853cad504e481e"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["322360ac5185a8446d3e0b530b2068bef67cd3d5","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","a45bec74b98f6fc05f52770cfb425739e6563960","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a45bec74b98f6fc05f52770cfb425739e6563960":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"51f5280f31484820499077f41fcdfe92d527d9dc":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["31741cf1390044e38a2ec3127cf302ba841bfd75","92212fd254551a0b1156aafc3a1a6ed1a43932ad"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"04e775de416dd2d8067b10db1c8af975a1d5017e":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["9d153abcf92dc5329d98571a8c3035df9bd80648","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","92212fd254551a0b1156aafc3a1a6ed1a43932ad","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}