{"path":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","date":1310389132,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SlowSynonymFilterFactory#parseRules(Iterable[String],SlowSynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SlowSynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SlowSynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["c26f00b574427b55127e869b935845554afde1fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"]},"commit2Childs":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}