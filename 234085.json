{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","commits":[{"id":"92ff363eabbaa0b7706976aea7997bb2f620caa0","date":1412866130,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      if (fi.isIndexed() && !fi.omitsNorms()) {\n        if (random().nextBoolean()) {\n          fi.setNormValueType(DocValuesType.NUMERIC);\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      if (fi.isIndexed() && !fi.omitsNorms()) {\n        if (random().nextBoolean()) {\n          fi.setNormValueType(DocValuesType.NUMERIC);\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05da2d758a6089e737cdfc230e57a51b472b94b6","date":1413392310,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      if (fi.isIndexed() && !fi.omitsNorms()) {\n        if (random().nextBoolean()) {\n          fi.setNormValueType(DocValuesType.NUMERIC);\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","date":1413458798,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      if (fi.isIndexed() && !fi.omitsNorms()) {\n        if (random().nextBoolean()) {\n          fi.setNormValueType(DocValuesType.NUMERIC);\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3184874f7f3aca850248483485b4995343066875","date":1413876758,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != null && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a22eafe3f72a4c2945eaad9547e6c78816978f4","date":1413956657,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != null && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != IndexOptions.NO && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != null && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95ce1375367b92d411a06175eab3915fe93c6bc","date":1414788502,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != IndexOptions.NO && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eac6ccb51c439bec7f67cb0e299d3cb77b62b87e","date":1415435053,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.addOrUpdate(field, fieldType);\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7e4ca6dc9612ff741d8713743e2bccfae5eadac","date":1528093718,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseFieldInfoFormatTestCase#testRandom().mjava","sourceNew":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","sourceOld":"  /** Test field infos read/write with random fields, with different values. */\n  public void testRandom() throws Exception {\n    Directory dir = newDirectory();\n    Codec codec = getCodec();\n    SegmentInfo segmentInfo = newSegmentInfo(dir, \"_123\");\n    \n    // generate a bunch of fields\n    int numFields = atLeast(2000);\n    Set<String> fieldNames = new HashSet<>();\n    for (int i = 0; i < numFields; i++) {\n      fieldNames.add(TestUtil.randomUnicodeString(random()));\n    }\n    FieldInfos.Builder builder = new FieldInfos.Builder();\n    for (String field : fieldNames) {\n      IndexableFieldType fieldType = randomFieldType(random());\n      FieldInfo fi = builder.getOrAdd(field);\n      IndexOptions indexOptions = fieldType.indexOptions();\n      if (indexOptions != IndexOptions.NONE) {\n        fi.setIndexOptions(indexOptions);\n        if (fieldType.omitNorms()) {      \n          fi.setOmitsNorms();\n        }\n      }\n      fi.setDocValuesType(fieldType.docValuesType());\n      if (fieldType.indexOptions() != IndexOptions.NONE && fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {\n        if (random().nextBoolean()) {\n          fi.setStorePayloads();\n        }\n      }\n      addAttributes(fi);\n    }\n    FieldInfos infos = builder.finish();\n    codec.fieldInfosFormat().write(dir, segmentInfo, \"\", infos, IOContext.DEFAULT);\n    FieldInfos infos2 = codec.fieldInfosFormat().read(dir, segmentInfo, \"\", IOContext.DEFAULT);\n    assertEquals(infos, infos2);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"05da2d758a6089e737cdfc230e57a51b472b94b6":["92ff363eabbaa0b7706976aea7997bb2f620caa0"],"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84":["55980207f1977bd1463465de1659b821347e2fa8","05da2d758a6089e737cdfc230e57a51b472b94b6"],"55980207f1977bd1463465de1659b821347e2fa8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","92ff363eabbaa0b7706976aea7997bb2f620caa0"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["3184874f7f3aca850248483485b4995343066875"],"f95ce1375367b92d411a06175eab3915fe93c6bc":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"3184874f7f3aca850248483485b4995343066875":["05da2d758a6089e737cdfc230e57a51b472b94b6"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","3184874f7f3aca850248483485b4995343066875"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["eac6ccb51c439bec7f67cb0e299d3cb77b62b87e","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["eac6ccb51c439bec7f67cb0e299d3cb77b62b87e"],"eac6ccb51c439bec7f67cb0e299d3cb77b62b87e":["f95ce1375367b92d411a06175eab3915fe93c6bc"],"92ff363eabbaa0b7706976aea7997bb2f620caa0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f592209545c71895260367152601e9200399776d":["eac6ccb51c439bec7f67cb0e299d3cb77b62b87e","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac"]},"commit2Childs":{"05da2d758a6089e737cdfc230e57a51b472b94b6":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","3184874f7f3aca850248483485b4995343066875"],"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84":["0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"55980207f1977bd1463465de1659b821347e2fa8":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["f95ce1375367b92d411a06175eab3915fe93c6bc"],"3184874f7f3aca850248483485b4995343066875":["2bb2842e561df4e8e9ad89010605fc86ac265465","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"f95ce1375367b92d411a06175eab3915fe93c6bc":["eac6ccb51c439bec7f67cb0e299d3cb77b62b87e"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["55980207f1977bd1463465de1659b821347e2fa8","92ff363eabbaa0b7706976aea7997bb2f620caa0"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"eac6ccb51c439bec7f67cb0e299d3cb77b62b87e":["b70042a8a492f7054d480ccdd2be9796510d4327","b7e4ca6dc9612ff741d8713743e2bccfae5eadac","f592209545c71895260367152601e9200399776d"],"92ff363eabbaa0b7706976aea7997bb2f620caa0":["05da2d758a6089e737cdfc230e57a51b472b94b6","55980207f1977bd1463465de1659b821347e2fa8"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0a22eafe3f72a4c2945eaad9547e6c78816978f4","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}