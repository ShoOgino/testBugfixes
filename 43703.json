{"path":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","commits":[{"id":"790c3f61c9b891d66d919c5d10db9fa5216eb0f1","date":1274818604,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"lucene/src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb38e04906cc704c95b1bb9cdc7a960017b0cc25","date":1288942385,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":["b94de30789d3265084ce35298d0675ada43e7643"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd10af23d6329d28dbd5033cccfbbf9748f593f0","date":1288946780,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n    \n    // add any document keywords if they exist\n    String keywords = parser.getMetaTags().getProperty(\"keywords\");\n    if (keywords != null)\n      doc.add(new Field(\"contents\", keywords, Field.Store.NO, Field.Index.ANALYZED));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n    \n    // add any document keywords if they exist\n    String keywords = parser.getMetaTags().getProperty(\"keywords\");\n    if (keywords != null)\n      doc.add(new Field(\"contents\", keywords, Field.Store.NO, Field.Index.ANALYZED));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n    \n    // add any document keywords if they exist\n    String keywords = parser.getMetaTags().getProperty(\"keywords\");\n    if (keywords != null)\n      doc.add(new Field(\"contents\", keywords, Field.Store.NO, Field.Index.ANALYZED));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81ea17596392ebd5d12741eb9e3b2516258b9413","date":1298090976,"type":4,"author":"Steven Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":null,"sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n    \n    // add any document keywords if they exist\n    String keywords = parser.getMetaTags().getProperty(\"keywords\");\n    if (keywords != null)\n      doc.add(new Field(\"contents\", keywords, Field.Store.NO, Field.Index.ANALYZED));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":null,"sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n    \n    // add any document keywords if they exist\n    String keywords = parser.getMetaTags().getProperty(\"keywords\");\n    if (keywords != null)\n      doc.add(new Field(\"contents\", keywords, Field.Store.NO, Field.Index.ANALYZED));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":null,"sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    InputStreamReader reader = new InputStreamReader(fis, \"UTF-8\");\n    HTMLParser parser = new HTMLParser(reader);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n    \n    // add any document keywords if they exist\n    String keywords = parser.getMetaTags().getProperty(\"keywords\");\n    if (keywords != null)\n      doc.add(new Field(\"contents\", keywords, Field.Store.NO, Field.Index.ANALYZED));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f1bdbf92da222965b46c0a942c3857ba56e5c638":["85a883878c0af761245ab048babc63d099f835f3","81ea17596392ebd5d12741eb9e3b2516258b9413"],"81ea17596392ebd5d12741eb9e3b2516258b9413":["fd10af23d6329d28dbd5033cccfbbf9748f593f0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"85a883878c0af761245ab048babc63d099f835f3":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","fd10af23d6329d28dbd5033cccfbbf9748f593f0"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","fd10af23d6329d28dbd5033cccfbbf9748f593f0"],"fd10af23d6329d28dbd5033cccfbbf9748f593f0":["fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","81ea17596392ebd5d12741eb9e3b2516258b9413"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["81ea17596392ebd5d12741eb9e3b2516258b9413"],"fb38e04906cc704c95b1bb9cdc7a960017b0cc25":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"81ea17596392ebd5d12741eb9e3b2516258b9413":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85a883878c0af761245ab048babc63d099f835f3":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"fd10af23d6329d28dbd5033cccfbbf9748f593f0":["81ea17596392ebd5d12741eb9e3b2516258b9413","85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"fb38e04906cc704c95b1bb9cdc7a960017b0cc25":["fd10af23d6329d28dbd5033cccfbbf9748f593f0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}