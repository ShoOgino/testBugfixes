{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","commits":[{"id":"a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4","date":1576125737,"type":1,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df724d84dab24a0cc54bec95a8680867adc7f171","date":1576156608,"type":1,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e96aca6dcb4268a4da0be1c4cb4fb7ac8ee6de96","date":1581390836,"type":3,"author":"Mike","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","sourceNew":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","sourceNew":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","sourceNew":null,"sourceOld":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"df724d84dab24a0cc54bec95a8680867adc7f171":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4"],"e96aca6dcb4268a4da0be1c4cb4fb7ac8ee6de96":["a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["e96aca6dcb4268a4da0be1c4cb4fb7ac8ee6de96"],"3f504512a03d978990cbff30db0522b354e846db":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"]},"commit2Childs":{"a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4":["df724d84dab24a0cc54bec95a8680867adc7f171","e96aca6dcb4268a4da0be1c4cb4fb7ac8ee6de96"],"df724d84dab24a0cc54bec95a8680867adc7f171":[],"e96aca6dcb4268a4da0be1c4cb4fb7ac8ee6de96":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4","df724d84dab24a0cc54bec95a8680867adc7f171"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["3f504512a03d978990cbff30db0522b354e846db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["df724d84dab24a0cc54bec95a8680867adc7f171","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}