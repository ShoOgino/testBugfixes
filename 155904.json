{"path":"solr/contrib/solr-morphlines-core/src/test/org/apache/solr/morphlines/solr/SolrMorphlineZkAvroTest#doTest().mjava","commits":[{"id":"d6e604e9030fb0cabf0c5a85ae6039921a81419c","date":1386009743,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/solr-morphlines-core/src/test/org/apache/solr/morphlines/solr/SolrMorphlineZkAvroTest#doTest().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    File file = new File(RESOURCES_DIR + \"/test-documents/sample-statuses-20120906-141433-medium.avro\");\n    \n    waitForRecoveriesToFinish(false);\n    \n    // load avro records via morphline and zk into solr\n    morphline = parse(\"test-morphlines/tutorialReadAvroContainer\");    \n    Record record = new Record();\n    byte[] body = Files.toByteArray(file);    \n    record.put(Fields.ATTACHMENT_BODY, body);\n    startSession();\n    Notifications.notifyBeginTransaction(morphline);\n    assertTrue(morphline.process(record));\n    assertEquals(1, collector.getNumStartEvents());\n    \n    commit();\n    \n    // fetch sorted result set from solr\n    QueryResponse rsp = cloudClient.query(new SolrQuery(\"*:*\").setRows(100000).addSort(\"id\", SolrQuery.ORDER.asc));   \n    assertEquals(2104, collector.getRecords().size());\n    assertEquals(collector.getRecords().size(), rsp.getResults().size());\n    \n    Collections.sort(collector.getRecords(), new Comparator<Record>() {\n      @Override\n      public int compare(Record r1, Record r2) {\n        return r1.get(\"id\").toString().compareTo(r2.get(\"id\").toString());\n      }      \n    });   \n\n    // fetch test input data and sort like solr result set\n    List<GenericData.Record> records = new ArrayList();\n    FileReader<GenericData.Record> reader = new DataFileReader(file, new GenericDatumReader());\n    while (reader.hasNext()) {\n      GenericData.Record expected = reader.next();\n      records.add(expected);\n    }\n    assertEquals(collector.getRecords().size(), records.size());    \n    Collections.sort(records, new Comparator<GenericData.Record>() {\n      @Override\n      public int compare(GenericData.Record r1, GenericData.Record r2) {\n        return r1.get(\"id\").toString().compareTo(r2.get(\"id\").toString());\n      }      \n    });   \n    \n    Object lastId = null;\n    for (int i = 0; i < records.size(); i++) {  \n      //System.out.println(\"myrec\" + i + \":\" + records.get(i));      \n      Object id = records.get(i);\n      if (id != null && id.equals(lastId)) {\n        throw new IllegalStateException(\"Detected duplicate id. Test input data must not contain duplicate ids!\");        \n      }\n      lastId = id;\n    }\n    \n    for (int i = 0; i < records.size(); i++) {  \n      //System.out.println(\"myrsp\" + i + \":\" + rsp.getResults().get(i));      \n    }    \n\n    Iterator<SolrDocument> rspIter = rsp.getResults().iterator();\n    for (int i = 0; i < records.size(); i++) {  \n      // verify morphline spat out expected data\n      Record actual = collector.getRecords().get(i);\n      GenericData.Record expected = records.get(i);\n      Preconditions.checkNotNull(expected);\n      assertTweetEquals(expected, actual, i);\n      \n      // verify Solr result set contains expected data\n      actual = new Record();\n      actual.getFields().putAll(next(rspIter));\n      assertTweetEquals(expected, actual, i);\n    }\n    \n    Notifications.notifyRollbackTransaction(morphline);\n    Notifications.notifyShutdown(morphline);\n    cloudClient.shutdown();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/SolrMorphlineZkAvroTest#doTest().mjava","pathOld":"solr/contrib/solr-morphlines-core/src/test/org/apache/solr/morphlines/solr/SolrMorphlineZkAvroTest#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    File file = new File(RESOURCES_DIR + \"/test-documents/sample-statuses-20120906-141433-medium.avro\");\n    \n    waitForRecoveriesToFinish(false);\n    \n    // load avro records via morphline and zk into solr\n    morphline = parse(\"test-morphlines/tutorialReadAvroContainer\");    \n    Record record = new Record();\n    byte[] body = Files.toByteArray(file);    \n    record.put(Fields.ATTACHMENT_BODY, body);\n    startSession();\n    Notifications.notifyBeginTransaction(morphline);\n    assertTrue(morphline.process(record));\n    assertEquals(1, collector.getNumStartEvents());\n    \n    commit();\n    \n    // fetch sorted result set from solr\n    QueryResponse rsp = cloudClient.query(new SolrQuery(\"*:*\").setRows(100000).addSort(\"id\", SolrQuery.ORDER.asc));   \n    assertEquals(2104, collector.getRecords().size());\n    assertEquals(collector.getRecords().size(), rsp.getResults().size());\n    \n    Collections.sort(collector.getRecords(), new Comparator<Record>() {\n      @Override\n      public int compare(Record r1, Record r2) {\n        return r1.get(\"id\").toString().compareTo(r2.get(\"id\").toString());\n      }      \n    });   \n\n    // fetch test input data and sort like solr result set\n    List<GenericData.Record> records = new ArrayList();\n    FileReader<GenericData.Record> reader = new DataFileReader(file, new GenericDatumReader());\n    while (reader.hasNext()) {\n      GenericData.Record expected = reader.next();\n      records.add(expected);\n    }\n    assertEquals(collector.getRecords().size(), records.size());    \n    Collections.sort(records, new Comparator<GenericData.Record>() {\n      @Override\n      public int compare(GenericData.Record r1, GenericData.Record r2) {\n        return r1.get(\"id\").toString().compareTo(r2.get(\"id\").toString());\n      }      \n    });   \n    \n    Object lastId = null;\n    for (int i = 0; i < records.size(); i++) {  \n      //System.out.println(\"myrec\" + i + \":\" + records.get(i));      \n      Object id = records.get(i);\n      if (id != null && id.equals(lastId)) {\n        throw new IllegalStateException(\"Detected duplicate id. Test input data must not contain duplicate ids!\");        \n      }\n      lastId = id;\n    }\n    \n    for (int i = 0; i < records.size(); i++) {  \n      //System.out.println(\"myrsp\" + i + \":\" + rsp.getResults().get(i));      \n    }    \n\n    Iterator<SolrDocument> rspIter = rsp.getResults().iterator();\n    for (int i = 0; i < records.size(); i++) {  \n      // verify morphline spat out expected data\n      Record actual = collector.getRecords().get(i);\n      GenericData.Record expected = records.get(i);\n      Preconditions.checkNotNull(expected);\n      assertTweetEquals(expected, actual, i);\n      \n      // verify Solr result set contains expected data\n      actual = new Record();\n      actual.getFields().putAll(next(rspIter));\n      assertTweetEquals(expected, actual, i);\n    }\n    \n    Notifications.notifyRollbackTransaction(morphline);\n    Notifications.notifyShutdown(morphline);\n    cloudClient.shutdown();\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    File file = new File(RESOURCES_DIR + \"/test-documents/sample-statuses-20120906-141433-medium.avro\");\n    \n    waitForRecoveriesToFinish(false);\n    \n    // load avro records via morphline and zk into solr\n    morphline = parse(\"test-morphlines/tutorialReadAvroContainer\");    \n    Record record = new Record();\n    byte[] body = Files.toByteArray(file);    \n    record.put(Fields.ATTACHMENT_BODY, body);\n    startSession();\n    Notifications.notifyBeginTransaction(morphline);\n    assertTrue(morphline.process(record));\n    assertEquals(1, collector.getNumStartEvents());\n    \n    commit();\n    \n    // fetch sorted result set from solr\n    QueryResponse rsp = cloudClient.query(new SolrQuery(\"*:*\").setRows(100000).addSort(\"id\", SolrQuery.ORDER.asc));   \n    assertEquals(2104, collector.getRecords().size());\n    assertEquals(collector.getRecords().size(), rsp.getResults().size());\n    \n    Collections.sort(collector.getRecords(), new Comparator<Record>() {\n      @Override\n      public int compare(Record r1, Record r2) {\n        return r1.get(\"id\").toString().compareTo(r2.get(\"id\").toString());\n      }      \n    });   \n\n    // fetch test input data and sort like solr result set\n    List<GenericData.Record> records = new ArrayList();\n    FileReader<GenericData.Record> reader = new DataFileReader(file, new GenericDatumReader());\n    while (reader.hasNext()) {\n      GenericData.Record expected = reader.next();\n      records.add(expected);\n    }\n    assertEquals(collector.getRecords().size(), records.size());    \n    Collections.sort(records, new Comparator<GenericData.Record>() {\n      @Override\n      public int compare(GenericData.Record r1, GenericData.Record r2) {\n        return r1.get(\"id\").toString().compareTo(r2.get(\"id\").toString());\n      }      \n    });   \n    \n    Object lastId = null;\n    for (int i = 0; i < records.size(); i++) {  \n      //System.out.println(\"myrec\" + i + \":\" + records.get(i));      \n      Object id = records.get(i);\n      if (id != null && id.equals(lastId)) {\n        throw new IllegalStateException(\"Detected duplicate id. Test input data must not contain duplicate ids!\");        \n      }\n      lastId = id;\n    }\n    \n    for (int i = 0; i < records.size(); i++) {  \n      //System.out.println(\"myrsp\" + i + \":\" + rsp.getResults().get(i));      \n    }    \n\n    Iterator<SolrDocument> rspIter = rsp.getResults().iterator();\n    for (int i = 0; i < records.size(); i++) {  \n      // verify morphline spat out expected data\n      Record actual = collector.getRecords().get(i);\n      GenericData.Record expected = records.get(i);\n      Preconditions.checkNotNull(expected);\n      assertTweetEquals(expected, actual, i);\n      \n      // verify Solr result set contains expected data\n      actual = new Record();\n      actual.getFields().putAll(next(rspIter));\n      assertTweetEquals(expected, actual, i);\n    }\n    \n    Notifications.notifyRollbackTransaction(morphline);\n    Notifications.notifyShutdown(morphline);\n    cloudClient.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"]},"commit2Childs":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}