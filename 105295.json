{"path":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","commits":[{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              LOG.info(\"a row on docroot\" + docWrapper);\n              if (!docWrapper.isEmpty()) {\n                LOG.info(\"adding a doc \"+docWrapper);\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              LOG.info(\"a row on docroot\" + docWrapper);\n              if (!docWrapper.isEmpty()) {\n                LOG.info(\"adding a doc \"+docWrapper);\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              LOG.info(\"a row on docroot\" + docWrapper);\n              if (!docWrapper.isEmpty()) {\n                LOG.info(\"adding a doc \"+docWrapper);\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              LOG.info(\"a row on docroot\" + docWrapper);\n              if (!docWrapper.isEmpty()) {\n                LOG.info(\"adding a doc \"+docWrapper);\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ec0d5e9105277591879116e94248c4c5b9fb85d","date":1310462009,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              LOG.info(\"a row on docroot\" + docWrapper);\n              if (!docWrapper.isEmpty()) {\n                LOG.info(\"adding a doc \"+docWrapper);\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":["65f4e997b946a4eadce22b758749046a63ba2eff"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17a92a6c6955645d64747d96f75583d591643464","date":1311245814,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      try {\n        Context.CURRENT_CONTEXT.set(context);\n        epw.init(rows);\n        initEntity();\n        DocWrapper docWrapper = this.docWrapper;\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      initEntity();\n      try {\n        epw.init(rows);\n        DocWrapper docWrapper = this.docWrapper;\n        Context.CURRENT_CONTEXT.set(context);\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":["65f4e997b946a4eadce22b758749046a63ba2eff"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95755793ac5f02eed6154c705e8638e001a5a0a","date":1312178495,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      try {\n        Context.CURRENT_CONTEXT.set(context);\n        epw.init(rows);\n        initEntity();\n        DocWrapper docWrapper = this.docWrapper;\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                if(reqParams.debug) {\n                \treqParams.debugDocuments.add(docWrapper);\n                }\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      try {\n        Context.CURRENT_CONTEXT.set(context);\n        epw.init(rows);\n        initEntity();\n        DocWrapper docWrapper = this.docWrapper;\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3337b86edd36607f0208321f1deee79c55e5fd21","date":1321266471,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      try {\n        Context.CURRENT_CONTEXT.set(context);\n        epw.init(rows);\n        initEntity();\n        DocWrapper docWrapper = this.docWrapper;\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                if(reqParams.debug) {\n                \treqParams.debugDocuments.add(docWrapper);\n                }\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      try {\n        Context.CURRENT_CONTEXT.set(context);\n        epw.init(rows);\n        initEntity();\n        DocWrapper docWrapper = this.docWrapper;\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                if(reqParams.debug) {\n                \treqParams.debugDocuments.add(docWrapper);\n                }\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        epw.destroy();\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b84e23a1c994ea309896dd9424563e0092f3607","date":1332774278,"type":4,"author":"James Dyer","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder.EntityRunner#runAThread(ThreadedEntityProcessorWrapper,EntityRow,String).mjava","sourceNew":null,"sourceOld":"    private void runAThread(ThreadedEntityProcessorWrapper epw, EntityRow rows, String currProcess) throws Exception {\n      currentEntityProcWrapper.set(epw);\n      epw.threadedInit(context);\n      try {\n        Context.CURRENT_CONTEXT.set(context);\n        epw.init(rows);\n        initEntity();\n        DocWrapper docWrapper = this.docWrapper;\n        for (; ;) {\n          if(DocBuilder.this.stop.get()) break;\n          try {\n            Map<String, Object> arow = epw.nextRow();\n            if (arow == null) {\n              break;\n            } else {\n              importStatistics.rowsCount.incrementAndGet();\n              if (docWrapper == null && entity.isDocRoot) {\n                docWrapper = new DocWrapper();\n                context.setDoc(docWrapper);\n                DataConfig.Entity e = entity.parentEntity;\n                for (EntityRow row = rows;  row != null&& e !=null; row = row.tail,e=e.parentEntity) {\n                    addFields(e, docWrapper, row.row, epw.resolver);\n                }\n              }\n              if (docWrapper != null) {\n                handleSpecialCommands(arow, docWrapper);\n                addFields(entity, docWrapper, arow, epw.resolver);\n              }\n              if (entity.entities != null) {\n                EntityRow nextRow = new EntityRow(arow, rows, entity.name);\n                for (DataConfig.Entity e : entity.entities) {\n                  epw.children.get(e).run(docWrapper,currProcess,nextRow);\n                }\n              }\n            }\n            if (entity.isDocRoot) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"a row on docroot\" + docWrapper);\n              }\n              if (!docWrapper.isEmpty()) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"adding a doc \"+docWrapper);\n                }\n                boolean result = writer.upload(docWrapper);\n                if(reqParams.debug) {\n                \treqParams.debugDocuments.add(docWrapper);\n                }\n                docWrapper = null;\n                if (result){\n                  importStatistics.docCount.incrementAndGet();\n                } else {\n                  importStatistics.failedDocCount.incrementAndGet();\n                }\n              }\n            }\n          } catch (DataImportHandlerException dihe) {\n            exception = dihe;\n            if(dihe.getErrCode() == SKIP_ROW || dihe.getErrCode() == SKIP) {\n              importStatistics.skipDocCount.getAndIncrement();\n              exception = null;//should not propogate up\n              continue;\n            }\n            if (entity.isDocRoot) {\n              if (dihe.getErrCode() == DataImportHandlerException.SKIP) {\n                importStatistics.skipDocCount.getAndIncrement();\n                exception = null;//should not propogate up\n              } else {\n                SolrException.log(LOG, \"Exception while processing: \"\n                        + entity.name + \" document : \" + docWrapper, dihe);\n              }\n              if (dihe.getErrCode() == DataImportHandlerException.SEVERE)\n                throw dihe;\n            } else {\n              //if this is not the docRoot then the execution has happened in the same thread. so propogate up,\n              // it will be handled at the docroot\n              entityEnded.set(true); \n              throw dihe;\n            }\n            entityEnded.set(true);\n          }\n        }\n      } finally {\n        currentEntityProcWrapper.remove();\n        Context.CURRENT_CONTEXT.remove();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4b84e23a1c994ea309896dd9424563e0092f3607":["3337b86edd36607f0208321f1deee79c55e5fd21"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"3337b86edd36607f0208321f1deee79c55e5fd21":["f95755793ac5f02eed6154c705e8638e001a5a0a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7ec0d5e9105277591879116e94248c4c5b9fb85d":["c26f00b574427b55127e869b935845554afde1fa"],"f95755793ac5f02eed6154c705e8638e001a5a0a":["17a92a6c6955645d64747d96f75583d591643464"],"17a92a6c6955645d64747d96f75583d591643464":["7ec0d5e9105277591879116e94248c4c5b9fb85d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4b84e23a1c994ea309896dd9424563e0092f3607"]},"commit2Childs":{"4b84e23a1c994ea309896dd9424563e0092f3607":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["7ec0d5e9105277591879116e94248c4c5b9fb85d"],"3337b86edd36607f0208321f1deee79c55e5fd21":["4b84e23a1c994ea309896dd9424563e0092f3607"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","c26f00b574427b55127e869b935845554afde1fa"],"7ec0d5e9105277591879116e94248c4c5b9fb85d":["17a92a6c6955645d64747d96f75583d591643464"],"f95755793ac5f02eed6154c705e8638e001a5a0a":["3337b86edd36607f0208321f1deee79c55e5fd21"],"17a92a6c6955645d64747d96f75583d591643464":["f95755793ac5f02eed6154c705e8638e001a5a0a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}