{"path":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","commits":[{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashConsumerPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n\n    // Gather all FieldData's that have postings, across all\n    // ThreadStates\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashConsumerPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.termsHashPerField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":1,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashConsumerPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n\n    // Gather all FieldData's that have postings, across all\n    // ThreadStates\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashConsumerPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.termsHashPerField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":1,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashConsumerPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n\n    // Gather all FieldData's that have postings, across all\n    // ThreadStates\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashConsumerPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.termsHashPerField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63","date":1398957288,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a16b40feb4e6e0d55c1716733bde48296bedd20","date":1400540388,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    FreqProxFields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    if (state.liveDocs != null) {\n      fields.setLiveDocs(state.liveDocs);\n    }\n\n    System.out.println(\"now: \" + state.liveDocs + \" pf=\" + state.segmentInfo.getCodec().postingsFormat());\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efcf27cd5ca23def8376b4c321970c14dd71623","date":1400662679,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    FreqProxFields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    if (state.liveDocs != null) {\n      fields.setLiveDocs(state.liveDocs);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    FreqProxFields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    if (state.liveDocs != null) {\n      fields.setLiveDocs(state.liveDocs);\n    }\n\n    System.out.println(\"now: \" + state.liveDocs + \" pf=\" + state.segmentInfo.getCodec().postingsFormat());\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2a0b58a171748f1022e63a0483908e6f50b0abf","date":1400686165,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    FreqProxFields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    FreqProxFields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    if (state.liveDocs != null) {\n      fields.setLiveDocs(state.liveDocs);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9017ec91c7e47796f2938c5f5705089cb048c4ae","date":1400795272,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    FreqProxFields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"556a4aab886d75371b2af129d87be3c2795cea76","date":1414954991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.isIndexed();\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      fields = new SortingLeafReader.SortingFields(fields, state.fieldInfos, sortMap);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState).mjava","sourceNew":null,"sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {\n    super.flush(fieldsToFlush, state);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n\n    applyDeletes(state, fields);\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a16b40feb4e6e0d55c1716733bde48296bedd20":["7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3394716f52b34ab259ad5247e7595d9f9db6e935"],"9017ec91c7e47796f2938c5f5705089cb048c4ae":["a2a0b58a171748f1022e63a0483908e6f50b0abf"],"0efcf27cd5ca23def8376b4c321970c14dd71623":["0a16b40feb4e6e0d55c1716733bde48296bedd20"],"a2a0b58a171748f1022e63a0483908e6f50b0abf":["0efcf27cd5ca23def8376b4c321970c14dd71623"],"556a4aab886d75371b2af129d87be3c2795cea76":["7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","52c7e49be259508735752fba88085255014a6ecf"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["556a4aab886d75371b2af129d87be3c2795cea76","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["556a4aab886d75371b2af129d87be3c2795cea76"],"52c7e49be259508735752fba88085255014a6ecf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"]},"commit2Childs":{"0a16b40feb4e6e0d55c1716733bde48296bedd20":["0efcf27cd5ca23def8376b4c321970c14dd71623"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"9017ec91c7e47796f2938c5f5705089cb048c4ae":[],"0efcf27cd5ca23def8376b4c321970c14dd71623":["a2a0b58a171748f1022e63a0483908e6f50b0abf"],"a2a0b58a171748f1022e63a0483908e6f50b0abf":["9017ec91c7e47796f2938c5f5705089cb048c4ae"],"556a4aab886d75371b2af129d87be3c2795cea76":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63":["0a16b40feb4e6e0d55c1716733bde48296bedd20","556a4aab886d75371b2af129d87be3c2795cea76"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3394716f52b34ab259ad5247e7595d9f9db6e935","52c7e49be259508735752fba88085255014a6ecf"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","9017ec91c7e47796f2938c5f5705089cb048c4ae","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}