{"path":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","commits":[{"id":"6eeb17a2bb36160ebf1f228be37f19a8b332f059","date":1359555682,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"/dev/null","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // nocommit: this must be some kind of worst case for BytesRefHash / its hash fn... \n  // or there is some other perf bug...VERY slow!\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte)(expectedValue >> 24);\n        bytes[1] = (byte)(expectedValue >> 16);\n        bytes[2] = (byte)(expectedValue >> 8);\n        bytes[3] = (byte) expectedValue;\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"63b807a2dfeca71d954bb673f4823d813a243fdb","date":1359556698,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // nocommit: this must be some kind of worst case for BytesRefHash / its hash fn... \n  // or there is some other perf bug...VERY slow!\n  // if you cut this test to use random.nextBytes its much faster, but still quite slow...\n  // and its not unrealistic for users to index something thats already in sorted order?\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte)(expectedValue >> 24);\n        bytes[1] = (byte)(expectedValue >> 16);\n        bytes[2] = (byte)(expectedValue >> 8);\n        bytes[3] = (byte) expectedValue;\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // nocommit: this must be some kind of worst case for BytesRefHash / its hash fn... \n  // or there is some other perf bug...VERY slow!\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte)(expectedValue >> 24);\n        bytes[1] = (byte)(expectedValue >> 16);\n        bytes[2] = (byte)(expectedValue >> 8);\n        bytes[3] = (byte) expectedValue;\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9eafdf27a0bda3d70664dd39f3a1683d8416dcf","date":1359644871,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // nocommit: this must be some kind of worst case for BytesRefHash / its hash fn... \n  // or there is some other perf bug...VERY slow!\n  // if you cut this test to use random.nextBytes its much faster, but still quite slow...\n  // and its not unrealistic for users to index something thats already in sorted order?\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte)(expectedValue >> 24);\n        bytes[1] = (byte)(expectedValue >> 16);\n        bytes[2] = (byte)(expectedValue >> 8);\n        bytes[3] = (byte) expectedValue;\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"/dev/null","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c","date":1396633078,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a442c93371e04bc15f485fa6db34ad61fd854fc","date":1397588144,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      random.nextBytes(bytes);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7515a5978a8752c2e7587e0feb4e4fac127db632","date":1397674950,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    long seed = random().nextLong();\n    Random random = new Random(seed);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    random.setSeed(seed);\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        random.nextBytes(bytes);\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        dv.get(i, scratch);\n        assertEquals(data, scratch);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc1451a888296ae68f6a92f5e9550a5788428fbf","date":1412414951,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"656cfb06eff2244ff5a25ffb3ed3a79942ece85c","date":1413181096,"type":3,"author":"Shawn Heisey","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":["6eeb17a2bb36160ebf1f228be37f19a8b332f059"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b7cfe63c9be9c1b5a69e87693b33cc1311ebeac","date":1433258843,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValuesOrds#test2BOrds().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues#test2BOrds().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with a fixed binary field\n  public void test2BOrds() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BOrds\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    byte bytes[] = new byte[4];\n    BytesRef data = new BytesRef(bytes);\n    SortedDocValuesField dvField = new SortedDocValuesField(\"dv\", data);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      bytes[0] = (byte)(i >> 24);\n      bytes[1] = (byte)(i >> 16);\n      bytes[2] = (byte)(i >> 8);\n      bytes[3] = (byte) i;\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    int counter = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      BytesRef scratch = new BytesRef();\n      BinaryDocValues dv = reader.getSortedDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        bytes[0] = (byte) (counter >> 24);\n        bytes[1] = (byte) (counter >> 16);\n        bytes[2] = (byte) (counter >> 8);\n        bytes[3] = (byte) counter;\n        counter++;\n        final BytesRef term = dv.get(i);\n        assertEquals(data, term);\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"55980207f1977bd1463465de1659b821347e2fa8":["d9a47902d6207303f5ed3e7aaca62ca33433af66","656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["6613659748fe4411a7dcf85266e55db1f95f7315","a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"4b7cfe63c9be9c1b5a69e87693b33cc1311ebeac":["656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["7515a5978a8752c2e7587e0feb4e4fac127db632"],"6613659748fe4411a7dcf85266e55db1f95f7315":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"7515a5978a8752c2e7587e0feb4e4fac127db632":["9a442c93371e04bc15f485fa6db34ad61fd854fc"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["c9fb5f46e264daf5ba3860defe623a89d202dd87","fc1451a888296ae68f6a92f5e9550a5788428fbf"],"6eeb17a2bb36160ebf1f228be37f19a8b332f059":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d0d579490a72f2e6297eaa648940611234c57cf1":["6613659748fe4411a7dcf85266e55db1f95f7315"],"fc1451a888296ae68f6a92f5e9550a5788428fbf":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"9a442c93371e04bc15f485fa6db34ad61fd854fc":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e9eafdf27a0bda3d70664dd39f3a1683d8416dcf"],"e9eafdf27a0bda3d70664dd39f3a1683d8416dcf":["63b807a2dfeca71d954bb673f4823d813a243fdb"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["d0d579490a72f2e6297eaa648940611234c57cf1"],"656cfb06eff2244ff5a25ffb3ed3a79942ece85c":["fc1451a888296ae68f6a92f5e9550a5788428fbf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"63b807a2dfeca71d954bb673f4823d813a243fdb":["6eeb17a2bb36160ebf1f228be37f19a8b332f059"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4b7cfe63c9be9c1b5a69e87693b33cc1311ebeac"]},"commit2Childs":{"55980207f1977bd1463465de1659b821347e2fa8":[],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"4b7cfe63c9be9c1b5a69e87693b33cc1311ebeac":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6613659748fe4411a7dcf85266e55db1f95f7315":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","d0d579490a72f2e6297eaa648940611234c57cf1"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"7515a5978a8752c2e7587e0feb4e4fac127db632":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["55980207f1977bd1463465de1659b821347e2fa8"],"6eeb17a2bb36160ebf1f228be37f19a8b332f059":["63b807a2dfeca71d954bb673f4823d813a243fdb"],"d0d579490a72f2e6297eaa648940611234c57cf1":["a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"fc1451a888296ae68f6a92f5e9550a5788428fbf":["d9a47902d6207303f5ed3e7aaca62ca33433af66","656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d9a47902d6207303f5ed3e7aaca62ca33433af66","fc1451a888296ae68f6a92f5e9550a5788428fbf"],"9a442c93371e04bc15f485fa6db34ad61fd854fc":["7515a5978a8752c2e7587e0feb4e4fac127db632"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"e9eafdf27a0bda3d70664dd39f3a1683d8416dcf":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"656cfb06eff2244ff5a25ffb3ed3a79942ece85c":["55980207f1977bd1463465de1659b821347e2fa8","4b7cfe63c9be9c1b5a69e87693b33cc1311ebeac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6eeb17a2bb36160ebf1f228be37f19a8b332f059","d4d69c535930b5cce125cff868d40f6373dc27d4"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["9a442c93371e04bc15f485fa6db34ad61fd854fc"],"63b807a2dfeca71d954bb673f4823d813a243fdb":["e9eafdf27a0bda3d70664dd39f3a1683d8416dcf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}