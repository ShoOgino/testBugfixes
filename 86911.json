{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","commits":[{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":0,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene80DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      try (RAMInputStream in = new RAMInputStream(\"\", buffer)) {\n        BytesRefBuilder b = new BytesRefBuilder();\n        for (int i = 0; i < maxDoc; ++i) {\n          assertEquals(i, values.nextDoc());\n          final int numValues = in.readVInt();\n\n          for (int j = 0; j < numValues; ++j) {\n            b.setLength(in.readVInt());\n            b.grow(b.length());\n            in.readBytes(b.bytes(), 0, b.length());\n            assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n          }\n\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n        }\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":0,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene80DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      try (RAMInputStream in = new RAMInputStream(\"\", buffer)) {\n        BytesRefBuilder b = new BytesRefBuilder();\n        for (int i = 0; i < maxDoc; ++i) {\n          assertEquals(i, values.nextDoc());\n          final int numValues = in.readVInt();\n\n          for (int j = 0; j < numValues; ++j) {\n            b.setLength(in.readVInt());\n            b.grow(b.length());\n            in.readBytes(b.bytes(), 0, b.length());\n            assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n          }\n\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n        }\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene80DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput out = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = out.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene80DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      try (RAMInputStream in = new RAMInputStream(\"\", buffer)) {\n        BytesRefBuilder b = new BytesRefBuilder();\n        for (int i = 0; i < maxDoc; ++i) {\n          assertEquals(i, values.nextDoc());\n          final int numValues = in.readVInt();\n\n          for (int j = 0; j < numValues; ++j) {\n            b.setLength(in.readVInt());\n            b.grow(b.length());\n            in.readBytes(b.bytes(), 0, b.length());\n            assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n          }\n\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n        }\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c6c784f777a2cc8fa014507ea129526822714d","date":1579733373,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene80/TestLucene80DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Nightly\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene80DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput out = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = out.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene80DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput out = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = out.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"57c6c784f777a2cc8fa014507ea129526822714d":["d77dafd89756a5161d244985903e3487ca109182"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","03e17b020972a0d6e8d6823f545571a66646a167"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d77dafd89756a5161d244985903e3487ca109182":["03e17b020972a0d6e8d6823f545571a66646a167"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57c6c784f777a2cc8fa014507ea129526822714d"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","d77dafd89756a5161d244985903e3487ca109182"],"57c6c784f777a2cc8fa014507ea129526822714d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"d77dafd89756a5161d244985903e3487ca109182":["57c6c784f777a2cc8fa014507ea129526822714d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}