{"path":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","commits":[{"id":"ad252c98ff183bc59bd0617be14fa46f9696d6fc","date":1363962178,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"/dev/null","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(100);\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    final IndexWriterConfig iwc2 = iwc1.clone();\n    iwc2.setMergePolicy(new SortingMergePolicy(iwc2.getMergePolicy(), sorter));\n    final IndexWriter iw1 = new IndexWriter(dir1, iwc1);\n    final IndexWriter iw2 = new IndexWriter(dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || rarely()) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    iw1.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw2.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33c3bb55ee942889539c3976972673c297aab4f2","date":1364086026,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(100);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(new SortingMergePolicy(iwc2.getMergePolicy(), sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || rarely()) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    iw1.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw2.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(100);\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    final IndexWriterConfig iwc2 = iwc1.clone();\n    iwc2.setMergePolicy(new SortingMergePolicy(iwc2.getMergePolicy(), sorter));\n    final IndexWriter iw1 = new IndexWriter(dir1, iwc1);\n    final IndexWriter iw2 = new IndexWriter(dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || rarely()) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    iw1.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw2.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bdda4a900a933ff6d9c7ae26244943f2b5db675b","date":1364138057,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(100);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(new SortingMergePolicy(iwc2.getMergePolicy(), sorter));\n    iwc2.setMergeScheduler(new SerialMergeScheduler()); // Remove this line when LUCENE-4752 is fixed\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && rarely())) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    iw1.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw2.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(100);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(new SortingMergePolicy(iwc2.getMergePolicy(), sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || rarely()) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    iw1.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw2.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"66b61ab77ab36893d701d693f1b6df2a383bb7b5","date":1364405461,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(_TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && random().nextInt(8) == 0)) {\n        iw1.commit();\n        iw2.commit();\n      }\n      if (random().nextInt(5) == 0) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n    }\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(100);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(new SortingMergePolicy(iwc2.getMergePolicy(), sorter));\n    iwc2.setMergeScheduler(new SerialMergeScheduler()); // Remove this line when LUCENE-4752 is fixed\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && rarely())) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    iw1.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw2.deleteDocuments(new Term(\"s\", DELETE_TERM));\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7ad6eed24e557585be7c29a40cab86db8f06d7b2","date":1367333440,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(_TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    iw1.addDocument(doc);\n    iw2.addDocument(doc);\n\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(_TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && random().nextInt(8) == 0)) {\n        iw1.commit();\n        iw2.commit();\n      }\n      if (random().nextInt(5) == 0) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n    }\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(_TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(_TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    iw1.addDocument(doc);\n    iw2.addDocument(doc);\n\n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(_TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b060a9c887ff2c6f4280953afc6fb6000934dae5","date":1394119540,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4637747f71df783fc2014ef1f1e0418466e3bed6","date":1394196311,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sorter));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<String>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<String>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.shutdown();\n    iw2.shutdown();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.shutdown();\n    iw2.shutdown();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.shutdown();\n    iw2.shutdown();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.shutdown();\n    iw2.shutdown();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad2a673349939e48652bf304cccf673c3412198f","date":1409585169,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    // update NDV of docs belonging to one term (covers many documents)\n    final long value = random().nextLong();\n    final String term = RandomPicks.randomFrom(random(), terms);\n    iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    // update NDV of docs belonging to one term (covers many documents)\n    final long value = random().nextLong();\n    final String term = RandomPicks.randomFrom(random(), terms);\n    iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    if (defaultCodecSupportsFieldUpdates()) {\n      // update NDV of docs belonging to one term (covers many documents)\n      final long value = random().nextLong();\n      final String term = RandomPicks.randomFrom(random(), terms);\n      iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n      iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    }\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","date":1419346542,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/TestSortingMergePolicy#createRandomIndexes().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy#createRandomIndexes().mjava","sourceNew":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    // update NDV of docs belonging to one term (covers many documents)\n    final long value = random().nextLong();\n    final String term = RandomPicks.randomFrom(random(), terms);\n    iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","sourceOld":"  private void createRandomIndexes() throws IOException {\n    dir1 = newDirectory();\n    dir2 = newDirectory();\n    final int numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc1 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    final IndexWriterConfig iwc2 = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc2.setMergePolicy(newSortingMergePolicy(sort));\n    final RandomIndexWriter iw1 = new RandomIndexWriter(new Random(seed), dir1, iwc1);\n    final RandomIndexWriter iw2 = new RandomIndexWriter(new Random(seed), dir2, iwc2);\n    for (int i = 0; i < numDocs; ++i) {\n      if (random().nextInt(5) == 0 && i != numDocs - 1) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw1.deleteDocuments(new Term(\"s\", term));\n        iw2.deleteDocuments(new Term(\"s\", term));\n      }\n      final Document doc = randomDocument();\n      iw1.addDocument(doc);\n      iw2.addDocument(doc);\n      if (random().nextInt(8) == 0) {\n        iw1.commit();\n        iw2.commit();\n      }\n    }\n    // Make sure we have something to merge\n    iw1.commit();\n    iw2.commit();\n    final Document doc = randomDocument();\n    // NOTE: don't use RIW.addDocument directly, since it sometimes commits\n    // which may trigger a merge, at which case forceMerge may not do anything.\n    // With field updates this is a problem, since the updates can go into the\n    // single segment in the index, and threefore the index won't be sorted.\n    // This hurts the assumption of the test later on, that the index is sorted\n    // by SortingMP.\n    iw1.w.addDocument(doc);\n    iw2.w.addDocument(doc);\n\n    // update NDV of docs belonging to one term (covers many documents)\n    final long value = random().nextLong();\n    final String term = RandomPicks.randomFrom(random(), terms);\n    iw1.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    iw2.w.updateNumericDocValue(new Term(\"s\", term), \"ndv\", value);\n    \n    iw1.forceMerge(1);\n    iw2.forceMerge(1);\n    iw1.close();\n    iw2.close();\n    reader = DirectoryReader.open(dir1);\n    sortedReader = DirectoryReader.open(dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["7ad6eed24e557585be7c29a40cab86db8f06d7b2"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["6613659748fe4411a7dcf85266e55db1f95f7315","4637747f71df783fc2014ef1f1e0418466e3bed6"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"33c3bb55ee942889539c3976972673c297aab4f2":["ad252c98ff183bc59bd0617be14fa46f9696d6fc"],"6613659748fe4411a7dcf85266e55db1f95f7315":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["bdda4a900a933ff6d9c7ae26244943f2b5db675b"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["d0ef034a4f10871667ae75181537775ddcf8ade4","ad2a673349939e48652bf304cccf673c3412198f"],"ad252c98ff183bc59bd0617be14fa46f9696d6fc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b060a9c887ff2c6f4280953afc6fb6000934dae5":["6613659748fe4411a7dcf85266e55db1f95f7315"],"7ad6eed24e557585be7c29a40cab86db8f06d7b2":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"ad2a673349939e48652bf304cccf673c3412198f":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"4637747f71df783fc2014ef1f1e0418466e3bed6":["6613659748fe4411a7dcf85266e55db1f95f7315","b060a9c887ff2c6f4280953afc6fb6000934dae5"],"bdda4a900a933ff6d9c7ae26244943f2b5db675b":["33c3bb55ee942889539c3976972673c297aab4f2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e"]},"commit2Childs":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["6613659748fe4411a7dcf85266e55db1f95f7315"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":[],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"33c3bb55ee942889539c3976972673c297aab4f2":["bdda4a900a933ff6d9c7ae26244943f2b5db675b"],"6613659748fe4411a7dcf85266e55db1f95f7315":["96ea64d994d340044e0d57aeb6a5871539d10ca5","b060a9c887ff2c6f4280953afc6fb6000934dae5","4637747f71df783fc2014ef1f1e0418466e3bed6"],"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["7ad6eed24e557585be7c29a40cab86db8f06d7b2"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e"],"ad252c98ff183bc59bd0617be14fa46f9696d6fc":["33c3bb55ee942889539c3976972673c297aab4f2"],"b060a9c887ff2c6f4280953afc6fb6000934dae5":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"7ad6eed24e557585be7c29a40cab86db8f06d7b2":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ad252c98ff183bc59bd0617be14fa46f9696d6fc"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["402ad3ddc9da7b70da1b167667a60ece6a1381fb","ad2a673349939e48652bf304cccf673c3412198f"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ad2a673349939e48652bf304cccf673c3412198f":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"4637747f71df783fc2014ef1f1e0418466e3bed6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","96ea64d994d340044e0d57aeb6a5871539d10ca5"],"bdda4a900a933ff6d9c7ae26244943f2b5db675b":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["96ea64d994d340044e0d57aeb6a5871539d10ca5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}