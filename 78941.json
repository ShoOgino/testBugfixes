{"path":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    testTermDocs(1);\n  }\n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    testTermDocs(1);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    testTermDocs(1);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    testTermDocs(1);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = _TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    DocsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FLAG_FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","date":1497408244,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()), Collections.emptyMap());\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()), Collections.emptyMap());\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs#testTermDocs().mjava","sourceNew":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","sourceOld":"  public void testTermDocs() throws IOException {\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n\n    TermsEnum terms = reader.terms(DocHelper.TEXT_FIELD_2_KEY).iterator();\n    terms.seekCeil(new BytesRef(\"field\"));\n    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);\n    if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {\n      int docId = termDocs.docID();\n      assertTrue(docId == 0);\n      int freq = termDocs.freq();\n      assertTrue(freq == 3);  \n    }\n    reader.close();\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["28288370235ed02234a64753cdbf0c6ec096304a"],"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"6613659748fe4411a7dcf85266e55db1f95f7315":["a45bec74b98f6fc05f52770cfb425739e6563960"],"a45bec74b98f6fc05f52770cfb425739e6563960":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bec68e7c41fed133827595747d853cad504e481e":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"51f5280f31484820499077f41fcdfe92d527d9dc":["6613659748fe4411a7dcf85266e55db1f95f7315"],"28288370235ed02234a64753cdbf0c6ec096304a":["31741cf1390044e38a2ec3127cf302ba841bfd75","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["92212fd254551a0b1156aafc3a1a6ed1a43932ad","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"]},"commit2Childs":{"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"6613659748fe4411a7dcf85266e55db1f95f7315":["51f5280f31484820499077f41fcdfe92d527d9dc"],"a45bec74b98f6fc05f52770cfb425739e6563960":["6613659748fe4411a7dcf85266e55db1f95f7315"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"28288370235ed02234a64753cdbf0c6ec096304a":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","28288370235ed02234a64753cdbf0c6ec096304a"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["bec68e7c41fed133827595747d853cad504e481e"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["31741cf1390044e38a2ec3127cf302ba841bfd75","92212fd254551a0b1156aafc3a1a6ed1a43932ad"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}