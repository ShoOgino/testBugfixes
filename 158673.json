{"path":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92751ba9273251eab6a2e379ec42a1697a32ff96","date":1407954233,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n      \n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n          \n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circut out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          \n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n            \n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n        \n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n        \n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(null, rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n\n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKeyEncoded + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKeyEncoded+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":["fa16b8f2a7bb28ece5a9fdc471357e89de17bc57"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8ff4734b6c86245e852fe8b6a286716d5e59d415","date":1410194063,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(null, rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n      \n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n          \n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circut out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          \n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n            \n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n        \n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n        \n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(null, rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59d82b0be40ecfcc2c94c776b324e0903a62b844","date":1423535462,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          //TODO remove interval faceting, and ranges and heatmap too?\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(null, rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(null, rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa16b8f2a7bb28ece5a9fdc471357e89de17bc57","date":1423733077,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          //TODO remove interval faceting, and ranges and heatmap too?\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          //TODO remove interval faceting, and ranges and heatmap too?\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(null, rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":["92751ba9273251eab6a2e379ec42a1697a32ff96"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9874be20d2b434883108f2fd050817c222e74f99","date":1424839331,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n      List<String> distribFieldFacetRefinements = null;\n\n      // FieldFacetAdditions\n      for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n        if (!dff.needRefinements) continue;\n        List<String> refList = dff._toRefine[shardNum];\n        if (refList == null || refList.size() == 0) continue;\n\n        String key = dff.getKey(); // reuse the same key that was used for the\n                                   // main facet\n        String termsKey = key + \"__terms\";\n        String termsVal = StrUtils.join(refList, ',');\n\n        String facetCommand;\n        // add terms into the original facet.field command\n        // do it via parameter reference to avoid another layer of encoding.\n\n        String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n        if (dff.localParams != null) {\n          facetCommand = commandPrefix + termsKeyEncoded + \" \"\n              + dff.facetStr.substring(2);\n        } else {\n          facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n        }\n\n        if (distribFieldFacetRefinements == null) {\n          distribFieldFacetRefinements = new ArrayList<>();\n        }\n\n        distribFieldFacetRefinements.add(facetCommand);\n        distribFieldFacetRefinements.add(termsKey);\n        distribFieldFacetRefinements.add(termsVal);\n      }\n\n      if (distribFieldFacetRefinements != null) {\n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes too great, we may want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null\n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n\n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n\n        shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n        removeMainFacetTypeParams(shardsRefineRequest);\n\n        for (int i = 0; i < distribFieldFacetRefinements.size();) {\n          String facetCommand = distribFieldFacetRefinements.get(i++);\n          String termsKey = distribFieldFacetRefinements.get(i++);\n          String termsVal = distribFieldFacetRefinements.get(i++);\n\n          shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n              facetCommand);\n          shardsRefineRequest.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n      }\n\n\n      // PivotFacetAdditions\n      if (doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum)) {\n        enqueuePivotFacetShardRequests(rb, shardNum);\n      }\n\n    } // for shardNum\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          //TODO remove interval faceting, and ranges and heatmap too?\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n      List<String> distribFieldFacetRefinements = null;\n\n      // FieldFacetAdditions\n      for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n        if (!dff.needRefinements) continue;\n        List<String> refList = dff._toRefine[shardNum];\n        if (refList == null || refList.size() == 0) continue;\n\n        String key = dff.getKey(); // reuse the same key that was used for the\n                                   // main facet\n        String termsKey = key + \"__terms\";\n        String termsVal = StrUtils.join(refList, ',');\n\n        String facetCommand;\n        // add terms into the original facet.field command\n        // do it via parameter reference to avoid another layer of encoding.\n\n        String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n        if (dff.localParams != null) {\n          facetCommand = commandPrefix + termsKeyEncoded + \" \"\n              + dff.facetStr.substring(2);\n        } else {\n          facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n        }\n\n        if (distribFieldFacetRefinements == null) {\n          distribFieldFacetRefinements = new ArrayList<>();\n        }\n\n        distribFieldFacetRefinements.add(facetCommand);\n        distribFieldFacetRefinements.add(termsKey);\n        distribFieldFacetRefinements.add(termsVal);\n      }\n\n      if (distribFieldFacetRefinements != null) {\n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes too great, we may want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null\n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n\n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n\n        shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n        removeMainFacetTypeParams(shardsRefineRequest);\n\n        for (int i = 0; i < distribFieldFacetRefinements.size();) {\n          String facetCommand = distribFieldFacetRefinements.get(i++);\n          String termsKey = distribFieldFacetRefinements.get(i++);\n          String termsVal = distribFieldFacetRefinements.get(i++);\n\n          shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n              facetCommand);\n          shardsRefineRequest.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n      }\n\n\n      // PivotFacetAdditions\n      if (doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum)) {\n        enqueuePivotFacetShardRequests(rb, shardNum);\n      }\n\n    } // for shardNum\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    \n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count\n      // for particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n        List<String> distribFieldFacetRefinements = null;\n        \n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size() == 0) continue;\n          \n          String key = dff.getKey(); // reuse the same key that was used for the\n                                     // main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n          \n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          \n          String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix + termsKeyEncoded + \" \"\n                + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n          }\n          \n          if (distribFieldFacetRefinements == null) {\n            distribFieldFacetRefinements = new ArrayList<>();\n          }\n\n          distribFieldFacetRefinements.add(facetCommand);\n          distribFieldFacetRefinements.add(termsKey);\n          distribFieldFacetRefinements.add(termsVal);\n        }\n        \n        boolean pivotFacetRefinementRequestsExistForShard = \n          doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum);\n\n        if (distribFieldFacetRefinements == null\n            && !pivotFacetRefinementRequestsExistForShard) {\n          // nothing to refine, short circuit out\n          continue;\n        }\n        \n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n        \n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null \n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n        \n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n        \n        // FieldFacetAdditions\n        if (distribFieldFacetRefinements != null) {\n          shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n          shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n          shardsRefineRequest.params.remove(FacetParams.FACET_FIELD);\n          shardsRefineRequest.params.remove(FacetParams.FACET_QUERY);\n          //TODO remove interval faceting, and ranges and heatmap too?\n\n          for (int i = 0; i < distribFieldFacetRefinements.size();) {\n            String facetCommand = distribFieldFacetRefinements.get(i++);\n            String termsKey = distribFieldFacetRefinements.get(i++);\n            String termsVal = distribFieldFacetRefinements.get(i++);\n\n            shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n                facetCommand);\n            shardsRefineRequest.params.set(termsKey, termsVal);\n          }\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n\n        // PivotFacetAdditions\n        if (pivotFacetRefinementRequestsExistForShard) {\n          if (newRequest) {\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT);\n            shardsRefineRequest.params.remove(FacetParams.FACET_PIVOT_MINCOUNT);\n          }\n          \n          enqueuePivotFacetShardRequests(rb, shardNum);\n        }\n      }\n    }\n    \n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"13d45ae511f63e9686357f412e5b4d60b82df041","date":1493210332,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n      List<String> distribFieldFacetRefinements = null;\n\n      // FieldFacetAdditions\n      for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n        if (!dff.needRefinements) continue;\n        List<String> refList = dff._toRefine[shardNum];\n        if (refList == null || refList.size() == 0) continue;\n\n        String key = dff.getKey(); // reuse the same key that was used for the\n                                   // main facet\n        String termsKey = key + \"__terms\";\n        String termsVal = StrUtils.join(refList, ',');\n\n        String facetCommand;\n        // add terms into the original facet.field command\n        // do it via parameter reference to avoid another layer of encoding.\n\n        String termsKeyEncoded = ClientUtils.encodeLocalParamVal(termsKey);\n        if (dff.localParams != null) {\n          facetCommand = commandPrefix + termsKeyEncoded + \" \"\n              + dff.facetStr.substring(2);\n        } else {\n          facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n        }\n\n        if (distribFieldFacetRefinements == null) {\n          distribFieldFacetRefinements = new ArrayList<>();\n        }\n\n        distribFieldFacetRefinements.add(facetCommand);\n        distribFieldFacetRefinements.add(termsKey);\n        distribFieldFacetRefinements.add(termsVal);\n      }\n\n      if (distribFieldFacetRefinements != null) {\n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes too great, we may want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null\n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n\n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n\n        shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n        removeMainFacetTypeParams(shardsRefineRequest);\n\n        for (int i = 0; i < distribFieldFacetRefinements.size();) {\n          String facetCommand = distribFieldFacetRefinements.get(i++);\n          String termsKey = distribFieldFacetRefinements.get(i++);\n          String termsVal = distribFieldFacetRefinements.get(i++);\n\n          shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n              facetCommand);\n          shardsRefineRequest.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n      }\n\n\n      // PivotFacetAdditions\n      if (doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum)) {\n        enqueuePivotFacetShardRequests(rb, shardNum);\n      }\n\n    } // for shardNum\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n      List<String> distribFieldFacetRefinements = null;\n\n      // FieldFacetAdditions\n      for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n        if (!dff.needRefinements) continue;\n        List<String> refList = dff._toRefine[shardNum];\n        if (refList == null || refList.size() == 0) continue;\n\n        String key = dff.getKey(); // reuse the same key that was used for the\n                                   // main facet\n        String termsKey = key + \"__terms\";\n        String termsVal = StrUtils.join(refList, ',');\n\n        String facetCommand;\n        // add terms into the original facet.field command\n        // do it via parameter reference to avoid another layer of encoding.\n\n        String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n        if (dff.localParams != null) {\n          facetCommand = commandPrefix + termsKeyEncoded + \" \"\n              + dff.facetStr.substring(2);\n        } else {\n          facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n        }\n\n        if (distribFieldFacetRefinements == null) {\n          distribFieldFacetRefinements = new ArrayList<>();\n        }\n\n        distribFieldFacetRefinements.add(facetCommand);\n        distribFieldFacetRefinements.add(termsKey);\n        distribFieldFacetRefinements.add(termsVal);\n      }\n\n      if (distribFieldFacetRefinements != null) {\n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes too great, we may want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null\n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n\n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n\n        shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n        removeMainFacetTypeParams(shardsRefineRequest);\n\n        for (int i = 0; i < distribFieldFacetRefinements.size();) {\n          String facetCommand = distribFieldFacetRefinements.get(i++);\n          String termsKey = distribFieldFacetRefinements.get(i++);\n          String termsVal = distribFieldFacetRefinements.get(i++);\n\n          shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n              facetCommand);\n          shardsRefineRequest.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n      }\n\n\n      // PivotFacetAdditions\n      if (doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum)) {\n        enqueuePivotFacetShardRequests(rb, shardNum);\n      }\n\n    } // for shardNum\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n      List<String> distribFieldFacetRefinements = null;\n\n      // FieldFacetAdditions\n      for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n        if (!dff.needRefinements) continue;\n        List<String> refList = dff._toRefine[shardNum];\n        if (refList == null || refList.size() == 0) continue;\n\n        String key = dff.getKey(); // reuse the same key that was used for the\n                                   // main facet\n        String termsKey = key + \"__terms\";\n        String termsVal = StrUtils.join(refList, ',');\n\n        String facetCommand;\n        // add terms into the original facet.field command\n        // do it via parameter reference to avoid another layer of encoding.\n\n        String termsKeyEncoded = ClientUtils.encodeLocalParamVal(termsKey);\n        if (dff.localParams != null) {\n          facetCommand = commandPrefix + termsKeyEncoded + \" \"\n              + dff.facetStr.substring(2);\n        } else {\n          facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n        }\n\n        if (distribFieldFacetRefinements == null) {\n          distribFieldFacetRefinements = new ArrayList<>();\n        }\n\n        distribFieldFacetRefinements.add(facetCommand);\n        distribFieldFacetRefinements.add(termsKey);\n        distribFieldFacetRefinements.add(termsVal);\n      }\n\n      if (distribFieldFacetRefinements != null) {\n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes too great, we may want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null\n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n\n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n\n        shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n        removeMainFacetTypeParams(shardsRefineRequest);\n\n        for (int i = 0; i < distribFieldFacetRefinements.size();) {\n          String facetCommand = distribFieldFacetRefinements.get(i++);\n          String termsKey = distribFieldFacetRefinements.get(i++);\n          String termsVal = distribFieldFacetRefinements.get(i++);\n\n          shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n              facetCommand);\n          shardsRefineRequest.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n      }\n\n\n      // PivotFacetAdditions\n      if (doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum)) {\n        enqueuePivotFacetShardRequests(rb, shardNum);\n      }\n\n    } // for shardNum\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {\n      List<String> distribFieldFacetRefinements = null;\n\n      // FieldFacetAdditions\n      for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n        if (!dff.needRefinements) continue;\n        List<String> refList = dff._toRefine[shardNum];\n        if (refList == null || refList.size() == 0) continue;\n\n        String key = dff.getKey(); // reuse the same key that was used for the\n                                   // main facet\n        String termsKey = key + \"__terms\";\n        String termsVal = StrUtils.join(refList, ',');\n\n        String facetCommand;\n        // add terms into the original facet.field command\n        // do it via parameter reference to avoid another layer of encoding.\n\n        String termsKeyEncoded = QueryParsing.encodeLocalParamVal(termsKey);\n        if (dff.localParams != null) {\n          facetCommand = commandPrefix + termsKeyEncoded + \" \"\n              + dff.facetStr.substring(2);\n        } else {\n          facetCommand = commandPrefix + termsKeyEncoded + '}' + dff.field;\n        }\n\n        if (distribFieldFacetRefinements == null) {\n          distribFieldFacetRefinements = new ArrayList<>();\n        }\n\n        distribFieldFacetRefinements.add(facetCommand);\n        distribFieldFacetRefinements.add(termsKey);\n        distribFieldFacetRefinements.add(termsVal);\n      }\n\n      if (distribFieldFacetRefinements != null) {\n        String shard = rb.shards[shardNum];\n        ShardRequest shardsRefineRequest = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes too great, we may want to move to hashing for\n        // better scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0\n              && sreq.shards != null\n              && sreq.shards.length == 1\n              && sreq.shards[0].equals(shard)) {\n            shardsRefineRequest = sreq;\n            break;\n          }\n        }\n\n        if (shardsRefineRequest == null) {\n          // we didn't find any other suitable requests going out to that shard,\n          // so create one ourselves.\n          newRequest = true;\n          shardsRefineRequest = new ShardRequest();\n          shardsRefineRequest.shards = new String[] { rb.shards[shardNum] };\n          shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          shardsRefineRequest.params.remove(CommonParams.START);\n          shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        }\n\n        shardsRefineRequest.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        shardsRefineRequest.params.set(FacetParams.FACET, \"true\");\n        removeMainFacetTypeParams(shardsRefineRequest);\n\n        for (int i = 0; i < distribFieldFacetRefinements.size();) {\n          String facetCommand = distribFieldFacetRefinements.get(i++);\n          String termsKey = distribFieldFacetRefinements.get(i++);\n          String termsVal = distribFieldFacetRefinements.get(i++);\n\n          shardsRefineRequest.params.add(FacetParams.FACET_FIELD,\n              facetCommand);\n          shardsRefineRequest.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, shardsRefineRequest);\n        }\n      }\n\n\n      // PivotFacetAdditions\n      if (doAnyPivotFacetRefinementRequestsExistForShard(rb._facetInfo, shardNum)) {\n        enqueuePivotFacetShardRequests(rb, shardNum);\n      }\n\n    } // for shardNum\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"59d82b0be40ecfcc2c94c776b324e0903a62b844":["8ff4734b6c86245e852fe8b6a286716d5e59d415"],"13d45ae511f63e9686357f412e5b4d60b82df041":["9874be20d2b434883108f2fd050817c222e74f99"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["c26f00b574427b55127e869b935845554afde1fa"],"92751ba9273251eab6a2e379ec42a1697a32ff96":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"9874be20d2b434883108f2fd050817c222e74f99":["fa16b8f2a7bb28ece5a9fdc471357e89de17bc57"],"fa16b8f2a7bb28ece5a9fdc471357e89de17bc57":["59d82b0be40ecfcc2c94c776b324e0903a62b844"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["9874be20d2b434883108f2fd050817c222e74f99","13d45ae511f63e9686357f412e5b4d60b82df041"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["fa16b8f2a7bb28ece5a9fdc471357e89de17bc57","9874be20d2b434883108f2fd050817c222e74f99"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8ff4734b6c86245e852fe8b6a286716d5e59d415":["92751ba9273251eab6a2e379ec42a1697a32ff96"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["13d45ae511f63e9686357f412e5b4d60b82df041"]},"commit2Childs":{"59d82b0be40ecfcc2c94c776b324e0903a62b844":["fa16b8f2a7bb28ece5a9fdc471357e89de17bc57"],"13d45ae511f63e9686357f412e5b4d60b82df041":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["92751ba9273251eab6a2e379ec42a1697a32ff96"],"92751ba9273251eab6a2e379ec42a1697a32ff96":["8ff4734b6c86245e852fe8b6a286716d5e59d415"],"c26f00b574427b55127e869b935845554afde1fa":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"9874be20d2b434883108f2fd050817c222e74f99":["13d45ae511f63e9686357f412e5b4d60b82df041","e9017cf144952056066919f1ebc7897ff9bd71b1","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"fa16b8f2a7bb28ece5a9fdc471357e89de17bc57":["9874be20d2b434883108f2fd050817c222e74f99","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"8ff4734b6c86245e852fe8b6a286716d5e59d415":["59d82b0be40ecfcc2c94c776b324e0903a62b844"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}