{"path":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestUpdateLogSynchronisation().mjava","commits":[{"id":"86290366cefc1b9d4eced13b430858c4a4c0421d","date":1432321109,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestUpdateLogSynchronisation().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Check that the update logs are synchronised between leader and non-leader nodes\n   */\n  public void doTestUpdateLogSynchronisation() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // buffering is enabled by default, so disable it\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.DISABLEBUFFER);\n\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n\n    for (int i = 0; i < 50; i++) {\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i))); // will perform a commit for every document\n    }\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // Stop CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    index(SOURCE_COLLECTION, getDoc(id, Integer.toString(0))); // trigger update log cleaning on the non-leader nodes\n\n    // some of the tlogs should be trimmed, we must have less than 50 tlog files on both leader and non-leader\n    assertUpdateLogs(SOURCE_COLLECTION, 50);\n\n    for (int i = 50; i < 100; i++) {\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    index(SOURCE_COLLECTION, getDoc(id, Integer.toString(0))); // trigger update log cleaning on the non-leader nodes\n\n    // at this stage, we should have created one tlog file per document, and some of them must have been cleaned on the\n    // leader since we are not buffering and replication is stopped, (we should have exactly 10 tlog files on the leader\n    // and 11 on the non-leader)\n    // the non-leader must have synchronised its update log with its leader\n    assertUpdateLogs(SOURCE_COLLECTION, 50);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4dcd1fe49b76116e7d358993339fe8adbb030638","date":1437151093,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestUpdateLogSynchronisation().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestUpdateLogSynchronisation().mjava","sourceNew":"  /**\n   * Check that the update logs are synchronised between leader and non-leader nodes\n   */\n  public void doTestUpdateLogSynchronisation() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // buffering is enabled by default, so disable it\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.DISABLEBUFFER);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    for (int i = 0; i < 50; i++) {\n      // will perform a commit for every document and will create one tlog file per commit\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // Stop CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    // some of the tlogs should be trimmed, we must have less than 50 tlog files on both leader and non-leader\n    assertNumberOfTlogFiles(SOURCE_COLLECTION, 50);\n\n    for (int i = 50; i < 100; i++) {\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    // at this stage, we should have created one tlog file per document, and some of them must have been cleaned on the\n    // leader since we are not buffering and replication is stopped, (we should have exactly 10 tlog files on the leader\n    // and 11 on the non-leader)\n    // the non-leader must have synchronised its update log with its leader\n    assertNumberOfTlogFiles(SOURCE_COLLECTION, 50);\n  }\n\n","sourceOld":"  /**\n   * Check that the update logs are synchronised between leader and non-leader nodes\n   */\n  public void doTestUpdateLogSynchronisation() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // buffering is enabled by default, so disable it\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.DISABLEBUFFER);\n\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n\n    for (int i = 0; i < 50; i++) {\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i))); // will perform a commit for every document\n    }\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // Stop CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    index(SOURCE_COLLECTION, getDoc(id, Integer.toString(0))); // trigger update log cleaning on the non-leader nodes\n\n    // some of the tlogs should be trimmed, we must have less than 50 tlog files on both leader and non-leader\n    assertUpdateLogs(SOURCE_COLLECTION, 50);\n\n    for (int i = 50; i < 100; i++) {\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    index(SOURCE_COLLECTION, getDoc(id, Integer.toString(0))); // trigger update log cleaning on the non-leader nodes\n\n    // at this stage, we should have created one tlog file per document, and some of them must have been cleaned on the\n    // leader since we are not buffering and replication is stopped, (we should have exactly 10 tlog files on the leader\n    // and 11 on the non-leader)\n    // the non-leader must have synchronised its update log with its leader\n    assertUpdateLogs(SOURCE_COLLECTION, 50);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5","date":1446841099,"type":5,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#testUpdateLogSynchronisation().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestUpdateLogSynchronisation().mjava","sourceNew":"  /**\n   * Check that the update logs are synchronised between leader and non-leader nodes\n   * when CDCR is on and buffer is disabled\n   */\n  @Test\n  @ShardsFixed(num = 4)\n  public void testUpdateLogSynchronisation() throws Exception {\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    for (int i = 0; i < 100; i++) {\n      // will perform a commit for every document and will create one tlog file per commit\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // Check that the replication was done properly\n    assertNumDocs(100, SOURCE_COLLECTION);\n    assertNumDocs(100, TARGET_COLLECTION);\n\n    // Get the number of tlog files on the replicas (should be equal to the number of documents indexed)\n    int nTlogs = getNumberOfTlogFilesOnReplicas(SOURCE_COLLECTION);\n\n    // Disable the buffer - ulog synch should start on non-leader nodes\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.DISABLEBUFFER);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    int cnt = 15; // timeout after 15 seconds\n    while (cnt > 0) {\n      // Index a new document with a commit to trigger update log cleaning\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(50)));\n\n      // Check the update logs on non-leader nodes, the number of tlog files should decrease\n      int n = getNumberOfTlogFilesOnReplicas(SOURCE_COLLECTION);\n      if (n < nTlogs) return;\n\n      cnt--;\n      Thread.sleep(1000);\n    }\n\n    throw new AssertionError(\"Timeout while trying to assert update logs @ source_collection\");\n  }\n\n","sourceOld":"  /**\n   * Check that the update logs are synchronised between leader and non-leader nodes\n   */\n  public void doTestUpdateLogSynchronisation() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // buffering is enabled by default, so disable it\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.DISABLEBUFFER);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    for (int i = 0; i < 50; i++) {\n      // will perform a commit for every document and will create one tlog file per commit\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // Stop CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    // some of the tlogs should be trimmed, we must have less than 50 tlog files on both leader and non-leader\n    assertNumberOfTlogFiles(SOURCE_COLLECTION, 50);\n\n    for (int i = 50; i < 100; i++) {\n      index(SOURCE_COLLECTION, getDoc(id, Integer.toString(i)));\n    }\n\n    // at this stage, we should have created one tlog file per document, and some of them must have been cleaned on the\n    // leader since we are not buffering and replication is stopped, (we should have exactly 10 tlog files on the leader\n    // and 11 on the non-leader)\n    // the non-leader must have synchronised its update log with its leader\n    assertNumberOfTlogFiles(SOURCE_COLLECTION, 50);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"86290366cefc1b9d4eced13b430858c4a4c0421d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["4dcd1fe49b76116e7d358993339fe8adbb030638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4dcd1fe49b76116e7d358993339fe8adbb030638":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"]},"commit2Childs":{"86290366cefc1b9d4eced13b430858c4a4c0421d":["4dcd1fe49b76116e7d358993339fe8adbb030638"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"4dcd1fe49b76116e7d358993339fe8adbb030638":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}