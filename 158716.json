{"path":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<IndexableField> fields = new ArrayList<IndexableField>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<IndexableField> fields = new ArrayList<IndexableField>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409324b31a1419d7c05a38211168cf317e39be77","date":1344866765,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<Field>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<IndexableField> fields = new ArrayList<IndexableField>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<Field>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<IndexableField> fields = new ArrayList<IndexableField>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<Field>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.shutdown();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2#indexSerial(Random,Map[String,Document],Directory).mjava","sourceNew":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<IndexableField> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","sourceOld":"  public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {\n    IndexWriter w = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(random, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n\n    // index all docs in a single thread\n    Iterator<Document> iter = docs.values().iterator();\n    while (iter.hasNext()) {\n      Document d = iter.next();\n      ArrayList<Field> fields = new ArrayList<>();\n      fields.addAll(d.getFields());\n      // put fields in same order each time\n      Collections.sort(fields, fieldNameComparator);\n      \n      Document d1 = new Document();\n      for (int i=0; i<fields.size(); i++) {\n        d1.add(fields.get(i));\n      }\n      w.addDocument(d1);\n      // System.out.println(\"indexing \"+d1);\n    }\n    \n    w.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"409324b31a1419d7c05a38211168cf317e39be77":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["1d028314cced5858683a1bb4741423d0f934257b"],"1d028314cced5858683a1bb4741423d0f934257b":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","409324b31a1419d7c05a38211168cf317e39be77"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["d0ef034a4f10871667ae75181537775ddcf8ade4"]},"commit2Childs":{"409324b31a1419d7c05a38211168cf317e39be77":["1d028314cced5858683a1bb4741423d0f934257b"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"1d028314cced5858683a1bb4741423d0f934257b":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["409324b31a1419d7c05a38211168cf317e39be77","1d028314cced5858683a1bb4741423d0f934257b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}