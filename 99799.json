{"path":"lucene/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","commits":[{"id":"660345363f16c7d4c38aa11a35bf59aa99466cf1","date":1328227279,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactDocScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactDocScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"660345363f16c7d4c38aa11a35bf59aa99466cf1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["660345363f16c7d4c38aa11a35bf59aa99466cf1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"660345363f16c7d4c38aa11a35bf59aa99466cf1":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["660345363f16c7d4c38aa11a35bf59aa99466cf1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}