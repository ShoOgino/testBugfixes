{"path":"src/java/org/apache/solr/request/SimpleFacets#getFacetTermEnumCounts(String).mjava","commits":[{"id":"d1b4f9f023bf5098df34505adf1ed91daa67c239","date":1157655314,"type":0,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/SimpleFacets#getFacetTermEnumCounts(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns a list of terms in the specified field along with the \n   * corrisponding count of documents in the set that match that constraint.\n   *\n   * @see SolrParams#FACET_LIMIT\n   * @see SolrParams#FACET_ZEROS\n   */\n  public NamedList getFacetTermEnumCounts(String fieldName) \n    throws IOException {\n    \n    /* :TODO: potential optimization...\n     * cache the Terms with the highest docFreq and try them first\n     * don't enum if we get our max from them\n     */\n     \n    IndexSchema schema = searcher.getSchema();\n    IndexReader r = searcher.getReader();\n    FieldType ft = schema.getFieldType(fieldName);\n\n    Set<CountPair<String,Integer>> counts \n      = new HashSet<CountPair<String,Integer>>();\n\n    String limit = params.getFieldParam(fieldName, params.FACET_LIMIT);\n    if (null != limit) {\n      counts = new BoundedTreeSet<CountPair<String,Integer>>\n        (Integer.parseInt(limit));\n    }\n\n    boolean zeros = params.getFieldBool(fieldName, params.FACET_ZEROS, true);\n      \n    TermEnum te = r.terms(new Term(fieldName,\"\"));\n    do {\n      Term t = te.term();\n\n      if (null == t || ! t.field().equals(fieldName)) \n        break;\n\n      if (0 < te.docFreq()) { /* all docs may be deleted */\n        int count = searcher.numDocs(new TermQuery(t),\n                                     docs);\n\n        /* :TODO: is indexedToReadable correct? */ \n        if (zeros || 0 < count) \n          counts.add(new CountPair<String,Integer>\n                     (ft.indexedToReadable(t.text()), count));\n\n      }\n    } while (te.next());\n\n    NamedList res = new NamedList();\n    for (CountPair<String,Integer> p : counts) {\n      res.add(p.key, p.val);\n    }\n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc88118f21ca5b1a14ab1ebe8a80abf1a5ed54fb","date":1158102718,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/SimpleFacets#getFacetTermEnumCounts(String).mjava","pathOld":"src/java/org/apache/solr/request/SimpleFacets#getFacetTermEnumCounts(String).mjava","sourceNew":"  /**\n   * Returns a list of terms in the specified field along with the \n   * corrisponding count of documents in the set that match that constraint.\n   *\n   * @see SolrParams#FACET_LIMIT\n   * @see SolrParams#FACET_ZEROS\n   */\n  public NamedList getFacetTermEnumCounts(String fieldName) \n    throws IOException {\n    \n    /* :TODO: potential optimization...\n     * cache the Terms with the highest docFreq and try them first\n     * don't enum if we get our max from them\n     */\n     \n    IndexSchema schema = searcher.getSchema();\n    IndexReader r = searcher.getReader();\n    FieldType ft = schema.getFieldType(fieldName);\n\n    Set<CountPair<String,Integer>> counts \n      = new HashSet<CountPair<String,Integer>>();\n\n    int limit = params.getFieldInt(fieldName, params.FACET_LIMIT, 100);\n    if (0 <= limit) {\n      counts = new BoundedTreeSet<CountPair<String,Integer>>(limit);\n    }\n\n    boolean zeros = params.getFieldBool(fieldName, params.FACET_ZEROS, true);\n      \n    TermEnum te = r.terms(new Term(fieldName,\"\"));\n    do {\n      Term t = te.term();\n\n      if (null == t || ! t.field().equals(fieldName)) \n        break;\n\n      if (0 < te.docFreq()) { /* all docs may be deleted */\n        int count = searcher.numDocs(new TermQuery(t),\n                                     docs);\n\n        /* :TODO: is indexedToReadable correct? */ \n        if (zeros || 0 < count) \n          counts.add(new CountPair<String,Integer>\n                     (ft.indexedToReadable(t.text()), count));\n\n      }\n    } while (te.next());\n\n    NamedList res = new NamedList();\n    for (CountPair<String,Integer> p : counts) {\n      res.add(p.key, p.val);\n    }\n    return res;\n  }\n\n","sourceOld":"  /**\n   * Returns a list of terms in the specified field along with the \n   * corrisponding count of documents in the set that match that constraint.\n   *\n   * @see SolrParams#FACET_LIMIT\n   * @see SolrParams#FACET_ZEROS\n   */\n  public NamedList getFacetTermEnumCounts(String fieldName) \n    throws IOException {\n    \n    /* :TODO: potential optimization...\n     * cache the Terms with the highest docFreq and try them first\n     * don't enum if we get our max from them\n     */\n     \n    IndexSchema schema = searcher.getSchema();\n    IndexReader r = searcher.getReader();\n    FieldType ft = schema.getFieldType(fieldName);\n\n    Set<CountPair<String,Integer>> counts \n      = new HashSet<CountPair<String,Integer>>();\n\n    String limit = params.getFieldParam(fieldName, params.FACET_LIMIT);\n    if (null != limit) {\n      counts = new BoundedTreeSet<CountPair<String,Integer>>\n        (Integer.parseInt(limit));\n    }\n\n    boolean zeros = params.getFieldBool(fieldName, params.FACET_ZEROS, true);\n      \n    TermEnum te = r.terms(new Term(fieldName,\"\"));\n    do {\n      Term t = te.term();\n\n      if (null == t || ! t.field().equals(fieldName)) \n        break;\n\n      if (0 < te.docFreq()) { /* all docs may be deleted */\n        int count = searcher.numDocs(new TermQuery(t),\n                                     docs);\n\n        /* :TODO: is indexedToReadable correct? */ \n        if (zeros || 0 < count) \n          counts.add(new CountPair<String,Integer>\n                     (ft.indexedToReadable(t.text()), count));\n\n      }\n    } while (te.next());\n\n    NamedList res = new NamedList();\n    for (CountPair<String,Integer> p : counts) {\n      res.add(p.key, p.val);\n    }\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9727734a64d33a1345c9251f53eb375f04c583e","date":1158874656,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/request/SimpleFacets#getFacetTermEnumCounts(SolrIndexSearcher,DocSet,String,int,boolean,boolean).mjava","pathOld":"src/java/org/apache/solr/request/SimpleFacets#getFacetTermEnumCounts(String).mjava","sourceNew":"  /**\n   * Returns a list of terms in the specified field along with the \n   * corrisponding count of documents in the set that match that constraint.\n   * This method uses the FilterCache to get the intersection count between <code>docs</code>\n   * and the DocSet for each term in the filter.\n   *\n   * @see SolrParams#FACET_LIMIT\n   * @see SolrParams#FACET_ZEROS\n   * @see SolrParams#FACET_MISSING\n   */\n  public NamedList getFacetTermEnumCounts(SolrIndexSearcher searcher, DocSet docs, String field, int limit, boolean zeros, boolean missing)\n    throws IOException {\n\n    /* :TODO: potential optimization...\n    * cache the Terms with the highest docFreq and try them first\n    * don't enum if we get our max from them\n    */\n\n    IndexSchema schema = searcher.getSchema();\n    IndexReader r = searcher.getReader();\n    FieldType ft = schema.getFieldType(field);\n\n    Set<CountPair<String,Integer>> counts\n      = new HashSet<CountPair<String,Integer>>();\n\n    if (0 <= limit) {\n      counts = new BoundedTreeSet<CountPair<String,Integer>>(limit);\n    }\n\n    TermEnum te = r.terms(new Term(field,\"\"));\n    do {\n      Term t = te.term();\n\n      if (null == t || ! t.field().equals(field))\n        break;\n\n      if (0 < te.docFreq()) { /* all docs may be deleted */\n        int count = searcher.numDocs(new TermQuery(t),\n                                     docs);\n\n        if (zeros || 0 < count)\n          counts.add(new CountPair<String,Integer>\n                     (t.text(), count));\n\n      }\n    } while (te.next());\n\n    NamedList res = new NamedList();\n    for (CountPair<String,Integer> p : counts) {\n      res.add(ft.indexedToReadable(p.key), p.val);\n    }\n\n    if (missing) {\n      res.add(null, getFieldMissingCount(searcher,docs,field));\n    }\n\n    return res;\n  }\n\n","sourceOld":"  /**\n   * Returns a list of terms in the specified field along with the \n   * corrisponding count of documents in the set that match that constraint.\n   *\n   * @see SolrParams#FACET_LIMIT\n   * @see SolrParams#FACET_ZEROS\n   */\n  public NamedList getFacetTermEnumCounts(String fieldName) \n    throws IOException {\n    \n    /* :TODO: potential optimization...\n     * cache the Terms with the highest docFreq and try them first\n     * don't enum if we get our max from them\n     */\n     \n    IndexSchema schema = searcher.getSchema();\n    IndexReader r = searcher.getReader();\n    FieldType ft = schema.getFieldType(fieldName);\n\n    Set<CountPair<String,Integer>> counts \n      = new HashSet<CountPair<String,Integer>>();\n\n    int limit = params.getFieldInt(fieldName, params.FACET_LIMIT, 100);\n    if (0 <= limit) {\n      counts = new BoundedTreeSet<CountPair<String,Integer>>(limit);\n    }\n\n    boolean zeros = params.getFieldBool(fieldName, params.FACET_ZEROS, true);\n      \n    TermEnum te = r.terms(new Term(fieldName,\"\"));\n    do {\n      Term t = te.term();\n\n      if (null == t || ! t.field().equals(fieldName)) \n        break;\n\n      if (0 < te.docFreq()) { /* all docs may be deleted */\n        int count = searcher.numDocs(new TermQuery(t),\n                                     docs);\n\n        /* :TODO: is indexedToReadable correct? */ \n        if (zeros || 0 < count) \n          counts.add(new CountPair<String,Integer>\n                     (ft.indexedToReadable(t.text()), count));\n\n      }\n    } while (te.next());\n\n    NamedList res = new NamedList();\n    for (CountPair<String,Integer> p : counts) {\n      res.add(p.key, p.val);\n    }\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d1b4f9f023bf5098df34505adf1ed91daa67c239":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cc88118f21ca5b1a14ab1ebe8a80abf1a5ed54fb":["d1b4f9f023bf5098df34505adf1ed91daa67c239"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"c9727734a64d33a1345c9251f53eb375f04c583e":["cc88118f21ca5b1a14ab1ebe8a80abf1a5ed54fb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"d1b4f9f023bf5098df34505adf1ed91daa67c239":["cc88118f21ca5b1a14ab1ebe8a80abf1a5ed54fb"],"cc88118f21ca5b1a14ab1ebe8a80abf1a5ed54fb":["c9727734a64d33a1345c9251f53eb375f04c583e"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["d1b4f9f023bf5098df34505adf1ed91daa67c239"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c9727734a64d33a1345c9251f53eb375f04c583e":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c9727734a64d33a1345c9251f53eb375f04c583e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}