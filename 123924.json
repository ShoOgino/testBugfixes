{"path":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","commits":[{"id":"1774e2854ef0f77de7f31ba1d9586139928e06fe","date":1285965652,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    Arrays.sort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b","date":1288192616,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    Arrays.sort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca0ffea399542e8aac8ed7608f34f8ec4cb8904d","date":1288424244,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    Arrays.sort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e230a61047bc041516c811baa08a7174d6f8322a","date":1306175633,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b":["1774e2854ef0f77de7f31ba1d9586139928e06fe"],"e230a61047bc041516c811baa08a7174d6f8322a":["ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b","e230a61047bc041516c811baa08a7174d6f8322a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1774e2854ef0f77de7f31ba1d9586139928e06fe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b"],"ca0ffea399542e8aac8ed7608f34f8ec4cb8904d":["1774e2854ef0f77de7f31ba1d9586139928e06fe","ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e230a61047bc041516c811baa08a7174d6f8322a"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["ca0ffea399542e8aac8ed7608f34f8ec4cb8904d","e230a61047bc041516c811baa08a7174d6f8322a"]},"commit2Childs":{"ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b":["e230a61047bc041516c811baa08a7174d6f8322a","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ca0ffea399542e8aac8ed7608f34f8ec4cb8904d"],"e230a61047bc041516c811baa08a7174d6f8322a":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","cd5edd1f2b162a5cfa08efd17851a07373a96817","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1774e2854ef0f77de7f31ba1d9586139928e06fe","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1774e2854ef0f77de7f31ba1d9586139928e06fe":["ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b","ca0ffea399542e8aac8ed7608f34f8ec4cb8904d"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"ca0ffea399542e8aac8ed7608f34f8ec4cb8904d":["2e10cb22a8bdb44339e282925a29182bb2f3174d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2e10cb22a8bdb44339e282925a29182bb2f3174d":[]},"heads":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}