{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","commits":[{"id":"6ce825e9276493231308229152c48f755ce1a0a5","date":1348871483,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(new LookupResult(e.surfaceForm, e.weight));\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71c3a16c8d34d59ba60b59178c5f2d9622167ec","date":1352572085,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(new LookupResult(e.surfaceForm, e.weight));\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(new LookupResult(e.surfaceForm, e.weight));\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70728fc5d87dc51506cd3f763d68d2c16948e127","date":1363037076,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a48377c9931ddb38c784846217ff68d7dcd0b44","date":1363202036,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreq[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreq[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreq(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(payloadKeys));\n    } else {\n      suggester.build(new TermFreqArrayIterator(keys));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["889901f1b564e80868c57d5f3743f4ddbb4ce44a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"889901f1b564e80868c57d5f3743f4ddbb4ce44a","date":1375181138,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreq[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreq[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreq(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new TermFreqArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreq[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreq[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreq(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(payloadKeys));\n    } else {\n      suggester.build(new TermFreqArrayIterator(keys));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":["5a48377c9931ddb38c784846217ff68d7dcd0b44"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreq[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreq[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreq(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new TermFreqArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreq[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreq[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreq(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(payloadKeys));\n    } else {\n      suggester.build(new TermFreqArrayIterator(keys));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreqPayload[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreqPayload[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreqPayload(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreq[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreq[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreq(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new TermFreqArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    TermFreqPayload[] keys = null;\n    TermFreqPayload[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new TermFreqPayload[numQueries];\n    } else {\n      keys = new TermFreqPayload[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new TermFreqPayload(key, weight, payload);\n      } else {\n        keys[i] = new TermFreqPayload(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new TermFreqPayloadArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4e0095ef720d1b8e7406847147af69f19af3ab6","date":1383131477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, false);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33f87fe6faf49dfc1e66f45e841e24838c2f725c","date":1383142987,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, false);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<TermFreq2>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"867e3d9153fb761456b54a9dcce566e1545c5ef6","date":1444903098,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandom().mjava","sourceNew":"  @Slow\n  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(200);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(1000);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    boolean doPayloads = random().nextBoolean();\n\n    Input[] keys = null;\n    Input[] payloadKeys = null;\n    if (doPayloads) {\n      payloadKeys = new Input[numQueries];\n    } else {\n      keys = new Input[numQueries];\n    }\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != SEP) {\n                analyzedKey += SEP;\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                lastRemoved = true;\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += SEP;\n                }\n              } else {\n                lastRemoved = false;\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^|\" + SEP + \")\" + SEP + \"$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += SEP;\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      BytesRef payload;\n      if (doPayloads) {\n        byte[] bytes = new byte[random().nextInt(10)];\n        random().nextBytes(bytes);\n        payload = new BytesRef(bytes);\n        payloadKeys[i] = new Input(key, weight, payload);\n      } else {\n        keys[i] = new Input(key, weight);\n        payload = null;\n      }\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight, payload));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \"' analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true);\n    if (doPayloads) {\n      suggester.build(new InputArrayIterator(shuffle(payloadKeys)));\n    } else {\n      suggester.build(new InputArrayIterator(shuffle(keys)));\n    }\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<TermFreq2> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\"\"+SEP)) {\n          builder.append(SEP);\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(SEP);\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(SEP + \"$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += SEP;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      for (TermFreq2 e : slowCompletor) {\n        if (e.analyzedForm.startsWith(analyzedKey)) {\n          matches.add(e);\n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<TermFreq2>() {\n            @Override\n            public int compare(TermFreq2 left, TermFreq2 right) {\n              int cmp = Float.compare(right.weight, left.weight);\n              if (cmp == 0) {\n                return left.analyzedForm.compareTo(right.analyzedForm);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(TermFreq2 lr : matches) {\n          System.out.println(\"    key=\" + lr.surfaceForm + \" weight=\" + lr.weight);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n\n      assertEquals(matches.size(), r.size());\n\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(matches.get(hit).surfaceForm.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).weight, r.get(hit).value, 0f);\n        if (doPayloads) {\n          assertEquals(matches.get(hit).payload, r.get(hit).payload);\n        }\n      }\n    }\n    IOUtils.close(a, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","7530de27b87b961b51f01bd1299b7004d46e8823"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"6613659748fe4411a7dcf85266e55db1f95f7315":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"407687e67faf6e1f02a211ca078d8e3eed631027":["6ce825e9276493231308229152c48f755ce1a0a5","a71c3a16c8d34d59ba60b59178c5f2d9622167ec"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"a71c3a16c8d34d59ba60b59178c5f2d9622167ec":["6ce825e9276493231308229152c48f755ce1a0a5"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","a56958d7f71a28824f20031ffbb2e13502a0274e"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["7530de27b87b961b51f01bd1299b7004d46e8823"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["5a48377c9931ddb38c784846217ff68d7dcd0b44"],"889901f1b564e80868c57d5f3743f4ddbb4ce44a":["5a48377c9931ddb38c784846217ff68d7dcd0b44"],"5a48377c9931ddb38c784846217ff68d7dcd0b44":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"6ce825e9276493231308229152c48f755ce1a0a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"7530de27b87b961b51f01bd1299b7004d46e8823":["a71c3a16c8d34d59ba60b59178c5f2d9622167ec"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["889901f1b564e80868c57d5f3743f4ddbb4ce44a"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a71c3a16c8d34d59ba60b59178c5f2d9622167ec":["407687e67faf6e1f02a211ca078d8e3eed631027","7530de27b87b961b51f01bd1299b7004d46e8823"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["5a48377c9931ddb38c784846217ff68d7dcd0b44"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6ce825e9276493231308229152c48f755ce1a0a5"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"6ce825e9276493231308229152c48f755ce1a0a5":["407687e67faf6e1f02a211ca078d8e3eed631027","a71c3a16c8d34d59ba60b59178c5f2d9622167ec"],"5a48377c9931ddb38c784846217ff68d7dcd0b44":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","889901f1b564e80868c57d5f3743f4ddbb4ce44a"],"889901f1b564e80868c57d5f3743f4ddbb4ce44a":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","867e3d9153fb761456b54a9dcce566e1545c5ef6"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","70728fc5d87dc51506cd3f763d68d2c16948e127"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}