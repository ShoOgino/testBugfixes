{"path":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","commits":[{"id":"1d28f215464f76024caf026606f8ea51a5319c53","date":1527226629,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,IndexWriter).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, infos.asList());\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, IndexWriter writer) throws IOException {\n    if (verbose(writer)) {\n      message(\"findForcedDeletesMerges infos=\" + writer.segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, writer);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Set<SegmentCommitInfo> merging = writer.getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.numDeletesToMerge(info))/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(writer, infos.asList());\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(writer)) {\n      message(\"eligible=\" + eligible, writer);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose(writer)) {\n        message(\"add merge=\" + writer.segString(merge.segments), writer);\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56fb5e4e4b239474721e13b4cd9542ea2d215451","date":1529091182,"type":3,"author":"Erick","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n\n    // First do a quick check that there's any work to do.\n    // NOTE: this makes BaseMergePOlicyTestCase.testFindForcedDeletesMerges work\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n    boolean haveWork = false;\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        haveWork = true;\n        break;\n      }\n    }\n\n    if (haveWork == false) {\n      return null;\n    }\n\n    List<SegmentSizeAndDocs> sortedInfos = getSortedBySegmentSize(infos, mergeContext);\n\n    Iterator<SegmentSizeAndDocs> iter = sortedInfos.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      double pctDeletes = 100. * ((double) segSizeDocs.delCount / (double) segSizeDocs.maxDoc);\n      if (merging.contains(segSizeDocs.segInfo) || pctDeletes <= forceMergeDeletesPctAllowed) {\n        iter.remove();\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedInfos, mergeContext);\n    }\n    return doFindMerges(sortedInfos, maxMergedSegmentBytes,\n        maxMergeAtOnceExplicit, Integer.MAX_VALUE, MERGE_TYPE.FORCE_MERGE_DELETES, mergeContext, false);\n\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, infos.asList());\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n\n    // First do a quick check that there's any work to do.\n    // NOTE: this makes BaseMergePOlicyTestCase.testFindForcedDeletesMerges work\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n    boolean haveWork = false;\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        haveWork = true;\n        break;\n      }\n    }\n\n    if (haveWork == false) {\n      return null;\n    }\n\n    List<SegmentSizeAndDocs> sortedInfos = getSortedBySegmentSize(infos, mergeContext);\n\n    Iterator<SegmentSizeAndDocs> iter = sortedInfos.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      double pctDeletes = 100. * ((double) segSizeDocs.delCount / (double) segSizeDocs.maxDoc);\n      if (merging.contains(segSizeDocs.segInfo) || pctDeletes <= forceMergeDeletesPctAllowed) {\n        iter.remove();\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedInfos, mergeContext);\n    }\n    return doFindMerges(sortedInfos, maxMergedSegmentBytes,\n        maxMergeAtOnceExplicit, Integer.MAX_VALUE, MERGE_TYPE.FORCE_MERGE_DELETES, mergeContext, false);\n\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, infos.asList());\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a90cc8c90aa53ddf51fbd15019989ac269514a3","date":1531845066,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n\n    // First do a quick check that there's any work to do.\n    // NOTE: this makes BaseMergePOlicyTestCase.testFindForcedDeletesMerges work\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n    boolean haveWork = false;\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        haveWork = true;\n        break;\n      }\n    }\n\n    if (haveWork == false) {\n      return null;\n    }\n\n    List<SegmentSizeAndDocs> sortedInfos = getSortedBySegmentSize(infos, mergeContext);\n\n    Iterator<SegmentSizeAndDocs> iter = sortedInfos.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      double pctDeletes = 100. * ((double) segSizeDocs.delCount / (double) segSizeDocs.maxDoc);\n      if (merging.contains(segSizeDocs.segInfo) || pctDeletes <= forceMergeDeletesPctAllowed) {\n        iter.remove();\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedInfos, mergeContext);\n    }\n    return doFindMerges(sortedInfos, maxMergedSegmentBytes,\n        maxMergeAtOnceExplicit, Integer.MAX_VALUE, 0, MERGE_TYPE.FORCE_MERGE_DELETES, mergeContext, false);\n\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n\n    // First do a quick check that there's any work to do.\n    // NOTE: this makes BaseMergePOlicyTestCase.testFindForcedDeletesMerges work\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n    boolean haveWork = false;\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        haveWork = true;\n        break;\n      }\n    }\n\n    if (haveWork == false) {\n      return null;\n    }\n\n    List<SegmentSizeAndDocs> sortedInfos = getSortedBySegmentSize(infos, mergeContext);\n\n    Iterator<SegmentSizeAndDocs> iter = sortedInfos.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      double pctDeletes = 100. * ((double) segSizeDocs.delCount / (double) segSizeDocs.maxDoc);\n      if (merging.contains(segSizeDocs.segInfo) || pctDeletes <= forceMergeDeletesPctAllowed) {\n        iter.remove();\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedInfos, mergeContext);\n    }\n    return doFindMerges(sortedInfos, maxMergedSegmentBytes,\n        maxMergeAtOnceExplicit, Integer.MAX_VALUE, MERGE_TYPE.FORCE_MERGE_DELETES, mergeContext, false);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos,MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n\n    // First do a quick check that there's any work to do.\n    // NOTE: this makes BaseMergePOlicyTestCase.testFindForcedDeletesMerges work\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n    boolean haveWork = false;\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        haveWork = true;\n        break;\n      }\n    }\n\n    if (haveWork == false) {\n      return null;\n    }\n\n    List<SegmentSizeAndDocs> sortedInfos = getSortedBySegmentSize(infos, mergeContext);\n\n    Iterator<SegmentSizeAndDocs> iter = sortedInfos.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      double pctDeletes = 100. * ((double) segSizeDocs.delCount / (double) segSizeDocs.maxDoc);\n      if (merging.contains(segSizeDocs.segInfo) || pctDeletes <= forceMergeDeletesPctAllowed) {\n        iter.remove();\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedInfos, mergeContext);\n    }\n    return doFindMerges(sortedInfos, maxMergedSegmentBytes,\n        maxMergeAtOnceExplicit, Integer.MAX_VALUE, 0, MERGE_TYPE.FORCE_MERGE_DELETES, mergeContext, false);\n\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedDeletesMerges infos=\" + segString(mergeContext, infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed, mergeContext);\n    }\n    final List<SegmentCommitInfo> eligible = new ArrayList<>();\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    for(SegmentCommitInfo info : infos) {\n      int delCount = mergeContext.numDeletesToMerge(info);\n      assert assertDelCount(delCount, info);\n      double pctDeletes = 100.*((double) delCount)/info.info.maxDoc();\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, infos.asList());\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["1d28f215464f76024caf026606f8ea51a5319c53","4a90cc8c90aa53ddf51fbd15019989ac269514a3"],"56fb5e4e4b239474721e13b4cd9542ea2d215451":["1d28f215464f76024caf026606f8ea51a5319c53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1d28f215464f76024caf026606f8ea51a5319c53":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4a90cc8c90aa53ddf51fbd15019989ac269514a3":["56fb5e4e4b239474721e13b4cd9542ea2d215451"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4a90cc8c90aa53ddf51fbd15019989ac269514a3"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["1d28f215464f76024caf026606f8ea51a5319c53","56fb5e4e4b239474721e13b4cd9542ea2d215451"]},"commit2Childs":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"56fb5e4e4b239474721e13b4cd9542ea2d215451":["4a90cc8c90aa53ddf51fbd15019989ac269514a3","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d28f215464f76024caf026606f8ea51a5319c53"],"1d28f215464f76024caf026606f8ea51a5319c53":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","56fb5e4e4b239474721e13b4cd9542ea2d215451","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"4a90cc8c90aa53ddf51fbd15019989ac269514a3":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}