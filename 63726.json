{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bdb5e42b0cecd8dfb27767a02ada71899bf17917","date":1334100099,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a238fc456663f685a9db1ed8d680e348bb45171","date":1334173266,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = firstReader.getSequentialSubReaders();\n    IndexReader[] sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":["ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":["ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ced66195b26fdb1f77ee00e2a77ec6918dedd766","date":1344948886,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":["02331260bb246364779cb6f04919ca47900d01bb","2fbe641a3ba9e8ab6b19044e4e89b979bfebbed1","da6d5ac19a80d65b1e864251f155d30960353b7e","4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<? extends AtomicReader> sequentialSubReaders = firstReader.getSequentialSubReaders();\n    List<? extends AtomicReader> sequentialSubReaders2 = secondReader.getSequentialSubReaders();\n    \n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, sequentialSubReaders2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6616b1fd222bb5a60f7f7856ace312252bc97890","date":1350142044,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1151ecb4798f5c31137aec032c241638018ed20","date":1394284367,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.shutdown();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.shutdown();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.shutdown();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.close();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.shutdown();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.close();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.close();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumDifferentReader().mjava","sourceNew":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.close();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","sourceOld":"  // make sure we never reuse from another reader even if it is the same field & codec etc\n  public void testReuseDocsEnumDifferentReader() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(analyzer).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader firstReader = DirectoryReader.open(dir);\n    DirectoryReader secondReader = DirectoryReader.open(dir);\n    List<AtomicReaderContext> leaves = firstReader.leaves();\n    List<AtomicReaderContext> leaves2 = secondReader.leaves();\n    \n    for (AtomicReaderContext ctx : leaves) {\n      Terms terms = ctx.reader().terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(firstReader.maxDoc());\n      iterator = terms.iterator(null);\n      DocsEnum docs = null;\n      BytesRef term = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(null, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n      \n      iterator = terms.iterator(null);\n      enums.clear();\n      docs = null;\n      while ((term = iterator.next()) != null) {\n        docs = iterator.docs(bits, randomDocsEnum(\"body\", term, leaves2, bits), random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      assertEquals(terms.size(), enums.size());\n    }\n    writer.close();\n    IOUtils.close(firstReader, secondReader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["6613659748fe4411a7dcf85266e55db1f95f7315","e1151ecb4798f5c31137aec032c241638018ed20"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d6f074e73200c07d54f242d3880a8da5a35ff97b","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"e1151ecb4798f5c31137aec032c241638018ed20":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"ced66195b26fdb1f77ee00e2a77ec6918dedd766":["02331260bb246364779cb6f04919ca47900d01bb"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e1151ecb4798f5c31137aec032c241638018ed20"],"6616b1fd222bb5a60f7f7856ace312252bc97890":["ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"5a238fc456663f685a9db1ed8d680e348bb45171":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"6613659748fe4411a7dcf85266e55db1f95f7315":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["d0ef034a4f10871667ae75181537775ddcf8ade4","4cc45c615dbb82bf79d5f9550286098367874fbf"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","6616b1fd222bb5a60f7f7856ace312252bc97890"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"02331260bb246364779cb6f04919ca47900d01bb":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["5a238fc456663f685a9db1ed8d680e348bb45171","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["bdb5e42b0cecd8dfb27767a02ada71899bf17917","5a238fc456663f685a9db1ed8d680e348bb45171"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"e1151ecb4798f5c31137aec032c241638018ed20":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ced66195b26fdb1f77ee00e2a77ec6918dedd766":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","6616b1fd222bb5a60f7f7856ace312252bc97890","db4fdbf3d262768eabc027cd8321edca0cd11fa8","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6616b1fd222bb5a60f7f7856ace312252bc97890":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"5a238fc456663f685a9db1ed8d680e348bb45171":[],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"6613659748fe4411a7dcf85266e55db1f95f7315":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","e1151ecb4798f5c31137aec032c241638018ed20"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","db4fdbf3d262768eabc027cd8321edca0cd11fa8","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","6613659748fe4411a7dcf85266e55db1f95f7315"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"02331260bb246364779cb6f04919ca47900d01bb":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","5a238fc456663f685a9db1ed8d680e348bb45171","db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}