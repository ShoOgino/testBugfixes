{"path":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","commits":[{"id":"e7a005111928c661ab5d236ed6a3a079b438d2cf","date":1205411670,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accesing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      throw new IOException(\"Source index is not optimized.\");\n    }\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n\n    initialize();\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.numDocs()];\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.numDocs(); i++) {\n      if (!sourceIndexReader.isDeleted(i)) {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["317c809622a7a74e9257dd0eaf0b7c4dd7399bc7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"317c809622a7a74e9257dd0eaf0b7c4dd7399bc7","date":1214673815,"type":3,"author":"Karl-Johan Wettin","isMerge":false,"pathNew":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accesing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.numDocs()];\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.numDocs(); i++) {\n      if (!sourceIndexReader.isDeleted(i)) {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accesing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      throw new IOException(\"Source index is not optimized.\");\n    }\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n\n    initialize();\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.numDocs()];\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.numDocs(); i++) {\n      if (!sourceIndexReader.isDeleted(i)) {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["e7a005111928c661ab5d236ed6a3a079b438d2cf"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"62b33f7eac4ae2f09b2d9a56be992bbd3545aecd","date":1244930047,"type":3,"author":"Karl-Johan Wettin","isMerge":false,"pathNew":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accesing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.add(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accesing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.numDocs()];\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.numDocs(); i++) {\n      if (!sourceIndexReader.isDeleted(i)) {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add7d922e63099fbce8f0a1b31216df7ef5067f1","date":1252002701,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.add(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accesing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.add(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a9bdeeeb073d19ab2bbfdd2b4cda4c9d5005b27","date":1254576225,"type":3,"author":"Karl-Johan Wettin","isMerge":false,"pathNew":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.add(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.add(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Field field : (List<Field>) sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Field field : (List<Field>) document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Field field : (List<Field>) document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c41356c8a19fd7493940c7a1d798ede2fe03ddf8","date":1260481087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.add(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["406e7055a3e99d3fa6ce49a555a51dd18b321806"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c41356c8a19fd7493940c7a1d798ede2fe03ddf8":["3a9bdeeeb073d19ab2bbfdd2b4cda4c9d5005b27"],"3a9bdeeeb073d19ab2bbfdd2b4cda4c9d5005b27":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"317c809622a7a74e9257dd0eaf0b7c4dd7399bc7":["e7a005111928c661ab5d236ed6a3a079b438d2cf"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["62b33f7eac4ae2f09b2d9a56be992bbd3545aecd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e7a005111928c661ab5d236ed6a3a079b438d2cf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["c41356c8a19fd7493940c7a1d798ede2fe03ddf8"],"62b33f7eac4ae2f09b2d9a56be992bbd3545aecd":["317c809622a7a74e9257dd0eaf0b7c4dd7399bc7"]},"commit2Childs":{"c41356c8a19fd7493940c7a1d798ede2fe03ddf8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3a9bdeeeb073d19ab2bbfdd2b4cda4c9d5005b27":["c41356c8a19fd7493940c7a1d798ede2fe03ddf8"],"317c809622a7a74e9257dd0eaf0b7c4dd7399bc7":["62b33f7eac4ae2f09b2d9a56be992bbd3545aecd"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["3a9bdeeeb073d19ab2bbfdd2b4cda4c9d5005b27"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e7a005111928c661ab5d236ed6a3a079b438d2cf"],"e7a005111928c661ab5d236ed6a3a079b438d2cf":["317c809622a7a74e9257dd0eaf0b7c4dd7399bc7"],"62b33f7eac4ae2f09b2d9a56be992bbd3545aecd":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}